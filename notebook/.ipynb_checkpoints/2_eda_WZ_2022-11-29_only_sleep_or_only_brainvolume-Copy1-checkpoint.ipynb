{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "20f5d23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.tree import export_text\n",
    "import mglearn\n",
    "from dashboard_one import *\n",
    "from feature_selection import *\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5789ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#f, axes = plt.subplots(len(col_lst)-1, 1,figsize=(8, 60))\n",
    "#for i in range(len(col_lst)-1):\n",
    "#    sns.histplot(data=sleep_dxch['NPIK1', 'NPIK2', 'NPIK3', 'NPIK4', 'NPIK5', 'NPIK6', 'NPIK7', 'NPIK8',\n",
    "#       'NPIK9A', 'NPIK9B', 'NPIK9C', 'NPIKTOT', 'NPIKSEV', 'insomnia','OSA'], x=\"DXCHANGE\", multiple=\"dodge\", shrink=.8, ax=axes[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f5902a",
   "metadata": {},
   "source": [
    "### sleep, brain_volume_ratio_to_baseline_____VS_____diagnosischanges from every visit\n",
    "\n",
    "\n",
    "#### sleep_brain_dxch.csv\n",
    "#### drop column 'NPIKSEV', otherwise we get no samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "08ef9a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RID</th>\n",
       "      <th>Phase</th>\n",
       "      <th>VISCODE</th>\n",
       "      <th>PTID</th>\n",
       "      <th>NPIK1</th>\n",
       "      <th>NPIK2</th>\n",
       "      <th>NPIK3</th>\n",
       "      <th>NPIK4</th>\n",
       "      <th>NPIK5</th>\n",
       "      <th>NPIK6</th>\n",
       "      <th>...</th>\n",
       "      <th>ratio_PTAU_bl</th>\n",
       "      <th>Ventricles_reduction_per_year</th>\n",
       "      <th>Hippocampus_reduction_per_year</th>\n",
       "      <th>wholebrain_reduction_per_year</th>\n",
       "      <th>Entorhinal_reduction_per_year</th>\n",
       "      <th>Fusiform_reduction_per_year</th>\n",
       "      <th>ICV_reduction_per_year</th>\n",
       "      <th>ABETA_reduction_per_year</th>\n",
       "      <th>TAU_reduction_per_year</th>\n",
       "      <th>PTAU_reduction_per_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>m06</td>\n",
       "      <td>011_S_0002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>m36</td>\n",
       "      <td>011_S_0002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>m60</td>\n",
       "      <td>011_S_0002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>m72</td>\n",
       "      <td>011_S_0002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>011_S_0002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17155</th>\n",
       "      <td>7083</td>\n",
       "      <td>ADNI3</td>\n",
       "      <td>sc</td>\n",
       "      <td>126_S_7083</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17156</th>\n",
       "      <td>7085</td>\n",
       "      <td>ADNI3</td>\n",
       "      <td>sc</td>\n",
       "      <td>941_S_7085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17157</th>\n",
       "      <td>7088</td>\n",
       "      <td>ADNI3</td>\n",
       "      <td>sc</td>\n",
       "      <td>033_S_7088</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17158</th>\n",
       "      <td>7092</td>\n",
       "      <td>ADNI3</td>\n",
       "      <td>sc</td>\n",
       "      <td>021_S_7092</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17159</th>\n",
       "      <td>7100</td>\n",
       "      <td>ADNI3</td>\n",
       "      <td>sc</td>\n",
       "      <td>033_S_7100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17160 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RID  Phase VISCODE        PTID  NPIK1  NPIK2  NPIK3  NPIK4  NPIK5  \\\n",
       "0         2  ADNI1     m06  011_S_0002    NaN    NaN    NaN    NaN    NaN   \n",
       "1         2  ADNI1     m36  011_S_0002    NaN    NaN    NaN    NaN    NaN   \n",
       "2         2  ADNI1     m60  011_S_0002    NaN    NaN    NaN    NaN    NaN   \n",
       "3         2  ADNI1     m72  011_S_0002    NaN    NaN    NaN    NaN    NaN   \n",
       "4         2  ADNI1     NaN  011_S_0002    NaN    NaN    NaN    NaN    NaN   \n",
       "...     ...    ...     ...         ...    ...    ...    ...    ...    ...   \n",
       "17155  7083  ADNI3      sc  126_S_7083    NaN    NaN    NaN    NaN    NaN   \n",
       "17156  7085  ADNI3      sc  941_S_7085    NaN    NaN    NaN    NaN    NaN   \n",
       "17157  7088  ADNI3      sc  033_S_7088    NaN    NaN    NaN    NaN    NaN   \n",
       "17158  7092  ADNI3      sc  021_S_7092    NaN    NaN    NaN    NaN    NaN   \n",
       "17159  7100  ADNI3      sc  033_S_7100    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "       NPIK6  ...  ratio_PTAU_bl  Ventricles_reduction_per_year  \\\n",
       "0        NaN  ...            NaN                            NaN   \n",
       "1        NaN  ...            NaN                            NaN   \n",
       "2        NaN  ...            NaN                            NaN   \n",
       "3        NaN  ...            NaN                            NaN   \n",
       "4        NaN  ...            NaN                            NaN   \n",
       "...      ...  ...            ...                            ...   \n",
       "17155    NaN  ...            NaN                            NaN   \n",
       "17156    NaN  ...            NaN                            NaN   \n",
       "17157    NaN  ...            NaN                            NaN   \n",
       "17158    NaN  ...            NaN                            NaN   \n",
       "17159    NaN  ...            NaN                            NaN   \n",
       "\n",
       "       Hippocampus_reduction_per_year  wholebrain_reduction_per_year  \\\n",
       "0                                 NaN                            NaN   \n",
       "1                                 NaN                            NaN   \n",
       "2                                 NaN                            NaN   \n",
       "3                                 NaN                            NaN   \n",
       "4                                 NaN                            NaN   \n",
       "...                               ...                            ...   \n",
       "17155                             NaN                            NaN   \n",
       "17156                             NaN                            NaN   \n",
       "17157                             NaN                            NaN   \n",
       "17158                             NaN                            NaN   \n",
       "17159                             NaN                            NaN   \n",
       "\n",
       "       Entorhinal_reduction_per_year  Fusiform_reduction_per_year  \\\n",
       "0                                NaN                          NaN   \n",
       "1                                NaN                          NaN   \n",
       "2                                NaN                          NaN   \n",
       "3                                NaN                          NaN   \n",
       "4                                NaN                          NaN   \n",
       "...                              ...                          ...   \n",
       "17155                            NaN                          NaN   \n",
       "17156                            NaN                          NaN   \n",
       "17157                            NaN                          NaN   \n",
       "17158                            NaN                          NaN   \n",
       "17159                            NaN                          NaN   \n",
       "\n",
       "       ICV_reduction_per_year  ABETA_reduction_per_year  \\\n",
       "0                         NaN                       NaN   \n",
       "1                         NaN                       NaN   \n",
       "2                         NaN                       NaN   \n",
       "3                         NaN                       NaN   \n",
       "4                         NaN                       NaN   \n",
       "...                       ...                       ...   \n",
       "17155                     NaN                       NaN   \n",
       "17156                     NaN                       NaN   \n",
       "17157                     NaN                       NaN   \n",
       "17158                     NaN                       NaN   \n",
       "17159                     NaN                       NaN   \n",
       "\n",
       "      TAU_reduction_per_year  PTAU_reduction_per_year  \n",
       "0                        NaN                      NaN  \n",
       "1                        NaN                      NaN  \n",
       "2                        NaN                      NaN  \n",
       "3                        NaN                      NaN  \n",
       "4                        NaN                      NaN  \n",
       "...                      ...                      ...  \n",
       "17155                    NaN                      NaN  \n",
       "17156                    NaN                      NaN  \n",
       "17157                    NaN                      NaN  \n",
       "17158                    NaN                      NaN  \n",
       "17159                    NaN                      NaN  \n",
       "\n",
       "[17160 rows x 37 columns]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sleep_brain_dxch = pd.read_csv('sleep_brain_dxch.csv').iloc[:,1:].drop(['NPIKSEV'],axis=1)\n",
    "sleep_brain_dxch = sleep_brain_dxch[sleep_brain_dxch['DXCHANGE'].notna()].reset_index().drop(['index'],axis=1)   # keep the rows where DXCHANGE is not nan\n",
    "sleep_brain_dxch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c9b465",
   "metadata": {},
   "source": [
    "### sleep______VS______DXCHANGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "b9b829bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phase</th>\n",
       "      <th>RID</th>\n",
       "      <th>VISCODE</th>\n",
       "      <th>PTID</th>\n",
       "      <th>DXCHANGE</th>\n",
       "      <th>NPIK1</th>\n",
       "      <th>NPIK2</th>\n",
       "      <th>NPIK3</th>\n",
       "      <th>NPIK4</th>\n",
       "      <th>NPIK5</th>\n",
       "      <th>NPIK6</th>\n",
       "      <th>NPIK7</th>\n",
       "      <th>NPIK8</th>\n",
       "      <th>NPIK9A</th>\n",
       "      <th>NPIK9B</th>\n",
       "      <th>NPIK9C</th>\n",
       "      <th>NPIKTOT</th>\n",
       "      <th>insomnia</th>\n",
       "      <th>OSA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADNI2</td>\n",
       "      <td>8</td>\n",
       "      <td>v06</td>\n",
       "      <td>011_S_0008</td>\n",
       "      <td>CN-CN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADNI2</td>\n",
       "      <td>8</td>\n",
       "      <td>v41</td>\n",
       "      <td>011_S_0008</td>\n",
       "      <td>CN-MCI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADNI2</td>\n",
       "      <td>31</td>\n",
       "      <td>v06</td>\n",
       "      <td>023_S_0031</td>\n",
       "      <td>CN-CN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADNI2</td>\n",
       "      <td>31</td>\n",
       "      <td>v11</td>\n",
       "      <td>023_S_0031</td>\n",
       "      <td>CN-CN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADNI2</td>\n",
       "      <td>31</td>\n",
       "      <td>v21</td>\n",
       "      <td>023_S_0031</td>\n",
       "      <td>CN-CN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>6890</td>\n",
       "      <td>y1</td>\n",
       "      <td>021_S_6890</td>\n",
       "      <td>MCI-MCI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>6891</td>\n",
       "      <td>y1</td>\n",
       "      <td>123_S_6891</td>\n",
       "      <td>AD-AD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>6897</td>\n",
       "      <td>y1</td>\n",
       "      <td>036_S_6897</td>\n",
       "      <td>MCI-MCI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>6947</td>\n",
       "      <td>y1</td>\n",
       "      <td>035_S_6947</td>\n",
       "      <td>MCI-MCI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>6962</td>\n",
       "      <td>y1</td>\n",
       "      <td>941_S_6962</td>\n",
       "      <td>AD-AD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1131 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Phase   RID VISCODE        PTID DXCHANGE  NPIK1  NPIK2  NPIK3  NPIK4  \\\n",
       "0     ADNI2     8     v06  011_S_0008    CN-CN    1.0    0.0    0.0    0.0   \n",
       "1     ADNI2     8     v41  011_S_0008   CN-MCI    0.0    0.0    0.0    0.0   \n",
       "2     ADNI2    31     v06  023_S_0031    CN-CN    0.0    1.0    0.0    0.0   \n",
       "3     ADNI2    31     v11  023_S_0031    CN-CN    0.0    1.0    0.0    0.0   \n",
       "4     ADNI2    31     v21  023_S_0031    CN-CN    0.0    0.0    0.0    1.0   \n",
       "...     ...   ...     ...         ...      ...    ...    ...    ...    ...   \n",
       "1126  ADNI3  6890      y1  021_S_6890  MCI-MCI    0.0    1.0    0.0    0.0   \n",
       "1127  ADNI3  6891      y1  123_S_6891    AD-AD    1.0    1.0    0.0    1.0   \n",
       "1128  ADNI3  6897      y1  036_S_6897  MCI-MCI    0.0    0.0    0.0    1.0   \n",
       "1129  ADNI3  6947      y1  035_S_6947  MCI-MCI    0.0    1.0    0.0    0.0   \n",
       "1130  ADNI3  6962      y1  941_S_6962    AD-AD    0.0    1.0    0.0    0.0   \n",
       "\n",
       "      NPIK5  NPIK6  NPIK7  NPIK8  NPIK9A  NPIK9B  NPIK9C  NPIKTOT  insomnia  \\\n",
       "0       0.0    0.0    0.0    0.0     3.0     2.0     0.0      6.0       1.0   \n",
       "1       0.0    0.0    1.0    0.0     4.0     2.0     1.0      8.0       1.0   \n",
       "2       0.0    1.0    0.0    0.0     2.0     1.0     0.0      2.0       1.0   \n",
       "3       0.0    1.0    0.0    0.0     2.0     1.0     0.0      2.0       1.0   \n",
       "4       0.0    0.0    0.0    0.0     3.0     1.0     1.0      3.0       1.0   \n",
       "...     ...    ...    ...    ...     ...     ...     ...      ...       ...   \n",
       "1126    0.0    0.0    0.0    0.0     4.0     1.0     1.0      4.0       1.0   \n",
       "1127    0.0    0.0    1.0    0.0     4.0     2.0     3.0      8.0       1.0   \n",
       "1128    0.0    0.0    0.0    1.0     1.0     1.0     1.0      1.0       1.0   \n",
       "1129    0.0    0.0    1.0    0.0     1.0     1.0     1.0      1.0       1.0   \n",
       "1130    0.0    0.0    0.0    1.0     3.0     2.0     2.0      6.0       1.0   \n",
       "\n",
       "      OSA  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  \n",
       "...   ...  \n",
       "1126  1.0  \n",
       "1127  0.0  \n",
       "1128  0.0  \n",
       "1129  0.0  \n",
       "1130  0.0  \n",
       "\n",
       "[1131 rows x 19 columns]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_lst = [ 'DXCHANGE','NPIK1', 'NPIK2', 'NPIK3', 'NPIK4', 'NPIK5', 'NPIK6', 'NPIK7', 'NPIK8',\n",
    "       'NPIK9A', 'NPIK9B', 'NPIK9C', 'NPIKTOT',  'insomnia','OSA']\n",
    "sleep_dxch = sleep_brain_dxch[['Phase', 'RID', 'VISCODE','PTID'] + col_lst].set_index(['Phase', 'RID', 'VISCODE','PTID']).dropna(how='any',axis=0).reset_index()\n",
    "sleep_dxch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "ca961c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Phase       0\n",
       "RID         0\n",
       "VISCODE     0\n",
       "PTID        0\n",
       "DXCHANGE    0\n",
       "NPIK1       0\n",
       "NPIK2       0\n",
       "NPIK3       0\n",
       "NPIK4       0\n",
       "NPIK5       0\n",
       "NPIK6       0\n",
       "NPIK7       0\n",
       "NPIK8       0\n",
       "NPIK9A      0\n",
       "NPIK9B      0\n",
       "NPIK9C      0\n",
       "NPIKTOT     0\n",
       "insomnia    0\n",
       "OSA         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(sleep_dxch.isna())   # check nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "6a1db76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phase</th>\n",
       "      <th>RID</th>\n",
       "      <th>VISCODE</th>\n",
       "      <th>PTID</th>\n",
       "      <th>NPIK1</th>\n",
       "      <th>NPIK2</th>\n",
       "      <th>NPIK3</th>\n",
       "      <th>NPIK4</th>\n",
       "      <th>NPIK5</th>\n",
       "      <th>NPIK6</th>\n",
       "      <th>NPIK7</th>\n",
       "      <th>NPIK8</th>\n",
       "      <th>NPIK9A</th>\n",
       "      <th>NPIK9B</th>\n",
       "      <th>NPIK9C</th>\n",
       "      <th>NPIKTOT</th>\n",
       "      <th>insomnia</th>\n",
       "      <th>OSA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DXCHANGE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AD-AD</th>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AD-MCI</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CN-AD</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CN-CN</th>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CN-MCI</th>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCI-AD</th>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCI-CN</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCI-MCI</th>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Phase  RID  VISCODE  PTID  NPIK1  NPIK2  NPIK3  NPIK4  NPIK5  NPIK6  \\\n",
       "DXCHANGE                                                                        \n",
       "AD-AD       159  159      159   159    159    159    159    159    159    159   \n",
       "AD-MCI        2    2        2     2      2      2      2      2      2      2   \n",
       "CN-AD         6    6        6     6      6      6      6      6      6      6   \n",
       "CN-CN       291  291      291   291    291    291    291    291    291    291   \n",
       "CN-MCI       38   38       38    38     38     38     38     38     38     38   \n",
       "MCI-AD       80   80       80    80     80     80     80     80     80     80   \n",
       "MCI-CN       39   39       39    39     39     39     39     39     39     39   \n",
       "MCI-MCI     516  516      516   516    516    516    516    516    516    516   \n",
       "\n",
       "          NPIK7  NPIK8  NPIK9A  NPIK9B  NPIK9C  NPIKTOT  insomnia  OSA  \n",
       "DXCHANGE                                                                \n",
       "AD-AD       159    159     159     159     159      159       159  159  \n",
       "AD-MCI        2      2       2       2       2        2         2    2  \n",
       "CN-AD         6      6       6       6       6        6         6    6  \n",
       "CN-CN       291    291     291     291     291      291       291  291  \n",
       "CN-MCI       38     38      38      38      38       38        38   38  \n",
       "MCI-AD       80     80      80      80      80       80        80   80  \n",
       "MCI-CN       39     39      39      39      39       39        39   39  \n",
       "MCI-MCI     516    516     516     516     516      516       516  516  "
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sleep_dxch.groupby('DXCHANGE').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c160d02",
   "metadata": {},
   "source": [
    "#### select only the MCI-AD, MCI-MCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "3ee34959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phase</th>\n",
       "      <th>RID</th>\n",
       "      <th>VISCODE</th>\n",
       "      <th>PTID</th>\n",
       "      <th>DXCHANGE</th>\n",
       "      <th>NPIK1</th>\n",
       "      <th>NPIK2</th>\n",
       "      <th>NPIK3</th>\n",
       "      <th>NPIK4</th>\n",
       "      <th>NPIK5</th>\n",
       "      <th>NPIK6</th>\n",
       "      <th>NPIK7</th>\n",
       "      <th>NPIK8</th>\n",
       "      <th>NPIK9A</th>\n",
       "      <th>NPIK9B</th>\n",
       "      <th>NPIK9C</th>\n",
       "      <th>NPIKTOT</th>\n",
       "      <th>insomnia</th>\n",
       "      <th>OSA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ADNI2</td>\n",
       "      <td>55</td>\n",
       "      <td>v11</td>\n",
       "      <td>018_S_0055</td>\n",
       "      <td>MCI-MCI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ADNI2</td>\n",
       "      <td>61</td>\n",
       "      <td>v21</td>\n",
       "      <td>023_S_0061</td>\n",
       "      <td>MCI-AD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ADNI2</td>\n",
       "      <td>112</td>\n",
       "      <td>v31</td>\n",
       "      <td>127_S_0112</td>\n",
       "      <td>MCI-MCI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ADNI2</td>\n",
       "      <td>112</td>\n",
       "      <td>v41</td>\n",
       "      <td>127_S_0112</td>\n",
       "      <td>MCI-AD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>112</td>\n",
       "      <td>init</td>\n",
       "      <td>127_S_0112</td>\n",
       "      <td>MCI-AD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>6871</td>\n",
       "      <td>y1</td>\n",
       "      <td>305_S_6871</td>\n",
       "      <td>MCI-MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>6888</td>\n",
       "      <td>y1</td>\n",
       "      <td>123_S_6888</td>\n",
       "      <td>MCI-MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>6890</td>\n",
       "      <td>y1</td>\n",
       "      <td>021_S_6890</td>\n",
       "      <td>MCI-MCI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>6897</td>\n",
       "      <td>y1</td>\n",
       "      <td>036_S_6897</td>\n",
       "      <td>MCI-MCI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>6947</td>\n",
       "      <td>y1</td>\n",
       "      <td>035_S_6947</td>\n",
       "      <td>MCI-MCI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>596 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Phase   RID VISCODE        PTID DXCHANGE  NPIK1  NPIK2  NPIK3  NPIK4  \\\n",
       "6     ADNI2    55     v11  018_S_0055  MCI-MCI    0.0    0.0    0.0    1.0   \n",
       "9     ADNI2    61     v21  023_S_0061   MCI-AD    0.0    1.0    0.0    0.0   \n",
       "17    ADNI2   112     v31  127_S_0112  MCI-MCI    0.0    0.0    0.0    0.0   \n",
       "18    ADNI2   112     v41  127_S_0112   MCI-AD    0.0    1.0    0.0    1.0   \n",
       "19    ADNI3   112    init  127_S_0112   MCI-AD    0.0    1.0    1.0    1.0   \n",
       "...     ...   ...     ...         ...      ...    ...    ...    ...    ...   \n",
       "1123  ADNI3  6871      y1  305_S_6871  MCI-MCI    1.0    1.0    0.0    0.0   \n",
       "1125  ADNI3  6888      y1  123_S_6888  MCI-MCI    1.0    0.0    0.0    0.0   \n",
       "1126  ADNI3  6890      y1  021_S_6890  MCI-MCI    0.0    1.0    0.0    0.0   \n",
       "1128  ADNI3  6897      y1  036_S_6897  MCI-MCI    0.0    0.0    0.0    1.0   \n",
       "1129  ADNI3  6947      y1  035_S_6947  MCI-MCI    0.0    1.0    0.0    0.0   \n",
       "\n",
       "      NPIK5  NPIK6  NPIK7  NPIK8  NPIK9A  NPIK9B  NPIK9C  NPIKTOT  insomnia  \\\n",
       "6       0.0    0.0    0.0    0.0     1.0     1.0     0.0      1.0       1.0   \n",
       "9       0.0    0.0    0.0    0.0     1.0     1.0     1.0      1.0       1.0   \n",
       "17      0.0    0.0    1.0    0.0     4.0     1.0     2.0      4.0       1.0   \n",
       "18      0.0    0.0    0.0    0.0     4.0     1.0     1.0      4.0       1.0   \n",
       "19      1.0    0.0    1.0    0.0     4.0     2.0     3.0      8.0       1.0   \n",
       "...     ...    ...    ...    ...     ...     ...     ...      ...       ...   \n",
       "1123    0.0    0.0    0.0    0.0     2.0     1.0     1.0      2.0       1.0   \n",
       "1125    0.0    0.0    0.0    0.0     3.0     1.0     2.0      3.0       1.0   \n",
       "1126    0.0    0.0    0.0    0.0     4.0     1.0     1.0      4.0       1.0   \n",
       "1128    0.0    0.0    0.0    1.0     1.0     1.0     1.0      1.0       1.0   \n",
       "1129    0.0    0.0    1.0    0.0     1.0     1.0     1.0      1.0       1.0   \n",
       "\n",
       "      OSA  \n",
       "6     0.0  \n",
       "9     0.0  \n",
       "17    0.0  \n",
       "18    0.0  \n",
       "19    0.0  \n",
       "...   ...  \n",
       "1123  0.0  \n",
       "1125  0.0  \n",
       "1126  1.0  \n",
       "1128  0.0  \n",
       "1129  0.0  \n",
       "\n",
       "[596 rows x 19 columns]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sleep_dxch_2g = sleep_dxch.loc[sleep_dxch['DXCHANGE'].isin(['MCI-AD','MCI-MCI'])].reset_index().drop(['index'],axis=1)\n",
    "sleep_dxch_2g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01011c36",
   "metadata": {},
   "source": [
    "- drop DXCHANGE labels 'AD-MCI','CN-AD', then undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "e18f53f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phase</th>\n",
       "      <th>RID</th>\n",
       "      <th>VISCODE</th>\n",
       "      <th>PTID</th>\n",
       "      <th>DXCHANGE</th>\n",
       "      <th>NPIK1</th>\n",
       "      <th>NPIK2</th>\n",
       "      <th>NPIK3</th>\n",
       "      <th>NPIK4</th>\n",
       "      <th>NPIK5</th>\n",
       "      <th>NPIK6</th>\n",
       "      <th>NPIK7</th>\n",
       "      <th>NPIK8</th>\n",
       "      <th>NPIK9A</th>\n",
       "      <th>NPIK9B</th>\n",
       "      <th>NPIK9C</th>\n",
       "      <th>NPIKTOT</th>\n",
       "      <th>insomnia</th>\n",
       "      <th>OSA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADNI2</td>\n",
       "      <td>8</td>\n",
       "      <td>v06</td>\n",
       "      <td>011_S_0008</td>\n",
       "      <td>CN-CN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADNI2</td>\n",
       "      <td>8</td>\n",
       "      <td>v41</td>\n",
       "      <td>011_S_0008</td>\n",
       "      <td>CN-MCI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADNI2</td>\n",
       "      <td>31</td>\n",
       "      <td>v06</td>\n",
       "      <td>023_S_0031</td>\n",
       "      <td>CN-CN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADNI2</td>\n",
       "      <td>31</td>\n",
       "      <td>v11</td>\n",
       "      <td>023_S_0031</td>\n",
       "      <td>CN-CN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADNI2</td>\n",
       "      <td>31</td>\n",
       "      <td>v21</td>\n",
       "      <td>023_S_0031</td>\n",
       "      <td>CN-CN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>6890</td>\n",
       "      <td>y1</td>\n",
       "      <td>021_S_6890</td>\n",
       "      <td>MCI-MCI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>6891</td>\n",
       "      <td>y1</td>\n",
       "      <td>123_S_6891</td>\n",
       "      <td>AD-AD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>6897</td>\n",
       "      <td>y1</td>\n",
       "      <td>036_S_6897</td>\n",
       "      <td>MCI-MCI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>6947</td>\n",
       "      <td>y1</td>\n",
       "      <td>035_S_6947</td>\n",
       "      <td>MCI-MCI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>6962</td>\n",
       "      <td>y1</td>\n",
       "      <td>941_S_6962</td>\n",
       "      <td>AD-AD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1123 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Phase   RID VISCODE        PTID DXCHANGE  NPIK1  NPIK2  NPIK3  NPIK4  \\\n",
       "0     ADNI2     8     v06  011_S_0008    CN-CN    1.0    0.0    0.0    0.0   \n",
       "1     ADNI2     8     v41  011_S_0008   CN-MCI    0.0    0.0    0.0    0.0   \n",
       "2     ADNI2    31     v06  023_S_0031    CN-CN    0.0    1.0    0.0    0.0   \n",
       "3     ADNI2    31     v11  023_S_0031    CN-CN    0.0    1.0    0.0    0.0   \n",
       "4     ADNI2    31     v21  023_S_0031    CN-CN    0.0    0.0    0.0    1.0   \n",
       "...     ...   ...     ...         ...      ...    ...    ...    ...    ...   \n",
       "1118  ADNI3  6890      y1  021_S_6890  MCI-MCI    0.0    1.0    0.0    0.0   \n",
       "1119  ADNI3  6891      y1  123_S_6891    AD-AD    1.0    1.0    0.0    1.0   \n",
       "1120  ADNI3  6897      y1  036_S_6897  MCI-MCI    0.0    0.0    0.0    1.0   \n",
       "1121  ADNI3  6947      y1  035_S_6947  MCI-MCI    0.0    1.0    0.0    0.0   \n",
       "1122  ADNI3  6962      y1  941_S_6962    AD-AD    0.0    1.0    0.0    0.0   \n",
       "\n",
       "      NPIK5  NPIK6  NPIK7  NPIK8  NPIK9A  NPIK9B  NPIK9C  NPIKTOT  insomnia  \\\n",
       "0       0.0    0.0    0.0    0.0     3.0     2.0     0.0      6.0       1.0   \n",
       "1       0.0    0.0    1.0    0.0     4.0     2.0     1.0      8.0       1.0   \n",
       "2       0.0    1.0    0.0    0.0     2.0     1.0     0.0      2.0       1.0   \n",
       "3       0.0    1.0    0.0    0.0     2.0     1.0     0.0      2.0       1.0   \n",
       "4       0.0    0.0    0.0    0.0     3.0     1.0     1.0      3.0       1.0   \n",
       "...     ...    ...    ...    ...     ...     ...     ...      ...       ...   \n",
       "1118    0.0    0.0    0.0    0.0     4.0     1.0     1.0      4.0       1.0   \n",
       "1119    0.0    0.0    1.0    0.0     4.0     2.0     3.0      8.0       1.0   \n",
       "1120    0.0    0.0    0.0    1.0     1.0     1.0     1.0      1.0       1.0   \n",
       "1121    0.0    0.0    1.0    0.0     1.0     1.0     1.0      1.0       1.0   \n",
       "1122    0.0    0.0    0.0    1.0     3.0     2.0     2.0      6.0       1.0   \n",
       "\n",
       "      OSA  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  \n",
       "...   ...  \n",
       "1118  1.0  \n",
       "1119  0.0  \n",
       "1120  0.0  \n",
       "1121  0.0  \n",
       "1122  0.0  \n",
       "\n",
       "[1123 rows x 19 columns]"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sleep_dxch_6g = sleep_dxch[(sleep_dxch['DXCHANGE'].isin(['CN-CN', 'CN-MCI', 'AD-AD', 'MCI-MCI', 'MCI-AD', 'MCI-CN']))].reset_index().drop(['index'],axis=1)\n",
    "sleep_dxch_6g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5f296a",
   "metadata": {},
   "source": [
    "### oversampling and undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "94fdc22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sleep_dxch_2g\n",
    "y = sleep_dxch_2g['DXCHANGE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "231baaf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 Resampled dataset shape Counter({'MCI-AD': 80, 'MCI-MCI': 80})\n"
     ]
    }
   ],
   "source": [
    "# undersampling\n",
    "rus = RandomUnderSampler(random_state=432)\n",
    "X_undersampled, y_unsampled = rus.fit_resample(X, y)\n",
    "print(len(X_undersampled),'Resampled dataset shape %s' % Counter(y_unsampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3feff965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phase</th>\n",
       "      <th>RID</th>\n",
       "      <th>VISCODE</th>\n",
       "      <th>NPIK1</th>\n",
       "      <th>NPIK2</th>\n",
       "      <th>NPIK3</th>\n",
       "      <th>NPIK4</th>\n",
       "      <th>NPIK5</th>\n",
       "      <th>NPIK6</th>\n",
       "      <th>NPIK7</th>\n",
       "      <th>NPIK8</th>\n",
       "      <th>NPIK9A</th>\n",
       "      <th>NPIK9B</th>\n",
       "      <th>NPIK9C</th>\n",
       "      <th>NPIKTOT</th>\n",
       "      <th>insomnia</th>\n",
       "      <th>OSA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DXCHANGE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MCI-AD</th>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCI-MCI</th>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Phase  RID  VISCODE  NPIK1  NPIK2  NPIK3  NPIK4  NPIK5  NPIK6  \\\n",
       "DXCHANGE                                                                  \n",
       "MCI-AD       80   80       80     80     80     80     80     80     80   \n",
       "MCI-MCI      80   80       80     80     80     80     80     80     80   \n",
       "\n",
       "          NPIK7  NPIK8  NPIK9A  NPIK9B  NPIK9C  NPIKTOT  insomnia  OSA  \n",
       "DXCHANGE                                                                \n",
       "MCI-AD       80     80      80      80      80       80        80   80  \n",
       "MCI-MCI      80     80      80      80      80       80        80   80  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_undersampled.groupby(['DXCHANGE']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd46c83",
   "metadata": {},
   "source": [
    "### logistic regression, diagnosis changes as the target variable.\n",
    "use dataframe sleep_dxch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "fb81f319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After undersampling data size is 160 ; Resampled dataset shape Counter({'MCI-AD': 80, 'MCI-MCI': 80})\n",
      "\n",
      "9 principle components are needed to explain 90% of the data\n",
      "\n",
      "Output dataframes sequence: X_train,X_test,X_train_scaled,X_test_scaled,X_train_pca,X_test_pca,y_train,y_test\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAwFElEQVR4nO3deZzVc9/H8dfHSIlCxEWL0h2uulpNpaIVZSstVLZC0uWqlPsistTFxdVtSfYkicuSRIQkJF2IpigttNwKo6RCC21Tn/uP72nuaTozcxpzOnPmvJ+Pxzxmfsv5nc+cmvM5v+/2MXdHRERS1wGJDkBERBJLiUBEJMUpEYiIpDglAhGRFKdEICKS4g5MdAD76qijjvJq1aolOgwRkaQyd+7cde5eMdqxpEsE1apVY86cOYkOQ0QkqZjZt3kdU9OQiEiKUyIQEUlxSgQiIiku6foIotmxYweZmZls3bo10aGIlEhlypShcuXKlCpVKtGhSByUiESQmZlJuXLlqFatGmaW6HBEShR3Z/369WRmZlK9evVEhyNxUCKahrZu3cqRRx6pJCASB2bGkUceqTvuEqxEJAJASUAkjvT3VbKVmEQgIpIUsrJg7dpER7EHJYIi8uOPP9K9e3dq1KhBrVq1OOecc1i6dGlcn7NVq1YFTq4bOXIkv//+e/b2Oeecw6+//vqHn7tatWrUqVOH+vXrU79+fQYMGFCo6wwbNoz77rsv33NGjRrFs88+W6jr59arVy8mTpy4x75x48bRo0ePPfatW7eOihUrsm3btpiuO2fOnEK/BvvL3Xffvcd2s2bNEhRJCnKH2bNhwACoVAmuvTbREe2hRHQWJ5q706lTJ3r27Mn48eMBmDdvHmvWrOHEE09MaGwjR47k0ksvpWzZsgBMmTKlyK79wQcfcNRRRxXZ9fLSt2/fuF6/c+fO/P3vf+f333/Pfp0mTpxIhw4dKF26dIGPz8rKIj09nfT09LjGWZCdO3eSlpaW5/G7776bIUOGZG9/8skn+yOs1LZsGTz/fPhavhxKl4bzz4devRId2R50R1AEPvjgA0qVKrXHG1b9+vU5/fTTmTFjBuedd172/n79+jFu3DggfKoeMmQITZs2JT09nc8//5x27dpRo0YNRo0aBZDv43P661//Snp6OrVr12bo0KEAPPTQQ6xatYrWrVvTunXr7Odct24dgwcP5rHHHst+/LBhw7j//vsBuPfee2nUqBF169bNvlYssrKyaNSoETNmzADg5ptv5pZbbsl+3sGDB9O4cWMaN27M8uXL93r8k08+SaNGjahXrx5dunTJvpPJedfQqlWr7OuceOKJ/Oc//wHCm+ANN9yQHfcTTzwBhCTdr18/atWqxbnnnstPP/201/OWL1+eFi1a8MYbb2TvGz9+PD169OCNN96gSZMmNGjQgDPOOIM1a9Zkx9SnTx/OOussLr/88j3+nWbPnk2zZs1o0KABzZo1Y8mSJUC48+jcuTPt27enZs2a3HjjjdnPN3XqVBo2bEi9evVo27YtAL/99htXXnkljRo1okGDBrz++ut7xT5jxgxat27NxRdfTJ06dQC44IILOOWUU6hduzajR48G4KabbmLLli3Ur1+fSy65BIBDDz00+zW64YYb+Mtf/kKdOnV46aWX8vtnloKsWQMPPQSNG8OJJ8Idd0DVqjB2bDj28stw7rmJjnIPJe+OYOBAmDevaK9Zvz6MHJnn4YULF3LKKacU6tJVqlRh1qxZDBo0iF69evHxxx+zdetWateuvU+fhO+66y4qVKjAzp07adu2LV9++SUDBgxgxIgRUT+5d+/enYEDB3Jt5BZ1woQJTJ06lWnTprFs2TJmz56Nu9OhQwdmzpxJixYt9nrO1q1bZ38C7dmzJ4MGDWLcuHF07dqVhx56iKlTp/LZZ59ln1++fHlmz57Ns88+y8CBA3nzzTf3uF7nzp25+uqrAbj11lt56qmn6N+//17Pm5WVxezZs5kyZQr/+Mc/eO+993jqqac47LDDyMjIYNu2bTRv3pyzzjqLL774giVLlrBgwQLWrFlDrVq1uPLKK/e6Zo8ePXjhhRfo1q0bq1atYunSpbRu3ZqNGzfy6aefYmaMGTOGe+65Jzthzp07l48++oiDDz44O/kBnHzyycycOZMDDzyQ9957jyFDhvDKK68A4U7xiy++oHTp0px00kn079+fMmXKcPXVVzNz5kyqV6/Ozz//nP1v2qZNG8aOHcuvv/5K48aNOeOMMzjkkEP2iH327NksXLgwe2jn2LFjqVChAlu2bKFRo0Z06dKF4cOH88gjjzAvyt/Gq6++yrx585g/fz7r1q2jUaNGtGjRgmOPPXavcyUPmzfDpEnhk/9778HOndCgAdx3H3TvHpqDirGSlwiSTIcOHQCoU6cOmzdvply5cpQrV44yZcrsU1v+hAkTGD16NFlZWaxevZrFixdTt27dPM9v0KABP/30E6tWrWLt2rUcccQRVK1alYceeohp06bRoEEDADZv3syyZcuiJoJoCaZ27dpcdtllnH/++cyaNYuDDjoo+9judvgePXowaNCgva63cOFCbr31Vn799Vc2b95Mu3btosbeuXNnAE455RRWrlwJwLRp0/jyyy+z2/83bNjAsmXLmDlzJj169CAtLY3jjjuONm3aRL3meeedx7XXXsvGjRuZMGECXbt2JS0tjczMTLp168bq1avZvn37HuPoO3TowMEHH7zXtTZs2EDPnj1ZtmwZZsaOHTuyj7Vt25bDDjsMgFq1avHtt9/yyy+/0KJFi+xrV6hQIft3mjx5cvbd0NatW/nuu+/485//vMfzNW7ceI+4HnroISZNmgTA999/z7JlyzjyyCOj/t4AH330UfZrdMwxx9CyZUsyMjKy/29KHnbsgGnTwpv/a6/Bli1QrRoMHgyXXAK1aiU6wpiVvESQzyf3eKldu/ZeHZC7HXjggezatSt7O/dY7N1t0AcccMAe7dEHHHAAWVlZBT4eYMWKFdx3331kZGRwxBFH0KtXr5jGfHft2pWJEydmd3RDaCa4+eabueaaawp8fF4WLFjA4Ycfnt2MslvOIYjRhiP26tWL1157jXr16jFu3Lg9PmXntPt1SktLIysrKzvuhx9+eK/kMWXKlJiGPh588MG0b9+eSZMmMX78eB544AEA+vfvz/XXX0+HDh2YMWMGw4YNy35M7k/mu9122220bt2aSZMmsXLlSlq1arVX7Dnjd/eoMbo7r7zyCieddFK+seeMY8aMGbz33nvMmjWLsmXL0qpVqwL/L7h7vsclB3eYNSu8+U+YAOvWQYUKoc3/kkugWTNIwqG26iMoAm3atGHbtm08+eST2fsyMjL48MMPOf7441m8eDHbtm1jw4YNvP/++/t07Vgev3HjRg455BAOO+ww1qxZw9tvv519rFy5cmzatCnqtbt378748eOZOHEiXbt2BaBdu3aMHTuWzZs3A/DDDz9EbVfPy6uvvsr69euZOXMmAwYM2OOuZnfb80svvUTTpk33euymTZs49thj2bFjB88//3zMz7k77scffzz70/fSpUv57bffaNGiBePHj2fnzp2sXr2aDz74IM9r9OjRgxEjRrBmzRpOPfVUIHy6rxS5rX/mmWdiiiXnY6L15+TWtGlTPvzwQ1asWAGQ3TTUrl07Hn744ew36i+++CKm5z7iiCMoW7YsX3/9NZ9++mn2sVKlSu1xd7JbixYteOmll9i5cydr165l5syZNG7cuMDnSilffw233Qb/9V/QvHlo72/bFiZPhtWr4bHHwv4kTAJQEu8IEsDMmDRpEgMHDmT48OGUKVOGatWqMXLkSKpUqcJFF11E3bp1qVmzZnaTS6xieXy9evVo0KABtWvX5oQTTqB58+bZx/r06cPZZ5/Nscceu9ebYO3atdm0aROVKlXKbg8+66yz+Oqrr7LfqA899FCee+45jj766L2eN2cfQd26dRkxYgQ33XQT77//PlWqVKFfv35cd9112W+g27Zto0mTJuzatYsXX3xxr+vdeeedNGnShOOPP546derkmcCi6d27NytXrqRhw4a4OxUrVuS1116jU6dOTJ8+nTp16nDiiSfSsmXLPK9x1lln0bNnT6666qrsT+jDhg3jwgsvpFKlSpx66qnZb9b5ufHGG+nZsycjRozIsykqp4oVKzJ69Gg6d+7Mrl27OProo3n33Xe57bbbGDhwIHXr1sXdqVat2l79Krm1b9+eUaNGUbduXU466aTshAbh/0LdunVp2LDhHom2U6dOzJo1i3r16mFm3HPPPfzpT38qMO4Sb/VqGD8ennsOPv8cDjggvPkPHQqdOkG5comOsMhYst0Wpqene+6x81999dVe7aZSvOwuKLQ/hptKfKTE39nGjfDqq6HpZ/p02LUL0tNDs0+3bpDEHehmNtfdo45x1h2BiKS27dth6tTwyf+NN2DrVjjhBLjllpAACuijKQmUCGS/2D26R6RY2LULPv44fPJ/+WX4+WeoWBF69w5v/k2aJG17f2HENRGYWXvgQSANGOPuw3MdPwx4DqgaieU+d3+6MM+V18gLEfnjkq0JOU+LFoU3/xdegG+/hbJl4YILwpv/mWdCitZbiFsiMLM04FHgTCATyDCzye6+OMdpfwMWu/v5ZlYRWGJmz7v79n15rjJlyrB+/XotRS0SB7vrEZQpUybRoRTOb7/Bs8/CE0/A/PmQlhbe9O+6Czp2hMgM61QWzzuCxsByd/8GwMzGAx2BnInAgXIW3r0PBX4Gsvb1iSpXrkxmZiZri9mKfiIlxe4KZUnl22/hkUdgzBj49Vdo2DAs/dCtG0QZBZfK4pkIKgHf59jOBJrkOucRYDKwCigHdHP3XbnOwcz6AH0AqlatutcTlSpVSpWTRCRM+PrPf+DBB8NsXzPo0gWuuw6aNk2pdv99Ec8JZdFe8dwNje2AecBxQH3gETMrv9eD3Ee7e7q7p1esWLGo4xSRZLd1K4wbFz71t2wJM2bAjTfCihXw0ktJO+N3f4nnHUEmUCXHdmXCJ/+crgCGe+iJWm5mK4CTgdlxjEtESorVq+Hxx2HUqFDspXZtGD06dP5GlhSXgsUzEWQANc2sOvAD0B24ONc53wFtgf+Y2THAScA3cYxJREqCjIzQ/DNhQqj4dd55ofmnTRt98i+EuCUCd88ys37AO4Tho2PdfZGZ9Y0cHwXcCYwzswWEpqTB7r4uXjGJSBLbsSPM+n3wwbDwW7lyodJXv35hDSAptLjOI3D3KcCUXPtG5fh5FXBWPGMQkSS3fn1o7nn0UfjhB6hRIySDXr2g/F5dilIImlksIsXTggVhuOdzz4XO4DPOCH0B55wTFoCTIqNEICLFx86d8NZb4RP/9Olw8MFw+eWh6Hvt2omOrsRSIhCRxNuwAZ5+Gh5+GL75BipXhuHDw9o/+VRXk6KhRCAiibNsWXjzf/rpUPe3efOQADp1ggP19rS/6JUWkf3LPRR4f/BBmDIlvOF37x6Gf55ySqKjS0lKBCKyf/z+O/z736EDePHisN7P7bdD376gimgJpUQgIvH13Xdh6OeTT8Ivv4RlIJ55Jiz+Vrp0oqMTlAhEJF4+/RRGjAiTwNyhc+fQ/JPERd5LKiUCESk6O3fCpEkhAcyaBYcfDtdfD3/7Gxx/fKKjkzwoEYjIH7dpUxj5M3JkWPHzhBNCX8AVV6jwSxJQIhCRwsvMDMM/n3gizAVo3hzuuy9U/kpLS3R0EiMlAhHZd59/DvffH1b/3LULunYNTUBNcteekmSgRCAisdm1Kyz/MGJEKPxSrhz07x+Wf6hWLdHRyR+gRCAi+fv991D8/YEHYOlSqFIlNP/07g2HHZbo6KQIKBGISHQ//hjG/z/+eFgKOj0dXnwx1AAuVSrR0UkRiutarmbW3syWmNlyM7spyvEbzGxe5Guhme00swrxjElECrBwIVx5ZRjuedddcNppMHMmzJ4dloJQEihx4nZHYGZpwKPAmYT6xRlmNtndF+8+x93vBe6NnH8+MMjdf45XTCKSB3d4993QATxtWlj+uXdvGDgQatZMdHQSZ/FsGmoMLHf3bwDMbDzQEVicx/k9gBfjGI+I5LZtG7zwQugAXrgwrPlz111wzTVa/jmFxDMRVAK+z7GdCUQdW2ZmZYH2QL88jvcB+gBUrVq1aKMUSUXr1oVqX488AmvWQN26MG5caPrR+j8pJ56JINpiIp7HuecDH+fVLOTuo4HRAOnp6XldQ0QKsmRJmP37zDOwZQucfXYY/9+2rdb/SWHxTASZQJUc25WBVXmc2x01C4nEh3vo7L3/fnjjjfCJ/9JLYdAglX8UIIZRQ2ZW2cwmmdlaM1tjZq+YWeUYrp0B1DSz6mZ2EOHNfnKU6x8GtARe39fgRSQfO3aE9v/0dGjVKiwCN3QofPstjBmjJCDZYhk++jThDfxYQrv/G5F9+XL3LEKb/zvAV8AEd19kZn3NrG+OUzsB09z9t30NXkSi2LAB7r03LPx2ySVhQtjo0aEuwLBhcMwxiY5Qihlzz7/J3czmuXv9gvbtL+np6T5nzpxEPLVI8bZhQ1jxc8QI+PVXaNMmtP+ffTYcENcpQ5IEzGyuu6dHOxZLH8E6M7uU/2/D7wGsL6rgROQPyp0AOnaE225T/V+JWSyJ4ErgEeABwqifTyL7RCSRoiWAoUOhQYNERyZJpsBE4O7fAR32QywiEotoCeD220MtYJFCyDMRmNmN7n6PmT1MlPH/7j4grpGJyJ42bAhFYEaMCEXglQCkiOR3R/BV5Lt6ZkUSaePG/78D+OUX6NAhNAEpAUgRyTMRuPsbkR9/d/eXcx4zswvjGpWIKAHIfhPLmLKbY9wnIkVh40b45z9D1a/bboPTT4c5c+D115UEJC7y6yM4GzgHqGRmD+U4VB7IindgIiln48bQB3D//f9/B3D77RoGKnGXXx/BKkL/QAdgbo79m4BB8QxKJKXkTgDnnx+agJQAZD/Jr49gPjDfzF5w9x37MSaR1KAEIMVELBPKqpnZv4BaQJndO939hLhFJVKSKQFIMRNLIngaGEqYWdwauILotQZEJD8bN4ZCMPffDz//DOedFxJAetTlX0T2m1hGDR3s7u8TFqj71t2HAW3iG5ZICbJxI9x9N1SvDrfcAs2aQUZGqA2gJCDFQCx3BFvN7ABgmZn1A34Ajo5vWCIlgO4AJEnEckcwECgLDABOAS4FesYxJpHktmmT7gAkqeSbCMwsDbjI3Te7e6a7X+HuXdz901gubmbtzWyJmS03s5vyOKeVmc0zs0Vm9mEhfgeR4mHTJvjXv8JEsFtugaZNYfZsJQAp9vJtGnL3nWZ2ipmZF1TBJpdIEnkUOJNQvzjDzCa7++Ic5xwOPAa0d/fvzExNTpJ8tm2Dxx6Du+6C9evh3HNDE1CjRomOTCQmsfQRfAG8bmYvA9nlJN391QIe1xhY7u7fAJjZeKAjsDjHORcDr0aWusbdf9qH2EUSa9cuePFFuPVWWLkSzjwzJAMlAEkysSSCCoSKZDlHCjlQUCKoBHyfYzsTaJLrnBOBUmY2AygHPOjuz+a+kJn1AfoAVK1aNYaQReLsvffgxhvhiy+gfn2YNi0kApEkFEthmisKee1ocw1yNy8dSOiAbgscDMwys0/dfWmuGEYDoyHULC5kPCJ/3Lx5MHhweOM//nh47jno0UM1gSWpxfN/byZQJcd2ZcL6RbnPmeruv7n7OmAmUC+OMYkUzrffwuWXh9U/MzLCkNCvv4ZLLlESkKQXz//BGUBNM6tuZgcB3YHJuc55HTjdzA40s7KEpqOvECkufv4Z/v53OPFEePnl0Bz0zTdw/fVQpkzBjxdJArH0ERSKu2dFJqC9A6QBY919kZn1jRwf5e5fmdlU4EtgFzDG3RfGKyaRmG3dGtYDuvvuUCKyZ0+44w6oUqXgx4okGStoVKiZHQPcDRzn7mebWS2gqbs/tT8CzC09Pd3nzFH1TImTnTvh+efDSKDvv4dzzoHhw6FOnURHJvKHmNlcd486oSWWpqFxhE/1x0W2lxJmG4uUHO4wdWroA+jZE445BqZPh7feUhKQEi+WRHCUu08gNN3g7lnAzrhGJbI/zZ0LZ5wBZ58NmzfD+PHw2WfQunWiIxPZL2JJBL+Z2ZFEhn6a2anAhrhGJbI/rFgBF18cln/48kt48EH46ivo1k0jgSSlxNJZfD1htE8NM/sYqAh0jWtUIvG0bl0oDv/YY3DggWFdoBtvhPLlEx2ZSELEMqHsczNrCZxEmCS2RKUrJSn9/nv41D98eGgCuvJKGDYMKlVKdGQiCVXg/a+Z/Q041N0XRYZ2Hmpm18Y/NJEisnMnPPVUmAswZAi0agULFsCTTyoJiBBbH8HV7v7r7g13/wW4Om4RiRQVd3jzTahbF3r3hsqVYeZMeP11qFUr0dGJFBuxJIIDzCx73aDI8tIHxS8kkSLw2Wfhk//558OOHTBxIsyaBaefnujIRIqdWBLBO8AEM2trZm2AF4Gp8Q1LpJCWLYMLL4RTTw1rAT32GCxaBF26gEVbB1FEYhk1NBi4BvgrobN4GjAmnkGJ7LOffgpLQDzxBJQuHQrD/Pd/Q7lyiY5MpNiLZdTQLuDxyJdI8fLbbzBiBNxzD2zZAn36wO23w5/+lOjIRJJGgYnAzJoDw4DjI+cb4O5+QnxDE8mHO0yaBNddB5mZ0LlzWCDupJMSHZlI0omlaegpYBAwFy0tIcXBihXQv39YB6hevbAkRPPmiY5KJGnFkgg2uPvbcY9EpCDbt4eCMHfeCWlpoUmof/8wO1hECi2Wv6APzOxeQo3ibbt3uvvncYtKJLcPP4S//jWsBdSlC4wcGeYFiMgfFksi2F1wPuc61s6exexF4uOnn+CGG+DZZ6F69dAcdM45iY5KpESJZdRQodfiNbP2wIOECmVj3H14ruOtCOUqV0R2verudxT2+aQE2bULxoyBm24K6wINGRIWhytbNtGRiZQ4MTWumtm5QG0gu0hrQW/YkRnIjwJnEorUZ5jZZHdfnOvU/7j7efsUtZRs8+eHZqBZs6BlS3j8cfjznxMdlUiJFcuic6OAbkB/wtDRCwlDSQvSGFju7t+4+3ZgPNDxD8QqJd2mTaEo/CmnwPLloTnogw+UBETiLJYlJpq5++XAL+7+D6ApEEsF70rA9zm2MyP7cmtqZvPN7G0zqx3tQmbWx8zmmNmctWvXxvDUklTc4ZVXwhv+Aw+EBeK+/houu0zLQojsB7Ekgi2R77+b2XHADqB6DI+L9hfsubY/B45393rAw8Br0S7k7qPdPd3d0ytWrBjDU0vSWLECzjsPunaFo44KzUGjRkGFComOTCRlxJII3jSzw4F7CW/cKwnNPAXJZM87h8rAqpwnuPtGd98c+XkKUMrMjorh2pLstm8PM4Fr1QpLQ48YAXPmhMXiRGS/imXU0J2RH18xszeBMu4eS83iDKCmmVUHfgC6AxfnPMHM/gSscXc3s8aExLR+X34BSUIzZsC112pOgEgxkWciMLM27j7dzDpHOYa7v5rfhd09y8z6EZaxTgPGuvsiM+sbOT6KUPv4r2aWRWiC6u7uuZuPpKTQnACRYim/O4KWwHTg/CjHnDDTOF+R5p4pufaNyvHzI8AjMUUqySv3nIBbbgnzAjQnQKRYyDMRuPtQMzsAeNvdJ+zHmKQkmT8f+vaFTz8NFcMee0zDQUWKmXw7iyO1CPrtp1ikJMk5J+B//zc0B02friQgUgzFMmroXTP7u5lVMbMKu7/iHpkkp5xzAkaODHMClizRnACRYiyWJSaujHz/W459DqgwjexpxQro1w+mTAl1AiZO1HBQkSQQy/DRWCaPSSrbvh3uuy/UCTjwwDA7uF8/1QkQSRKxLjr3F6AWey4692y8gpIkMmNGWCDu66/D7OAHHtCcAJEkE8uic0MJyz88DLQG7gE6xDkuKe5++gkuvxxat4Zt28KcgJdfVhIQSUKxdBZ3BdoCP7r7FUA9oHRco5LibeLEUCR+/PgwJ2DhQk0ME0liMS06FxlGmmVm5YGfUEdxatq+HQYOhAsvDIlg/nz45z81MUwkycXSRzAnsujck8BcYDMwO55BSTGUmQkXXRRWB73uOrjnHjjooERHJSJFIJZRQ9dGfhxlZlOB8u7+ZXzDkmLl3Xfh4oth61Z46aWQEESkxIils/h1M7vYzA5x95VKAilk1y644w5o1w6OOQYyMpQEREqgWPoIRgCnAYvN7GUz62pmZQp6kCS5detCB/DQoXDJJfDZZ3DyyYmOSkTiIJamoQ+BDyPF6NsAVwNjgfJxjk0S5bPPQofwmjWhWlifPloeQqQEi+WOADM7GOgC9AUaAc/EMyhJEHd4+GE4/XRIS4NPPoFrrlESECnhYukjeAn4inA38ChQw937x3JxM2tvZkvMbLmZ3ZTPeY3MbKeZdY01cClimzaFDuEBA0KfwNy5YeVQESnxYhk++jRwsbvv3JcLR5qSHgXOJNQvzjCzye6+OMp5/0OoZCaJsGhRWB5i6dJQR3jwYDggpptFESkBCvxrd/ep+5oEIhoDy939G3ffTih43zHKef2BVwgT1WR/e/55aNwYfv4Z3nsPbr5ZSUAkxcTzL74S8H2O7czIvmxmVgnoBIwiH2bWx8zmmNmctWvXFnmgKWnbtlBA/tJLQxPQF1+EdYNEJOXEMxFE62HMXZh+JDC4oDsOdx/t7ununl6xYsWiii91rVwJp50Gjz8eislPnw7HHZfoqEQkQfLsIzCzhvk90N0/L+DamUCVHNuVgVW5zkkHxlsYlXIUcI6ZZbn7awVcWwrrrbdCtbCdO2HSJLjggkRHJCIJll9n8f2R72UIb9jzCZ/y6wKfESaZ5ScDqGlm1YEfgO7AxTlPyFn0xszGAW8qCcTJzp1hcthdd0H9+mEF0Ro1Eh2ViBQDeTYNuXtrd28NfAs0jDTNnAI0AJYXdGF3zyIUvn+HMPx0grsvMrO+Zta3aMKXmKxZA2edFZLAVVeF+QFKAiISEcvw0ZPdfcHuDXdfaGb1Y7m4u08BpuTaF7Vj2N17xXJN2UcffRTWB/rlFxg7Fq64ItERiUgxE0tn8VdmNsbMWplZSzN7kvAJX4ozd7j/fmjVCg45BD79VElARKKK5Y7gCuCvwHWR7ZnA43GLSP64DRvCm/6kSdC5c7gTOOywREclIsVULIvObTWzUcAUd1+yH2KSP2L+fOjSJQwRvf9+GDRIawWJSL5iWWuoAzAPmBrZrm9mk+MclxTG00/DqafCli0wYwZcf72SgIgUKJY+gqGE5SJ+BXD3eUC1uEUk+27LljAa6MoroXnzMEv4tIJG94qIBLEkgix33xD3SKRwli+Hpk1DP8Ctt8I778DRRyc6KhFJIrF0Fi80s4uBNDOrCQwAPolvWBKTSZOgV69QO+Ctt0JFMRGRfRTLHUF/oDawDXgR2AgMjGNMUpAdO8IaQZ07w0knhaYgJQERKaRYRg39DtwS+ZJEW7UKunULE8WuvRZGjIDSpRMdlYgksQITgZmdCPyd0EGcfb67t4lfWBLVBx9A9+6weXOoI3DxxQU/RkSkALH0EbxMqBcwBihMgRopCq+/HgrK16gREkKtWomOSERKiFgSQZa7ayZxIk2aFNYLatgwjAo6/PBERyQiJUgsncVvmNm1ZnasmVXY/RX3yCR49dWQBE45BaZNUxIQkSIXyx1Bz8j3G3Lsc+CEog9H9vDKK6FjuHFjmDoVypdPdEQiUgLFMmqoekHnSBy8/DL06AFNmsDbbysJiEjc5Feqso27TzezztGOu/urBV3czNoDDwJpwBh3H57reEfgTmAXkAUMdPeP9iH+kmnChDAi6NRTQxIoVy7REYlICZbfHUFLYDpwfpRjDuSbCMwsDXgUOJNQvzjDzCa7++Icp70PTHZ3N7O6wATg5H2Iv+QZPx4uvRSaNQuzhZUERCTO8kwE7j408r2w1UwaA8vd/RsAMxsPdASyE4G7b85x/iGEBJO6XnghFJY/7bSQBA49NNERiUgKiKWzGDM7l7DMRJnd+9z9jgIeVgn4Psd2JtAkyrU7Af8CjgbOzeP5+wB9AKpWrRpLyMnn+efh8suhRQt4881QVUxEZD+IpR7BKKAbYc0hAy4Ejo/h2tEWwt/rE7+7T3L3k4ELCP0Fez/IfbS7p7t7esWKFWN46iTz73+HJNCypZKAiOx3scwjaObulwO/uPs/gKZAlRgel5nrvMrAqrxOdveZQA0zOyqGa5cczzwDPXuG2sJKAiKSALEkgi2R77+b2XHADiCWIaUZQE0zq25mBwHdgT0qm5nZf5mFElpm1hA4CFgfa/BJb9y4UFu4bVt44w0oWzbREYlICoqlj+BNMzscuBf4nNC8M6agB7l7lpn1A94hDB8d6+6LzKxv5PgooAtwuZntICScbu6eGh3GY8dC795wxhlhHaGDD050RCKSomxf3nfNrDRQJpEVy9LT033OnDmJevqiMWYMXH01tGsX1hFSEhCRODOzue6eHu1YfhPKok4kixyLaUKZRDF6NFxzDbRvH5JAmTIFP0ZEJI7yaxqKNpFstwInlEkUTzwBffvC2WeHxeSUBESkGMhvQllhJ5JJNI8/HiqKnXtuWExOVcVEpJiIZR7BkWb2kJl9bmZzzexBMztyfwRXYjz6aEgC552nJCAixU4sw0fHA2sJI3y6Rn5+KZ5BlSgPPwz9+kGHDjBxopKAiBQ7sQwfreDuOWf8/tPMLohTPCXLgw/CwIHQsWNYUfSggxIdkYjIXmK5I/jAzLqb2QGRr4uAt+IdWNJ74IGQBDp1UhIQkWItlkRwDfACsC3yNR643sw2mdnGeAaXtEaMgOuvhy5d4KWXlAREpFiLpUKZFsTfF/fdBzfcAF27hmWlS5VKdEQiIvmKZdTQVbm208xsaPxCSmL33BOSwEUXKQmISNKIpWmorZlNMbNjzawO8Cmgu4Tc/ud/YPBg6N491BZQEhCRJBFL09DFZtYNWAD8DvRw94/jHlky+de/YMiQUGz+2WfhwJjq/YiIFAuxNA3VBK4DXgFWApeZmdZL3u2uu0ISuOQSJQERSUqxNA29Adzm7tcQCtovI9QakDvvhFtvDcXmn3lGSUBEklIs71yN3X0jQKRWwP1mNrmAx5R8//gHDBsWis0//TSkpSU6IhGRQsnzjsDMbgRw941mdmGuwzEtSGdm7c1siZktN7Obohy/xMy+jHx9Ymb19in6RHCHoUNDEujZU0lARJJefk1D3XP8fHOuY+0LurCZpQGPAmcDtYAeZlYr12krgJbuXpdQuH50gREn0u4kcMcdocTkU08pCYhI0ssvEVgeP0fbjqYxsNzdv3H37YQZyR1znuDun7j7L5HNTwkF7osnd7jtttAvcNVVocqYkoCIlAD5JQLP4+do29FUAr7PsZ0Z2ZeXq4C3ox0wsz5mNsfM5qxduzaGpy5i7nDLLWGEUO/eocrYAbH0s4uIFH/5dRbXi6wlZMDBOdYVMiCW0lrR7hqiJhAza01IBKdFO+7uo4k0G6Wnp+/f4vbucPPNYcJYnz6hwIySgIiUIPlVKPuj7R6ZQJUc25WBVblPMrO6wBjgbHdf/wefs+j9858hCfTtGwrMKAmISAkTz4HvGUBNM6sO/EDofL445wlmVpVQ+/gyd18ax1gAqHbTvq+efeLaCnQ89ULuLX8uDInacpWnlcPP3efnExHZ3+KWCNw9y8z6Ae8AacBYd19kZn0jx0cBtwNHAo+ZGUCWu6fHK6bCWFqxGve2rJboMERE4iauU2HdfQowJde+UTl+7g30jmcMIiKSPzV4i4ikOCUCEZEUp0QgIpLilAhERFKcEoGISIpTIhARSXFKBCIiKU6JQEQkxam2YoIUZrmLP0LLXYhIXnRHICKS4pQIRERSnBKBiEiKUyIQEUlxSgQiIilOiUBEJMXFNRGYWXszW2Jmy83spijHTzazWWa2zcz+Hs9YREQkurjNIzCzNOBR4ExC/eIMM5vs7otznPYzMAC4IF5xSMH255wGzWcQKX7ieUfQGFju7t+4+3ZgPNAx5wnu/pO7ZwA74hiHiIjkI56JoBLwfY7tzMg+EREpRuKZCCzKPi/Uhcz6mNkcM5uzdu3aPxiWiIjkFM9EkAlUybFdGVhVmAu5+2h3T3f39IoVKxZJcCIiEsQzEWQANc2supkdBHQHJsfx+UREpBDiNmrI3bPMrB/wDpAGjHX3RWbWN3J8lJn9CZgDlAd2mdlAoJa7b4xXXFJ8aUVWkcSI6zLU7j4FmJJr36gcP/9IaDISEZEEUT0CkSg0t0JSiRKBSDGm5jLZH7TWkIhIitMdgYjERHcnJZcSgYgkHfXhFC01DYmIpDjdEYiIFFJJaS7THYGISIpTIhARSXFKBCIiKU6JQEQkxSkRiIikOCUCEZEUp0QgIpLilAhERFKcEoGISIqLayIws/ZmtsTMlpvZTVGOm5k9FDn+pZk1jGc8IiKyt7glAjNLAx4FzgZqAT3MrFau084Gaka++gCPxyseERGJLp53BI2B5e7+jbtvB8YDHXOd0xF41oNPgcPN7Ng4xiQiIrmYu8fnwmZdgfbu3juyfRnQxN375TjnTWC4u38U2X4fGOzuc3Jdqw/hjgHgJGBJXIJODkcB6xIdRDGj12Rvek32luqvyfHuXjHagXiuPmpR9uXOOrGcg7uPBkYXRVDJzszmuHt6ouMoTvSa7E2vyd70muQtnk1DmUCVHNuVgVWFOEdEROIonokgA6hpZtXN7CCgOzA51zmTgcsjo4dOBTa4++o4xiQiIrnErWnI3bPMrB/wDpAGjHX3RWbWN3J8FDAFOAdYDvwOXBGveEoQNZHtTa/J3vSa7E2vSR7i1lksIiLJQTOLRURSnBKBiEiKUyJIAmZWxcw+MLOvzGyRmV2X6JiKCzNLM7MvInNSBDCzw81sopl9Hfk/0zTRMSWamQ2K/O0sNLMXzaxMomMqTpQIkkMW8N/u/mfgVOBvUZbrSFXXAV8lOohi5kFgqrufDNQjxV8fM6sEDADS3f0vhMEr3RMbVfGiRJAE3H21u38e+XkT4Q+7UmKjSjwzqwycC4xJdCzFhZmVB1oATwG4+3Z3/zWhQRUPBwIHm9mBQFk0X2kPSgRJxsyqAQ2AzxIcSnEwErgR2JXgOIqTE4C1wNORJrMxZnZIooNKJHf/AbgP+A5YTZivNC2xURUvSgRJxMwOBV4BBrr7xkTHk0hmdh7wk7vPTXQsxcyBQEPgcXdvAPwG7LUEfCoxsyMIC1xWB44DDjGzSxMbVfGiRJAkzKwUIQk87+6vJjqeYqA50MHMVhJWtm1jZs8lNqRiIRPIdPfdd4wTCYkhlZ0BrHD3te6+A3gVaJbgmIoVJYIkYGZGaPP9yt1HJDqe4sDdb3b3yu5ejdDxN93dU/5Tnrv/CHxvZidFdrUFFicwpOLgO+BUMysb+VtqS4p3oOcWz9VHpeg0By4DFpjZvMi+Ie4+JXEhSTHWH3g+ssbXN6T40i3u/pmZTQQ+J4zA+wItN7EHLTEhIpLi1DQkIpLilAhERFKcEoGISIpTIhARSXFKBCIiKU6JQEokM/uTmY03s/81s8VmNsXMTkx0XIVlZq3MTJOgJC6UCKTEiUwamgTMcPca7l4LGAIck9jI/pBWaDasxIkSgZRErYEdkbrYALj7POAjM7s3sib9AjPrBtmftj80swlmttTMhpvZJWY2O3Jejch548xslJn9J3LeeZH9Zczs6ci5X5hZ68j+Xmb2qplNNbNlZnbP7njM7Cwzm2Vmn5vZy5F1pDCzlWb2j8j+BWZ2cmShwb7AIDObZ2anm9mFkd9jvpnN3D8vq5RUmlksJdFfgGiL0XUG6hPW6D8KyMjxJloP+DPwM2E27hh3bxwpAtQfGBg5rxrQEqgBfGBm/wX8DcDd65jZycC0HM1Q9QmrxW4DlpjZw8AW4FbgDHf/zcwGA9cDd0Qes87dG5rZtcDf3b23mY0CNrv7fQBmtgBo5+4/mNnhhX6lRNAdgaSW04AX3X2nu68BPgQaRY5lROo+bAP+F9i9TPECwpv/bhPcfZe7LyMkjJMj1/03gLt/DXwL7E4E77v7BnffSljz53hCcaFawMeRJUN6RvbvtntRwbm5njunj4FxZnY1odCKSKHpjkBKokVA1yj7LZ/HbMvx864c27vY8+8k95osvg/X3Rm5lgHvunuPAh6z+/y9uHtfM2tCKMwzz8zqu/v6fOIQyZPuCKQkmg6UjnxaBsDMGgG/AN0idY4rEip5zd7Ha19oZgdE+g1OAJYAM4FLIs9zIlA1sj8vnwLNI81KRFbFLGhE0yagXI7fp4a7f+butwPrgCr7+HuIZNMdgZQ47u5m1gkYaWY3AVuBlYR2/kOB+YRP8je6+4+Rdv1YLSE0KR0D9HX3rWb2GDAq0m6fBfRy921h8FLU+NaaWS/gRTMrHdl9K7A0n+d9A5hoZh0JfRaDzKwm4e7i/cjvJFIoWn1UJEZmNg54090nJjoWkaKkpiERkRSnOwIRkRSnOwIRkRSnRCAikuKUCEREUpwSgYhIilMiEBFJcf8HzBfQ2w2+nQcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = usampling_split_scale_data(X,'DXCHANGE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "090e1f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def usampling_split_scale_data(df,drop_lst,target):\n",
    "    '''\n",
    "    undersampling data, split data (4:1),data scaling, pca components which could explains 90% data\n",
    "    ----------------------------------\n",
    "    df: the full dataframe\n",
    "    target: the target feature name\n",
    "    -----------\n",
    "    Outputs: X_train,X_test,X_train_scaled,X_test_scaled,X_train_pca,X_test_pca,y_train,y_test\n",
    "       '''\n",
    "    # undersampling \n",
    "    X = df.copy()\n",
    "    y = X[target]\n",
    "    rus = RandomUnderSampler(random_state=432)\n",
    "    X_undersampled, y_unsampled = rus.fit_resample(X, y)\n",
    "    print('After undersampling data size is',len(X_undersampled),'; Resampled dataset shape %s' % Counter(y_unsampled))\n",
    "    # split data\n",
    "    train, test = train_test_split(X_undersampled,test_size=0.2)   \n",
    "    # feature list for the X \n",
    "    lst = X_undersampled.columns.drop(drop_lst)\n",
    "    X_train = train[lst]\n",
    "    y_train = train[target]\n",
    "    X_test = test[lst]\n",
    "    y_test = test[target]\n",
    "    # data scaling\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    # pca components\n",
    "    pca = PCA(n_components=X_train_scaled.shape[1]) # keep all n principal components \n",
    "    pca.fit(X_train_scaled) # fit PCA model with scaled data\n",
    "    X_pca = pca.transform(X_train_scaled)  #transform data onto the first two principal components\n",
    "    ex_ratio = pca.explained_variance_ratio_\n",
    "    cum_sum = 0\n",
    "    for i in range(len(ex_ratio)):\n",
    "        cum_sum += ex_ratio[i]\n",
    "        if cum_sum >= 0.9:  # if it could explain 90% of the data, then stop\n",
    "            break\n",
    "    n_com = i         \n",
    "         # PCA with first n_com components\n",
    "    pca = PCA(n_com)\n",
    "    pca.fit(X_train_scaled)\n",
    "    X_train_pca = pca.transform(X_train_scaled)\n",
    "    X_test_pca = pca.transform(X_test_scaled)\n",
    "       #plot \n",
    "    plt.bar(range(1,len(pca.explained_variance_ratio_ )+1),pca.explained_variance_ratio_ )\n",
    "    plt.ylabel('Explained variance ratio')\n",
    "    plt.xlabel('Components')\n",
    "    plt.plot(range(1,len(pca.explained_variance_ )+1),\n",
    "             np.cumsum(pca.explained_variance_ratio_),\n",
    "             c='red',\n",
    "             label=\"Cumulative Explained Variance ratio\")\n",
    "    plt.legend(loc='upper left')\n",
    "    print('\\n{} principle components are needed to explain 90% of the data\\n'.format(n_com))  \n",
    "    print('Output dataframes sequence: X_train,X_test,X_train_scaled,X_test_scaled,X_train_pca,X_test_pca,y_train,y_test')\n",
    "    X_labels = ['original dataset','scaled dataset','%s pca-components'%n_com]\n",
    "    return X_train,X_test,X_train_scaled,X_test_scaled,X_train_pca,X_test_pca,y_train,y_test,X_labels  \n",
    "\n",
    "def models(df,drop_lst,target):\n",
    "    '''\n",
    "    for splitted data\n",
    "    '''\n",
    "    res = usampling_split_scale_data(df,drop_lst,target)\n",
    "    y_train = res[6]\n",
    "    y_test = res[7]\n",
    "    X_labels = res[8]\n",
    "    for i in range(len(X_labels)):\n",
    "        print('- Using {}:'.format(X_labels[i]))\n",
    "        X_train = res[2*i]\n",
    "        X_test = res[2*i+1]\n",
    "    # logistic regression\n",
    "    C_lst = [0.001,0.01,0.1,1,10,100,1000]\n",
    "    print('    - Logistic regression')\n",
    "    for i in range(len(C_lst)):\n",
    "        print('       - C = {}'.format(C_lst[i]))\n",
    "        logreg = LogisticRegression(C=C_lst[i],solver='lbfgs',multi_class='auto',penalty='l2',max_iter=10000).fit(X_train,y_train)\n",
    "        print('          - lbfgs_L2, Training set f1-score:{:.3f}, Test set f1-score: {:.3f}'\n",
    "              .format(f1_score(logreg.predict(X_train),y_train,average='weighted'),f1_score(logreg.predict(X_test),y_test,average='weighted')))\n",
    "        logreg = LogisticRegression(C=C_lst[i],solver='saga',multi_class='auto',penalty='l1',max_iter=10000).fit(X_train,y_train)\n",
    "        print('          - saga_L1, Training set f1-score:{:.3f}, Test set f1-score: {:.3f}'\n",
    "              .format(f1_score(logreg.predict(X_train),y_train,average='weighted'),f1_score(logreg.predict(X_test),y_test,average='weighted')))\n",
    "        logreg = LogisticRegression(C=C_lst[i],solver='newton-cg',multi_class='auto',penalty='l2',max_iter=10000).fit(X_train,y_train)\n",
    "        print('          - newton-cg_L2, Training set f1-score:{:.3f}, Test set f1-score: {:.3f}'\n",
    "              .format(f1_score(logreg.predict(X_train),y_train,average='weighted'),f1_score(logreg.predict(X_test),y_test,average='weighted')))\n",
    "    \n",
    "    # decision tree\n",
    "    print('    - Decision tree')\n",
    "    for i in range(1,15):\n",
    "        dtree = DecisionTreeClassifier(random_state=0,max_depth=i,criterion='gini')\n",
    "        dtree.fit(X_train,y_train)\n",
    "        print('          - tree depth: {:.3f}. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'\n",
    "          .format(i,f1_score(dtree.predict(X_train),y_train,average='weighted'),f1_score(dtree.predict(X_test),y_test,average='weighted')))\n",
    "    # random forest\n",
    "    print('    - Random forest')\n",
    "    for i in range(1,20):   \n",
    "        m= 5*i\n",
    "        forest = RandomForestClassifier(n_estimators=m,random_state=5862)\n",
    "        forest.fit(X_train,y_train)\n",
    "        print('          - {}trees. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'\n",
    "          .format(m,f1_score(forest.predict(X_train),y_train,average='weighted'),f1_score(forest.predict(X_test),y_test,average='weighted')))\n",
    "    # MLP  \n",
    "    print('    - MLP')\n",
    "    hls = [[50,50],[20,20],[100,100],[50,50,50]] # hidden layer size\n",
    "    for i in range(len(hls)):\n",
    "        mlp = MLPClassifier(solver='lbfgs',random_state=460,hidden_layer_sizes = hls[i],max_iter=20000)\n",
    "        mlp.fit(X_train,y_train)\n",
    "        print('          - hidden layer size{}. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'.format(hls[i],f1_score(mlp.predict(X_train),y_train,average='weighted'),f1_score(mlp.predict(X_test),y_test,average='weighted')))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "cf0d4fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After undersampling data size is 160 ; Resampled dataset shape Counter({'MCI-AD': 80, 'MCI-MCI': 80})\n",
      "\n",
      "10 principle components are needed to explain 90% of the data\n",
      "\n",
      "Output dataframes sequence: X_train,X_test,X_train_scaled,X_test_scaled,X_train_pca,X_test_pca,y_train,y_test\n",
      "- Using original dataset:\n",
      "- Using scaled dataset:\n",
      "- Using 10 pca-components:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, Training set f1-score:0.704, Test set f1-score: 0.562\n",
      "          - saga_L1, Training set f1-score:0.667, Test set f1-score: 0.667\n",
      "          - newton-cg_L2, Training set f1-score:0.696, Test set f1-score: 0.562\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, Training set f1-score:0.712, Test set f1-score: 0.564\n",
      "          - saga_L1, Training set f1-score:0.667, Test set f1-score: 0.667\n",
      "          - newton-cg_L2, Training set f1-score:0.712, Test set f1-score: 0.564\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, Training set f1-score:0.711, Test set f1-score: 0.626\n",
      "          - saga_L1, Training set f1-score:0.665, Test set f1-score: 0.469\n",
      "          - newton-cg_L2, Training set f1-score:0.711, Test set f1-score: 0.626\n",
      "       - C = 1\n",
      "          - lbfgs_L2, Training set f1-score:0.703, Test set f1-score: 0.626\n",
      "          - saga_L1, Training set f1-score:0.719, Test set f1-score: 0.626\n",
      "          - newton-cg_L2, Training set f1-score:0.703, Test set f1-score: 0.626\n",
      "       - C = 10\n",
      "          - lbfgs_L2, Training set f1-score:0.750, Test set f1-score: 0.594\n",
      "          - saga_L1, Training set f1-score:0.742, Test set f1-score: 0.594\n",
      "          - newton-cg_L2, Training set f1-score:0.750, Test set f1-score: 0.594\n",
      "       - C = 100\n",
      "          - lbfgs_L2, Training set f1-score:0.750, Test set f1-score: 0.594\n",
      "          - saga_L1, Training set f1-score:0.750, Test set f1-score: 0.594\n",
      "          - newton-cg_L2, Training set f1-score:0.750, Test set f1-score: 0.594\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, Training set f1-score:0.750, Test set f1-score: 0.594\n",
      "          - saga_L1, Training set f1-score:0.750, Test set f1-score: 0.594\n",
      "          - newton-cg_L2, Training set f1-score:0.750, Test set f1-score: 0.594\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. f1-score on training data: 0.689 f1-score on test data: 0.440\n",
      "          - tree depth: 2.000. f1-score on training data: 0.727 f1-score on test data: 0.508\n",
      "          - tree depth: 3.000. f1-score on training data: 0.787 f1-score on test data: 0.543\n",
      "          - tree depth: 4.000. f1-score on training data: 0.813 f1-score on test data: 0.469\n",
      "          - tree depth: 5.000. f1-score on training data: 0.876 f1-score on test data: 0.508\n",
      "          - tree depth: 6.000. f1-score on training data: 0.930 f1-score on test data: 0.440\n",
      "          - tree depth: 7.000. f1-score on training data: 0.953 f1-score on test data: 0.535\n",
      "          - tree depth: 8.000. f1-score on training data: 0.969 f1-score on test data: 0.469\n",
      "          - tree depth: 9.000. f1-score on training data: 0.977 f1-score on test data: 0.469\n",
      "          - tree depth: 10.000. f1-score on training data: 0.977 f1-score on test data: 0.469\n",
      "          - tree depth: 11.000. f1-score on training data: 0.977 f1-score on test data: 0.469\n",
      "          - tree depth: 12.000. f1-score on training data: 0.977 f1-score on test data: 0.469\n",
      "          - tree depth: 13.000. f1-score on training data: 0.977 f1-score on test data: 0.469\n",
      "          - tree depth: 14.000. f1-score on training data: 0.977 f1-score on test data: 0.469\n",
      "    - Random forest\n",
      "          - 5trees. f1-score on training data: 0.922 f1-score on test data: 0.625\n",
      "          - 10trees. f1-score on training data: 0.953 f1-score on test data: 0.692\n",
      "          - 15trees. f1-score on training data: 0.969 f1-score on test data: 0.594\n",
      "          - 20trees. f1-score on training data: 0.977 f1-score on test data: 0.657\n",
      "          - 25trees. f1-score on training data: 0.977 f1-score on test data: 0.625\n",
      "          - 30trees. f1-score on training data: 0.969 f1-score on test data: 0.625\n",
      "          - 35trees. f1-score on training data: 0.977 f1-score on test data: 0.625\n",
      "          - 40trees. f1-score on training data: 0.977 f1-score on test data: 0.625\n",
      "          - 45trees. f1-score on training data: 0.977 f1-score on test data: 0.625\n",
      "          - 50trees. f1-score on training data: 0.977 f1-score on test data: 0.657\n",
      "          - 55trees. f1-score on training data: 0.977 f1-score on test data: 0.657\n",
      "          - 60trees. f1-score on training data: 0.977 f1-score on test data: 0.688\n",
      "          - 65trees. f1-score on training data: 0.977 f1-score on test data: 0.688\n",
      "          - 70trees. f1-score on training data: 0.977 f1-score on test data: 0.688\n",
      "          - 75trees. f1-score on training data: 0.977 f1-score on test data: 0.688\n",
      "          - 80trees. f1-score on training data: 0.977 f1-score on test data: 0.657\n",
      "          - 85trees. f1-score on training data: 0.977 f1-score on test data: 0.657\n",
      "          - 90trees. f1-score on training data: 0.977 f1-score on test data: 0.657\n",
      "          - 95trees. f1-score on training data: 0.977 f1-score on test data: 0.597\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. f1-score on training data: 0.977 f1-score on test data: 0.594\n",
      "          - hidden layer size[20, 20]. f1-score on training data: 0.977 f1-score on test data: 0.532\n",
      "          - hidden layer size[100, 100]. f1-score on training data: 0.977 f1-score on test data: 0.665\n",
      "          - hidden layer size[50, 50, 50]. f1-score on training data: 0.977 f1-score on test data: 0.626\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "models(sleep_dxch_2g,drop_lst,'DXCHANGE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5d6aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "models(sleep_dxch_6g,drop_lst,'DXCHANGE',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240d5b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After undersampling data size is 228 ; Resampled dataset shape Counter({'AD-AD': 38, 'CN-CN': 38, 'CN-MCI': 38, 'MCI-AD': 38, 'MCI-CN': 38, 'MCI-MCI': 38})\n",
      "\n",
      "9 principle components are needed to explain 90% of the data\n",
      "\n",
      "Output dataframes sequence: X_,X_scaled,X_pca,y_\n",
      "- Using original dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.104\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.050\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.104\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.160\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.042\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.160\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.182\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.106\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.182\n",
      "       - C = 1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.192\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.188\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.192\n",
      "       - C = 10\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.196\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.194\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.196\n",
      "       - C = 100\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.202\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.205\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.202\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.202\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.200\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.202\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. average weighted f1-score of 10-cross validation:0.098\n",
      "          - tree depth: 2.000. average weighted f1-score of 10-cross validation:0.180\n",
      "          - tree depth: 3.000. average weighted f1-score of 10-cross validation:0.143\n",
      "          - tree depth: 4.000. average weighted f1-score of 10-cross validation:0.148\n",
      "          - tree depth: 5.000. average weighted f1-score of 10-cross validation:0.157\n",
      "          - tree depth: 6.000. average weighted f1-score of 10-cross validation:0.170\n",
      "          - tree depth: 7.000. average weighted f1-score of 10-cross validation:0.132\n",
      "          - tree depth: 8.000. average weighted f1-score of 10-cross validation:0.217\n",
      "          - tree depth: 9.000. average weighted f1-score of 10-cross validation:0.191\n",
      "          - tree depth: 10.000. average weighted f1-score of 10-cross validation:0.212\n",
      "          - tree depth: 11.000. average weighted f1-score of 10-cross validation:0.170\n",
      "          - tree depth: 12.000. average weighted f1-score of 10-cross validation:0.203\n",
      "          - tree depth: 13.000. average weighted f1-score of 10-cross validation:0.185\n",
      "          - tree depth: 14.000. average weighted f1-score of 10-cross validation:0.190\n",
      "    - Random forest\n",
      "          - 5trees. average weighted f1-score of 10-cross validation:0.166\n",
      "          - 10trees. average weighted f1-score of 10-cross validation:0.189\n",
      "          - 15trees. average weighted f1-score of 10-cross validation:0.183\n",
      "          - 20trees. average weighted f1-score of 10-cross validation:0.181\n",
      "          - 25trees. average weighted f1-score of 10-cross validation:0.179\n",
      "          - 30trees. average weighted f1-score of 10-cross validation:0.194\n",
      "          - 35trees. average weighted f1-score of 10-cross validation:0.195\n",
      "          - 40trees. average weighted f1-score of 10-cross validation:0.203\n",
      "          - 45trees. average weighted f1-score of 10-cross validation:0.195\n",
      "          - 50trees. average weighted f1-score of 10-cross validation:0.206\n",
      "          - 55trees. average weighted f1-score of 10-cross validation:0.198\n",
      "          - 60trees. average weighted f1-score of 10-cross validation:0.195\n",
      "          - 65trees. average weighted f1-score of 10-cross validation:0.197\n",
      "          - 70trees. average weighted f1-score of 10-cross validation:0.207\n",
      "          - 75trees. average weighted f1-score of 10-cross validation:0.214\n",
      "          - 80trees. average weighted f1-score of 10-cross validation:0.204\n"
     ]
    }
   ],
   "source": [
    "cv_models(sleep_dxch_6g,drop_lst,'DXCHANGE',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "c8a90a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### cv_models(df,drop_lst,target,k)\n",
    "\n",
    "def usampling_scale_data(df,drop_lst,target):\n",
    "    '''\n",
    "    undersampling data, NOT SPLIT data (later use CROSS VALIDATION),data scaling, pca components which could explains 90% data\n",
    "    ----------------------------------\n",
    "    df: the full dataframe\n",
    "    drop_lst: drop the features which are not gonna be used in modeling, e.g. RID,...\n",
    "    target: the target feature name\n",
    "    -----------\n",
    "    Outputs: X_train,X_test,X_train_scaled,X_test_scaled,X_train_pca,X_test_pca,y_train,y_test\n",
    "       '''\n",
    "    # undersampling \n",
    "    y = df[target]\n",
    "    rus = RandomUnderSampler(random_state=432)\n",
    "    X_undersampled, y_unsampled = rus.fit_resample(df, y)\n",
    "    print('After undersampling data size is',len(X_undersampled),'; Resampled dataset shape %s' % Counter(y_unsampled)) \n",
    "    # feature list for the X \n",
    "    lst = X_undersampled.columns.drop(drop_lst)  #['Phase', 'RID', 'VISCODE','PTID',target]\n",
    "    # normal input output data\n",
    "    X_ = X_undersampled[lst]\n",
    "    y_ = X_undersampled[target]\n",
    "    # data scaling\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X_scaled = scaler.transform(X_)\n",
    "    # pca components\n",
    "    pca = PCA(n_components=X_scaled.shape[1]) # keep all n principal components \n",
    "    pca.fit(X_scaled) # fit PCA model with scaled data\n",
    "    X_pca = pca.transform(X_scaled)  #transform data onto the first two principal components\n",
    "    ex_ratio = pca.explained_variance_ratio_\n",
    "    cum_sum = 0\n",
    "    for i in range(len(ex_ratio)):\n",
    "        cum_sum += ex_ratio[i]\n",
    "        if cum_sum >= 0.9:  # if it could explain 90% of the data, then stop\n",
    "            break\n",
    "    n_com = i         \n",
    "         # PCA with first n_com components\n",
    "    pca = PCA(n_com)\n",
    "    pca.fit(X_scaled)\n",
    "    X_pca = pca.transform(X_scaled)\n",
    "       #plot \n",
    "    plt.bar(range(1,len(pca.explained_variance_ratio_ )+1),pca.explained_variance_ratio_ )\n",
    "    plt.ylabel('Explained variance ratio')\n",
    "    plt.xlabel('Components')\n",
    "    plt.plot(range(1,len(pca.explained_variance_ )+1),\n",
    "             np.cumsum(pca.explained_variance_ratio_),\n",
    "             c='red',\n",
    "             label=\"Cumulative Explained Variance ratio\")\n",
    "    plt.legend(loc='upper left')\n",
    "    print('\\n{} principle components are needed to explain 90% of the data\\n'.format(n_com))  \n",
    "    #print('Output dataframes sequence: X_,X_scaled,X_pca,y_')\n",
    "    X_labels = ['original dataset','scaled dataset','%s pca-components'%n_com]\n",
    "    return X_,X_scaled,X_pca,y_,X_labels \n",
    "\n",
    "def cv_models(df,drop_lst,target,k):\n",
    "    '''\n",
    "    df: full dataframe.\n",
    "    drop_lst: drop the features which are not gonna be used in modeling, e.g. RID,...\n",
    "    target: the target feature name\n",
    "    k: folds of cross-validation\n",
    "    '''\n",
    "    res = usampling_scale_data(df,drop_lst,target) # Output dataframes sequence: X_,X_scaled,X_pca,y_\n",
    "    \n",
    "    y = res[3]\n",
    "    X_labels = res[4]\n",
    "    for i in range(3):\n",
    "        X = res[i]\n",
    "        print('- Using {}:'.format(X_labels[i]))\n",
    "        # logistic regression\n",
    "        C_lst = [0.001,0.01,0.1,1,10,100,1000]\n",
    "        print('    - Logistic regression')\n",
    "        for i in range(len(C_lst)):\n",
    "            print('       - C = {}'.format(C_lst[i]))\n",
    "            logreg = LogisticRegression(C=C_lst[i],solver='lbfgs',multi_class='auto',penalty='l2',max_iter=10000).fit(X,y)\n",
    "            print('          - lbfgs_L2, average weighted f1-score of {}-cross validation:{:.3f}'.format(k,cross_val_score(logreg, X, y, cv = k,scoring='f1_weighted').mean()))\n",
    "            logreg = LogisticRegression(C=C_lst[i],solver='saga',multi_class='auto',penalty='l1',max_iter=10000).fit(X_train,y_train)\n",
    "            print('          - saga_L1, average weighted f1-score of {}-cross validation:{:.3f}'.format(k,cross_val_score(logreg, X, y, cv = k,scoring='f1_weighted').mean()))\n",
    "            logreg = LogisticRegression(C=C_lst[i],solver='newton-cg',multi_class='auto',penalty='l2',max_iter=10000).fit(X_train,y_train)\n",
    "            print('          - newton-cg_L2, average weighted f1-score of {}-cross validation:{:.3f}'.format(k,cross_val_score(logreg, X, y, cv = k,scoring='f1_weighted').mean()))\n",
    "\n",
    "        # decision tree\n",
    "        print('    - Decision tree')\n",
    "        for i in range(1,15):\n",
    "            dtree = DecisionTreeClassifier(random_state=0,max_depth=i,criterion='gini')\n",
    "            dtree.fit(X,y)\n",
    "            print('          - tree depth: {:.3f}. average weighted f1-score of {}-cross validation:{:.3f}'\n",
    "                .format(i,k,cross_val_score(dtree, X, y, cv = k,scoring='f1_weighted').mean()))\n",
    "\n",
    "        # random forest\n",
    "        print('    - Random forest')\n",
    "        for i in range(1,20):   \n",
    "            m= 5*i\n",
    "            forest = RandomForestClassifier(n_estimators=m,random_state=5862)\n",
    "            forest.fit(X,y)\n",
    "            print('          - {}trees. average weighted f1-score of {}-cross validation:{:.3f}'\n",
    "                .format(m,k,cross_val_score(forest, X, y, cv = k,scoring='f1_weighted').mean()))\n",
    "        # MLP \n",
    "        print('    - MLP')\n",
    "        hls = [[50,50],[20,20],[100,100],[50,50,50]] # hidden layer size\n",
    "        for i in range(len(hls)):\n",
    "            mlp = MLPClassifier(solver='lbfgs',random_state=460,hidden_layer_sizes = hls[i],max_iter=20000).fit(X,y)\n",
    "            mlp.fit(X,y)\n",
    "            print('          - hidden layer size{}. average weighted f1-score of {}-cross validation:{:.3f}'.format(hls[i],k,cross_val_score(mlp, X, y, cv = k,scoring='f1_weighted').mean()))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "f1ff8dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_lst = ['Phase', 'RID', 'VISCODE','PTID','DXCHANGE']\n",
    "def usampling_scale_data(df,drop_lst,target):\n",
    "    '''\n",
    "    undersampling data, NOT SPLIT data (later use CROSS VALIDATION),data scaling, pca components which could explains 90% data\n",
    "    ----------------------------------\n",
    "    df: the full dataframe\n",
    "    drop_lst: drop the features which are not gonna be used in modeling, e.g. RID,...\n",
    "    target: the target feature name\n",
    "    -----------\n",
    "    Outputs: X_train,X_test,X_train_scaled,X_test_scaled,X_train_pca,X_test_pca,y_train,y_test\n",
    "       '''\n",
    "    # undersampling \n",
    "    y = df[target]\n",
    "    rus = RandomUnderSampler(random_state=432)\n",
    "    X_undersampled, y_unsampled = rus.fit_resample(df, y)\n",
    "    print('After undersampling data size is',len(X_undersampled),'; Resampled dataset shape %s' % Counter(y_unsampled)) \n",
    "    # feature list for the X \n",
    "    lst = X_undersampled.columns.drop(drop_lst)  #['Phase', 'RID', 'VISCODE','PTID',target]\n",
    "    # normal input output data\n",
    "    X_ = X_undersampled[lst]\n",
    "    y_ = X_undersampled[target]\n",
    "    # data scaling\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X_scaled = scaler.transform(X_)\n",
    "    # pca components\n",
    "    pca = PCA(n_components=X_scaled.shape[1]) # keep all n principal components \n",
    "    pca.fit(X_scaled) # fit PCA model with scaled data\n",
    "    X_pca = pca.transform(X_scaled)  #transform data onto the first two principal components\n",
    "    ex_ratio = pca.explained_variance_ratio_\n",
    "    cum_sum = 0\n",
    "    for i in range(len(ex_ratio)):\n",
    "        cum_sum += ex_ratio[i]\n",
    "        if cum_sum >= 0.9:  # if it could explain 90% of the data, then stop\n",
    "            break\n",
    "    n_com = i         \n",
    "         # PCA with first n_com components\n",
    "    pca = PCA(n_com)\n",
    "    pca.fit(X_scaled)\n",
    "    X_pca = pca.transform(X_scaled)\n",
    "       #plot \n",
    "    plt.bar(range(1,len(pca.explained_variance_ratio_ )+1),pca.explained_variance_ratio_ )\n",
    "    plt.ylabel('Explained variance ratio')\n",
    "    plt.xlabel('Components')\n",
    "    plt.plot(range(1,len(pca.explained_variance_ )+1),\n",
    "             np.cumsum(pca.explained_variance_ratio_),\n",
    "             c='red',\n",
    "             label=\"Cumulative Explained Variance ratio\")\n",
    "    plt.legend(loc='upper left')\n",
    "    print('\\n{} principle components are needed to explain 90% of the data\\n'.format(n_com))  \n",
    "    print('Output dataframes sequence: X_,X_scaled,X_pca,y_train')\n",
    "    return X_,X_scaled,X_pca,y_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf4223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(estimator=clf, X=sleep_dxch_drop.iloc[:,5:], y=sleep_dxch_drop['DXCHANGE'], cv=7, n_jobs=4,scoring=scoring[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "df937b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def models(X_train,X_test,y_train,y_test):\n",
    "    # logistic regression\n",
    "    C_lst = [0.001,0.01,0.1,1,10,100]\n",
    "    print('Logistic regression')\n",
    "    for i in range(len(C_lst)):\n",
    "        print('  - C = {}'.format(C_lst[i]))\n",
    "        logreg = LogisticRegression(C=C_lst[i],solver='lbfgs',multi_class='auto',penalty='l2',max_iter=10000).fit(X_train,y_train)\n",
    "        print('     - lbfgs_L2, Training set score:{:.3f}, Test set score: {:.3f}'.format(logreg.score(X_train,y_train),logreg.score(X_test,y_test)))\n",
    "        logreg = LogisticRegression(C=C_lst[i],solver='saga',multi_class='auto',penalty='l1',max_iter=10000).fit(X_train,y_train)\n",
    "        print('     - saga_L1, Training set score:{:.3f}, Test set score: {:.3f}'.format(logreg.score(X_train,y_train),logreg.score(X_test,y_test)))\n",
    "        logreg = LogisticRegression(C=C_lst[i],solver='newton-cg',multi_class='auto',penalty='l2',max_iter=10000).fit(X_train,y_train)\n",
    "        print('     - newton-cg_L2, Training set score:{:.3f}, Test set score: {:.3f}'.format(logreg.score(X_train,y_train),logreg.score(X_test,y_test)))\n",
    "    \n",
    "    # decision tree\n",
    "    print('Decision tree')\n",
    "    for i in range(1,15):\n",
    "        dtree = DecisionTreeClassifier(random_state=0,max_depth=i,criterion='gini')\n",
    "        dtree.fit(X_train,y_train)\n",
    "        print('     - tree depth: {:.3f}. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'\n",
    "          .format(i,f1_score(tree.predict(X_train),y_train,average='weighted'),f1_score(tree.predict(X_test),y_test,average='weighted')))\n",
    "    # random forest\n",
    "    print('Random forest')\n",
    "    for i in range(1,20):   \n",
    "        m= 5*i\n",
    "        forest = RandomForestClassifier(n_estimators=m,random_state=5862)\n",
    "        forest.fit(X_train,y_train)\n",
    "        print('     - {}trees. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'\n",
    "          .format(m,f1_score(forest.predict(X_train),y_train,average='weighted'),f1_score(forest.predict(X_test),y_test,average='weighted')))\n",
    "    # MLP with PCA \n",
    "    hls = [[50,50],[20,20],[100,100],[50,50,50]] # hidden layer size\n",
    "    for i in range(len(hls)):\n",
    "        mlp = MLPClassifier(solver='lbfgs',random_state=460,hidden_layer_sizes = hls[i],max_iter=20000).fit(X_train,y_train)\n",
    "        mlp.fit(X_train,y_train)\n",
    "        print('     - hidden layer size{}. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'.format(hls[i],f1_score(mlp.predict(X_train),y_train,average='weighted'),f1_score(mlp.predict(X_test),y_test,average='weighted')))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "fb913ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CN-CN', 'CN-MCI', 'AD-AD', 'MCI-MCI', 'MCI-AD', 'MCI-CN', 'CN-AD',\n",
       "       'AD-MCI'], dtype=object)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sleep_dxch['DXCHANGE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "182b5b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "7ff36ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 5]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [[2,5],[5,8,7]]\n",
    "l[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "d1b260e3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression\n",
      "  - C = 0.001\n",
      "     - lbfgs_L2, Training set score:0.562, Test set score: 0.406\n",
      "     - saga_L1, Training set score:0.539, Test set score: 0.344\n",
      "     - newton-cg_L2, Training set score:0.562, Test set score: 0.406\n",
      "  - C = 0.01\n",
      "     - lbfgs_L2, Training set score:0.609, Test set score: 0.562\n",
      "     - saga_L1, Training set score:0.539, Test set score: 0.344\n",
      "     - newton-cg_L2, Training set score:0.609, Test set score: 0.562\n",
      "  - C = 0.1\n",
      "     - lbfgs_L2, Training set score:0.703, Test set score: 0.531\n",
      "     - saga_L1, Training set score:0.609, Test set score: 0.500\n",
      "     - newton-cg_L2, Training set score:0.703, Test set score: 0.531\n",
      "  - C = 1\n",
      "     - lbfgs_L2, Training set score:0.711, Test set score: 0.656\n",
      "     - saga_L1, Training set score:0.703, Test set score: 0.625\n",
      "     - newton-cg_L2, Training set score:0.711, Test set score: 0.656\n",
      "  - C = 10\n",
      "     - lbfgs_L2, Training set score:0.703, Test set score: 0.656\n",
      "     - saga_L1, Training set score:0.695, Test set score: 0.656\n",
      "     - newton-cg_L2, Training set score:0.703, Test set score: 0.656\n",
      "  - C = 100\n",
      "     - lbfgs_L2, Training set score:0.695, Test set score: 0.656\n",
      "     - saga_L1, Training set score:0.703, Test set score: 0.656\n",
      "     - newton-cg_L2, Training set score:0.695, Test set score: 0.656\n"
     ]
    }
   ],
   "source": [
    "models(X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e4e3b6",
   "metadata": {},
   "source": [
    "## best score: newton-cg_L2,C:1, Training set score:0.711, Test set score: 0.688"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "64813e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn model with PCA data. Training set f1-score:0.752, Test set f-score: 0.464\n",
      "logistic with PCA data. C:0.001, Training set f1-score:0.699, Test set f1-score: 0.512\n",
      "logistic with PCA data. C:0.01, Training set f1-score:0.723, Test set f1-score: 0.500\n",
      "logistic with PCA data. C:0.1, Training set f1-score:0.658, Test set f1-score: 0.713\n",
      "logistic with PCA data. C:1, Training set f1-score:0.673, Test set f1-score: 0.713\n",
      "logistic with PCA data. C:10, Training set f1-score:0.673, Test set f1-score: 0.713\n",
      "logistic with PCA data. C:100, Training set f1-score:0.673, Test set f1-score: 0.713\n",
      "Decision tree with unscaled data. tree depth: 1.000. f1-score on training data: 0.648 f1-score on test data: 0.474\n",
      "Decision tree with unscaled data. tree depth: 2.000. f1-score on training data: 0.657 f1-score on test data: 0.784\n",
      "Decision tree with unscaled data. tree depth: 3.000. f1-score on training data: 0.735 f1-score on test data: 0.746\n",
      "Decision tree with unscaled data. tree depth: 4.000. f1-score on training data: 0.790 f1-score on test data: 0.616\n",
      "Decision tree with unscaled data. tree depth: 5.000. f1-score on training data: 0.820 f1-score on test data: 0.649\n",
      "Decision tree with unscaled data. tree depth: 6.000. f1-score on training data: 0.844 f1-score on test data: 0.680\n",
      "Decision tree with unscaled data. tree depth: 7.000. f1-score on training data: 0.891 f1-score on test data: 0.527\n",
      "Decision tree with unscaled data. tree depth: 8.000. f1-score on training data: 0.930 f1-score on test data: 0.616\n",
      "Decision tree with unscaled data. tree depth: 9.000. f1-score on training data: 0.938 f1-score on test data: 0.585\n",
      "Decision tree with unscaled data. tree depth: 10.000. f1-score on training data: 0.946 f1-score on test data: 0.556\n",
      "Decision tree with unscaled data. tree depth: 11.000. f1-score on training data: 0.961 f1-score on test data: 0.556\n",
      "Decision tree with unscaled data. tree depth: 12.000. f1-score on training data: 0.977 f1-score on test data: 0.556\n",
      "Decision tree with unscaled data. tree depth: 13.000. f1-score on training data: 0.977 f1-score on test data: 0.556\n",
      "Random forest with unscaled data. 250 trees. f1-score on training data: 0.977 f1-score on test data: 0.598\n",
      "Random forest with unscaled data. 300 trees. f1-score on training data: 0.977 f1-score on test data: 0.562\n",
      "Random forest with unscaled data. 350 trees. f1-score on training data: 0.977 f1-score on test data: 0.562\n",
      "Random forest with unscaled data. 400 trees. f1-score on training data: 0.977 f1-score on test data: 0.562\n",
      "Random forest with unscaled data. 450 trees. f1-score on training data: 0.977 f1-score on test data: 0.562\n",
      "Random forest with unscaled data. 500 trees. f1-score on training data: 0.977 f1-score on test data: 0.562\n",
      "Random forest with unscaled data. 550 trees. f1-score on training data: 0.977 f1-score on test data: 0.562\n",
      "Random forest with unscaled data. 600 trees. f1-score on training data: 0.977 f1-score on test data: 0.562\n",
      "Random forest with unscaled data. 650 trees. f1-score on training data: 0.977 f1-score on test data: 0.598\n",
      "Random forest with unscaled data. 700 trees. f1-score on training data: 0.977 f1-score on test data: 0.598\n",
      "Random forest with unscaled data. 750 trees. f1-score on training data: 0.977 f1-score on test data: 0.598\n",
      "Random forest with unscaled data. 800 trees. f1-score on training data: 0.977 f1-score on test data: 0.598\n",
      "Random forest with unscaled data. 850 trees. f1-score on training data: 0.977 f1-score on test data: 0.562\n",
      "Random forest with unscaled data. 900 trees. f1-score on training data: 0.977 f1-score on test data: 0.562\n",
      "Random forest with unscaled data. 950 trees. f1-score on training data: 0.977 f1-score on test data: 0.562\n",
      "Decision tree with PCA data. tree depth: 1.000 f1-score on training data: 0.691 f1-score on test data: 0.552\n",
      "Decision tree with PCA data. tree depth: 2.000 f1-score on training data: 0.734 f1-score on test data: 0.653\n",
      "Decision tree with PCA data. tree depth: 3.000 f1-score on training data: 0.758 f1-score on test data: 0.791\n",
      "Decision tree with PCA data. tree depth: 4.000 f1-score on training data: 0.828 f1-score on test data: 0.767\n",
      "Decision tree with PCA data. tree depth: 5.000 f1-score on training data: 0.891 f1-score on test data: 0.682\n",
      "Decision tree with PCA data. tree depth: 6.000 f1-score on training data: 0.953 f1-score on test data: 0.649\n",
      "Decision tree with PCA data. tree depth: 7.000 f1-score on training data: 0.977 f1-score on test data: 0.750\n",
      "Decision tree with PCA data. tree depth: 8.000 f1-score on training data: 0.977 f1-score on test data: 0.682\n",
      "Decision tree with PCA data. tree depth: 9.000 f1-score on training data: 0.977 f1-score on test data: 0.682\n",
      "Decision tree with PCA data. tree depth: 10.000 f1-score on training data: 0.977 f1-score on test data: 0.682\n",
      "Decision tree with PCA data. tree depth: 11.000 f1-score on training data: 0.977 f1-score on test data: 0.682\n",
      "Decision tree with PCA data. tree depth: 12.000 f1-score on training data: 0.977 f1-score on test data: 0.682\n",
      "Decision tree with PCA data. tree depth: 13.000 f1-score on training data: 0.977 f1-score on test data: 0.682\n",
      "Decision tree with scaled data. tree depth: 1.000. f1-score on training data: 0.648 f1-score on test data: 0.474\n",
      "Decision tree with scaled data. tree depth: 2.000. f1-score on training data: 0.657 f1-score on test data: 0.784\n",
      "Decision tree with scaled data. tree depth: 3.000. f1-score on training data: 0.735 f1-score on test data: 0.746\n",
      "Decision tree with scaled data. tree depth: 4.000. f1-score on training data: 0.790 f1-score on test data: 0.616\n",
      "Decision tree with scaled data. tree depth: 5.000. f1-score on training data: 0.820 f1-score on test data: 0.649\n",
      "Decision tree with scaled data. tree depth: 6.000. f1-score on training data: 0.844 f1-score on test data: 0.680\n",
      "Decision tree with scaled data. tree depth: 7.000. f1-score on training data: 0.891 f1-score on test data: 0.527\n",
      "Decision tree with scaled data. tree depth: 8.000. f1-score on training data: 0.930 f1-score on test data: 0.616\n",
      "Decision tree with scaled data. tree depth: 9.000. f1-score on training data: 0.938 f1-score on test data: 0.585\n",
      "Decision tree with scaled data. tree depth: 10.000. f1-score on training data: 0.946 f1-score on test data: 0.556\n",
      "Decision tree with scaled data. tree depth: 11.000. f1-score on training data: 0.961 f1-score on test data: 0.556\n",
      "Decision tree with scaled data. tree depth: 12.000. f1-score on training data: 0.977 f1-score on test data: 0.556\n",
      "Decision tree with scaled data. tree depth: 13.000. f1-score on training data: 0.977 f1-score on test data: 0.556\n",
      "Random forest with scaled data. 250 trees. f1-score on training data: 0.977 f1-score on test data: 0.634\n",
      "Random forest with scaled data. 300 trees. f1-score on training data: 0.977 f1-score on test data: 0.598\n",
      "Random forest with scaled data. 350 trees. f1-score on training data: 0.977 f1-score on test data: 0.598\n",
      "Random forest with scaled data. 400 trees. f1-score on training data: 0.977 f1-score on test data: 0.598\n",
      "Random forest with scaled data. 450 trees. f1-score on training data: 0.977 f1-score on test data: 0.598\n",
      "Random forest with scaled data. 500 trees. f1-score on training data: 0.977 f1-score on test data: 0.598\n",
      "Random forest with scaled data. 550 trees. f1-score on training data: 0.977 f1-score on test data: 0.598\n",
      "Random forest with scaled data. 600 trees. f1-score on training data: 0.977 f1-score on test data: 0.598\n",
      "Random forest with scaled data. 650 trees. f1-score on training data: 0.977 f1-score on test data: 0.634\n",
      "Random forest with scaled data. 700 trees. f1-score on training data: 0.977 f1-score on test data: 0.634\n",
      "Random forest with scaled data. 750 trees. f1-score on training data: 0.977 f1-score on test data: 0.634\n",
      "Random forest with scaled data. 800 trees. f1-score on training data: 0.977 f1-score on test data: 0.634\n",
      "Random forest with scaled data. 850 trees. f1-score on training data: 0.977 f1-score on test data: 0.598\n",
      "Random forest with scaled data. 900 trees. f1-score on training data: 0.977 f1-score on test data: 0.598\n",
      "Random forest with scaled data. 950 trees. f1-score on training data: 0.977 f1-score on test data: 0.598\n",
      "Decision tree with PCA data. tree depth: 1.000 f1-score on training data: 0.691 f1-score on test data: 0.552\n",
      "Decision tree with PCA data. tree depth: 2.000 f1-score on training data: 0.734 f1-score on test data: 0.653\n",
      "Decision tree with PCA data. tree depth: 3.000 f1-score on training data: 0.758 f1-score on test data: 0.791\n",
      "Decision tree with PCA data. tree depth: 4.000 f1-score on training data: 0.828 f1-score on test data: 0.767\n",
      "Decision tree with PCA data. tree depth: 5.000 f1-score on training data: 0.891 f1-score on test data: 0.682\n",
      "Decision tree with PCA data. tree depth: 6.000 f1-score on training data: 0.953 f1-score on test data: 0.649\n",
      "Decision tree with PCA data. tree depth: 7.000 f1-score on training data: 0.977 f1-score on test data: 0.750\n",
      "Decision tree with PCA data. tree depth: 8.000 f1-score on training data: 0.977 f1-score on test data: 0.682\n",
      "Decision tree with PCA data. tree depth: 9.000 f1-score on training data: 0.977 f1-score on test data: 0.682\n",
      "Decision tree with PCA data. tree depth: 10.000 f1-score on training data: 0.977 f1-score on test data: 0.682\n",
      "Decision tree with PCA data. tree depth: 11.000 f1-score on training data: 0.977 f1-score on test data: 0.682\n",
      "Decision tree with PCA data. tree depth: 12.000 f1-score on training data: 0.977 f1-score on test data: 0.682\n",
      "Decision tree with PCA data. tree depth: 13.000 f1-score on training data: 0.977 f1-score on test data: 0.682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest with unscaled data. 250 trees. f1-score on training data: 0.977 f1-score on test data: 0.619\n",
      "Random forest with unscaled data. 300 trees. f1-score on training data: 0.977 f1-score on test data: 0.649\n",
      "Random forest with unscaled data. 350 trees. f1-score on training data: 0.977 f1-score on test data: 0.584\n",
      "Random forest with unscaled data. 400 trees. f1-score on training data: 0.977 f1-score on test data: 0.584\n",
      "Random forest with unscaled data. 450 trees. f1-score on training data: 0.977 f1-score on test data: 0.584\n",
      "Random forest with unscaled data. 500 trees. f1-score on training data: 0.977 f1-score on test data: 0.584\n",
      "Random forest with unscaled data. 550 trees. f1-score on training data: 0.977 f1-score on test data: 0.584\n",
      "Random forest with unscaled data. 600 trees. f1-score on training data: 0.977 f1-score on test data: 0.584\n",
      "Random forest with unscaled data. 650 trees. f1-score on training data: 0.977 f1-score on test data: 0.584\n",
      "Random forest with unscaled data. 700 trees. f1-score on training data: 0.977 f1-score on test data: 0.584\n",
      "Random forest with unscaled data. 750 trees. f1-score on training data: 0.977 f1-score on test data: 0.584\n",
      "Random forest with unscaled data. 800 trees. f1-score on training data: 0.977 f1-score on test data: 0.584\n",
      "Random forest with unscaled data. 850 trees. f1-score on training data: 0.977 f1-score on test data: 0.584\n",
      "Random forest with unscaled data. 900 trees. f1-score on training data: 0.977 f1-score on test data: 0.584\n",
      "Random forest with unscaled data. 950 trees. f1-score on training data: 0.977 f1-score on test data: 0.584\n",
      "MLP with scaled data. f1-score on training data: 0.977 f1-score on test data: 0.555\n",
      "MLP with PCA. f1-score on training data: 0.930 f1-score on test data: 0.562\n"
     ]
    }
   ],
   "source": [
    "# knn\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "knn = KNeighborsClassifier(n_neighbors=4)    \n",
    "knn.fit(X_pca,y_train)\n",
    "print('knn model with PCA data. Training set f1-score:{:.3f}, Test set f-score: {:.3f}'.format(f1_score(knn.predict(X_pca),y_train,average='weighted'),f1_score(knn.predict(X_test_pca),y_test,average='weighted')))\n",
    "\n",
    "# logistic regression on pca data\n",
    "for i in range(len(C_lst)):     \n",
    "    logreg = LogisticRegression(C=C_lst[i],solver='lbfgs',multi_class='auto',penalty='l2',max_iter=100000).fit(X_pca,y_train)\n",
    "    print('logistic with PCA data. C:{}, Training set f1-score:{:.3f}, Test set f1-score: {:.3f}'.format(C_lst[i],f1_score(logreg.predict(X_pca),y_train,average='weighted'),f1_score(logreg.predict(X_test_pca),y_test,average='weighted')))\n",
    "    \n",
    "# decision tree and random forest with unscaled data \n",
    "for i in range(1,14):\n",
    "    tree = DecisionTreeClassifier(random_state=0,max_depth=i)\n",
    "    tree.fit(X_train,y_train)\n",
    "    print('Decision tree with unscaled data. tree depth: {:.3f}. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'\n",
    "          .format(i,f1_score(tree.predict(X_train),y_train,average='weighted'),f1_score(tree.predict(X_test),y_test,average='weighted')))\n",
    "for m in range(5,20):    \n",
    "    forest = RandomForestClassifier(n_estimators=m*50,random_state=5862)\n",
    "    forest.fit(X_train,y_train)\n",
    "    print('Random forest with unscaled data. {} trees. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'\n",
    "          .format(m*50,f1_score(forest.predict(X_train),y_train,average='weighted'),f1_score(forest.predict(X_test),y_test,average='weighted')))\n",
    "    \n",
    "\n",
    "# decision tree and random forest with scaled data \n",
    "for i in range(1,14):\n",
    "    tree = DecisionTreeClassifier(random_state=0,max_depth=i)\n",
    "    tree.fit(X_train_scaled,y_train)\n",
    "    print('Decision tree with scaled data. tree depth: {:.3f}. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'\n",
    "          .format(i,f1_score(tree.predict(X_train_scaled),y_train,average='weighted'),f1_score(tree.predict(X_test_scaled),y_test,average='weighted')))\n",
    "for m in range(5,20):    \n",
    "    forest = RandomForestClassifier(n_estimators=m*50,random_state=5862)\n",
    "    forest.fit(X_train_scaled,y_train)\n",
    "    print('Random forest with scaled data. {} trees. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'\n",
    "          .format(m*50,f1_score(forest.predict(X_train_scaled),y_train,average='weighted'),f1_score(forest.predict(X_test_scaled),y_test,average='weighted')))\n",
    "    \n",
    "# decision tree and random forest with PCA data \n",
    "for i in range(1,14):\n",
    "    tree = DecisionTreeClassifier(random_state=0,max_depth=i)\n",
    "    tree.fit(X_pca,y_train)\n",
    "    print('Decision tree with PCA data. tree depth: {:.3f} f1-score on training data: {:.3f} f1-score on test data: {:.3f}'.format(i,f1_score(tree.predict(X_pca),y_train,average='weighted'),f1_score(tree.predict(X_test_pca),y_test,average='weighted')))    \n",
    "for m in range(5,20):    \n",
    "    forest = RandomForestClassifier(n_estimators=m*50,random_state=5862)\n",
    "    forest.fit(X_pca,y_train)\n",
    "    print('Random forest with PCA data. {} trees. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'\n",
    "          .format(m*50,f1_score(forest.predict(X_pca),y_train,average='weighted'),f1_score(forest.predict(X_test_pca),y_test,average='weighted')))    \n",
    "    \n",
    "# MLP with scaled data\n",
    "mlp = MLPClassifier(solver='lbfgs',random_state=0,hidden_layer_sizes = [8,10],max_iter=10000).fit(X_train_scaled,y_train)\n",
    "mlp.fit(X_train_scaled,y_train)\n",
    "print('MLP with scaled data. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'.format(f1_score(mlp.predict(X_train_scaled),y_train,average='weighted'),f1_score(mlp.predict(X_test_scaled),y_test,average='weighted')))\n",
    "    \n",
    "    \n",
    "# MLP with PCA \n",
    "mlp = MLPClassifier(solver='lbfgs',random_state=0,hidden_layer_sizes = [18,10,5],max_iter=20000).fit(X_pca,y_train)\n",
    "mlp.fit(X_pca,y_train)\n",
    "print('MLP with PCA. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'.format(f1_score(mlp.predict(X_pca),y_train,average='weighted'),f1_score(mlp.predict(X_test_pca),y_test,average='weighted')))    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec278b5e",
   "metadata": {},
   "source": [
    "Decision tree with unscaled data. tree depth: 6.000. f1-score on training data: 0.844 f1-score on test data: 0.680\n",
    "Random forest with unscaled data. 50 trees. f1-score on training data: 0.977 f1-score on test data: 0.682\n",
    "Decision tree with PCA data. tree depth: 4.000 f1-score on training data: 0.828 f1-score on test data: 0.767"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2de6828",
   "metadata": {},
   "source": [
    "### feature selections from previous work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c30879",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a670079b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6394a929",
   "metadata": {},
   "source": [
    "## use dataframe sleep_dx, target_variable 'DX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bce9650",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1359e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(sleep_dx.dropna(axis=0,how='any'),test_size=0.2)    \n",
    "X_train = train[lst]\n",
    "y_train = train['DX']\n",
    "X_test = test[lst]\n",
    "y_test = test['DX']\n",
    "## data scaling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train_scaled,X_test_scaled\n",
    "# logistic regression\n",
    "C_lst = [0.001,0.01,0.1,1,10,100]\n",
    "for i in range(len(C_lst)):\n",
    "    logreg = LogisticRegression(C=C_lst[i],solver='lbfgs',multi_class='auto',penalty='l2',max_iter=10000).fit(X_train_scaled,y_train)\n",
    "    print('lbfgs_L2,C:{}, Training set score:{:.3f}, Test set score: {:.3f}'.format(C_lst[i],logreg.score(X_train_scaled,y_train),logreg.score(X_test_scaled,y_test)))\n",
    "    \n",
    "for i in range(len(C_lst)):\n",
    "    logreg = LogisticRegression(C=C_lst[i],solver='saga',multi_class='auto',penalty='l1',max_iter=10000).fit(X_train_scaled,y_train)\n",
    "    print('saga_L1,C:{}, Training set score:{:.3f}, Test set score: {:.3f}'.format(C_lst[i],logreg.score(X_train_scaled,y_train),logreg.score(X_test_scaled,y_test)))\n",
    "    \n",
    "for i in range(len(C_lst)):\n",
    "    logreg = LogisticRegression(C=C_lst[i],solver='newton-cg',multi_class='auto',penalty='l2',max_iter=10000).fit(X_train_scaled,y_train)\n",
    "    print('newton-cg_L2,C:{}, Training set score:{:.3f}, Test set score: {:.3f}'.format(C_lst[i],logreg.score(X_train_scaled,y_train),logreg.score(X_test_scaled,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc59068c",
   "metadata": {},
   "source": [
    "#### after trying different solvers for multi_class labels: 'saga','lbfgs','sag','newton-cg' with possible penalty ('l2' or 'l1'), all logistic models work not that good on our data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f21fbc",
   "metadata": {},
   "source": [
    "### PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791cdb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10) #keep the first two principal components of the data\n",
    "pca.fit(X_train_scaled) # fit PCA model to sleep-diagnosis_change data\n",
    "X_pca = pca.transform(X_train_scaled)  #transform data onto the first two principal components\n",
    "print(\"Origianl shape: {}\".format(str(X_train_scaled.shape)))\n",
    "print(\"Reduced shape: {}\".format(str(X_pca.shape)))\n",
    "# Explained variance is the amount of variance explained by each of the selected components.\n",
    "print(\"explained variance: {}\".format(pca.explained_variance_))\n",
    "print(\"explained variance ratio: {}\".format(pca.explained_variance_ratio_))\n",
    "\n",
    "plt.bar(range(1,len(pca.explained_variance_ratio_ )+1),pca.explained_variance_ratio_ )\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Components')\n",
    "plt.plot(range(1,len(pca.explained_variance_ )+1),\n",
    "         np.cumsum(pca.explained_variance_ratio_),\n",
    "         c='red',\n",
    "         label=\"Cumulative Explained Variance ratio\")\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "# The component 1 can explain about 20% of the variance, conponent 2 can explain about 11.7%,... \n",
    "# It needs almost 10 principal components to explain at least 90% of the variance. \n",
    "pca = PCA(n_components=4) \n",
    "pca.fit(X_train_scaled) # fit PCA model to sleep-diagnosis_change data\n",
    "X_pca = pca.transform(X_train_scaled)  #transform data onto the first two principal components\n",
    "print(\"Origianl shape: {}\".format(str(X_train_scaled.shape)))\n",
    "print(\"Reduced shape: {}\".format(str(X_pca.shape)))\n",
    "# plot\n",
    "plt.figure(figsize=(8,8))\n",
    "mglearn.discrete_scatter(X_pca[:,0],X_pca[:,1],train['DX'])\n",
    "plt.legend(train['DX'].unique(),loc='best')\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.xlabel(\"First principal component\")\n",
    "plt.ylabel('Seconde principal component')\n",
    "\n",
    "print('PCA components: \\n{}'.format(pca.components_))    # PCA components\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.matshow(pca.components_,cmap='viridis')\n",
    "plt.yticks([0,1],['First component','Seconde component'])\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(X_train.columns)),X_train.columns,rotation=60,ha='left')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Principal components')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9abb439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "knn = KNeighborsClassifier(n_neighbors=4)    \n",
    "knn.fit(X_pca,y_train)\n",
    "print('knn model with PCA data. Training set f1-score:{:.3f}, Test set f-score: {:.3f}'.format(f1_score(knn.predict(X_pca),y_train,average='weighted'),f1_score(knn.predict(X_test_pca),y_test,average='weighted')))\n",
    "\n",
    "# logistic regression on pca data\n",
    "for i in range(len(C_lst)):     \n",
    "    logreg = LogisticRegression(C=C_lst[i],solver='lbfgs',multi_class='auto',penalty='l2',max_iter=100000).fit(X_pca,y_train)\n",
    "    print('logistic with PCA data. C:{}, Training set f1-score:{:.3f}, Test set f1-score: {:.3f}'.format(C_lst[i],f1_score(logreg.predict(X_pca),y_train,average='weighted'),f1_score(logreg.predict(X_test_pca),y_test,average='weighted')))\n",
    "    \n",
    "# decision tree\n",
    "for i in range(1,14):\n",
    "    tree = DecisionTreeClassifier(random_state=0,max_depth=i)\n",
    "    tree.fit(X_train,y_train)\n",
    "    print('Decision tree with unscaled data. tree depth: {:.3f}. f1-score on training data: {:.3f} f1-score on test data: {}'.format(i,f1_score(tree.predict(X_train),y_train,average='weighted'),f1_score(tree.predict(X_test),y_test,average='weighted')))\n",
    "    \n",
    "# decision tree with PCA data \n",
    "for i in range(1,14):\n",
    "    tree = DecisionTreeClassifier(random_state=0,max_depth=i)\n",
    "    tree.fit(X_pca,y_train)\n",
    "    print('Decision tree with PCA data. tree depth: {:.3f} f1-score on training data: {:.3f} f1-score on test data: {}'.format(i,f1_score(tree.predict(X_pca),y_train,average='weighted'),f1_score(tree.predict(X_test_pca),y_test,average='weighted')))\n",
    "    \n",
    "# MLP with scaled data\n",
    "mlp = MLPClassifier(solver='lbfgs',random_state=0,hidden_layer_sizes = [8,10],max_iter=10000).fit(X_train_scaled,y_train)\n",
    "mlp.fit(X_train_scaled,y_train)\n",
    "print('MLP with scaled data. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'.format(f1_score(mlp.predict(X_train_scaled),y_train,average='weighted'),f1_score(mlp.predict(X_test_scaled),y_test,average='weighted')))\n",
    "    \n",
    "    \n",
    "# MLP with PCA \n",
    "mlp = MLPClassifier(solver='lbfgs',random_state=0,hidden_layer_sizes = [18,10,5],max_iter=20000).fit(X_pca,y_train)\n",
    "mlp.fit(X_pca,y_train)\n",
    "print('MLP with PCA. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'.format(f1_score(mlp.predict(X_pca),y_train,average='weighted'),f1_score(mlp.predict(X_test_pca),y_test,average='weighted')))    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d3e0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP with scaled data\n",
    "mlp = MLPClassifier(solver='lbfgs',random_state=0,hidden_layer_sizes = [8,12],max_iter=10000).fit(X_train_scaled,y_train)\n",
    "mlp.fit(X_train_scaled,y_train)\n",
    "print('MLP with scaled data. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'.format(f1_score(mlp.predict(X_train_scaled),y_train,average='weighted'),f1_score(mlp.predict(X_test_scaled),y_test,average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1932fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a08c3fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08de443e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5be298",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f00f425c",
   "metadata": {},
   "source": [
    "## use dataframe sleep_dxbl, target_variable 'DX_bl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8756088",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_dxbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba9ee9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(sleep_dxbl.dropna(axis=0,how='any'),test_size=0.2)    \n",
    "X_train = train[lst]\n",
    "y_train = train['DX_bl']\n",
    "X_test = test[lst]\n",
    "y_test = test['DX_bl']\n",
    "## data scaling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train_scaled,X_test_scaled\n",
    "# logistic regression\n",
    "C_lst = [0.001,0.01,0.1,1,10,100]\n",
    "for i in range(len(C_lst)):\n",
    "    logreg = LogisticRegression(C=C_lst[i],solver='lbfgs',multi_class='auto',penalty='l2',max_iter=10000).fit(X_train_scaled,y_train)\n",
    "    print('lbfgs_L2,C:{}, Training set score:{:.3f}, Test set score: {:.3f}'.format(C_lst[i],logreg.score(X_train_scaled,y_train),logreg.score(X_test_scaled,y_test)))\n",
    "    \n",
    "for i in range(len(C_lst)):\n",
    "    logreg = LogisticRegression(C=C_lst[i],solver='saga',multi_class='auto',penalty='l1',max_iter=10000).fit(X_train_scaled,y_train)\n",
    "    print('saga_L1,C:{}, Training set score:{:.3f}, Test set score: {:.3f}'.format(C_lst[i],logreg.score(X_train_scaled,y_train),logreg.score(X_test_scaled,y_test)))\n",
    "    \n",
    "for i in range(len(C_lst)):\n",
    "    logreg = LogisticRegression(C=C_lst[i],solver='newton-cg',multi_class='auto',penalty='l2',max_iter=10000).fit(X_train_scaled,y_train)\n",
    "    print('newton-cg_L2,C:{}, Training set score:{:.3f}, Test set score: {:.3f}'.format(C_lst[i],logreg.score(X_train_scaled,y_train),logreg.score(X_test_scaled,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cda469",
   "metadata": {},
   "source": [
    "#### after trying different solvers for multi_class labels: 'saga','lbfgs','sag','newton-cg' with possible penalty ('l2' or 'l1'), all logistic models work not that good on our data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e9d74d",
   "metadata": {},
   "source": [
    "### PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78af1545",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10) #keep the first two principal components of the data\n",
    "pca.fit(X_train_scaled) # fit PCA model to sleep-diagnosis_change data\n",
    "X_pca = pca.transform(X_train_scaled)  #transform data onto the first two principal components\n",
    "print(\"Origianl shape: {}\".format(str(X_train_scaled.shape)))\n",
    "print(\"Reduced shape: {}\".format(str(X_pca.shape)))\n",
    "# Explained variance is the amount of variance explained by each of the selected components.\n",
    "print(\"explained variance: {}\".format(pca.explained_variance_))\n",
    "print(\"explained variance ratio: {}\".format(pca.explained_variance_ratio_))\n",
    "\n",
    "plt.bar(range(1,len(pca.explained_variance_ratio_ )+1),pca.explained_variance_ratio_ )\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Components')\n",
    "plt.plot(range(1,len(pca.explained_variance_ )+1),\n",
    "         np.cumsum(pca.explained_variance_ratio_),\n",
    "         c='red',\n",
    "         label=\"Cumulative Explained Variance ratio\")\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "# The component 1 can explain about 20% of the variance, conponent 2 can explain about 11.7%,... \n",
    "# It needs almost 10 principal components to explain at least 90% of the variance. \n",
    "pca = PCA(n_components=4) \n",
    "pca.fit(X_train_scaled) # fit PCA model to sleep-diagnosis_change data\n",
    "X_pca = pca.transform(X_train_scaled)  #transform data onto the first two principal components\n",
    "print(\"Origianl shape: {}\".format(str(X_train_scaled.shape)))\n",
    "print(\"Reduced shape: {}\".format(str(X_pca.shape)))\n",
    "# plot\n",
    "plt.figure(figsize=(8,8))\n",
    "mglearn.discrete_scatter(X_pca[:,0],X_pca[:,1],train['DX_bl'])\n",
    "plt.legend(train['DX_bl'].unique(),loc='best')\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.xlabel(\"First principal component\")\n",
    "plt.ylabel('Seconde principal component')\n",
    "\n",
    "print('PCA components: \\n{}'.format(pca.components_))    # PCA components\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.matshow(pca.components_,cmap='viridis')\n",
    "plt.yticks([0,1,2,3],['First component','Seconde component','Third component','Fourth component'])\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(X_train.columns)),X_train.columns,rotation=60,ha='left')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Principal components')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773d6cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "knn = KNeighborsClassifier(n_neighbors=4)    \n",
    "knn.fit(X_pca,y_train)\n",
    "print('knn model with PCA data. Training set f1-score:{:.3f}, Test set f-score: {:.3f}'.format(f1_score(knn.predict(X_pca),y_train,average='weighted'),f1_score(knn.predict(X_test_pca),y_test,average='weighted')))\n",
    "\n",
    "# logistic regression on pca data\n",
    "for i in range(len(C_lst)):     \n",
    "    logreg = LogisticRegression(C=C_lst[i],solver='lbfgs',multi_class='auto',penalty='l2',max_iter=100000).fit(X_pca,y_train)\n",
    "    print('logistic with PCA data. C:{}, Training set f1-score:{:.3f}, Test set f1-score: {:.3f}'.format(C_lst[i],f1_score(logreg.predict(X_pca),y_train,average='weighted'),f1_score(logreg.predict(X_test_pca),y_test,average='weighted')))\n",
    "    \n",
    "# decision tree\n",
    "for i in range(1,14):\n",
    "    tree = DecisionTreeClassifier(random_state=0,max_depth=i)\n",
    "    tree.fit(X_train,y_train)\n",
    "    print('Decision tree with unscaled data. tree depth: {:.3f}. f1-score on training data: {:.3f} f1-score on test data: {}'.format(i,f1_score(tree.predict(X_train),y_train,average='weighted'),f1_score(tree.predict(X_test),y_test,average='weighted')))\n",
    "    \n",
    "# decision tree with PCA data \n",
    "for i in range(1,14):\n",
    "    tree = DecisionTreeClassifier(random_state=0,max_depth=i)\n",
    "    tree.fit(X_pca,y_train)\n",
    "    print('Decision tree with PCA data. tree depth: {:.3f} f1-score on training data: {:.3f} f1-score on test data: {}'.format(i,f1_score(tree.predict(X_pca),y_train,average='weighted'),f1_score(tree.predict(X_test_pca),y_test,average='weighted')))\n",
    "    \n",
    "# MLP with scaled data\n",
    "mlp = MLPClassifier(solver='lbfgs',random_state=0,hidden_layer_sizes = [8,10],max_iter=10000).fit(X_train_scaled,y_train)\n",
    "mlp.fit(X_train_scaled,y_train)\n",
    "print('MLP with scaled data. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'.format(f1_score(mlp.predict(X_train_scaled),y_train,average='weighted'),f1_score(mlp.predict(X_test_scaled),y_test,average='weighted')))\n",
    "    \n",
    "    \n",
    "# MLP with PCA \n",
    "mlp = MLPClassifier(solver='lbfgs',random_state=0,hidden_layer_sizes = [18,10,5],max_iter=20000).fit(X_pca,y_train)\n",
    "mlp.fit(X_pca,y_train)\n",
    "print('MLP with PCA. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'.format(f1_score(mlp.predict(X_pca),y_train,average='weighted'),f1_score(mlp.predict(X_test_pca),y_test,average='weighted')))    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf4806d",
   "metadata": {},
   "source": [
    "### neurobat.csv\n",
    "The Neuropsychological Assessment Battery (NAB; Stern & White, 2003) is a comprehensive test battery that assesses five cognitive domains (Attention, Language, Memory, Spatial, and Executive Functions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57db9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "neubat_s = pd.read_csv('neurobat_short.csv',sep=',').iloc[:,1:].drop(['RAVLT_perc_forgetting'],axis=1).replace(-1, np.NaN).replace(-4, np.NaN)\n",
    "neubat_s = neubat_s.dropna(subset=neubat_s.columns[3:],how='all').dropna(axis=1, how='all')\n",
    "neubat_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74474c89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neubat_s.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b050359",
   "metadata": {},
   "source": [
    "### brain volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5647826c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('main_file.csv').iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69aa4986",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7101bae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_neub_ss_dxch = neubat_ss.merge(sleep_dxch,how='inner',on=com_col)\n",
    "sleep_neub_ss_dxch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630b1d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "neubat_ss = pd.read_csv('neurobat_supershort.csv').dropna(how='any').iloc[:,1:]\n",
    "neubat_ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce175bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick check PCA\n",
    "\n",
    "def PCA_(df_X,n):\n",
    "    # data scaling\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(df_X)\n",
    "    X_scaled = scaler.transform(df_X)\n",
    "    pca = PCA(n_components=n)\n",
    "    pca.fit(X_scaled)\n",
    "    X_pca = pca.transform(X_scaled)\n",
    "    print(\"Origianl shape: {}\".format(str(X_scaled.shape)))\n",
    "    print(\"Reduced shape: {}\".format(str(X_pca.shape)))\n",
    "    print(\"explained variance: {}\".format(pca.explained_variance_))\n",
    "    print(\"explained variance ratio: {}\".format(pca.explained_variance_ratio_))\n",
    "    plt.bar(range(1,len(pca.explained_variance_ratio_ )+1),pca.explained_variance_ratio_ )\n",
    "    plt.ylabel('Explained variance ratio')\n",
    "    plt.xlabel('Components')\n",
    "    plt.plot(range(1,len(pca.explained_variance_ )+1),\n",
    "             np.cumsum(pca.explained_variance_ratio_),\n",
    "             c='red',\n",
    "             label=\"Cumulative Explained Variance ratio\")\n",
    "    plt.legend(loc='upper left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016e2bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_(neubat_ss.iloc[:,3:],4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411782d8",
   "metadata": {},
   "source": [
    "### sleep vs brain volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de96d7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_brain_v = pd.read_csv('sleep_brain_v.csv').iloc[:,1:]\n",
    "sleep_brain_v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd3a312",
   "metadata": {},
   "source": [
    "#### sleep vs brainvolume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba890480",
   "metadata": {},
   "source": [
    "NPIKTOT has no data to any of the brain volume data or biomarkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787f4660",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_brain_v.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af41903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_lst = ['NPIK1', 'NPIK2', 'NPIK3', 'NPIK4',\n",
    "       'NPIK5', 'NPIK6', 'NPIK7', 'NPIK8', 'NPIK9A', 'NPIK9B', 'NPIK9C',\n",
    "       'NPIKTOT', 'NPIKSEV', 'insomnia', 'OSA','ratio_ABETA_bl', 'ratio_TAU_bl',\n",
    "       'ratio_PTAU_bl']\n",
    "cat_lst = ['ratio_Ventricles_bl','ratio_Hippocampus_bl', 'ratio_WholeBrain_bl', 'ratio_Entorhinal_bl',\n",
    "       'ratio_Fusiform_bl', 'ratio_ICV_bl', 'ratio_ABETA_bl', 'ratio_TAU_bl',\n",
    "       'ratio_PTAU_bl']\n",
    "new_cat_lst = ['Ventricles_reduction_per_year','Hippocampus_reduction_per_year','wholebrain_reduction_per_year','Entorhinal_reduction_per_year',\n",
    "               'Fusiform_reduction_per_year','ICV_reduction_per_year','ABETA_reduction_per_year','TAU_reduction_per_year','PTAU_reduction_per_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d46bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.set_theme(style=\"ticks\")\n",
    "#sns.pairplot(sleep_brain_v[sleep_lst + new_cat_lst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746d4466",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=54, ncols=3, figsize=(18,280))\n",
    "axes = axes.ravel()  # array to 1D\n",
    "for j in range(len(sleep_lst)):\n",
    "    for i in range(len(cat_lst)):\n",
    "        axes[i+j*9].scatter(sleep_brain_v[sleep_lst[j]], sleep_brain_v[cat_lst[i]])\n",
    "        axes[i+j*9].set(title=f'{sleep_lst[j]} vs {cat_lst[i]}', xlabel=None)   \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f00f82b",
   "metadata": {},
   "source": [
    "NPIKSEV, insomnia, OSA have data available to correlate to "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee40f6dc",
   "metadata": {},
   "source": [
    "NPIKSEV vs brain volume ratio to baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f470319",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_brain_v = sleep_brain_v.drop(['NPIK1', 'NPIK2', 'NPIK3', 'NPIK4',\n",
    "       'NPIK5', 'NPIK6', 'NPIK7', 'NPIK8', 'NPIK9A', 'NPIK9B', 'NPIK9C',\n",
    "       'NPIKTOT'],axis=1)\n",
    "sleep_brain_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f166fb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_brain_red = sleep_brain_v.dropna(how='any',axis=0).reset_index().drop(['index'],axis=1)  # reduced\n",
    "sleep_brain_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fa7c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_brain_red.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb6df37",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"ticks\")\n",
    "sns.pairplot(sleep_brain_red[['NPIKSEV', 'insomnia', 'OSA',\n",
    "       'ratio_Ventricles_bl', 'ratio_Hippocampus_bl', 'ratio_WholeBrain_bl',\n",
    "       'ratio_Entorhinal_bl', 'ratio_Fusiform_bl', 'ratio_ICV_bl',\n",
    "       'ratio_ABETA_bl', 'ratio_TAU_bl', 'ratio_PTAU_bl']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0749972d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_brain_red.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d55f0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = train_test_split(sleep_brain_red,random_state=586,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffccbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7227c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9636cbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[['NPIKSEV', 'insomnia', 'OSA',\n",
    "       'ratio_ABETA_bl', 'ratio_TAU_bl', 'ratio_PTAU_bl']]\n",
    "X_test = test[['NPIKSEV', 'insomnia', 'OSA',\n",
    "       'ratio_ABETA_bl', 'ratio_TAU_bl', 'ratio_PTAU_bl']]\n",
    "y_lst = ['Ventricles_reduction_per_year', 'Hippocampus_reduction_per_year',\n",
    "       'wholebrain_reduction_per_year', 'Entorhinal_reduction_per_year',\n",
    "       'Fusiform_reduction_per_year', 'ICV_reduction_per_year',\n",
    "       'ABETA_reduction_per_year', 'TAU_reduction_per_year',\n",
    "       'PTAU_reduction_per_year','ratio_Ventricles_bl', 'ratio_Hippocampus_bl', 'ratio_WholeBrain_bl',\n",
    "       'ratio_Entorhinal_bl', 'ratio_Fusiform_bl', 'ratio_ICV_bl',\n",
    "       'ratio_ABETA_bl', 'ratio_TAU_bl', 'ratio_PTAU_bl']\n",
    "alpha_lst = [0.01,0.1,1,10]\n",
    "for i in range(len(y_lst)):\n",
    "    y_train = train[y_lst[i]]\n",
    "    y_test = test[y_lst[i]]\n",
    "    for j in range(len(alpha_lst)):\n",
    "        \n",
    "        ridge = Ridge(alpha = alpha_lst[j]).fit(X_train,y_train)\n",
    "        print('{}: target feature {}: alpha = {}; training set score: {:.3f}; test set score {:.3f}'.format('Ridge',y_lst[i],alpha_lst[j],lr.score(X_train,train_whole_brain),lr.score(X_test,test_whole_brain)))\n",
    "        lasso = Lasso(alpha = alpha_lst[j]).fit(X_train,y_train)\n",
    "        print('{}: target feature {}: alpha = {}; training set score: {:.3f}; test set score {:.3f}'.format('Lasso',y_lst[i],alpha_lst[j],lr.score(X_train,train_whole_brain),lr.score(X_test,test_whole_brain)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa934b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data to use PCA\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d796f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3) #keep the first two principal components of the data\n",
    "pca.fit(X_train_scaled) # fit PCA model to sleep-diagnosis_change data\n",
    "X_pca = pca.transform(X_train_scaled)  #transform data onto the first two principal components\n",
    "plt.bar(range(1,len(pca.explained_variance_ratio_ )+1),pca.explained_variance_ratio_ )\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Components')\n",
    "plt.plot(range(1,len(pca.explained_variance_ )+1),\n",
    "             np.cumsum(pca.explained_variance_ratio_),\n",
    "             c='red',\n",
    "             label=\"Cumulative Explained Variance ratio\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# The component 1 can explain about 20% of the variance, conponent 2 can explain about 11.7%,... \n",
    "# It needs almost 10 principal components to explain at least 90% of the variance. \n",
    "pca = PCA(n_components=3) \n",
    "pca.fit(X_train_scaled) # fit PCA model to sleep-diagnosis_change data\n",
    "X_pca = pca.transform(X_train_scaled)  #transform data onto the first two principal components\n",
    "print(\"Origianl shape: {}\".format(str(X_train_scaled.shape)))\n",
    "print(\"Reduced shape: {}\".format(str(X_pca.shape)))\n",
    "# plot\n",
    "plt.figure(figsize=(8,8))\n",
    "mglearn.discrete_scatter(X_pca[:,0],X_pca[:,1],train['wholebrain_reduction_per_year'])\n",
    "plt.legend(train['wholebrain_reduction_per_year'].unique(),loc='best')\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.xlabel(\"First principal component\")\n",
    "plt.ylabel('Seconde principal component')\n",
    "\n",
    "print('PCA components: \\n{}'.format(pca.components_))    # PCA components\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.matshow(pca.components_,cmap='viridis')\n",
    "plt.yticks([0,1,2,3],['First component','Seconde component','Third component','Fourth component'])\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(X_train.columns)),X_train.columns,rotation=60,ha='left')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Principal components')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5fc12b",
   "metadata": {},
   "source": [
    "## try to use all variables to predict diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c461ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_file = pd.read_csv('main_file.csv',sep=',')\n",
    "main_2 = main_file[com_col + ['DX','DXCHANGE']]\n",
    "sleep_bio_brain_dx = sleep_brain_v.merge(main_2,how='left',on=com_col).dropna(axis=1, how='all')\n",
    "sleep_bio_brain_dx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1209347",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sleep_bio_brain_dx = sleep_bio_brain_dx.dropna(how='any',axis=0)\n",
    "train,test = train_test_split(sleep_bio_brain_dx,random_state=586,test_size=0.25)\n",
    "X_train = train.drop(['Phase', 'RID', 'VISCODE','PTID','DX','DXCHANGE'],axis=1)\n",
    "X_test = test.drop(['Phase', 'RID', 'VISCODE','PTID','DX','DXCHANGE'],axis=1)\n",
    "y_lst = ['DX','DXCHANGE']\n",
    "for j in range(len(y_lst)):\n",
    "    y_train = train[y_lst[j]]\n",
    "    y_test = test[y_lst[j]]\n",
    "    print('target feature: {}'.format(y_lst[j]))\n",
    "    for i in range(1,14):\n",
    "        tree = DecisionTreeClassifier(random_state=5850,max_depth=i,criterion='gini')\n",
    "        tree.fit(X_train,y_train)\n",
    "        print('    Decision tree with unscaled data. tree depth: {:.3f}. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'\n",
    "              .format(i,f1_score(tree.predict(X_train),y_train,average='weighted'),f1_score(tree.predict(X_test),y_test,average='weighted')))\n",
    "        forest = RandomForestClassifier(n_estimators = 200, random_state = 560)\n",
    "        forest.fit(X_train,y_train)\n",
    "        print('    Random forest with unscaled data. n_estimators: 200. tree depth: {:.3f}. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'\n",
    "              .format(i,f1_score(forest.predict(X_train),y_train,average='weighted'),f1_score(forest.predict(X_test),y_test,average='weighted')))\n",
    "    # MLP with unscaled data\n",
    "    mlp = MLPClassifier(solver='lbfgs',random_state=785,hidden_layer_sizes = [100,100],max_iter=40000)\n",
    "    mlp.fit(X_train,y_train)\n",
    "    print('    -MLP with uscaled data. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'\n",
    "      .format(f1_score(mlp.predict(X_train),y_train,average='weighted'),f1_score(mlp.predict(X_test),y_test,average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbe89a0",
   "metadata": {},
   "source": [
    "For the target feature DXCHANGE tree depth of 3 works best. \n",
    "\n",
    "with f1-score on training data: 0.786 f1-score on test data: 0.606"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aec8238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled data \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "for j in range(len(y_lst)):\n",
    "    y_train = train[y_lst[j]]\n",
    "    y_test = test[y_lst[j]]\n",
    "    print('target feature: {}'.format(y_lst[j]))\n",
    "    for i in range(2,14):\n",
    "        tree = DecisionTreeClassifier(random_state=5850,max_depth=i,criterion='gini')\n",
    "        tree.fit(X_train_scaled,y_train)\n",
    "        print('    Decision tree with scaled data. tree depth: {:.3f}. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'\n",
    "              .format(i,f1_score(tree.predict(X_train_scaled),y_train,average='weighted'),f1_score(tree.predict(X_test_scaled),y_test,average='weighted')))\n",
    "        forest = RandomForestClassifier(n_estimators = 200, random_state = 560)\n",
    "        forest.fit(X_train_scaled,y_train)\n",
    "        print('    Random forest with scaled data. n_estimators: 200. tree depth: {:.3f}. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'\n",
    "              .format(i,f1_score(forest.predict(X_train_scaled),y_train,average='weighted'),f1_score(forest.predict(X_test_scaled),y_test,average='weighted')))\n",
    "    # MLP with scaled data\n",
    "    mlp = MLPClassifier(solver='lbfgs',random_state=785,hidden_layer_sizes = [200,200],max_iter=40000)\n",
    "    mlp.fit(X_train_scaled,y_train)\n",
    "    print('    -MLP with uscaled data. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'\n",
    "      .format(f1_score(mlp.predict(X_train_scaled),y_train,average='weighted'),f1_score(mlp.predict(X_test_scaled),y_test,average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d6f377",
   "metadata": {},
   "source": [
    " DXCHANGE: Decision tree with scaled data. tree depth: 3.000. f1-score on training data: 0.786 f1-score on test data: 0.606\n",
    " \n",
    " DX: Decision tree with scaled data. tree depth: 2.000. f1-score on training data: 0.778 f1-score on test data: 0.487"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f605dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "pca = PCA(n_components=X_train_scaled.shape[1]) #keep the first two principal components of the data\n",
    "pca.fit(X_train_scaled) # fit PCA model to sleep-diagnosis_change data\n",
    "X_pca = pca.transform(X_train_scaled)  #transform data onto the first two principal components\n",
    "plt.bar(range(1,len(pca.explained_variance_ratio_ )+1),pca.explained_variance_ratio_ )\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Components')\n",
    "plt.plot(range(1,len(pca.explained_variance_ )+1),\n",
    "             np.cumsum(pca.explained_variance_ratio_),\n",
    "             c='red',\n",
    "             label=\"Cumulative Explained Variance ratio\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(8,8))\n",
    "mglearn.discrete_scatter(X_pca[:,0],X_pca[:,1],train['DXCHANGE'])\n",
    "plt.legend(train['DXCHANGE'].unique(),loc='best')\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.xlabel(\"First principal component\")\n",
    "plt.ylabel('Seconde principal component')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(18,18))\n",
    "plt.matshow(pca.components_,cmap='viridis')\n",
    "plt.yticks([0,1,2,3,4,5,6],['First component','Seconde component','Third component','Fourth component','Fifth component','Sixth component','seventh component'])\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(X_train.columns)),X_train.columns,rotation=60,ha='left')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Principal components')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02c1830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree with PCA data \n",
    "\n",
    "for k in range(len(y_lst)):\n",
    "    y_train = train[y_lst[k]]\n",
    "    y_test = test[y_lst[k]]\n",
    "    print('- target feature: {}'.format(y_lst[k]))\n",
    "    max_f1_test = 0\n",
    "    max_n_component = 0\n",
    "    tree_depth = 0\n",
    "    _f1_train = 0\n",
    "    for j in range(2,X_train_scaled.shape[1]):\n",
    "        pca = PCA(n_components=j) # keep the first j principal components of the data\n",
    "        pca.fit(X_train_scaled) # fit PCA model to sleep-diagnosis_change data\n",
    "        X_pca = pca.transform(X_train_scaled)  #transform data onto the first two principal components\n",
    "        X_test_pca = pca.transform(X_test_scaled)\n",
    "        #print('   - Decision tree with PCA {} components:'.format(j))\n",
    "        \n",
    "        for i in range(1,14):\n",
    "            tree = DecisionTreeClassifier(random_state=580,max_depth=i,criterion='gini')\n",
    "            tree.fit(X_pca,y_train)\n",
    "            f1_score_test = f1_score(tree.predict(X_test_pca),y_test,average='weighted')\n",
    "            f1_score_train = f1_score(tree.predict(X_pca),y_train,average='weighted')\n",
    "            #print('        - tree depth: {:.3f}. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'.format(i,f1_score_train,f1_score_test))\n",
    "            forest = RandomForestClassifier(n_estimators = 200, random_state = 560)\n",
    "        forest.fit(X_pca,y_train)\n",
    "        print('    Random forest with pca data. n_estimators: 200. tree depth: {:.3f}. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'\n",
    "              .format(i,f1_score(forest.predict(X_pca),y_train,average='weighted'),f1_score(forest.predict(X_test_pca),y_test,average='weighted')))\n",
    "        if f1_score_test >= max_f1_test:\n",
    "                max_f1_test = f1_score_test\n",
    "                _f1_train = f1_score_train\n",
    "                max_n_component = j\n",
    "                tree_depth = i\n",
    "    print('The decision tree model predicting target feature {} with {:.3f} components, tree-depth of {} has the best f1-score on test set {:.3f}, on train set{:.3f}.'\n",
    "          .format(y_lst[k],max_n_component,tree_depth, max_f1_test,_f1_train))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dc3e2b",
   "metadata": {},
   "source": [
    "To predict feature DX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8079a821",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['DX']\n",
    "y_test = test['DX']\n",
    "clf = tree.DecisionTreeClassifier(random_state=580,max_depth=5,criterion='gini')\n",
    "clf = clf.fit(X_pca,y_train)\n",
    "fig = plt.figure(figsize=(20,15))\n",
    "tree.plot_tree(clf,fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0c199a",
   "metadata": {},
   "source": [
    "To predict feature DXCHANGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa8d603",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train,test = train_test_split(sleep_bio_brain_dx,random_state=586,test_size=0.25)\n",
    "X_train = train.drop(['Phase', 'RID', 'VISCODE','PTID','DX','DXCHANGE'],axis=1)\n",
    "X_test = test.drop(['Phase', 'RID', 'VISCODE','PTID','DX','DXCHANGE'],axis=1)\n",
    "feature_list = ['NPIKSEV', 'insomnia', 'OSA', 'ratio_Ventricles_bl',\n",
    "       'ratio_Hippocampus_bl', 'ratio_WholeBrain_bl', 'ratio_Entorhinal_bl',\n",
    "       'ratio_Fusiform_bl', 'ratio_ICV_bl', 'ratio_ABETA_bl', 'ratio_TAU_bl',\n",
    "       'ratio_PTAU_bl', 'Ventricles_reduction_per_year',\n",
    "       'Hippocampus_reduction_per_year', 'wholebrain_reduction_per_year',\n",
    "       'Entorhinal_reduction_per_year', 'Fusiform_reduction_per_year',\n",
    "       'ICV_reduction_per_year', 'ABETA_reduction_per_year',\n",
    "       'TAU_reduction_per_year', 'PTAU_reduction_per_year']\n",
    "y_train = train['DXCHANGE']\n",
    "y_test = test['DXCHANGE']\n",
    "clf = tree.DecisionTreeClassifier(random_state=5850,max_depth=3,criterion='gini')\n",
    "clf.fit(X_train,y_train)\n",
    "r = export_text(clf, feature_names=feature_list)\n",
    "print(r)\n",
    "fig = plt.figure(figsize=(20,15))\n",
    "tree.plot_tree(clf,fontsize=15,feature_names=feature_list)\n",
    "\n",
    "print('    Decision tree with unscaled data. tree depth: 2. f1-score on training data: {0.786} f1-score on test data: {0.606}')        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
