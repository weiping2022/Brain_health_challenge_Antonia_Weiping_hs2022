{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20f5d23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.tree import export_text\n",
    "import mglearn\n",
    "from dashboard_one import *\n",
    "from dash_model_two import *\n",
    "from feature_selection import *\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b74b94",
   "metadata": {},
   "source": [
    "### brain_volume_ratio_to_baseline_____VS_____final diagnosischanges of each patient in each phase\n",
    "\n",
    "\n",
    "#### sleep_brain_finaldxch.csv\n",
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fef6c499",
   "metadata": {},
   "outputs": [],
   "source": [
    "com_col = ['Phase', 'RID', 'VISCODE','PTID','RID_Phase']\n",
    "target = 'final_dxch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "769bd041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RID</th>\n",
       "      <th>Phase</th>\n",
       "      <th>VISCODE</th>\n",
       "      <th>PTID</th>\n",
       "      <th>RID_Phase</th>\n",
       "      <th>NPIK1</th>\n",
       "      <th>NPIK2</th>\n",
       "      <th>NPIK3</th>\n",
       "      <th>NPIK4</th>\n",
       "      <th>NPIK5</th>\n",
       "      <th>...</th>\n",
       "      <th>ratio_PTAU_bl</th>\n",
       "      <th>Ventricles_reduction_per_year</th>\n",
       "      <th>Hippocampus_reduction_per_year</th>\n",
       "      <th>wholebrain_reduction_per_year</th>\n",
       "      <th>Entorhinal_reduction_per_year</th>\n",
       "      <th>Fusiform_reduction_per_year</th>\n",
       "      <th>ICV_reduction_per_year</th>\n",
       "      <th>ABETA_reduction_per_year</th>\n",
       "      <th>TAU_reduction_per_year</th>\n",
       "      <th>PTAU_reduction_per_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>ADNI2</td>\n",
       "      <td>v06</td>\n",
       "      <td>011_S_0002</td>\n",
       "      <td>2_ADNI2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ADNI2</td>\n",
       "      <td>v11</td>\n",
       "      <td>011_S_0002</td>\n",
       "      <td>2_ADNI2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ADNI2</td>\n",
       "      <td>v21</td>\n",
       "      <td>011_S_0002</td>\n",
       "      <td>2_ADNI2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>ADNI2</td>\n",
       "      <td>v41</td>\n",
       "      <td>011_S_0002</td>\n",
       "      <td>2_ADNI2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>ADNI2</td>\n",
       "      <td>v51</td>\n",
       "      <td>011_S_0002</td>\n",
       "      <td>2_ADNI2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14740</th>\n",
       "      <td>6978</td>\n",
       "      <td>ADNI3</td>\n",
       "      <td>y1</td>\n",
       "      <td>021_S_6978</td>\n",
       "      <td>6978_ADNI3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14741</th>\n",
       "      <td>6999</td>\n",
       "      <td>ADNI3</td>\n",
       "      <td>m12</td>\n",
       "      <td>035_S_6999</td>\n",
       "      <td>6999_ADNI3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14742</th>\n",
       "      <td>6999</td>\n",
       "      <td>ADNI3</td>\n",
       "      <td>y1</td>\n",
       "      <td>035_S_6999</td>\n",
       "      <td>6999_ADNI3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14743</th>\n",
       "      <td>7000</td>\n",
       "      <td>ADNI3</td>\n",
       "      <td>m12</td>\n",
       "      <td>035_S_7000</td>\n",
       "      <td>7000_ADNI3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14744</th>\n",
       "      <td>7000</td>\n",
       "      <td>ADNI3</td>\n",
       "      <td>y1</td>\n",
       "      <td>035_S_7000</td>\n",
       "      <td>7000_ADNI3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14745 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RID  Phase VISCODE        PTID   RID_Phase  NPIK1  NPIK2  NPIK3  \\\n",
       "0         2  ADNI2     v06  011_S_0002     2_ADNI2    NaN    NaN    NaN   \n",
       "1         2  ADNI2     v11  011_S_0002     2_ADNI2    NaN    NaN    NaN   \n",
       "2         2  ADNI2     v21  011_S_0002     2_ADNI2    NaN    NaN    NaN   \n",
       "3         2  ADNI2     v41  011_S_0002     2_ADNI2    NaN    NaN    NaN   \n",
       "4         2  ADNI2     v51  011_S_0002     2_ADNI2    NaN    NaN    NaN   \n",
       "...     ...    ...     ...         ...         ...    ...    ...    ...   \n",
       "14740  6978  ADNI3      y1  021_S_6978  6978_ADNI3    NaN    NaN    NaN   \n",
       "14741  6999  ADNI3     m12  035_S_6999  6999_ADNI3    NaN    NaN    NaN   \n",
       "14742  6999  ADNI3      y1  035_S_6999  6999_ADNI3    NaN    NaN    NaN   \n",
       "14743  7000  ADNI3     m12  035_S_7000  7000_ADNI3    NaN    NaN    NaN   \n",
       "14744  7000  ADNI3      y1  035_S_7000  7000_ADNI3    NaN    NaN    NaN   \n",
       "\n",
       "       NPIK4  NPIK5  ...  ratio_PTAU_bl  Ventricles_reduction_per_year  \\\n",
       "0        NaN    NaN  ...            NaN                            NaN   \n",
       "1        NaN    NaN  ...            NaN                            NaN   \n",
       "2        NaN    NaN  ...            NaN                            NaN   \n",
       "3        NaN    NaN  ...            NaN                            NaN   \n",
       "4        NaN    NaN  ...            NaN                            NaN   \n",
       "...      ...    ...  ...            ...                            ...   \n",
       "14740    NaN    NaN  ...            NaN                            NaN   \n",
       "14741    NaN    NaN  ...            NaN                            NaN   \n",
       "14742    NaN    NaN  ...            NaN                            NaN   \n",
       "14743    NaN    NaN  ...            NaN                            NaN   \n",
       "14744    NaN    NaN  ...            NaN                            NaN   \n",
       "\n",
       "       Hippocampus_reduction_per_year  wholebrain_reduction_per_year  \\\n",
       "0                                 NaN                            NaN   \n",
       "1                                 NaN                            NaN   \n",
       "2                                 NaN                            NaN   \n",
       "3                                 NaN                            NaN   \n",
       "4                                 NaN                            NaN   \n",
       "...                               ...                            ...   \n",
       "14740                             NaN                            NaN   \n",
       "14741                             NaN                            NaN   \n",
       "14742                             NaN                            NaN   \n",
       "14743                             NaN                            NaN   \n",
       "14744                             NaN                            NaN   \n",
       "\n",
       "       Entorhinal_reduction_per_year  Fusiform_reduction_per_year  \\\n",
       "0                                NaN                          NaN   \n",
       "1                                NaN                          NaN   \n",
       "2                                NaN                          NaN   \n",
       "3                                NaN                          NaN   \n",
       "4                                NaN                          NaN   \n",
       "...                              ...                          ...   \n",
       "14740                            NaN                          NaN   \n",
       "14741                            NaN                          NaN   \n",
       "14742                            NaN                          NaN   \n",
       "14743                            NaN                          NaN   \n",
       "14744                            NaN                          NaN   \n",
       "\n",
       "       ICV_reduction_per_year  ABETA_reduction_per_year  \\\n",
       "0                         NaN                       NaN   \n",
       "1                         NaN                       NaN   \n",
       "2                         NaN                       NaN   \n",
       "3                         NaN                       NaN   \n",
       "4                         NaN                       NaN   \n",
       "...                       ...                       ...   \n",
       "14740                     NaN                       NaN   \n",
       "14741                     NaN                       NaN   \n",
       "14742                     NaN                       NaN   \n",
       "14743                     NaN                       NaN   \n",
       "14744                     NaN                       NaN   \n",
       "\n",
       "       TAU_reduction_per_year PTAU_reduction_per_year  \n",
       "0                         NaN                     NaN  \n",
       "1                         NaN                     NaN  \n",
       "2                         NaN                     NaN  \n",
       "3                         NaN                     NaN  \n",
       "4                         NaN                     NaN  \n",
       "...                       ...                     ...  \n",
       "14740                     NaN                     NaN  \n",
       "14741                     NaN                     NaN  \n",
       "14742                     NaN                     NaN  \n",
       "14743                     NaN                     NaN  \n",
       "14744                     NaN                     NaN  \n",
       "\n",
       "[14745 rows x 39 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sleep_brain_finaldxch = pd.read_csv('sleep_brain_finaldxch.csv').iloc[:,1:].drop(['NPIKSEV'],axis=1)\n",
    "sleep_brain_finaldxch = sleep_brain_finaldxch[sleep_brain_finaldxch['final_dxch'].notna()].reset_index().drop(['index'],axis=1)   # keep the rows where DXCHANGE is not nan\n",
    "sleep_brain_finaldxch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51ce40a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14745 entries, 0 to 14744\n",
      "Data columns (total 39 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   RID                             14745 non-null  int64  \n",
      " 1   Phase                           14745 non-null  object \n",
      " 2   VISCODE                         13649 non-null  object \n",
      " 3   PTID                            14745 non-null  object \n",
      " 4   RID_Phase                       14745 non-null  object \n",
      " 5   NPIK1                           884 non-null    float64\n",
      " 6   NPIK2                           883 non-null    float64\n",
      " 7   NPIK3                           882 non-null    float64\n",
      " 8   NPIK4                           882 non-null    float64\n",
      " 9   NPIK5                           882 non-null    float64\n",
      " 10  NPIK6                           883 non-null    float64\n",
      " 11  NPIK7                           883 non-null    float64\n",
      " 12  NPIK8                           882 non-null    float64\n",
      " 13  NPIK9A                          885 non-null    float64\n",
      " 14  NPIK9B                          884 non-null    float64\n",
      " 15  NPIK9C                          885 non-null    float64\n",
      " 16  NPIKTOT                         884 non-null    float64\n",
      " 17  insomnia                        9018 non-null   float64\n",
      " 18  OSA                             14745 non-null  float64\n",
      " 19  final_dxch                      14745 non-null  object \n",
      " 20  DXCHANGE                        14745 non-null  object \n",
      " 21  ratio_Ventricles_bl             5663 non-null   float64\n",
      " 22  ratio_Hippocampus_bl            4912 non-null   float64\n",
      " 23  ratio_WholeBrain_bl             5895 non-null   float64\n",
      " 24  ratio_Entorhinal_bl             4628 non-null   float64\n",
      " 25  ratio_Fusiform_bl               4628 non-null   float64\n",
      " 26  ratio_ICV_bl                    6212 non-null   float64\n",
      " 27  ratio_ABETA_bl                  838 non-null    float64\n",
      " 28  ratio_TAU_bl                    1029 non-null   float64\n",
      " 29  ratio_PTAU_bl                   717 non-null    float64\n",
      " 30  Ventricles_reduction_per_year   5663 non-null   float64\n",
      " 31  Hippocampus_reduction_per_year  4912 non-null   float64\n",
      " 32  wholebrain_reduction_per_year   5895 non-null   float64\n",
      " 33  Entorhinal_reduction_per_year   4628 non-null   float64\n",
      " 34  Fusiform_reduction_per_year     4628 non-null   float64\n",
      " 35  ICV_reduction_per_year          6212 non-null   float64\n",
      " 36  ABETA_reduction_per_year        838 non-null    float64\n",
      " 37  TAU_reduction_per_year          1029 non-null   float64\n",
      " 38  PTAU_reduction_per_year         717 non-null    float64\n",
      "dtypes: float64(32), int64(1), object(6)\n",
      "memory usage: 4.4+ MB\n"
     ]
    }
   ],
   "source": [
    "sleep_brain_finaldxch.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81696451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RID', 'Phase', 'VISCODE', 'PTID', 'RID_Phase', 'NPIK1', 'NPIK2',\n",
       "       'NPIK3', 'NPIK4', 'NPIK5', 'NPIK6', 'NPIK7', 'NPIK8', 'NPIK9A',\n",
       "       'NPIK9B', 'NPIK9C', 'NPIKTOT', 'insomnia', 'OSA', 'final_dxch',\n",
       "       'DXCHANGE', 'ratio_Ventricles_bl', 'ratio_Hippocampus_bl',\n",
       "       'ratio_WholeBrain_bl', 'ratio_Entorhinal_bl', 'ratio_Fusiform_bl',\n",
       "       'ratio_ICV_bl', 'ratio_ABETA_bl', 'ratio_TAU_bl', 'ratio_PTAU_bl',\n",
       "       'Ventricles_reduction_per_year', 'Hippocampus_reduction_per_year',\n",
       "       'wholebrain_reduction_per_year', 'Entorhinal_reduction_per_year',\n",
       "       'Fusiform_reduction_per_year', 'ICV_reduction_per_year',\n",
       "       'ABETA_reduction_per_year', 'TAU_reduction_per_year',\n",
       "       'PTAU_reduction_per_year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sleep_brain_finaldxch.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1b7f3e",
   "metadata": {},
   "source": [
    "### brain_biomarker______VS______final_dxch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9b829bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "col_lst = [ 'final_dxch','ratio_Ventricles_bl',\n",
    "       'ratio_Hippocampus_bl', 'ratio_WholeBrain_bl', 'ratio_Entorhinal_bl',\n",
    "       'ratio_Fusiform_bl', 'Ventricles_reduction_per_year',\n",
    "       'Hippocampus_reduction_per_year', 'wholebrain_reduction_per_year',\n",
    "       'Entorhinal_reduction_per_year', 'Fusiform_reduction_per_year',\n",
    "       'ICV_reduction_per_year']\n",
    "bio_lst = [ 'final_dxch','ratio_ABETA_bl', 'ratio_TAU_bl','ratio_PTAU_bl']\n",
    "brain_dxch = sleep_brain_finaldxch[com_col + col_lst].set_index(com_col).dropna(how='any',axis=0).reset_index()\n",
    "#biomarkers to dxch\n",
    "bio_dxch = sleep_brain_finaldxch[com_col + bio_lst].set_index(com_col).dropna(how='any',axis=0).reset_index()\n",
    "df = brain_dxch.copy()\n",
    "df2 = brain_dxch.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6726d1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['final_dxch'] = df2['final_dxch'].replace({'CN-MCI':'CN-AD','MCI-MCI':'MCI-AD'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c75224ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Phase                             0\n",
       "RID                               0\n",
       "VISCODE                           0\n",
       "PTID                              0\n",
       "RID_Phase                         0\n",
       "final_dxch                        0\n",
       "ratio_Ventricles_bl               0\n",
       "ratio_Hippocampus_bl              0\n",
       "ratio_WholeBrain_bl               0\n",
       "ratio_Entorhinal_bl               0\n",
       "ratio_Fusiform_bl                 0\n",
       "Ventricles_reduction_per_year     0\n",
       "Hippocampus_reduction_per_year    0\n",
       "wholebrain_reduction_per_year     0\n",
       "Entorhinal_reduction_per_year     0\n",
       "Fusiform_reduction_per_year       0\n",
       "ICV_reduction_per_year            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df.isna())   # check nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2af70e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phase</th>\n",
       "      <th>RID</th>\n",
       "      <th>VISCODE</th>\n",
       "      <th>PTID</th>\n",
       "      <th>RID_Phase</th>\n",
       "      <th>ratio_Ventricles_bl</th>\n",
       "      <th>ratio_Hippocampus_bl</th>\n",
       "      <th>ratio_WholeBrain_bl</th>\n",
       "      <th>ratio_Entorhinal_bl</th>\n",
       "      <th>ratio_Fusiform_bl</th>\n",
       "      <th>Ventricles_reduction_per_year</th>\n",
       "      <th>Hippocampus_reduction_per_year</th>\n",
       "      <th>wholebrain_reduction_per_year</th>\n",
       "      <th>Entorhinal_reduction_per_year</th>\n",
       "      <th>Fusiform_reduction_per_year</th>\n",
       "      <th>ICV_reduction_per_year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>final_dxch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AD-AD</th>\n",
       "      <td>493</td>\n",
       "      <td>493</td>\n",
       "      <td>493</td>\n",
       "      <td>493</td>\n",
       "      <td>493</td>\n",
       "      <td>493</td>\n",
       "      <td>493</td>\n",
       "      <td>493</td>\n",
       "      <td>493</td>\n",
       "      <td>493</td>\n",
       "      <td>493</td>\n",
       "      <td>493</td>\n",
       "      <td>493</td>\n",
       "      <td>493</td>\n",
       "      <td>493</td>\n",
       "      <td>493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AD-MCI</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CN-AD</th>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CN-CN</th>\n",
       "      <td>1289</td>\n",
       "      <td>1289</td>\n",
       "      <td>1289</td>\n",
       "      <td>1289</td>\n",
       "      <td>1289</td>\n",
       "      <td>1289</td>\n",
       "      <td>1289</td>\n",
       "      <td>1289</td>\n",
       "      <td>1289</td>\n",
       "      <td>1289</td>\n",
       "      <td>1289</td>\n",
       "      <td>1289</td>\n",
       "      <td>1289</td>\n",
       "      <td>1289</td>\n",
       "      <td>1289</td>\n",
       "      <td>1289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCI-AD</th>\n",
       "      <td>2028</td>\n",
       "      <td>2028</td>\n",
       "      <td>2028</td>\n",
       "      <td>2028</td>\n",
       "      <td>2028</td>\n",
       "      <td>2028</td>\n",
       "      <td>2028</td>\n",
       "      <td>2028</td>\n",
       "      <td>2028</td>\n",
       "      <td>2028</td>\n",
       "      <td>2028</td>\n",
       "      <td>2028</td>\n",
       "      <td>2028</td>\n",
       "      <td>2028</td>\n",
       "      <td>2028</td>\n",
       "      <td>2028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCI-CN</th>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Phase   RID  VISCODE  PTID  RID_Phase  ratio_Ventricles_bl  \\\n",
       "final_dxch                                                               \n",
       "AD-AD         493   493      493   493        493                  493   \n",
       "AD-MCI          2     2        2     2          2                    2   \n",
       "CN-AD         292   292      292   292        292                  292   \n",
       "CN-CN        1289  1289     1289  1289       1289                 1289   \n",
       "MCI-AD       2028  2028     2028  2028       2028                 2028   \n",
       "MCI-CN        166   166      166   166        166                  166   \n",
       "\n",
       "            ratio_Hippocampus_bl  ratio_WholeBrain_bl  ratio_Entorhinal_bl  \\\n",
       "final_dxch                                                                   \n",
       "AD-AD                        493                  493                  493   \n",
       "AD-MCI                         2                    2                    2   \n",
       "CN-AD                        292                  292                  292   \n",
       "CN-CN                       1289                 1289                 1289   \n",
       "MCI-AD                      2028                 2028                 2028   \n",
       "MCI-CN                       166                  166                  166   \n",
       "\n",
       "            ratio_Fusiform_bl  Ventricles_reduction_per_year  \\\n",
       "final_dxch                                                     \n",
       "AD-AD                     493                            493   \n",
       "AD-MCI                      2                              2   \n",
       "CN-AD                     292                            292   \n",
       "CN-CN                    1289                           1289   \n",
       "MCI-AD                   2028                           2028   \n",
       "MCI-CN                    166                            166   \n",
       "\n",
       "            Hippocampus_reduction_per_year  wholebrain_reduction_per_year  \\\n",
       "final_dxch                                                                  \n",
       "AD-AD                                  493                            493   \n",
       "AD-MCI                                   2                              2   \n",
       "CN-AD                                  292                            292   \n",
       "CN-CN                                 1289                           1289   \n",
       "MCI-AD                                2028                           2028   \n",
       "MCI-CN                                 166                            166   \n",
       "\n",
       "            Entorhinal_reduction_per_year  Fusiform_reduction_per_year  \\\n",
       "final_dxch                                                               \n",
       "AD-AD                                 493                          493   \n",
       "AD-MCI                                  2                            2   \n",
       "CN-AD                                 292                          292   \n",
       "CN-CN                                1289                         1289   \n",
       "MCI-AD                               2028                         2028   \n",
       "MCI-CN                                166                          166   \n",
       "\n",
       "            ICV_reduction_per_year  \n",
       "final_dxch                          \n",
       "AD-AD                          493  \n",
       "AD-MCI                           2  \n",
       "CN-AD                          292  \n",
       "CN-CN                         1289  \n",
       "MCI-AD                        2028  \n",
       "MCI-CN                         166  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.groupby(target).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af84a781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phase</th>\n",
       "      <th>RID</th>\n",
       "      <th>VISCODE</th>\n",
       "      <th>PTID</th>\n",
       "      <th>RID_Phase</th>\n",
       "      <th>ratio_Ventricles_bl</th>\n",
       "      <th>ratio_Hippocampus_bl</th>\n",
       "      <th>ratio_WholeBrain_bl</th>\n",
       "      <th>ratio_Entorhinal_bl</th>\n",
       "      <th>ratio_Fusiform_bl</th>\n",
       "      <th>Ventricles_reduction_per_year</th>\n",
       "      <th>Hippocampus_reduction_per_year</th>\n",
       "      <th>wholebrain_reduction_per_year</th>\n",
       "      <th>Entorhinal_reduction_per_year</th>\n",
       "      <th>Fusiform_reduction_per_year</th>\n",
       "      <th>ICV_reduction_per_year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>final_dxch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AD-AD</th>\n",
       "      <td>493</td>\n",
       "      <td>493</td>\n",
       "      <td>493</td>\n",
       "      <td>493</td>\n",
       "      <td>493</td>\n",
       "      <td>493</td>\n",
       "      <td>493</td>\n",
       "      <td>493</td>\n",
       "      <td>493</td>\n",
       "      <td>493</td>\n",
       "      <td>493</td>\n",
       "      <td>493</td>\n",
       "      <td>493</td>\n",
       "      <td>493</td>\n",
       "      <td>493</td>\n",
       "      <td>493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AD-MCI</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CN-AD</th>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CN-CN</th>\n",
       "      <td>1289</td>\n",
       "      <td>1289</td>\n",
       "      <td>1289</td>\n",
       "      <td>1289</td>\n",
       "      <td>1289</td>\n",
       "      <td>1289</td>\n",
       "      <td>1289</td>\n",
       "      <td>1289</td>\n",
       "      <td>1289</td>\n",
       "      <td>1289</td>\n",
       "      <td>1289</td>\n",
       "      <td>1289</td>\n",
       "      <td>1289</td>\n",
       "      <td>1289</td>\n",
       "      <td>1289</td>\n",
       "      <td>1289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CN-MCI</th>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCI-AD</th>\n",
       "      <td>867</td>\n",
       "      <td>867</td>\n",
       "      <td>867</td>\n",
       "      <td>867</td>\n",
       "      <td>867</td>\n",
       "      <td>867</td>\n",
       "      <td>867</td>\n",
       "      <td>867</td>\n",
       "      <td>867</td>\n",
       "      <td>867</td>\n",
       "      <td>867</td>\n",
       "      <td>867</td>\n",
       "      <td>867</td>\n",
       "      <td>867</td>\n",
       "      <td>867</td>\n",
       "      <td>867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCI-CN</th>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCI-MCI</th>\n",
       "      <td>1161</td>\n",
       "      <td>1161</td>\n",
       "      <td>1161</td>\n",
       "      <td>1161</td>\n",
       "      <td>1161</td>\n",
       "      <td>1161</td>\n",
       "      <td>1161</td>\n",
       "      <td>1161</td>\n",
       "      <td>1161</td>\n",
       "      <td>1161</td>\n",
       "      <td>1161</td>\n",
       "      <td>1161</td>\n",
       "      <td>1161</td>\n",
       "      <td>1161</td>\n",
       "      <td>1161</td>\n",
       "      <td>1161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Phase   RID  VISCODE  PTID  RID_Phase  ratio_Ventricles_bl  \\\n",
       "final_dxch                                                               \n",
       "AD-AD         493   493      493   493        493                  493   \n",
       "AD-MCI          2     2        2     2          2                    2   \n",
       "CN-AD          80    80       80    80         80                   80   \n",
       "CN-CN        1289  1289     1289  1289       1289                 1289   \n",
       "CN-MCI        212   212      212   212        212                  212   \n",
       "MCI-AD        867   867      867   867        867                  867   \n",
       "MCI-CN        166   166      166   166        166                  166   \n",
       "MCI-MCI      1161  1161     1161  1161       1161                 1161   \n",
       "\n",
       "            ratio_Hippocampus_bl  ratio_WholeBrain_bl  ratio_Entorhinal_bl  \\\n",
       "final_dxch                                                                   \n",
       "AD-AD                        493                  493                  493   \n",
       "AD-MCI                         2                    2                    2   \n",
       "CN-AD                         80                   80                   80   \n",
       "CN-CN                       1289                 1289                 1289   \n",
       "CN-MCI                       212                  212                  212   \n",
       "MCI-AD                       867                  867                  867   \n",
       "MCI-CN                       166                  166                  166   \n",
       "MCI-MCI                     1161                 1161                 1161   \n",
       "\n",
       "            ratio_Fusiform_bl  Ventricles_reduction_per_year  \\\n",
       "final_dxch                                                     \n",
       "AD-AD                     493                            493   \n",
       "AD-MCI                      2                              2   \n",
       "CN-AD                      80                             80   \n",
       "CN-CN                    1289                           1289   \n",
       "CN-MCI                    212                            212   \n",
       "MCI-AD                    867                            867   \n",
       "MCI-CN                    166                            166   \n",
       "MCI-MCI                  1161                           1161   \n",
       "\n",
       "            Hippocampus_reduction_per_year  wholebrain_reduction_per_year  \\\n",
       "final_dxch                                                                  \n",
       "AD-AD                                  493                            493   \n",
       "AD-MCI                                   2                              2   \n",
       "CN-AD                                   80                             80   \n",
       "CN-CN                                 1289                           1289   \n",
       "CN-MCI                                 212                            212   \n",
       "MCI-AD                                 867                            867   \n",
       "MCI-CN                                 166                            166   \n",
       "MCI-MCI                               1161                           1161   \n",
       "\n",
       "            Entorhinal_reduction_per_year  Fusiform_reduction_per_year  \\\n",
       "final_dxch                                                               \n",
       "AD-AD                                 493                          493   \n",
       "AD-MCI                                  2                            2   \n",
       "CN-AD                                  80                           80   \n",
       "CN-CN                                1289                         1289   \n",
       "CN-MCI                                212                          212   \n",
       "MCI-AD                                867                          867   \n",
       "MCI-CN                                166                          166   \n",
       "MCI-MCI                              1161                         1161   \n",
       "\n",
       "            ICV_reduction_per_year  \n",
       "final_dxch                          \n",
       "AD-AD                          493  \n",
       "AD-MCI                           2  \n",
       "CN-AD                           80  \n",
       "CN-CN                         1289  \n",
       "CN-MCI                         212  \n",
       "MCI-AD                         867  \n",
       "MCI-CN                         166  \n",
       "MCI-MCI                       1161  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(target).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae317f9",
   "metadata": {},
   "source": [
    "- unselect the AD-MCI. Because TOO FEW data.\n",
    "- the possible groups: ['AD-AD', 'CN-AD', 'CN-CN', 'CN-MCI', 'MCI-AD', 'MCI-CN','MCI-MCI']\n",
    "- ['CN-AD', 'CN-CN', 'CN-MCI'] \n",
    "- ['MCI-AD', 'MCI-CN','MCI-MCI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "173991a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2194, 17)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_2 = df2.loc[df2[target].isin(['CN-AD', 'CN-CN'])].reset_index().drop(['index'],axis=1)\n",
    "df2_2mci = df2.loc[df2[target].isin(['MCI-AD', 'MCI-CN'])].reset_index().drop(['index'],axis=1)\n",
    "df2_2mci.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ca8ee12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1369, 17)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2cn = df.loc[df[target].isin(['CN-AD', 'CN-CN'])].reset_index().drop(['index'],axis=1)\n",
    "df_2cn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "536cbc37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1581, 17)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3cn = df.loc[df[target].isin(['CN-AD', 'CN-CN', 'CN-MCI'])].reset_index().drop(['index'],axis=1)\n",
    "df_3cn.shape     # works not that good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c51e26d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1033, 17)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2mci = df.loc[df[target].isin(['MCI-AD', 'MCI-CN'])].reset_index().drop(['index'],axis=1)\n",
    "df_2mci.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b631153b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2194, 17)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3mci = df.loc[df[target].isin(['MCI-AD', 'MCI-CN','MCI-MCI'])].reset_index().drop(['index'],axis=1)\n",
    "df_3mci.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39783bf",
   "metadata": {},
   "source": [
    "### undersampling and modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdd62ca",
   "metadata": {},
   "source": [
    "- functions\n",
    "    - models(df,drop_lst,target) : under sampling, split, scale, pca, models\n",
    "    - cv_models(df,drop_lst,target,k): under sampling, NOT SPLIT, scale, pca, models with cross-validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c356c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_lst = ['Phase', 'RID', 'VISCODE', 'PTID','RID_Phase',target]\n",
    "\n",
    "k=10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2415a97",
   "metadata": {},
   "source": [
    "## 'CN-AD': 292, 'CN-CN': 292  (CN-AD include the renamed CN-MCI)\n",
    "- not renamed-mix is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a31f77bf",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After undersampling data size is 584 ; Resampled dataset shape Counter({'CN-AD': 292, 'CN-CN': 292})\n",
      "\n",
      "7 principle components are needed to explain 90% of the data\n",
      "\n",
      "Output dataframes sequence: X_train,X_test,X_train_scaled,X_test_scaled,X_train_pca,X_test_pca,y_train,y_test\n",
      "- Using original dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, Training set f1-score:0.675, Test set f1-score: 0.632\n",
      "          - saga_L1, Training set f1-score:0.675, Test set f1-score: 0.632\n",
      "          - newton-cg_L2, Training set f1-score:0.675, Test set f1-score: 0.632\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, Training set f1-score:0.675, Test set f1-score: 0.632\n",
      "          - saga_L1, Training set f1-score:0.675, Test set f1-score: 0.632\n",
      "          - newton-cg_L2, Training set f1-score:0.675, Test set f1-score: 0.632\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, Training set f1-score:0.598, Test set f1-score: 0.577\n",
      "          - saga_L1, Training set f1-score:0.675, Test set f1-score: 0.632\n",
      "          - newton-cg_L2, Training set f1-score:0.598, Test set f1-score: 0.577\n",
      "       - C = 1\n",
      "          - lbfgs_L2, Training set f1-score:0.582, Test set f1-score: 0.650\n",
      "          - saga_L1, Training set f1-score:0.579, Test set f1-score: 0.625\n",
      "          - newton-cg_L2, Training set f1-score:0.582, Test set f1-score: 0.650\n",
      "       - C = 10\n",
      "          - lbfgs_L2, Training set f1-score:0.580, Test set f1-score: 0.658\n",
      "          - saga_L1, Training set f1-score:0.585, Test set f1-score: 0.649\n",
      "          - newton-cg_L2, Training set f1-score:0.580, Test set f1-score: 0.658\n",
      "       - C = 100\n",
      "          - lbfgs_L2, Training set f1-score:0.586, Test set f1-score: 0.658\n",
      "          - saga_L1, Training set f1-score:0.603, Test set f1-score: 0.666\n",
      "          - newton-cg_L2, Training set f1-score:0.588, Test set f1-score: 0.658\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, Training set f1-score:0.601, Test set f1-score: 0.675\n",
      "          - saga_L1, Training set f1-score:0.598, Test set f1-score: 0.675\n",
      "          - newton-cg_L2, Training set f1-score:0.601, Test set f1-score: 0.675\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. f1-score on training data: 0.641 f1-score on test data: 0.615\n",
      "          - tree depth: 2.000. f1-score on training data: 0.651 f1-score on test data: 0.615\n",
      "          - tree depth: 3.000. f1-score on training data: 0.639 f1-score on test data: 0.651\n",
      "          - tree depth: 4.000. f1-score on training data: 0.682 f1-score on test data: 0.654\n",
      "          - tree depth: 5.000. f1-score on training data: 0.726 f1-score on test data: 0.581\n",
      "          - tree depth: 6.000. f1-score on training data: 0.747 f1-score on test data: 0.581\n",
      "          - tree depth: 7.000. f1-score on training data: 0.801 f1-score on test data: 0.565\n",
      "          - tree depth: 8.000. f1-score on training data: 0.844 f1-score on test data: 0.556\n",
      "          - tree depth: 9.000. f1-score on training data: 0.872 f1-score on test data: 0.521\n",
      "          - tree depth: 10.000. f1-score on training data: 0.906 f1-score on test data: 0.564\n",
      "          - tree depth: 11.000. f1-score on training data: 0.940 f1-score on test data: 0.556\n",
      "          - tree depth: 12.000. f1-score on training data: 0.961 f1-score on test data: 0.521\n",
      "          - tree depth: 13.000. f1-score on training data: 0.983 f1-score on test data: 0.521\n",
      "          - tree depth: 14.000. f1-score on training data: 0.989 f1-score on test data: 0.521\n",
      "    - Random forest\n",
      "          - 5trees. f1-score on training data: 0.949 f1-score on test data: 0.546\n",
      "          - 10trees. f1-score on training data: 0.976 f1-score on test data: 0.607\n",
      "          - 15trees. f1-score on training data: 0.996 f1-score on test data: 0.555\n",
      "          - 20trees. f1-score on training data: 0.996 f1-score on test data: 0.589\n",
      "          - 25trees. f1-score on training data: 1.000 f1-score on test data: 0.590\n",
      "          - 30trees. f1-score on training data: 1.000 f1-score on test data: 0.598\n",
      "          - 35trees. f1-score on training data: 1.000 f1-score on test data: 0.598\n",
      "          - 40trees. f1-score on training data: 1.000 f1-score on test data: 0.581\n",
      "          - 45trees. f1-score on training data: 1.000 f1-score on test data: 0.581\n",
      "          - 50trees. f1-score on training data: 1.000 f1-score on test data: 0.589\n",
      "          - 55trees. f1-score on training data: 1.000 f1-score on test data: 0.581\n",
      "          - 60trees. f1-score on training data: 1.000 f1-score on test data: 0.598\n",
      "          - 65trees. f1-score on training data: 1.000 f1-score on test data: 0.590\n",
      "          - 70trees. f1-score on training data: 1.000 f1-score on test data: 0.590\n",
      "          - 75trees. f1-score on training data: 1.000 f1-score on test data: 0.581\n",
      "          - 80trees. f1-score on training data: 1.000 f1-score on test data: 0.581\n",
      "          - 85trees. f1-score on training data: 1.000 f1-score on test data: 0.607\n",
      "          - 90trees. f1-score on training data: 1.000 f1-score on test data: 0.598\n",
      "          - 95trees. f1-score on training data: 1.000 f1-score on test data: 0.607\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. f1-score on training data: 0.773 f1-score on test data: 0.607\n",
      "          - hidden layer size[20, 20]. f1-score on training data: 0.776 f1-score on test data: 0.581\n",
      "- Using scaled dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, Training set f1-score:0.616, Test set f1-score: 0.626\n",
      "          - saga_L1, Training set f1-score:0.675, Test set f1-score: 0.632\n",
      "          - newton-cg_L2, Training set f1-score:0.616, Test set f1-score: 0.626\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, Training set f1-score:0.599, Test set f1-score: 0.667\n",
      "          - saga_L1, Training set f1-score:0.658, Test set f1-score: 0.700\n",
      "          - newton-cg_L2, Training set f1-score:0.599, Test set f1-score: 0.667\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, Training set f1-score:0.590, Test set f1-score: 0.658\n",
      "          - saga_L1, Training set f1-score:0.579, Test set f1-score: 0.632\n",
      "          - newton-cg_L2, Training set f1-score:0.590, Test set f1-score: 0.658\n",
      "       - C = 1\n",
      "          - lbfgs_L2, Training set f1-score:0.601, Test set f1-score: 0.675\n",
      "          - saga_L1, Training set f1-score:0.598, Test set f1-score: 0.675\n",
      "          - newton-cg_L2, Training set f1-score:0.601, Test set f1-score: 0.675\n",
      "       - C = 10\n",
      "          - lbfgs_L2, Training set f1-score:0.598, Test set f1-score: 0.675\n",
      "          - saga_L1, Training set f1-score:0.601, Test set f1-score: 0.675\n",
      "          - newton-cg_L2, Training set f1-score:0.598, Test set f1-score: 0.675\n",
      "       - C = 100\n",
      "          - lbfgs_L2, Training set f1-score:0.598, Test set f1-score: 0.675\n",
      "          - saga_L1, Training set f1-score:0.598, Test set f1-score: 0.675\n",
      "          - newton-cg_L2, Training set f1-score:0.598, Test set f1-score: 0.675\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, Training set f1-score:0.598, Test set f1-score: 0.675\n",
      "          - saga_L1, Training set f1-score:0.598, Test set f1-score: 0.675\n",
      "          - newton-cg_L2, Training set f1-score:0.598, Test set f1-score: 0.675\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. f1-score on training data: 0.641 f1-score on test data: 0.615\n",
      "          - tree depth: 2.000. f1-score on training data: 0.651 f1-score on test data: 0.615\n",
      "          - tree depth: 3.000. f1-score on training data: 0.639 f1-score on test data: 0.651\n",
      "          - tree depth: 4.000. f1-score on training data: 0.682 f1-score on test data: 0.654\n",
      "          - tree depth: 5.000. f1-score on training data: 0.726 f1-score on test data: 0.581\n",
      "          - tree depth: 6.000. f1-score on training data: 0.747 f1-score on test data: 0.581\n",
      "          - tree depth: 7.000. f1-score on training data: 0.801 f1-score on test data: 0.565\n",
      "          - tree depth: 8.000. f1-score on training data: 0.844 f1-score on test data: 0.556\n",
      "          - tree depth: 9.000. f1-score on training data: 0.872 f1-score on test data: 0.521\n",
      "          - tree depth: 10.000. f1-score on training data: 0.906 f1-score on test data: 0.564\n",
      "          - tree depth: 11.000. f1-score on training data: 0.940 f1-score on test data: 0.556\n",
      "          - tree depth: 12.000. f1-score on training data: 0.961 f1-score on test data: 0.521\n",
      "          - tree depth: 13.000. f1-score on training data: 0.983 f1-score on test data: 0.521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          - tree depth: 14.000. f1-score on training data: 0.989 f1-score on test data: 0.521\n",
      "    - Random forest\n",
      "          - 5trees. f1-score on training data: 0.949 f1-score on test data: 0.546\n",
      "          - 10trees. f1-score on training data: 0.976 f1-score on test data: 0.607\n",
      "          - 15trees. f1-score on training data: 0.996 f1-score on test data: 0.555\n",
      "          - 20trees. f1-score on training data: 0.996 f1-score on test data: 0.589\n",
      "          - 25trees. f1-score on training data: 1.000 f1-score on test data: 0.590\n",
      "          - 30trees. f1-score on training data: 1.000 f1-score on test data: 0.598\n",
      "          - 35trees. f1-score on training data: 1.000 f1-score on test data: 0.598\n",
      "          - 40trees. f1-score on training data: 1.000 f1-score on test data: 0.581\n",
      "          - 45trees. f1-score on training data: 1.000 f1-score on test data: 0.581\n",
      "          - 50trees. f1-score on training data: 1.000 f1-score on test data: 0.589\n",
      "          - 55trees. f1-score on training data: 1.000 f1-score on test data: 0.581\n",
      "          - 60trees. f1-score on training data: 1.000 f1-score on test data: 0.598\n",
      "          - 65trees. f1-score on training data: 1.000 f1-score on test data: 0.590\n",
      "          - 70trees. f1-score on training data: 1.000 f1-score on test data: 0.590\n",
      "          - 75trees. f1-score on training data: 1.000 f1-score on test data: 0.581\n",
      "          - 80trees. f1-score on training data: 1.000 f1-score on test data: 0.581\n",
      "          - 85trees. f1-score on training data: 1.000 f1-score on test data: 0.607\n",
      "          - 90trees. f1-score on training data: 1.000 f1-score on test data: 0.598\n",
      "          - 95trees. f1-score on training data: 1.000 f1-score on test data: 0.607\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. f1-score on training data: 1.000 f1-score on test data: 0.598\n",
      "          - hidden layer size[20, 20]. f1-score on training data: 1.000 f1-score on test data: 0.557\n",
      "- Using 7 pca-components:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, Training set f1-score:0.624, Test set f1-score: 0.636\n",
      "          - saga_L1, Training set f1-score:0.675, Test set f1-score: 0.632\n",
      "          - newton-cg_L2, Training set f1-score:0.624, Test set f1-score: 0.636\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, Training set f1-score:0.596, Test set f1-score: 0.676\n",
      "          - saga_L1, Training set f1-score:0.675, Test set f1-score: 0.632\n",
      "          - newton-cg_L2, Training set f1-score:0.596, Test set f1-score: 0.676\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, Training set f1-score:0.593, Test set f1-score: 0.641\n",
      "          - saga_L1, Training set f1-score:0.586, Test set f1-score: 0.668\n",
      "          - newton-cg_L2, Training set f1-score:0.593, Test set f1-score: 0.641\n",
      "       - C = 1\n",
      "          - lbfgs_L2, Training set f1-score:0.595, Test set f1-score: 0.633\n",
      "          - saga_L1, Training set f1-score:0.598, Test set f1-score: 0.641\n",
      "          - newton-cg_L2, Training set f1-score:0.595, Test set f1-score: 0.633\n",
      "       - C = 10\n",
      "          - lbfgs_L2, Training set f1-score:0.595, Test set f1-score: 0.633\n",
      "          - saga_L1, Training set f1-score:0.595, Test set f1-score: 0.633\n",
      "          - newton-cg_L2, Training set f1-score:0.595, Test set f1-score: 0.633\n",
      "       - C = 100\n",
      "          - lbfgs_L2, Training set f1-score:0.595, Test set f1-score: 0.633\n",
      "          - saga_L1, Training set f1-score:0.595, Test set f1-score: 0.633\n",
      "          - newton-cg_L2, Training set f1-score:0.595, Test set f1-score: 0.633\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, Training set f1-score:0.595, Test set f1-score: 0.633\n",
      "          - saga_L1, Training set f1-score:0.595, Test set f1-score: 0.633\n",
      "          - newton-cg_L2, Training set f1-score:0.595, Test set f1-score: 0.633\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. f1-score on training data: 0.618 f1-score on test data: 0.566\n",
      "          - tree depth: 2.000. f1-score on training data: 0.606 f1-score on test data: 0.590\n",
      "          - tree depth: 3.000. f1-score on training data: 0.662 f1-score on test data: 0.568\n",
      "          - tree depth: 4.000. f1-score on training data: 0.700 f1-score on test data: 0.554\n",
      "          - tree depth: 5.000. f1-score on training data: 0.727 f1-score on test data: 0.538\n",
      "          - tree depth: 6.000. f1-score on training data: 0.754 f1-score on test data: 0.536\n",
      "          - tree depth: 7.000. f1-score on training data: 0.802 f1-score on test data: 0.550\n",
      "          - tree depth: 8.000. f1-score on training data: 0.862 f1-score on test data: 0.533\n",
      "          - tree depth: 9.000. f1-score on training data: 0.891 f1-score on test data: 0.549\n",
      "          - tree depth: 10.000. f1-score on training data: 0.921 f1-score on test data: 0.531\n",
      "          - tree depth: 11.000. f1-score on training data: 0.951 f1-score on test data: 0.538\n",
      "          - tree depth: 12.000. f1-score on training data: 0.976 f1-score on test data: 0.555\n",
      "          - tree depth: 13.000. f1-score on training data: 0.981 f1-score on test data: 0.546\n",
      "          - tree depth: 14.000. f1-score on training data: 0.985 f1-score on test data: 0.513\n",
      "    - Random forest\n",
      "          - 5trees. f1-score on training data: 0.927 f1-score on test data: 0.530\n",
      "          - 10trees. f1-score on training data: 0.983 f1-score on test data: 0.572\n",
      "          - 15trees. f1-score on training data: 0.998 f1-score on test data: 0.584\n",
      "          - 20trees. f1-score on training data: 0.998 f1-score on test data: 0.606\n",
      "          - 25trees. f1-score on training data: 0.998 f1-score on test data: 0.572\n",
      "          - 30trees. f1-score on training data: 1.000 f1-score on test data: 0.590\n",
      "          - 35trees. f1-score on training data: 1.000 f1-score on test data: 0.581\n",
      "          - 40trees. f1-score on training data: 1.000 f1-score on test data: 0.564\n",
      "          - 45trees. f1-score on training data: 1.000 f1-score on test data: 0.590\n",
      "          - 50trees. f1-score on training data: 1.000 f1-score on test data: 0.581\n",
      "          - 55trees. f1-score on training data: 1.000 f1-score on test data: 0.572\n",
      "          - 60trees. f1-score on training data: 1.000 f1-score on test data: 0.555\n",
      "          - 65trees. f1-score on training data: 1.000 f1-score on test data: 0.572\n",
      "          - 70trees. f1-score on training data: 1.000 f1-score on test data: 0.563\n",
      "          - 75trees. f1-score on training data: 1.000 f1-score on test data: 0.555\n",
      "          - 80trees. f1-score on training data: 1.000 f1-score on test data: 0.564\n",
      "          - 85trees. f1-score on training data: 1.000 f1-score on test data: 0.547\n",
      "          - 90trees. f1-score on training data: 1.000 f1-score on test data: 0.538\n",
      "          - 95trees. f1-score on training data: 1.000 f1-score on test data: 0.564\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. f1-score on training data: 1.000 f1-score on test data: 0.559\n",
      "          - hidden layer size[20, 20]. f1-score on training data: 1.000 f1-score on test data: 0.615\n"
     ]
    }
   ],
   "source": [
    "models(df2_2,drop_lst,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916eb3f2",
   "metadata": {},
   "source": [
    "# - ''CN-AD': 80, 'CN-CN': 80"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5895d717",
   "metadata": {},
   "source": [
    "\n",
    "- unscaled data RandomForest 25trees. f1-score on training data: 1.000 f1-score on test data: 0.690"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad1e3a17",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After undersampling data size is 160 ; Resampled dataset shape Counter({'CN-AD': 80, 'CN-CN': 80})\n",
      "\n",
      "3 principle components are needed to explain 90% of the data\n",
      "\n",
      "Output dataframes sequence: X_train,X_test,X_train_scaled,X_test_scaled,X_train_pca,X_test_pca,y_train,y_test\n",
      "- Using original dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, Training set f1-score:0.674, Test set f1-score: 0.638\n",
      "          - saga_L1, Training set f1-score:0.674, Test set f1-score: 0.638\n",
      "          - newton-cg_L2, Training set f1-score:0.674, Test set f1-score: 0.638\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, Training set f1-score:0.674, Test set f1-score: 0.590\n",
      "          - saga_L1, Training set f1-score:0.674, Test set f1-score: 0.638\n",
      "          - newton-cg_L2, Training set f1-score:0.674, Test set f1-score: 0.590\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, Training set f1-score:0.559, Test set f1-score: 0.656\n",
      "          - saga_L1, Training set f1-score:0.674, Test set f1-score: 0.638\n",
      "          - newton-cg_L2, Training set f1-score:0.559, Test set f1-score: 0.656\n",
      "       - C = 1\n",
      "          - lbfgs_L2, Training set f1-score:0.657, Test set f1-score: 0.720\n",
      "          - saga_L1, Training set f1-score:0.571, Test set f1-score: 0.657\n",
      "          - newton-cg_L2, Training set f1-score:0.657, Test set f1-score: 0.720\n",
      "       - C = 10\n",
      "          - lbfgs_L2, Training set f1-score:0.642, Test set f1-score: 0.656\n",
      "          - saga_L1, Training set f1-score:0.680, Test set f1-score: 0.625\n",
      "          - newton-cg_L2, Training set f1-score:0.642, Test set f1-score: 0.656\n",
      "       - C = 100\n",
      "          - lbfgs_L2, Training set f1-score:0.672, Test set f1-score: 0.625\n",
      "          - saga_L1, Training set f1-score:0.688, Test set f1-score: 0.625\n",
      "          - newton-cg_L2, Training set f1-score:0.672, Test set f1-score: 0.625\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, Training set f1-score:0.688, Test set f1-score: 0.625\n",
      "          - saga_L1, Training set f1-score:0.688, Test set f1-score: 0.625\n",
      "          - newton-cg_L2, Training set f1-score:0.688, Test set f1-score: 0.625\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. f1-score on training data: 0.692 f1-score on test data: 0.634\n",
      "          - tree depth: 2.000. f1-score on training data: 0.692 f1-score on test data: 0.634\n",
      "          - tree depth: 3.000. f1-score on training data: 0.806 f1-score on test data: 0.538\n",
      "          - tree depth: 4.000. f1-score on training data: 0.891 f1-score on test data: 0.548\n",
      "          - tree depth: 5.000. f1-score on training data: 0.938 f1-score on test data: 0.500\n",
      "          - tree depth: 6.000. f1-score on training data: 0.969 f1-score on test data: 0.593\n",
      "          - tree depth: 7.000. f1-score on training data: 0.969 f1-score on test data: 0.562\n",
      "          - tree depth: 8.000. f1-score on training data: 0.984 f1-score on test data: 0.562\n",
      "          - tree depth: 9.000. f1-score on training data: 0.992 f1-score on test data: 0.593\n",
      "          - tree depth: 10.000. f1-score on training data: 0.992 f1-score on test data: 0.593\n",
      "          - tree depth: 11.000. f1-score on training data: 1.000 f1-score on test data: 0.562\n",
      "          - tree depth: 12.000. f1-score on training data: 1.000 f1-score on test data: 0.562\n",
      "          - tree depth: 13.000. f1-score on training data: 1.000 f1-score on test data: 0.562\n",
      "          - tree depth: 14.000. f1-score on training data: 1.000 f1-score on test data: 0.562\n",
      "    - Random forest\n",
      "          - 5trees. f1-score on training data: 0.930 f1-score on test data: 0.688\n",
      "          - 10trees. f1-score on training data: 0.977 f1-score on test data: 0.695\n",
      "          - 15trees. f1-score on training data: 0.992 f1-score on test data: 0.688\n",
      "          - 20trees. f1-score on training data: 1.000 f1-score on test data: 0.661\n",
      "          - 25trees. f1-score on training data: 1.000 f1-score on test data: 0.690\n",
      "          - 30trees. f1-score on training data: 1.000 f1-score on test data: 0.657\n",
      "          - 35trees. f1-score on training data: 1.000 f1-score on test data: 0.625\n",
      "          - 40trees. f1-score on training data: 1.000 f1-score on test data: 0.656\n",
      "          - 45trees. f1-score on training data: 1.000 f1-score on test data: 0.625\n",
      "          - 50trees. f1-score on training data: 1.000 f1-score on test data: 0.656\n",
      "          - 55trees. f1-score on training data: 1.000 f1-score on test data: 0.625\n",
      "          - 60trees. f1-score on training data: 1.000 f1-score on test data: 0.625\n",
      "          - 65trees. f1-score on training data: 1.000 f1-score on test data: 0.625\n",
      "          - 70trees. f1-score on training data: 1.000 f1-score on test data: 0.625\n",
      "          - 75trees. f1-score on training data: 1.000 f1-score on test data: 0.625\n",
      "          - 80trees. f1-score on training data: 1.000 f1-score on test data: 0.656\n",
      "          - 85trees. f1-score on training data: 1.000 f1-score on test data: 0.625\n",
      "          - 90trees. f1-score on training data: 1.000 f1-score on test data: 0.656\n",
      "          - 95trees. f1-score on training data: 1.000 f1-score on test data: 0.656\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. f1-score on training data: 0.790 f1-score on test data: 0.538\n",
      "          - hidden layer size[20, 20]. f1-score on training data: 0.789 f1-score on test data: 0.442\n",
      "- Using scaled dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, Training set f1-score:0.550, Test set f1-score: 0.566\n",
      "          - saga_L1, Training set f1-score:0.674, Test set f1-score: 0.638\n",
      "          - newton-cg_L2, Training set f1-score:0.550, Test set f1-score: 0.566\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, Training set f1-score:0.653, Test set f1-score: 0.690\n",
      "          - saga_L1, Training set f1-score:0.660, Test set f1-score: 0.694\n",
      "          - newton-cg_L2, Training set f1-score:0.653, Test set f1-score: 0.690\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, Training set f1-score:0.642, Test set f1-score: 0.657\n",
      "          - saga_L1, Training set f1-score:0.634, Test set f1-score: 0.661\n",
      "          - newton-cg_L2, Training set f1-score:0.642, Test set f1-score: 0.657\n",
      "       - C = 1\n",
      "          - lbfgs_L2, Training set f1-score:0.649, Test set f1-score: 0.625\n",
      "          - saga_L1, Training set f1-score:0.649, Test set f1-score: 0.625\n",
      "          - newton-cg_L2, Training set f1-score:0.649, Test set f1-score: 0.625\n",
      "       - C = 10\n",
      "          - lbfgs_L2, Training set f1-score:0.703, Test set f1-score: 0.657\n",
      "          - saga_L1, Training set f1-score:0.688, Test set f1-score: 0.625\n",
      "          - newton-cg_L2, Training set f1-score:0.703, Test set f1-score: 0.657\n",
      "       - C = 100\n",
      "          - lbfgs_L2, Training set f1-score:0.695, Test set f1-score: 0.625\n",
      "          - saga_L1, Training set f1-score:0.711, Test set f1-score: 0.657\n",
      "          - newton-cg_L2, Training set f1-score:0.695, Test set f1-score: 0.625\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, Training set f1-score:0.688, Test set f1-score: 0.625\n",
      "          - saga_L1, Training set f1-score:0.711, Test set f1-score: 0.657\n",
      "          - newton-cg_L2, Training set f1-score:0.688, Test set f1-score: 0.625\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. f1-score on training data: 0.692 f1-score on test data: 0.634\n",
      "          - tree depth: 2.000. f1-score on training data: 0.692 f1-score on test data: 0.634\n",
      "          - tree depth: 3.000. f1-score on training data: 0.806 f1-score on test data: 0.538\n",
      "          - tree depth: 4.000. f1-score on training data: 0.891 f1-score on test data: 0.548\n",
      "          - tree depth: 5.000. f1-score on training data: 0.938 f1-score on test data: 0.500\n",
      "          - tree depth: 6.000. f1-score on training data: 0.969 f1-score on test data: 0.593\n",
      "          - tree depth: 7.000. f1-score on training data: 0.969 f1-score on test data: 0.562\n",
      "          - tree depth: 8.000. f1-score on training data: 0.984 f1-score on test data: 0.562\n",
      "          - tree depth: 9.000. f1-score on training data: 0.992 f1-score on test data: 0.593\n",
      "          - tree depth: 10.000. f1-score on training data: 0.992 f1-score on test data: 0.593\n",
      "          - tree depth: 11.000. f1-score on training data: 1.000 f1-score on test data: 0.562\n",
      "          - tree depth: 12.000. f1-score on training data: 1.000 f1-score on test data: 0.562\n",
      "          - tree depth: 13.000. f1-score on training data: 1.000 f1-score on test data: 0.562\n",
      "          - tree depth: 14.000. f1-score on training data: 1.000 f1-score on test data: 0.562\n",
      "    - Random forest\n",
      "          - 5trees. f1-score on training data: 0.930 f1-score on test data: 0.688\n",
      "          - 10trees. f1-score on training data: 0.977 f1-score on test data: 0.695\n",
      "          - 15trees. f1-score on training data: 0.992 f1-score on test data: 0.688\n",
      "          - 20trees. f1-score on training data: 1.000 f1-score on test data: 0.661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          - 25trees. f1-score on training data: 1.000 f1-score on test data: 0.690\n",
      "          - 30trees. f1-score on training data: 1.000 f1-score on test data: 0.657\n",
      "          - 35trees. f1-score on training data: 1.000 f1-score on test data: 0.625\n",
      "          - 40trees. f1-score on training data: 1.000 f1-score on test data: 0.656\n",
      "          - 45trees. f1-score on training data: 1.000 f1-score on test data: 0.625\n",
      "          - 50trees. f1-score on training data: 1.000 f1-score on test data: 0.656\n",
      "          - 55trees. f1-score on training data: 1.000 f1-score on test data: 0.625\n",
      "          - 60trees. f1-score on training data: 1.000 f1-score on test data: 0.625\n",
      "          - 65trees. f1-score on training data: 1.000 f1-score on test data: 0.625\n",
      "          - 70trees. f1-score on training data: 1.000 f1-score on test data: 0.625\n",
      "          - 75trees. f1-score on training data: 1.000 f1-score on test data: 0.625\n",
      "          - 80trees. f1-score on training data: 1.000 f1-score on test data: 0.656\n",
      "          - 85trees. f1-score on training data: 1.000 f1-score on test data: 0.625\n",
      "          - 90trees. f1-score on training data: 1.000 f1-score on test data: 0.656\n",
      "          - 95trees. f1-score on training data: 1.000 f1-score on test data: 0.656\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. f1-score on training data: 1.000 f1-score on test data: 0.438\n",
      "          - hidden layer size[20, 20]. f1-score on training data: 1.000 f1-score on test data: 0.533\n",
      "- Using 3 pca-components:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, Training set f1-score:0.575, Test set f1-score: 0.566\n",
      "          - saga_L1, Training set f1-score:0.674, Test set f1-score: 0.638\n",
      "          - newton-cg_L2, Training set f1-score:0.575, Test set f1-score: 0.566\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, Training set f1-score:0.643, Test set f1-score: 0.695\n",
      "          - saga_L1, Training set f1-score:0.660, Test set f1-score: 0.694\n",
      "          - newton-cg_L2, Training set f1-score:0.643, Test set f1-score: 0.695\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, Training set f1-score:0.651, Test set f1-score: 0.690\n",
      "          - saga_L1, Training set f1-score:0.628, Test set f1-score: 0.723\n",
      "          - newton-cg_L2, Training set f1-score:0.651, Test set f1-score: 0.690\n",
      "       - C = 1\n",
      "          - lbfgs_L2, Training set f1-score:0.651, Test set f1-score: 0.657\n",
      "          - saga_L1, Training set f1-score:0.651, Test set f1-score: 0.690\n",
      "          - newton-cg_L2, Training set f1-score:0.651, Test set f1-score: 0.657\n",
      "       - C = 10\n",
      "          - lbfgs_L2, Training set f1-score:0.651, Test set f1-score: 0.657\n",
      "          - saga_L1, Training set f1-score:0.651, Test set f1-score: 0.657\n",
      "          - newton-cg_L2, Training set f1-score:0.651, Test set f1-score: 0.657\n",
      "       - C = 100\n",
      "          - lbfgs_L2, Training set f1-score:0.651, Test set f1-score: 0.625\n",
      "          - saga_L1, Training set f1-score:0.651, Test set f1-score: 0.657\n",
      "          - newton-cg_L2, Training set f1-score:0.651, Test set f1-score: 0.625\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, Training set f1-score:0.651, Test set f1-score: 0.625\n",
      "          - saga_L1, Training set f1-score:0.651, Test set f1-score: 0.625\n",
      "          - newton-cg_L2, Training set f1-score:0.651, Test set f1-score: 0.625\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. f1-score on training data: 0.655 f1-score on test data: 0.729\n",
      "          - tree depth: 2.000. f1-score on training data: 0.695 f1-score on test data: 0.625\n",
      "          - tree depth: 3.000. f1-score on training data: 0.766 f1-score on test data: 0.657\n",
      "          - tree depth: 4.000. f1-score on training data: 0.792 f1-score on test data: 0.690\n",
      "          - tree depth: 5.000. f1-score on training data: 0.837 f1-score on test data: 0.634\n",
      "          - tree depth: 6.000. f1-score on training data: 0.868 f1-score on test data: 0.657\n",
      "          - tree depth: 7.000. f1-score on training data: 0.930 f1-score on test data: 0.625\n",
      "          - tree depth: 8.000. f1-score on training data: 0.969 f1-score on test data: 0.531\n",
      "          - tree depth: 9.000. f1-score on training data: 0.969 f1-score on test data: 0.562\n",
      "          - tree depth: 10.000. f1-score on training data: 0.992 f1-score on test data: 0.593\n",
      "          - tree depth: 11.000. f1-score on training data: 1.000 f1-score on test data: 0.562\n",
      "          - tree depth: 12.000. f1-score on training data: 1.000 f1-score on test data: 0.562\n",
      "          - tree depth: 13.000. f1-score on training data: 1.000 f1-score on test data: 0.562\n",
      "          - tree depth: 14.000. f1-score on training data: 1.000 f1-score on test data: 0.562\n",
      "    - Random forest\n",
      "          - 5trees. f1-score on training data: 0.930 f1-score on test data: 0.628\n",
      "          - 10trees. f1-score on training data: 0.977 f1-score on test data: 0.538\n",
      "          - 15trees. f1-score on training data: 0.984 f1-score on test data: 0.566\n",
      "          - 20trees. f1-score on training data: 0.992 f1-score on test data: 0.573\n",
      "          - 25trees. f1-score on training data: 0.992 f1-score on test data: 0.538\n",
      "          - 30trees. f1-score on training data: 1.000 f1-score on test data: 0.548\n",
      "          - 35trees. f1-score on training data: 1.000 f1-score on test data: 0.600\n",
      "          - 40trees. f1-score on training data: 1.000 f1-score on test data: 0.538\n",
      "          - 45trees. f1-score on training data: 1.000 f1-score on test data: 0.595\n",
      "          - 50trees. f1-score on training data: 1.000 f1-score on test data: 0.451\n",
      "          - 55trees. f1-score on training data: 1.000 f1-score on test data: 0.477\n",
      "          - 60trees. f1-score on training data: 1.000 f1-score on test data: 0.477\n",
      "          - 65trees. f1-score on training data: 1.000 f1-score on test data: 0.504\n",
      "          - 70trees. f1-score on training data: 1.000 f1-score on test data: 0.562\n",
      "          - 75trees. f1-score on training data: 1.000 f1-score on test data: 0.504\n",
      "          - 80trees. f1-score on training data: 1.000 f1-score on test data: 0.504\n",
      "          - 85trees. f1-score on training data: 1.000 f1-score on test data: 0.451\n",
      "          - 90trees. f1-score on training data: 1.000 f1-score on test data: 0.477\n",
      "          - 95trees. f1-score on training data: 1.000 f1-score on test data: 0.477\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. f1-score on training data: 0.984 f1-score on test data: 0.538\n",
      "          - hidden layer size[20, 20]. f1-score on training data: 1.000 f1-score on test data: 0.538\n"
     ]
    }
   ],
   "source": [
    "models(df_2cn,drop_lst,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43e5725c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After undersampling data size is 160 ; Resampled dataset shape Counter({'CN-AD': 80, 'CN-CN': 80})\n",
      "\n",
      "3 principle components are needed to explain 90% of the data\n",
      "\n",
      "- Using original dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.598\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.333\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.598\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.619\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.333\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.619\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.628\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.333\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.628\n",
      "       - C = 1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.635\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.592\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.635\n",
      "       - C = 10\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.613\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.607\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.613\n",
      "       - C = 100\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.626\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.580\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.626\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.595\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.597\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.595\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. average weighted f1-score of 10-cross validation:0.512\n",
      "          - tree depth: 2.000. average weighted f1-score of 10-cross validation:0.581\n",
      "          - tree depth: 3.000. average weighted f1-score of 10-cross validation:0.628\n",
      "          - tree depth: 4.000. average weighted f1-score of 10-cross validation:0.655\n",
      "          - tree depth: 5.000. average weighted f1-score of 10-cross validation:0.605\n",
      "          - tree depth: 6.000. average weighted f1-score of 10-cross validation:0.606\n",
      "          - tree depth: 7.000. average weighted f1-score of 10-cross validation:0.613\n",
      "          - tree depth: 8.000. average weighted f1-score of 10-cross validation:0.615\n",
      "          - tree depth: 9.000. average weighted f1-score of 10-cross validation:0.590\n",
      "          - tree depth: 10.000. average weighted f1-score of 10-cross validation:0.597\n",
      "          - tree depth: 11.000. average weighted f1-score of 10-cross validation:0.597\n",
      "          - tree depth: 12.000. average weighted f1-score of 10-cross validation:0.597\n",
      "          - tree depth: 13.000. average weighted f1-score of 10-cross validation:0.597\n",
      "          - tree depth: 14.000. average weighted f1-score of 10-cross validation:0.597\n",
      "    - Random forest\n",
      "          - 5trees. average weighted f1-score of 10-cross validation:0.576\n",
      "          - 10trees. average weighted f1-score of 10-cross validation:0.602\n",
      "          - 15trees. average weighted f1-score of 10-cross validation:0.618\n",
      "          - 20trees. average weighted f1-score of 10-cross validation:0.598\n",
      "          - 25trees. average weighted f1-score of 10-cross validation:0.611\n",
      "          - 30trees. average weighted f1-score of 10-cross validation:0.613\n",
      "          - 35trees. average weighted f1-score of 10-cross validation:0.607\n",
      "          - 40trees. average weighted f1-score of 10-cross validation:0.606\n",
      "          - 45trees. average weighted f1-score of 10-cross validation:0.619\n",
      "          - 50trees. average weighted f1-score of 10-cross validation:0.619\n",
      "          - 55trees. average weighted f1-score of 10-cross validation:0.613\n",
      "          - 60trees. average weighted f1-score of 10-cross validation:0.618\n",
      "          - 65trees. average weighted f1-score of 10-cross validation:0.618\n",
      "          - 70trees. average weighted f1-score of 10-cross validation:0.618\n",
      "          - 75trees. average weighted f1-score of 10-cross validation:0.618\n",
      "          - 80trees. average weighted f1-score of 10-cross validation:0.605\n",
      "          - 85trees. average weighted f1-score of 10-cross validation:0.599\n",
      "          - 90trees. average weighted f1-score of 10-cross validation:0.598\n",
      "          - 95trees. average weighted f1-score of 10-cross validation:0.605\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. average weighted f1-score of 10-cross validation:0.589\n",
      "          - hidden layer size[20, 20]. average weighted f1-score of 10-cross validation:0.595\n",
      "- Using scaled dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.645\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.333\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.645\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.641\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.333\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.641\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.638\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.601\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.638\n",
      "       - C = 1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.614\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.620\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.614\n",
      "       - C = 10\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.595\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.601\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.595\n",
      "       - C = 100\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.607\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.607\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.607\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.607\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.607\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.607\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. average weighted f1-score of 10-cross validation:0.512\n",
      "          - tree depth: 2.000. average weighted f1-score of 10-cross validation:0.581\n",
      "          - tree depth: 3.000. average weighted f1-score of 10-cross validation:0.628\n",
      "          - tree depth: 4.000. average weighted f1-score of 10-cross validation:0.655\n",
      "          - tree depth: 5.000. average weighted f1-score of 10-cross validation:0.605\n",
      "          - tree depth: 6.000. average weighted f1-score of 10-cross validation:0.606\n",
      "          - tree depth: 7.000. average weighted f1-score of 10-cross validation:0.613\n",
      "          - tree depth: 8.000. average weighted f1-score of 10-cross validation:0.615\n",
      "          - tree depth: 9.000. average weighted f1-score of 10-cross validation:0.590\n",
      "          - tree depth: 10.000. average weighted f1-score of 10-cross validation:0.597\n",
      "          - tree depth: 11.000. average weighted f1-score of 10-cross validation:0.597\n",
      "          - tree depth: 12.000. average weighted f1-score of 10-cross validation:0.597\n",
      "          - tree depth: 13.000. average weighted f1-score of 10-cross validation:0.597\n",
      "          - tree depth: 14.000. average weighted f1-score of 10-cross validation:0.597\n",
      "    - Random forest\n",
      "          - 5trees. average weighted f1-score of 10-cross validation:0.576\n",
      "          - 10trees. average weighted f1-score of 10-cross validation:0.602\n",
      "          - 15trees. average weighted f1-score of 10-cross validation:0.618\n",
      "          - 20trees. average weighted f1-score of 10-cross validation:0.598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          - 25trees. average weighted f1-score of 10-cross validation:0.611\n",
      "          - 30trees. average weighted f1-score of 10-cross validation:0.613\n",
      "          - 35trees. average weighted f1-score of 10-cross validation:0.607\n",
      "          - 40trees. average weighted f1-score of 10-cross validation:0.606\n",
      "          - 45trees. average weighted f1-score of 10-cross validation:0.619\n",
      "          - 50trees. average weighted f1-score of 10-cross validation:0.619\n",
      "          - 55trees. average weighted f1-score of 10-cross validation:0.613\n",
      "          - 60trees. average weighted f1-score of 10-cross validation:0.618\n",
      "          - 65trees. average weighted f1-score of 10-cross validation:0.618\n",
      "          - 70trees. average weighted f1-score of 10-cross validation:0.618\n",
      "          - 75trees. average weighted f1-score of 10-cross validation:0.618\n",
      "          - 80trees. average weighted f1-score of 10-cross validation:0.605\n",
      "          - 85trees. average weighted f1-score of 10-cross validation:0.599\n",
      "          - 90trees. average weighted f1-score of 10-cross validation:0.598\n",
      "          - 95trees. average weighted f1-score of 10-cross validation:0.605\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. average weighted f1-score of 10-cross validation:0.558\n",
      "          - hidden layer size[20, 20]. average weighted f1-score of 10-cross validation:0.618\n",
      "- Using 3 pca-components:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.645\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.333\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.645\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.649\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.333\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.649\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.625\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.643\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.625\n",
      "       - C = 1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.625\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.619\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.625\n",
      "       - C = 10\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.625\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.625\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.625\n",
      "       - C = 100\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.625\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.625\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.625\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.625\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.625\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.625\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. average weighted f1-score of 10-cross validation:0.488\n",
      "          - tree depth: 2.000. average weighted f1-score of 10-cross validation:0.488\n",
      "          - tree depth: 3.000. average weighted f1-score of 10-cross validation:0.579\n",
      "          - tree depth: 4.000. average weighted f1-score of 10-cross validation:0.604\n",
      "          - tree depth: 5.000. average weighted f1-score of 10-cross validation:0.607\n",
      "          - tree depth: 6.000. average weighted f1-score of 10-cross validation:0.605\n",
      "          - tree depth: 7.000. average weighted f1-score of 10-cross validation:0.593\n",
      "          - tree depth: 8.000. average weighted f1-score of 10-cross validation:0.609\n",
      "          - tree depth: 9.000. average weighted f1-score of 10-cross validation:0.634\n",
      "          - tree depth: 10.000. average weighted f1-score of 10-cross validation:0.635\n",
      "          - tree depth: 11.000. average weighted f1-score of 10-cross validation:0.633\n",
      "          - tree depth: 12.000. average weighted f1-score of 10-cross validation:0.601\n",
      "          - tree depth: 13.000. average weighted f1-score of 10-cross validation:0.618\n",
      "          - tree depth: 14.000. average weighted f1-score of 10-cross validation:0.611\n",
      "    - Random forest\n",
      "          - 5trees. average weighted f1-score of 10-cross validation:0.585\n",
      "          - 10trees. average weighted f1-score of 10-cross validation:0.573\n",
      "          - 15trees. average weighted f1-score of 10-cross validation:0.577\n",
      "          - 20trees. average weighted f1-score of 10-cross validation:0.566\n",
      "          - 25trees. average weighted f1-score of 10-cross validation:0.554\n",
      "          - 30trees. average weighted f1-score of 10-cross validation:0.572\n",
      "          - 35trees. average weighted f1-score of 10-cross validation:0.571\n",
      "          - 40trees. average weighted f1-score of 10-cross validation:0.564\n",
      "          - 45trees. average weighted f1-score of 10-cross validation:0.564\n",
      "          - 50trees. average weighted f1-score of 10-cross validation:0.565\n",
      "          - 55trees. average weighted f1-score of 10-cross validation:0.543\n",
      "          - 60trees. average weighted f1-score of 10-cross validation:0.537\n",
      "          - 65trees. average weighted f1-score of 10-cross validation:0.537\n",
      "          - 70trees. average weighted f1-score of 10-cross validation:0.533\n",
      "          - 75trees. average weighted f1-score of 10-cross validation:0.533\n",
      "          - 80trees. average weighted f1-score of 10-cross validation:0.533\n",
      "          - 85trees. average weighted f1-score of 10-cross validation:0.531\n",
      "          - 90trees. average weighted f1-score of 10-cross validation:0.531\n",
      "          - 95trees. average weighted f1-score of 10-cross validation:0.538\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. average weighted f1-score of 10-cross validation:0.489\n",
      "          - hidden layer size[20, 20]. average weighted f1-score of 10-cross validation:0.558\n"
     ]
    }
   ],
   "source": [
    "cv_models(df_2cn,drop_lst,target,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0322c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = usampling_scale_data(df_2cn,drop_lst,target)     \n",
    "X = res[0]\n",
    "y = res[3]\n",
    "clf = RandomForestClassifier(n_estimators =25, random_state = 5862)\n",
    "title_label = '10-fold crossvalidation of random forest with ( 25 trees)'\n",
    "feature_importance(X,y,clf,10,title_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d453f68",
   "metadata": {},
   "source": [
    "### - 'MCI-AD': 166, 'MCI-CN': 166 where (MCI-MCI are renamed to MCI-AD)\n",
    "- original data, 40trees. average weighted f1-score of 10-cross validation:0.628\n",
    "--- not that good as directly use MCI-AD and MCI-CN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd8299cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After undersampling data size is 332 ; Resampled dataset shape Counter({'MCI-AD': 166, 'MCI-CN': 166})\n",
      "\n",
      "5 principle components are needed to explain 90% of the data\n",
      "\n",
      "- Using original dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.373\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.333\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.373\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.511\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.327\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.511\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.528\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.320\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.528\n",
      "       - C = 1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.569\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.563\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.569\n",
      "       - C = 10\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.585\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.577\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.585\n",
      "       - C = 100\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.587\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.577\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.587\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.587\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.574\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.587\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. average weighted f1-score of 10-cross validation:0.546\n",
      "          - tree depth: 2.000. average weighted f1-score of 10-cross validation:0.558\n",
      "          - tree depth: 3.000. average weighted f1-score of 10-cross validation:0.551\n",
      "          - tree depth: 4.000. average weighted f1-score of 10-cross validation:0.617\n",
      "          - tree depth: 5.000. average weighted f1-score of 10-cross validation:0.548\n",
      "          - tree depth: 6.000. average weighted f1-score of 10-cross validation:0.542\n",
      "          - tree depth: 7.000. average weighted f1-score of 10-cross validation:0.566\n",
      "          - tree depth: 8.000. average weighted f1-score of 10-cross validation:0.585\n",
      "          - tree depth: 9.000. average weighted f1-score of 10-cross validation:0.573\n",
      "          - tree depth: 10.000. average weighted f1-score of 10-cross validation:0.585\n",
      "          - tree depth: 11.000. average weighted f1-score of 10-cross validation:0.603\n",
      "          - tree depth: 12.000. average weighted f1-score of 10-cross validation:0.585\n",
      "          - tree depth: 13.000. average weighted f1-score of 10-cross validation:0.601\n",
      "          - tree depth: 14.000. average weighted f1-score of 10-cross validation:0.585\n",
      "    - Random forest\n",
      "          - 5trees. average weighted f1-score of 10-cross validation:0.539\n",
      "          - 10trees. average weighted f1-score of 10-cross validation:0.570\n",
      "          - 15trees. average weighted f1-score of 10-cross validation:0.585\n",
      "          - 20trees. average weighted f1-score of 10-cross validation:0.606\n",
      "          - 25trees. average weighted f1-score of 10-cross validation:0.606\n",
      "          - 30trees. average weighted f1-score of 10-cross validation:0.619\n",
      "          - 35trees. average weighted f1-score of 10-cross validation:0.610\n",
      "          - 40trees. average weighted f1-score of 10-cross validation:0.628\n",
      "          - 45trees. average weighted f1-score of 10-cross validation:0.615\n",
      "          - 50trees. average weighted f1-score of 10-cross validation:0.628\n",
      "          - 55trees. average weighted f1-score of 10-cross validation:0.615\n",
      "          - 60trees. average weighted f1-score of 10-cross validation:0.619\n",
      "          - 65trees. average weighted f1-score of 10-cross validation:0.609\n",
      "          - 70trees. average weighted f1-score of 10-cross validation:0.613\n",
      "          - 75trees. average weighted f1-score of 10-cross validation:0.606\n",
      "          - 80trees. average weighted f1-score of 10-cross validation:0.613\n",
      "          - 85trees. average weighted f1-score of 10-cross validation:0.612\n",
      "          - 90trees. average weighted f1-score of 10-cross validation:0.615\n",
      "          - 95trees. average weighted f1-score of 10-cross validation:0.615\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. average weighted f1-score of 10-cross validation:0.546\n",
      "          - hidden layer size[20, 20]. average weighted f1-score of 10-cross validation:0.573\n",
      "- Using scaled dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.580\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.340\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.580\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.581\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.337\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.581\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.585\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.593\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.585\n",
      "       - C = 1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.581\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.588\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.581\n",
      "       - C = 10\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.587\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.587\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.587\n",
      "       - C = 100\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.587\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.587\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.587\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.587\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.587\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.587\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. average weighted f1-score of 10-cross validation:0.546\n",
      "          - tree depth: 2.000. average weighted f1-score of 10-cross validation:0.558\n",
      "          - tree depth: 3.000. average weighted f1-score of 10-cross validation:0.551\n",
      "          - tree depth: 4.000. average weighted f1-score of 10-cross validation:0.617\n",
      "          - tree depth: 5.000. average weighted f1-score of 10-cross validation:0.548\n",
      "          - tree depth: 6.000. average weighted f1-score of 10-cross validation:0.542\n",
      "          - tree depth: 7.000. average weighted f1-score of 10-cross validation:0.566\n",
      "          - tree depth: 8.000. average weighted f1-score of 10-cross validation:0.585\n",
      "          - tree depth: 9.000. average weighted f1-score of 10-cross validation:0.573\n",
      "          - tree depth: 10.000. average weighted f1-score of 10-cross validation:0.585\n",
      "          - tree depth: 11.000. average weighted f1-score of 10-cross validation:0.603\n",
      "          - tree depth: 12.000. average weighted f1-score of 10-cross validation:0.585\n",
      "          - tree depth: 13.000. average weighted f1-score of 10-cross validation:0.601\n",
      "          - tree depth: 14.000. average weighted f1-score of 10-cross validation:0.585\n",
      "    - Random forest\n",
      "          - 5trees. average weighted f1-score of 10-cross validation:0.539\n",
      "          - 10trees. average weighted f1-score of 10-cross validation:0.570\n",
      "          - 15trees. average weighted f1-score of 10-cross validation:0.585\n",
      "          - 20trees. average weighted f1-score of 10-cross validation:0.606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          - 25trees. average weighted f1-score of 10-cross validation:0.606\n",
      "          - 30trees. average weighted f1-score of 10-cross validation:0.619\n",
      "          - 35trees. average weighted f1-score of 10-cross validation:0.610\n",
      "          - 40trees. average weighted f1-score of 10-cross validation:0.628\n",
      "          - 45trees. average weighted f1-score of 10-cross validation:0.615\n",
      "          - 50trees. average weighted f1-score of 10-cross validation:0.628\n",
      "          - 55trees. average weighted f1-score of 10-cross validation:0.615\n",
      "          - 60trees. average weighted f1-score of 10-cross validation:0.619\n",
      "          - 65trees. average weighted f1-score of 10-cross validation:0.609\n",
      "          - 70trees. average weighted f1-score of 10-cross validation:0.613\n",
      "          - 75trees. average weighted f1-score of 10-cross validation:0.606\n",
      "          - 80trees. average weighted f1-score of 10-cross validation:0.613\n",
      "          - 85trees. average weighted f1-score of 10-cross validation:0.612\n",
      "          - 90trees. average weighted f1-score of 10-cross validation:0.615\n",
      "          - 95trees. average weighted f1-score of 10-cross validation:0.615\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. average weighted f1-score of 10-cross validation:0.574\n",
      "          - hidden layer size[20, 20]. average weighted f1-score of 10-cross validation:0.547\n",
      "- Using 5 pca-components:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.560\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.337\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.560\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.575\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.330\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.575\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.585\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.545\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.585\n",
      "       - C = 1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.589\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.585\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.589\n",
      "       - C = 10\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.586\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.586\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.586\n",
      "       - C = 100\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.586\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.586\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.586\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.586\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.586\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.586\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. average weighted f1-score of 10-cross validation:0.446\n",
      "          - tree depth: 2.000. average weighted f1-score of 10-cross validation:0.511\n",
      "          - tree depth: 3.000. average weighted f1-score of 10-cross validation:0.476\n",
      "          - tree depth: 4.000. average weighted f1-score of 10-cross validation:0.528\n",
      "          - tree depth: 5.000. average weighted f1-score of 10-cross validation:0.522\n",
      "          - tree depth: 6.000. average weighted f1-score of 10-cross validation:0.523\n",
      "          - tree depth: 7.000. average weighted f1-score of 10-cross validation:0.533\n",
      "          - tree depth: 8.000. average weighted f1-score of 10-cross validation:0.535\n",
      "          - tree depth: 9.000. average weighted f1-score of 10-cross validation:0.542\n",
      "          - tree depth: 10.000. average weighted f1-score of 10-cross validation:0.540\n",
      "          - tree depth: 11.000. average weighted f1-score of 10-cross validation:0.524\n",
      "          - tree depth: 12.000. average weighted f1-score of 10-cross validation:0.547\n",
      "          - tree depth: 13.000. average weighted f1-score of 10-cross validation:0.531\n",
      "          - tree depth: 14.000. average weighted f1-score of 10-cross validation:0.533\n",
      "    - Random forest\n",
      "          - 5trees. average weighted f1-score of 10-cross validation:0.535\n",
      "          - 10trees. average weighted f1-score of 10-cross validation:0.508\n",
      "          - 15trees. average weighted f1-score of 10-cross validation:0.561\n",
      "          - 20trees. average weighted f1-score of 10-cross validation:0.565\n",
      "          - 25trees. average weighted f1-score of 10-cross validation:0.592\n",
      "          - 30trees. average weighted f1-score of 10-cross validation:0.601\n",
      "          - 35trees. average weighted f1-score of 10-cross validation:0.596\n",
      "          - 40trees. average weighted f1-score of 10-cross validation:0.580\n",
      "          - 45trees. average weighted f1-score of 10-cross validation:0.591\n",
      "          - 50trees. average weighted f1-score of 10-cross validation:0.575\n",
      "          - 55trees. average weighted f1-score of 10-cross validation:0.577\n",
      "          - 60trees. average weighted f1-score of 10-cross validation:0.581\n",
      "          - 65trees. average weighted f1-score of 10-cross validation:0.572\n",
      "          - 70trees. average weighted f1-score of 10-cross validation:0.575\n",
      "          - 75trees. average weighted f1-score of 10-cross validation:0.574\n",
      "          - 80trees. average weighted f1-score of 10-cross validation:0.575\n",
      "          - 85trees. average weighted f1-score of 10-cross validation:0.578\n",
      "          - 90trees. average weighted f1-score of 10-cross validation:0.582\n",
      "          - 95trees. average weighted f1-score of 10-cross validation:0.584\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. average weighted f1-score of 10-cross validation:0.542\n",
      "          - hidden layer size[20, 20]. average weighted f1-score of 10-cross validation:0.533\n"
     ]
    }
   ],
   "source": [
    "cv_models(df2_2mci,drop_lst,target,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8177c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = usampling_scale_data(d2f_2mci,drop_lst,target)     \n",
    "X = res[0]\n",
    "y = res[3]\n",
    "clf = RandomForestClassifier(n_estimators = 40, random_state = 5862)\n",
    "title_label = '10-fold crossvalidation of random forest with (40 trees)'\n",
    "feature_importance(X,y,clf,k,title_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d06ecb",
   "metadata": {},
   "source": [
    "### - 'MCI-AD': 112, 'MCI-CN': 112\n",
    "- 30trees. average weighted f1-score of 10-cross validation:0.715"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ab2c012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After undersampling data size is 332 ; Resampled dataset shape Counter({'MCI-AD': 166, 'MCI-CN': 166})\n",
      "\n",
      "5 principle components are needed to explain 90% of the data\n",
      "\n",
      "- Using original dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.409\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.337\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.409\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.618\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.333\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.618\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.641\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.323\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.641\n",
      "       - C = 1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.681\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.717\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.681\n",
      "       - C = 10\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.729\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.738\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.729\n",
      "       - C = 100\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.731\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.762\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.731\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.750\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.759\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.750\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. average weighted f1-score of 10-cross validation:0.730\n",
      "          - tree depth: 2.000. average weighted f1-score of 10-cross validation:0.720\n",
      "          - tree depth: 3.000. average weighted f1-score of 10-cross validation:0.735\n",
      "          - tree depth: 4.000. average weighted f1-score of 10-cross validation:0.746\n",
      "          - tree depth: 5.000. average weighted f1-score of 10-cross validation:0.724\n",
      "          - tree depth: 6.000. average weighted f1-score of 10-cross validation:0.713\n",
      "          - tree depth: 7.000. average weighted f1-score of 10-cross validation:0.731\n",
      "          - tree depth: 8.000. average weighted f1-score of 10-cross validation:0.685\n",
      "          - tree depth: 9.000. average weighted f1-score of 10-cross validation:0.659\n",
      "          - tree depth: 10.000. average weighted f1-score of 10-cross validation:0.668\n",
      "          - tree depth: 11.000. average weighted f1-score of 10-cross validation:0.695\n",
      "          - tree depth: 12.000. average weighted f1-score of 10-cross validation:0.686\n",
      "          - tree depth: 13.000. average weighted f1-score of 10-cross validation:0.676\n",
      "          - tree depth: 14.000. average weighted f1-score of 10-cross validation:0.676\n",
      "    - Random forest\n",
      "          - 5trees. average weighted f1-score of 10-cross validation:0.720\n",
      "          - 10trees. average weighted f1-score of 10-cross validation:0.729\n",
      "          - 15trees. average weighted f1-score of 10-cross validation:0.735\n",
      "          - 20trees. average weighted f1-score of 10-cross validation:0.742\n",
      "          - 25trees. average weighted f1-score of 10-cross validation:0.732\n",
      "          - 30trees. average weighted f1-score of 10-cross validation:0.729\n",
      "          - 35trees. average weighted f1-score of 10-cross validation:0.723\n",
      "          - 40trees. average weighted f1-score of 10-cross validation:0.727\n",
      "          - 45trees. average weighted f1-score of 10-cross validation:0.739\n",
      "          - 50trees. average weighted f1-score of 10-cross validation:0.733\n",
      "          - 55trees. average weighted f1-score of 10-cross validation:0.729\n",
      "          - 60trees. average weighted f1-score of 10-cross validation:0.736\n",
      "          - 65trees. average weighted f1-score of 10-cross validation:0.741\n",
      "          - 70trees. average weighted f1-score of 10-cross validation:0.752\n",
      "          - 75trees. average weighted f1-score of 10-cross validation:0.739\n",
      "          - 80trees. average weighted f1-score of 10-cross validation:0.748\n",
      "          - 85trees. average weighted f1-score of 10-cross validation:0.745\n",
      "          - 90trees. average weighted f1-score of 10-cross validation:0.751\n",
      "          - 95trees. average weighted f1-score of 10-cross validation:0.748\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. average weighted f1-score of 10-cross validation:0.742\n",
      "          - hidden layer size[20, 20]. average weighted f1-score of 10-cross validation:0.712\n",
      "- Using scaled dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.722\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.327\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.722\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.735\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.330\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.735\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.735\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.735\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.735\n",
      "       - C = 1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.753\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.763\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.753\n",
      "       - C = 10\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.747\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.744\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.747\n",
      "       - C = 100\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.747\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.747\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.747\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.747\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.747\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.747\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. average weighted f1-score of 10-cross validation:0.730\n",
      "          - tree depth: 2.000. average weighted f1-score of 10-cross validation:0.720\n",
      "          - tree depth: 3.000. average weighted f1-score of 10-cross validation:0.735\n",
      "          - tree depth: 4.000. average weighted f1-score of 10-cross validation:0.746\n",
      "          - tree depth: 5.000. average weighted f1-score of 10-cross validation:0.724\n",
      "          - tree depth: 6.000. average weighted f1-score of 10-cross validation:0.713\n",
      "          - tree depth: 7.000. average weighted f1-score of 10-cross validation:0.731\n",
      "          - tree depth: 8.000. average weighted f1-score of 10-cross validation:0.685\n",
      "          - tree depth: 9.000. average weighted f1-score of 10-cross validation:0.659\n",
      "          - tree depth: 10.000. average weighted f1-score of 10-cross validation:0.668\n",
      "          - tree depth: 11.000. average weighted f1-score of 10-cross validation:0.695\n",
      "          - tree depth: 12.000. average weighted f1-score of 10-cross validation:0.686\n",
      "          - tree depth: 13.000. average weighted f1-score of 10-cross validation:0.676\n",
      "          - tree depth: 14.000. average weighted f1-score of 10-cross validation:0.676\n",
      "    - Random forest\n",
      "          - 5trees. average weighted f1-score of 10-cross validation:0.720\n",
      "          - 10trees. average weighted f1-score of 10-cross validation:0.729\n",
      "          - 15trees. average weighted f1-score of 10-cross validation:0.735\n",
      "          - 20trees. average weighted f1-score of 10-cross validation:0.742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          - 25trees. average weighted f1-score of 10-cross validation:0.732\n",
      "          - 30trees. average weighted f1-score of 10-cross validation:0.729\n",
      "          - 35trees. average weighted f1-score of 10-cross validation:0.723\n",
      "          - 40trees. average weighted f1-score of 10-cross validation:0.727\n",
      "          - 45trees. average weighted f1-score of 10-cross validation:0.739\n",
      "          - 50trees. average weighted f1-score of 10-cross validation:0.733\n",
      "          - 55trees. average weighted f1-score of 10-cross validation:0.729\n",
      "          - 60trees. average weighted f1-score of 10-cross validation:0.736\n",
      "          - 65trees. average weighted f1-score of 10-cross validation:0.741\n",
      "          - 70trees. average weighted f1-score of 10-cross validation:0.752\n",
      "          - 75trees. average weighted f1-score of 10-cross validation:0.739\n",
      "          - 80trees. average weighted f1-score of 10-cross validation:0.748\n",
      "          - 85trees. average weighted f1-score of 10-cross validation:0.745\n",
      "          - 90trees. average weighted f1-score of 10-cross validation:0.751\n",
      "          - 95trees. average weighted f1-score of 10-cross validation:0.748\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. average weighted f1-score of 10-cross validation:0.653\n",
      "          - hidden layer size[20, 20]. average weighted f1-score of 10-cross validation:0.634\n",
      "- Using 5 pca-components:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.717\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.333\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.717\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.725\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.330\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.725\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.728\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.705\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.728\n",
      "       - C = 1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.726\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.723\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.726\n",
      "       - C = 10\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.726\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.726\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.726\n",
      "       - C = 100\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.726\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.726\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.726\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.726\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.726\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.726\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. average weighted f1-score of 10-cross validation:0.656\n",
      "          - tree depth: 2.000. average weighted f1-score of 10-cross validation:0.662\n",
      "          - tree depth: 3.000. average weighted f1-score of 10-cross validation:0.724\n",
      "          - tree depth: 4.000. average weighted f1-score of 10-cross validation:0.702\n",
      "          - tree depth: 5.000. average weighted f1-score of 10-cross validation:0.708\n",
      "          - tree depth: 6.000. average weighted f1-score of 10-cross validation:0.692\n",
      "          - tree depth: 7.000. average weighted f1-score of 10-cross validation:0.717\n",
      "          - tree depth: 8.000. average weighted f1-score of 10-cross validation:0.684\n",
      "          - tree depth: 9.000. average weighted f1-score of 10-cross validation:0.688\n",
      "          - tree depth: 10.000. average weighted f1-score of 10-cross validation:0.679\n",
      "          - tree depth: 11.000. average weighted f1-score of 10-cross validation:0.679\n",
      "          - tree depth: 12.000. average weighted f1-score of 10-cross validation:0.669\n",
      "          - tree depth: 13.000. average weighted f1-score of 10-cross validation:0.654\n",
      "          - tree depth: 14.000. average weighted f1-score of 10-cross validation:0.642\n",
      "    - Random forest\n",
      "          - 5trees. average weighted f1-score of 10-cross validation:0.687\n",
      "          - 10trees. average weighted f1-score of 10-cross validation:0.667\n",
      "          - 15trees. average weighted f1-score of 10-cross validation:0.709\n",
      "          - 20trees. average weighted f1-score of 10-cross validation:0.706\n",
      "          - 25trees. average weighted f1-score of 10-cross validation:0.715\n",
      "          - 30trees. average weighted f1-score of 10-cross validation:0.715\n",
      "          - 35trees. average weighted f1-score of 10-cross validation:0.709\n",
      "          - 40trees. average weighted f1-score of 10-cross validation:0.718\n",
      "          - 45trees. average weighted f1-score of 10-cross validation:0.717\n",
      "          - 50trees. average weighted f1-score of 10-cross validation:0.709\n",
      "          - 55trees. average weighted f1-score of 10-cross validation:0.714\n",
      "          - 60trees. average weighted f1-score of 10-cross validation:0.729\n",
      "          - 65trees. average weighted f1-score of 10-cross validation:0.720\n",
      "          - 70trees. average weighted f1-score of 10-cross validation:0.735\n",
      "          - 75trees. average weighted f1-score of 10-cross validation:0.738\n",
      "          - 80trees. average weighted f1-score of 10-cross validation:0.735\n",
      "          - 85trees. average weighted f1-score of 10-cross validation:0.732\n",
      "          - 90trees. average weighted f1-score of 10-cross validation:0.738\n",
      "          - 95trees. average weighted f1-score of 10-cross validation:0.732\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. average weighted f1-score of 10-cross validation:0.657\n",
      "          - hidden layer size[20, 20]. average weighted f1-score of 10-cross validation:0.680\n"
     ]
    }
   ],
   "source": [
    "cv_models(df_2mci,drop_lst,target,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7682b9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After undersampling data size is 332 ; Resampled dataset shape Counter({'MCI-AD': 166, 'MCI-CN': 166})\n",
      "\n",
      "5 principle components are needed to explain 90% of the data\n",
      "\n",
      "Features sorted by their score for each estimator \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_importance</th>\n",
       "      <th>importance_1</th>\n",
       "      <th>importance_2</th>\n",
       "      <th>importance_3</th>\n",
       "      <th>importance_4</th>\n",
       "      <th>importance_5</th>\n",
       "      <th>importance_6</th>\n",
       "      <th>importance_7</th>\n",
       "      <th>importance_8</th>\n",
       "      <th>importance_9</th>\n",
       "      <th>importance_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hippocampus_reduction_per_year</th>\n",
       "      <td>0.177241</td>\n",
       "      <td>0.210325</td>\n",
       "      <td>0.194679</td>\n",
       "      <td>0.193137</td>\n",
       "      <td>0.185286</td>\n",
       "      <td>0.165044</td>\n",
       "      <td>0.169569</td>\n",
       "      <td>0.174704</td>\n",
       "      <td>0.149219</td>\n",
       "      <td>0.152106</td>\n",
       "      <td>0.178339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ventricles_reduction_per_year</th>\n",
       "      <td>0.122864</td>\n",
       "      <td>0.091849</td>\n",
       "      <td>0.115754</td>\n",
       "      <td>0.110953</td>\n",
       "      <td>0.108686</td>\n",
       "      <td>0.143039</td>\n",
       "      <td>0.129935</td>\n",
       "      <td>0.135123</td>\n",
       "      <td>0.129318</td>\n",
       "      <td>0.136943</td>\n",
       "      <td>0.127040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ratio_Hippocampus_bl</th>\n",
       "      <td>0.115149</td>\n",
       "      <td>0.112412</td>\n",
       "      <td>0.092412</td>\n",
       "      <td>0.112829</td>\n",
       "      <td>0.127012</td>\n",
       "      <td>0.117522</td>\n",
       "      <td>0.118069</td>\n",
       "      <td>0.122996</td>\n",
       "      <td>0.115123</td>\n",
       "      <td>0.111382</td>\n",
       "      <td>0.121737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wholebrain_reduction_per_year</th>\n",
       "      <td>0.100880</td>\n",
       "      <td>0.095880</td>\n",
       "      <td>0.105021</td>\n",
       "      <td>0.112955</td>\n",
       "      <td>0.094291</td>\n",
       "      <td>0.102508</td>\n",
       "      <td>0.108333</td>\n",
       "      <td>0.102862</td>\n",
       "      <td>0.097489</td>\n",
       "      <td>0.106586</td>\n",
       "      <td>0.082877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ratio_Fusiform_bl</th>\n",
       "      <td>0.097253</td>\n",
       "      <td>0.086350</td>\n",
       "      <td>0.109370</td>\n",
       "      <td>0.104880</td>\n",
       "      <td>0.109683</td>\n",
       "      <td>0.083385</td>\n",
       "      <td>0.097863</td>\n",
       "      <td>0.102808</td>\n",
       "      <td>0.096822</td>\n",
       "      <td>0.102487</td>\n",
       "      <td>0.078880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entorhinal_reduction_per_year</th>\n",
       "      <td>0.078761</td>\n",
       "      <td>0.075927</td>\n",
       "      <td>0.083411</td>\n",
       "      <td>0.080330</td>\n",
       "      <td>0.079034</td>\n",
       "      <td>0.079799</td>\n",
       "      <td>0.069625</td>\n",
       "      <td>0.071387</td>\n",
       "      <td>0.083978</td>\n",
       "      <td>0.071606</td>\n",
       "      <td>0.092510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ICV_reduction_per_year</th>\n",
       "      <td>0.076159</td>\n",
       "      <td>0.086368</td>\n",
       "      <td>0.072810</td>\n",
       "      <td>0.068193</td>\n",
       "      <td>0.063812</td>\n",
       "      <td>0.087131</td>\n",
       "      <td>0.075712</td>\n",
       "      <td>0.072340</td>\n",
       "      <td>0.087240</td>\n",
       "      <td>0.077453</td>\n",
       "      <td>0.070534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ratio_Entorhinal_bl</th>\n",
       "      <td>0.069314</td>\n",
       "      <td>0.067242</td>\n",
       "      <td>0.070161</td>\n",
       "      <td>0.056786</td>\n",
       "      <td>0.059789</td>\n",
       "      <td>0.067379</td>\n",
       "      <td>0.067495</td>\n",
       "      <td>0.079448</td>\n",
       "      <td>0.077658</td>\n",
       "      <td>0.067209</td>\n",
       "      <td>0.079974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fusiform_reduction_per_year</th>\n",
       "      <td>0.066984</td>\n",
       "      <td>0.072966</td>\n",
       "      <td>0.069108</td>\n",
       "      <td>0.060107</td>\n",
       "      <td>0.066087</td>\n",
       "      <td>0.052316</td>\n",
       "      <td>0.067576</td>\n",
       "      <td>0.064101</td>\n",
       "      <td>0.069093</td>\n",
       "      <td>0.075811</td>\n",
       "      <td>0.072672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ratio_Ventricles_bl</th>\n",
       "      <td>0.048506</td>\n",
       "      <td>0.055795</td>\n",
       "      <td>0.051141</td>\n",
       "      <td>0.051036</td>\n",
       "      <td>0.060639</td>\n",
       "      <td>0.042883</td>\n",
       "      <td>0.048442</td>\n",
       "      <td>0.035085</td>\n",
       "      <td>0.043886</td>\n",
       "      <td>0.047577</td>\n",
       "      <td>0.048572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ratio_WholeBrain_bl</th>\n",
       "      <td>0.046889</td>\n",
       "      <td>0.044887</td>\n",
       "      <td>0.036133</td>\n",
       "      <td>0.048794</td>\n",
       "      <td>0.045681</td>\n",
       "      <td>0.058993</td>\n",
       "      <td>0.047379</td>\n",
       "      <td>0.039147</td>\n",
       "      <td>0.050173</td>\n",
       "      <td>0.050840</td>\n",
       "      <td>0.046865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                avg_importance  importance_1  importance_2  \\\n",
       "Hippocampus_reduction_per_year        0.177241      0.210325      0.194679   \n",
       "Ventricles_reduction_per_year         0.122864      0.091849      0.115754   \n",
       "ratio_Hippocampus_bl                  0.115149      0.112412      0.092412   \n",
       "wholebrain_reduction_per_year         0.100880      0.095880      0.105021   \n",
       "ratio_Fusiform_bl                     0.097253      0.086350      0.109370   \n",
       "Entorhinal_reduction_per_year         0.078761      0.075927      0.083411   \n",
       "ICV_reduction_per_year                0.076159      0.086368      0.072810   \n",
       "ratio_Entorhinal_bl                   0.069314      0.067242      0.070161   \n",
       "Fusiform_reduction_per_year           0.066984      0.072966      0.069108   \n",
       "ratio_Ventricles_bl                   0.048506      0.055795      0.051141   \n",
       "ratio_WholeBrain_bl                   0.046889      0.044887      0.036133   \n",
       "\n",
       "                                importance_3  importance_4  importance_5  \\\n",
       "Hippocampus_reduction_per_year      0.193137      0.185286      0.165044   \n",
       "Ventricles_reduction_per_year       0.110953      0.108686      0.143039   \n",
       "ratio_Hippocampus_bl                0.112829      0.127012      0.117522   \n",
       "wholebrain_reduction_per_year       0.112955      0.094291      0.102508   \n",
       "ratio_Fusiform_bl                   0.104880      0.109683      0.083385   \n",
       "Entorhinal_reduction_per_year       0.080330      0.079034      0.079799   \n",
       "ICV_reduction_per_year              0.068193      0.063812      0.087131   \n",
       "ratio_Entorhinal_bl                 0.056786      0.059789      0.067379   \n",
       "Fusiform_reduction_per_year         0.060107      0.066087      0.052316   \n",
       "ratio_Ventricles_bl                 0.051036      0.060639      0.042883   \n",
       "ratio_WholeBrain_bl                 0.048794      0.045681      0.058993   \n",
       "\n",
       "                                importance_6  importance_7  importance_8  \\\n",
       "Hippocampus_reduction_per_year      0.169569      0.174704      0.149219   \n",
       "Ventricles_reduction_per_year       0.129935      0.135123      0.129318   \n",
       "ratio_Hippocampus_bl                0.118069      0.122996      0.115123   \n",
       "wholebrain_reduction_per_year       0.108333      0.102862      0.097489   \n",
       "ratio_Fusiform_bl                   0.097863      0.102808      0.096822   \n",
       "Entorhinal_reduction_per_year       0.069625      0.071387      0.083978   \n",
       "ICV_reduction_per_year              0.075712      0.072340      0.087240   \n",
       "ratio_Entorhinal_bl                 0.067495      0.079448      0.077658   \n",
       "Fusiform_reduction_per_year         0.067576      0.064101      0.069093   \n",
       "ratio_Ventricles_bl                 0.048442      0.035085      0.043886   \n",
       "ratio_WholeBrain_bl                 0.047379      0.039147      0.050173   \n",
       "\n",
       "                                importance_9  importance_10  \n",
       "Hippocampus_reduction_per_year      0.152106       0.178339  \n",
       "Ventricles_reduction_per_year       0.136943       0.127040  \n",
       "ratio_Hippocampus_bl                0.111382       0.121737  \n",
       "wholebrain_reduction_per_year       0.106586       0.082877  \n",
       "ratio_Fusiform_bl                   0.102487       0.078880  \n",
       "Entorhinal_reduction_per_year       0.071606       0.092510  \n",
       "ICV_reduction_per_year              0.077453       0.070534  \n",
       "ratio_Entorhinal_bl                 0.067209       0.079974  \n",
       "Fusiform_reduction_per_year         0.075811       0.072672  \n",
       "ratio_Ventricles_bl                 0.047577       0.048572  \n",
       "ratio_WholeBrain_bl                 0.050840       0.046865  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = usampling_scale_data(df_2mci,drop_lst,target)     \n",
    "X = res[0]\n",
    "y = res[3]\n",
    "clf = RandomForestClassifier(n_estimators = 30, random_state = 5862)\n",
    "title_label = '10-fold crossvalidation of random forest with (30 trees)'\n",
    "feature_importance(X,y,clf,k,title_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d37f91",
   "metadata": {},
   "source": [
    "## - 'MCI-AD': 112, 'MCI-CN': 112, 'MCI-MCI': 112\n",
    "\n",
    "NOT GOOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03f26e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After undersampling data size is 498 ; Resampled dataset shape Counter({'MCI-AD': 166, 'MCI-CN': 166, 'MCI-MCI': 166})\n",
      "\n",
      "6 principle components are needed to explain 90% of the data\n",
      "\n",
      "Output dataframes sequence: X_train,X_test,X_train_scaled,X_test_scaled,X_train_pca,X_test_pca,y_train,y_test\n",
      "- Using original dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, Training set f1-score:0.503, Test set f1-score: 0.468\n",
      "          - saga_L1, Training set f1-score:0.495, Test set f1-score: 0.519\n",
      "          - newton-cg_L2, Training set f1-score:0.503, Test set f1-score: 0.468\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, Training set f1-score:0.459, Test set f1-score: 0.512\n",
      "          - saga_L1, Training set f1-score:0.504, Test set f1-score: 0.485\n",
      "          - newton-cg_L2, Training set f1-score:0.459, Test set f1-score: 0.512\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, Training set f1-score:0.442, Test set f1-score: 0.513\n",
      "          - saga_L1, Training set f1-score:0.504, Test set f1-score: 0.485\n",
      "          - newton-cg_L2, Training set f1-score:0.442, Test set f1-score: 0.513\n",
      "       - C = 1\n",
      "          - lbfgs_L2, Training set f1-score:0.466, Test set f1-score: 0.532\n",
      "          - saga_L1, Training set f1-score:0.463, Test set f1-score: 0.595\n",
      "          - newton-cg_L2, Training set f1-score:0.466, Test set f1-score: 0.532\n",
      "       - C = 10\n",
      "          - lbfgs_L2, Training set f1-score:0.461, Test set f1-score: 0.595\n",
      "          - saga_L1, Training set f1-score:0.489, Test set f1-score: 0.612\n",
      "          - newton-cg_L2, Training set f1-score:0.461, Test set f1-score: 0.595\n",
      "       - C = 100\n",
      "          - lbfgs_L2, Training set f1-score:0.503, Test set f1-score: 0.612\n",
      "          - saga_L1, Training set f1-score:0.492, Test set f1-score: 0.613\n",
      "          - newton-cg_L2, Training set f1-score:0.500, Test set f1-score: 0.612\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, Training set f1-score:0.503, Test set f1-score: 0.613\n",
      "          - saga_L1, Training set f1-score:0.495, Test set f1-score: 0.613\n",
      "          - newton-cg_L2, Training set f1-score:0.503, Test set f1-score: 0.613\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. f1-score on training data: 0.578 f1-score on test data: 0.654\n",
      "          - tree depth: 2.000. f1-score on training data: 0.530 f1-score on test data: 0.537\n",
      "          - tree depth: 3.000. f1-score on training data: 0.591 f1-score on test data: 0.495\n",
      "          - tree depth: 4.000. f1-score on training data: 0.638 f1-score on test data: 0.519\n",
      "          - tree depth: 5.000. f1-score on training data: 0.667 f1-score on test data: 0.563\n",
      "          - tree depth: 6.000. f1-score on training data: 0.716 f1-score on test data: 0.556\n",
      "          - tree depth: 7.000. f1-score on training data: 0.799 f1-score on test data: 0.529\n",
      "          - tree depth: 8.000. f1-score on training data: 0.860 f1-score on test data: 0.508\n",
      "          - tree depth: 9.000. f1-score on training data: 0.887 f1-score on test data: 0.489\n",
      "          - tree depth: 10.000. f1-score on training data: 0.922 f1-score on test data: 0.479\n",
      "          - tree depth: 11.000. f1-score on training data: 0.952 f1-score on test data: 0.503\n",
      "          - tree depth: 12.000. f1-score on training data: 0.972 f1-score on test data: 0.501\n",
      "          - tree depth: 13.000. f1-score on training data: 0.980 f1-score on test data: 0.509\n",
      "          - tree depth: 14.000. f1-score on training data: 0.990 f1-score on test data: 0.476\n",
      "    - Random forest\n",
      "          - 5trees. f1-score on training data: 0.901 f1-score on test data: 0.504\n",
      "          - 10trees. f1-score on training data: 0.970 f1-score on test data: 0.547\n",
      "          - 15trees. f1-score on training data: 0.997 f1-score on test data: 0.552\n",
      "          - 20trees. f1-score on training data: 1.000 f1-score on test data: 0.473\n",
      "          - 25trees. f1-score on training data: 1.000 f1-score on test data: 0.510\n",
      "          - 30trees. f1-score on training data: 1.000 f1-score on test data: 0.521\n",
      "          - 35trees. f1-score on training data: 1.000 f1-score on test data: 0.519\n",
      "          - 40trees. f1-score on training data: 1.000 f1-score on test data: 0.539\n",
      "          - 45trees. f1-score on training data: 1.000 f1-score on test data: 0.541\n",
      "          - 50trees. f1-score on training data: 1.000 f1-score on test data: 0.546\n",
      "          - 55trees. f1-score on training data: 1.000 f1-score on test data: 0.555\n",
      "          - 60trees. f1-score on training data: 1.000 f1-score on test data: 0.555\n",
      "          - 65trees. f1-score on training data: 1.000 f1-score on test data: 0.555\n",
      "          - 70trees. f1-score on training data: 1.000 f1-score on test data: 0.563\n",
      "          - 75trees. f1-score on training data: 1.000 f1-score on test data: 0.571\n",
      "          - 80trees. f1-score on training data: 1.000 f1-score on test data: 0.553\n",
      "          - 85trees. f1-score on training data: 1.000 f1-score on test data: 0.554\n",
      "          - 90trees. f1-score on training data: 1.000 f1-score on test data: 0.564\n",
      "          - 95trees. f1-score on training data: 1.000 f1-score on test data: 0.584\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. f1-score on training data: 0.695 f1-score on test data: 0.458\n",
      "          - hidden layer size[20, 20]. f1-score on training data: 0.681 f1-score on test data: 0.516\n",
      "- Using scaled dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, Training set f1-score:0.478, Test set f1-score: 0.598\n",
      "          - saga_L1, Training set f1-score:0.501, Test set f1-score: 0.496\n",
      "          - newton-cg_L2, Training set f1-score:0.478, Test set f1-score: 0.598\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, Training set f1-score:0.494, Test set f1-score: 0.636\n",
      "          - saga_L1, Training set f1-score:0.504, Test set f1-score: 0.485\n",
      "          - newton-cg_L2, Training set f1-score:0.494, Test set f1-score: 0.636\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, Training set f1-score:0.481, Test set f1-score: 0.623\n",
      "          - saga_L1, Training set f1-score:0.489, Test set f1-score: 0.513\n",
      "          - newton-cg_L2, Training set f1-score:0.481, Test set f1-score: 0.623\n",
      "       - C = 1\n",
      "          - lbfgs_L2, Training set f1-score:0.495, Test set f1-score: 0.613\n",
      "          - saga_L1, Training set f1-score:0.500, Test set f1-score: 0.634\n",
      "          - newton-cg_L2, Training set f1-score:0.495, Test set f1-score: 0.613\n",
      "       - C = 10\n",
      "          - lbfgs_L2, Training set f1-score:0.506, Test set f1-score: 0.633\n",
      "          - saga_L1, Training set f1-score:0.511, Test set f1-score: 0.633\n",
      "          - newton-cg_L2, Training set f1-score:0.506, Test set f1-score: 0.633\n",
      "       - C = 100\n",
      "          - lbfgs_L2, Training set f1-score:0.506, Test set f1-score: 0.633\n",
      "          - saga_L1, Training set f1-score:0.506, Test set f1-score: 0.633\n",
      "          - newton-cg_L2, Training set f1-score:0.506, Test set f1-score: 0.623\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, Training set f1-score:0.506, Test set f1-score: 0.623\n",
      "          - saga_L1, Training set f1-score:0.506, Test set f1-score: 0.633\n",
      "          - newton-cg_L2, Training set f1-score:0.506, Test set f1-score: 0.623\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. f1-score on training data: 0.578 f1-score on test data: 0.654\n",
      "          - tree depth: 2.000. f1-score on training data: 0.530 f1-score on test data: 0.537\n",
      "          - tree depth: 3.000. f1-score on training data: 0.591 f1-score on test data: 0.495\n",
      "          - tree depth: 4.000. f1-score on training data: 0.638 f1-score on test data: 0.519\n",
      "          - tree depth: 5.000. f1-score on training data: 0.667 f1-score on test data: 0.563\n",
      "          - tree depth: 6.000. f1-score on training data: 0.716 f1-score on test data: 0.556\n",
      "          - tree depth: 7.000. f1-score on training data: 0.799 f1-score on test data: 0.529\n",
      "          - tree depth: 8.000. f1-score on training data: 0.860 f1-score on test data: 0.508\n",
      "          - tree depth: 9.000. f1-score on training data: 0.887 f1-score on test data: 0.489\n",
      "          - tree depth: 10.000. f1-score on training data: 0.922 f1-score on test data: 0.479\n",
      "          - tree depth: 11.000. f1-score on training data: 0.952 f1-score on test data: 0.503\n",
      "          - tree depth: 12.000. f1-score on training data: 0.972 f1-score on test data: 0.501\n",
      "          - tree depth: 13.000. f1-score on training data: 0.980 f1-score on test data: 0.509\n",
      "          - tree depth: 14.000. f1-score on training data: 0.990 f1-score on test data: 0.476\n",
      "    - Random forest\n",
      "          - 5trees. f1-score on training data: 0.901 f1-score on test data: 0.504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          - 10trees. f1-score on training data: 0.970 f1-score on test data: 0.547\n",
      "          - 15trees. f1-score on training data: 0.997 f1-score on test data: 0.552\n",
      "          - 20trees. f1-score on training data: 1.000 f1-score on test data: 0.473\n",
      "          - 25trees. f1-score on training data: 1.000 f1-score on test data: 0.510\n",
      "          - 30trees. f1-score on training data: 1.000 f1-score on test data: 0.521\n",
      "          - 35trees. f1-score on training data: 1.000 f1-score on test data: 0.519\n",
      "          - 40trees. f1-score on training data: 1.000 f1-score on test data: 0.539\n",
      "          - 45trees. f1-score on training data: 1.000 f1-score on test data: 0.541\n",
      "          - 50trees. f1-score on training data: 1.000 f1-score on test data: 0.546\n",
      "          - 55trees. f1-score on training data: 1.000 f1-score on test data: 0.555\n",
      "          - 60trees. f1-score on training data: 1.000 f1-score on test data: 0.563\n",
      "          - 65trees. f1-score on training data: 1.000 f1-score on test data: 0.555\n",
      "          - 70trees. f1-score on training data: 1.000 f1-score on test data: 0.564\n",
      "          - 75trees. f1-score on training data: 1.000 f1-score on test data: 0.571\n",
      "          - 80trees. f1-score on training data: 1.000 f1-score on test data: 0.553\n",
      "          - 85trees. f1-score on training data: 1.000 f1-score on test data: 0.555\n",
      "          - 90trees. f1-score on training data: 1.000 f1-score on test data: 0.565\n",
      "          - 95trees. f1-score on training data: 1.000 f1-score on test data: 0.584\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. f1-score on training data: 1.000 f1-score on test data: 0.434\n",
      "          - hidden layer size[20, 20]. f1-score on training data: 1.000 f1-score on test data: 0.504\n",
      "- Using 6 pca-components:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, Training set f1-score:0.481, Test set f1-score: 0.543\n",
      "          - saga_L1, Training set f1-score:0.501, Test set f1-score: 0.496\n",
      "          - newton-cg_L2, Training set f1-score:0.481, Test set f1-score: 0.543\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, Training set f1-score:0.481, Test set f1-score: 0.610\n",
      "          - saga_L1, Training set f1-score:0.499, Test set f1-score: 0.602\n",
      "          - newton-cg_L2, Training set f1-score:0.481, Test set f1-score: 0.610\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, Training set f1-score:0.466, Test set f1-score: 0.646\n",
      "          - saga_L1, Training set f1-score:0.479, Test set f1-score: 0.582\n",
      "          - newton-cg_L2, Training set f1-score:0.466, Test set f1-score: 0.646\n",
      "       - C = 1\n",
      "          - lbfgs_L2, Training set f1-score:0.474, Test set f1-score: 0.628\n",
      "          - saga_L1, Training set f1-score:0.477, Test set f1-score: 0.618\n",
      "          - newton-cg_L2, Training set f1-score:0.474, Test set f1-score: 0.628\n",
      "       - C = 10\n",
      "          - lbfgs_L2, Training set f1-score:0.479, Test set f1-score: 0.628\n",
      "          - saga_L1, Training set f1-score:0.480, Test set f1-score: 0.628\n",
      "          - newton-cg_L2, Training set f1-score:0.479, Test set f1-score: 0.628\n",
      "       - C = 100\n",
      "          - lbfgs_L2, Training set f1-score:0.479, Test set f1-score: 0.628\n",
      "          - saga_L1, Training set f1-score:0.482, Test set f1-score: 0.628\n",
      "          - newton-cg_L2, Training set f1-score:0.479, Test set f1-score: 0.628\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, Training set f1-score:0.479, Test set f1-score: 0.628\n",
      "          - saga_L1, Training set f1-score:0.482, Test set f1-score: 0.628\n",
      "          - newton-cg_L2, Training set f1-score:0.479, Test set f1-score: 0.628\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. f1-score on training data: 0.525 f1-score on test data: 0.602\n",
      "          - tree depth: 2.000. f1-score on training data: 0.570 f1-score on test data: 0.556\n",
      "          - tree depth: 3.000. f1-score on training data: 0.534 f1-score on test data: 0.450\n",
      "          - tree depth: 4.000. f1-score on training data: 0.585 f1-score on test data: 0.528\n",
      "          - tree depth: 5.000. f1-score on training data: 0.625 f1-score on test data: 0.485\n",
      "          - tree depth: 6.000. f1-score on training data: 0.687 f1-score on test data: 0.472\n",
      "          - tree depth: 7.000. f1-score on training data: 0.741 f1-score on test data: 0.449\n",
      "          - tree depth: 8.000. f1-score on training data: 0.781 f1-score on test data: 0.475\n",
      "          - tree depth: 9.000. f1-score on training data: 0.843 f1-score on test data: 0.436\n",
      "          - tree depth: 10.000. f1-score on training data: 0.874 f1-score on test data: 0.490\n",
      "          - tree depth: 11.000. f1-score on training data: 0.912 f1-score on test data: 0.479\n",
      "          - tree depth: 12.000. f1-score on training data: 0.940 f1-score on test data: 0.479\n",
      "          - tree depth: 13.000. f1-score on training data: 0.962 f1-score on test data: 0.531\n",
      "          - tree depth: 14.000. f1-score on training data: 0.977 f1-score on test data: 0.519\n",
      "    - Random forest\n",
      "          - 5trees. f1-score on training data: 0.923 f1-score on test data: 0.463\n",
      "          - 10trees. f1-score on training data: 0.980 f1-score on test data: 0.559\n",
      "          - 15trees. f1-score on training data: 0.987 f1-score on test data: 0.500\n",
      "          - 20trees. f1-score on training data: 0.997 f1-score on test data: 0.509\n",
      "          - 25trees. f1-score on training data: 0.997 f1-score on test data: 0.509\n",
      "          - 30trees. f1-score on training data: 0.997 f1-score on test data: 0.507\n",
      "          - 35trees. f1-score on training data: 1.000 f1-score on test data: 0.522\n",
      "          - 40trees. f1-score on training data: 1.000 f1-score on test data: 0.527\n",
      "          - 45trees. f1-score on training data: 1.000 f1-score on test data: 0.527\n",
      "          - 50trees. f1-score on training data: 1.000 f1-score on test data: 0.523\n",
      "          - 55trees. f1-score on training data: 1.000 f1-score on test data: 0.488\n",
      "          - 60trees. f1-score on training data: 1.000 f1-score on test data: 0.494\n",
      "          - 65trees. f1-score on training data: 1.000 f1-score on test data: 0.525\n",
      "          - 70trees. f1-score on training data: 1.000 f1-score on test data: 0.529\n",
      "          - 75trees. f1-score on training data: 1.000 f1-score on test data: 0.498\n",
      "          - 80trees. f1-score on training data: 1.000 f1-score on test data: 0.489\n",
      "          - 85trees. f1-score on training data: 1.000 f1-score on test data: 0.468\n",
      "          - 90trees. f1-score on training data: 1.000 f1-score on test data: 0.512\n",
      "          - 95trees. f1-score on training data: 1.000 f1-score on test data: 0.511\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. f1-score on training data: 1.000 f1-score on test data: 0.509\n",
      "          - hidden layer size[20, 20]. f1-score on training data: 1.000 f1-score on test data: 0.472\n"
     ]
    }
   ],
   "source": [
    "models(df_3mci,drop_lst,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2de15359",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After undersampling data size is 498 ; Resampled dataset shape Counter({'MCI-AD': 166, 'MCI-CN': 166, 'MCI-MCI': 166})\n",
      "\n",
      "6 principle components are needed to explain 90% of the data\n",
      "\n",
      "- Using original dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.251\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.165\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.251\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.339\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.160\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.339\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.403\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.208\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.403\n",
      "       - C = 1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.432\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.438\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.432\n",
      "       - C = 10\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.461\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.482\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.460\n",
      "       - C = 100\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.486\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.488\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.486\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.485\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.486\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.485\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. average weighted f1-score of 10-cross validation:0.380\n",
      "          - tree depth: 2.000. average weighted f1-score of 10-cross validation:0.450\n",
      "          - tree depth: 3.000. average weighted f1-score of 10-cross validation:0.456\n",
      "          - tree depth: 4.000. average weighted f1-score of 10-cross validation:0.488\n",
      "          - tree depth: 5.000. average weighted f1-score of 10-cross validation:0.480\n",
      "          - tree depth: 6.000. average weighted f1-score of 10-cross validation:0.474\n",
      "          - tree depth: 7.000. average weighted f1-score of 10-cross validation:0.468\n",
      "          - tree depth: 8.000. average weighted f1-score of 10-cross validation:0.423\n",
      "          - tree depth: 9.000. average weighted f1-score of 10-cross validation:0.427\n",
      "          - tree depth: 10.000. average weighted f1-score of 10-cross validation:0.406\n",
      "          - tree depth: 11.000. average weighted f1-score of 10-cross validation:0.423\n",
      "          - tree depth: 12.000. average weighted f1-score of 10-cross validation:0.436\n",
      "          - tree depth: 13.000. average weighted f1-score of 10-cross validation:0.410\n",
      "          - tree depth: 14.000. average weighted f1-score of 10-cross validation:0.428\n",
      "    - Random forest\n",
      "          - 5trees. average weighted f1-score of 10-cross validation:0.436\n",
      "          - 10trees. average weighted f1-score of 10-cross validation:0.462\n",
      "          - 15trees. average weighted f1-score of 10-cross validation:0.468\n",
      "          - 20trees. average weighted f1-score of 10-cross validation:0.464\n",
      "          - 25trees. average weighted f1-score of 10-cross validation:0.464\n",
      "          - 30trees. average weighted f1-score of 10-cross validation:0.466\n",
      "          - 35trees. average weighted f1-score of 10-cross validation:0.469\n",
      "          - 40trees. average weighted f1-score of 10-cross validation:0.480\n",
      "          - 45trees. average weighted f1-score of 10-cross validation:0.483\n",
      "          - 50trees. average weighted f1-score of 10-cross validation:0.477\n",
      "          - 55trees. average weighted f1-score of 10-cross validation:0.476\n",
      "          - 60trees. average weighted f1-score of 10-cross validation:0.475\n",
      "          - 65trees. average weighted f1-score of 10-cross validation:0.485\n",
      "          - 70trees. average weighted f1-score of 10-cross validation:0.473\n",
      "          - 75trees. average weighted f1-score of 10-cross validation:0.474\n",
      "          - 80trees. average weighted f1-score of 10-cross validation:0.487\n",
      "          - 85trees. average weighted f1-score of 10-cross validation:0.480\n",
      "          - 90trees. average weighted f1-score of 10-cross validation:0.479\n",
      "          - 95trees. average weighted f1-score of 10-cross validation:0.479\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. average weighted f1-score of 10-cross validation:0.436\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-6159da5b1ce0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcv_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_3mci\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdrop_lst\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\GitHub\\Brain_health_challenge_tobereviewed\\notebook\\dash_model_two.py\u001b[0m in \u001b[0;36mcv_models\u001b[1;34m(df, drop_lst, target, k)\u001b[0m\n\u001b[0;32m    250\u001b[0m             \u001b[0mmlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'lbfgs'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m460\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhidden_layer_sizes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m             \u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'          - hidden layer size{}. average weighted f1-score of {}-cross validation:{:.3f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'f1_weighted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    513\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m     cv_results = cross_validate(\n\u001b[0m\u001b[0;32m    516\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;31m# independent, and that it is pickle-able.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m     results = parallel(\n\u001b[0m\u001b[0;32m    267\u001b[0m         delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m             \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mMLP\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m         \"\"\"\n\u001b[1;32m--> 762\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_solver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, incremental)\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[1;31m# Run the LBFGS solver\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"lbfgs\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m             self._fit_lbfgs(\n\u001b[0m\u001b[0;32m    442\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef_grads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintercept_grads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer_units\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit_lbfgs\u001b[1;34m(self, X, y, activations, deltas, coef_grads, intercept_grads, layer_units)\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[0miprint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 546\u001b[1;33m         opt_res = scipy.optimize.minimize(\n\u001b[0m\u001b[0;32m    547\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_loss_grad_lbfgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mpacked_coef_inter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    617\u001b[0m                                   **options)\n\u001b[0;32m    618\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'l-bfgs-b'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 619\u001b[1;33m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[0;32m    620\u001b[0m                                 callback=callback, **options)\n\u001b[0;32m    621\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tnc'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    358\u001b[0m             \u001b[1;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m             \u001b[1;31m# Overwrite f and g:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'NEW_X'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m             \u001b[1;31m# new iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;34m\"\"\" returns the the function value \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[0mfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_loss_grad_lbfgs\u001b[1;34m(self, packed_coef_inter, X, y, activations, deltas, coef_grads, intercept_grads)\u001b[0m\n\u001b[0;32m    233\u001b[0m         \"\"\"\n\u001b[0;32m    234\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpacked_coef_inter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m         loss, coef_grads, intercept_grads = self._backprop(\n\u001b[0m\u001b[0;32m    236\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef_grads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintercept_grads\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_backprop\u001b[1;34m(self, X, y, activations, deltas, coef_grads, intercept_grads)\u001b[0m\n\u001b[0;32m    284\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mloss_func_name\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"log_loss\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout_activation_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"logistic\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m             \u001b[0mloss_func_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"binary_log_loss\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLOSS_FUNCTIONS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloss_func_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m         \u001b[1;31m# Add L2 regularization term to loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_base.py\u001b[0m in \u001b[0;36mlog_loss\u001b[1;34m(y_true, y_prob)\u001b[0m\n\u001b[0;32m    193\u001b[0m     \"\"\"\n\u001b[0;32m    194\u001b[0m     \u001b[0meps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_prob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m     \u001b[0my_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_prob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[0my_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mclip\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mclip\u001b[1;34m(a, a_min, a_max, out, **kwargs)\u001b[0m\n\u001b[0;32m   2101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2102\u001b[0m     \"\"\"\n\u001b[1;32m-> 2103\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'clip'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_clip\u001b[1;34m(a, min, max, out, casting, **kwargs)\u001b[0m\n\u001b[0;32m    156\u001b[0m             um.maximum, a, min, out=out, casting=casting, **kwargs)\n\u001b[0;32m    157\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m         return _clip_dep_invoke_with_casting(\n\u001b[0m\u001b[0;32m    159\u001b[0m             um.clip, a, min, max, out=out, casting=casting, **kwargs)\n\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_clip_dep_invoke_with_casting\u001b[1;34m(ufunc, out, casting, *args, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# try to deal with broken casting rules\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_exceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_UFuncOutputCastingError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# Numpy 1.17.0, 2019-02-24\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv_models(df_3mci,drop_lst,target,k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
