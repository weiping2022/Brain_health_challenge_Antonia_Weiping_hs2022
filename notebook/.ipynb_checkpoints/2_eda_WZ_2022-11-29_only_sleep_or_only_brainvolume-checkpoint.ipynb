{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "20f5d23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.tree import export_text\n",
    "import mglearn\n",
    "from dashboard_one import *\n",
    "from feature_selection import *\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbb9fdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weipi\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (15,18) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RID</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>OSA</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>depression</th>\n",
       "      <th>PTGENDER</th>\n",
       "      <th>PTETHCAT</th>\n",
       "      <th>PTRACCAT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PTID</th>\n",
       "      <th>...</th>\n",
       "      <th>GDBETTER</th>\n",
       "      <th>GDTOTAL</th>\n",
       "      <th>GDCAT</th>\n",
       "      <th>LIMMTOTAL</th>\n",
       "      <th>AVTOT1</th>\n",
       "      <th>AVTOT2</th>\n",
       "      <th>AVTOT3</th>\n",
       "      <th>AVTOT4</th>\n",
       "      <th>AVTOT5</th>\n",
       "      <th>DX_bl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Not Hisp/Latino</td>\n",
       "      <td>White</td>\n",
       "      <td>74.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Not Hisp/Latino</td>\n",
       "      <td>White</td>\n",
       "      <td>74.3</td>\n",
       "      <td>011_S_0002</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Not Hisp/Latino</td>\n",
       "      <td>White</td>\n",
       "      <td>74.3</td>\n",
       "      <td>011_S_0002</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Not Hisp/Latino</td>\n",
       "      <td>White</td>\n",
       "      <td>74.3</td>\n",
       "      <td>011_S_0002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Not Hisp/Latino</td>\n",
       "      <td>White</td>\n",
       "      <td>74.3</td>\n",
       "      <td>011_S_0002</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27115</th>\n",
       "      <td>7102</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>341_S_7102</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27116</th>\n",
       "      <td>7103</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>013_S_7103</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27117</th>\n",
       "      <td>7104</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>153_S_7104</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27118</th>\n",
       "      <td>7105</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>035_S_7105</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27119</th>\n",
       "      <td>7106</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>941_S_7106</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27120 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RID  hypertension  OSA  anxiety  depression PTGENDER         PTETHCAT  \\\n",
       "0         2           0.0  0.0      1.0         1.0     Male  Not Hisp/Latino   \n",
       "1         2           0.0  0.0      1.0         1.0     Male  Not Hisp/Latino   \n",
       "2         2           0.0  0.0      1.0         1.0     Male  Not Hisp/Latino   \n",
       "3         2           0.0  0.0      1.0         1.0     Male  Not Hisp/Latino   \n",
       "4         2           0.0  0.0      1.0         1.0     Male  Not Hisp/Latino   \n",
       "...     ...           ...  ...      ...         ...      ...              ...   \n",
       "27115  7102           1.0  0.0      1.0         1.0      NaN              NaN   \n",
       "27116  7103           1.0  0.0      1.0         1.0      NaN              NaN   \n",
       "27117  7104           1.0  0.0      1.0         1.0      NaN              NaN   \n",
       "27118  7105           1.0  0.0      1.0         1.0      NaN              NaN   \n",
       "27119  7106           1.0  0.0      1.0         1.0      NaN              NaN   \n",
       "\n",
       "      PTRACCAT   AGE        PTID  ... GDBETTER GDTOTAL GDCAT LIMMTOTAL AVTOT1  \\\n",
       "0        White  74.3         NaN  ...      0.0     1.0   1.0      13.0    NaN   \n",
       "1        White  74.3  011_S_0002  ...      NaN     NaN   NaN       NaN    7.0   \n",
       "2        White  74.3  011_S_0002  ...      NaN     NaN   NaN       NaN    5.0   \n",
       "3        White  74.3  011_S_0002  ...      0.0     2.0   1.0      15.0    6.0   \n",
       "4        White  74.3  011_S_0002  ...      NaN     NaN   NaN       NaN    NaN   \n",
       "...        ...   ...         ...  ...      ...     ...   ...       ...    ...   \n",
       "27115      NaN   NaN  341_S_7102  ...      NaN     NaN   NaN       NaN    NaN   \n",
       "27116      NaN   NaN  013_S_7103  ...      NaN     NaN   NaN       NaN    NaN   \n",
       "27117      NaN   NaN  153_S_7104  ...      NaN     NaN   NaN       NaN    NaN   \n",
       "27118      NaN   NaN  035_S_7105  ...      NaN     NaN   NaN       NaN    NaN   \n",
       "27119      NaN   NaN  941_S_7106  ...      NaN     NaN   NaN       NaN    NaN   \n",
       "\n",
       "      AVTOT2 AVTOT3 AVTOT4 AVTOT5 DX_bl  \n",
       "0        NaN    NaN    NaN    NaN    CN  \n",
       "1        7.0    9.0   10.0   11.0    CN  \n",
       "2        9.0    9.0    9.0    8.0    CN  \n",
       "3        6.0    6.0    8.0    8.0    CN  \n",
       "4        NaN    NaN    NaN    NaN    CN  \n",
       "...      ...    ...    ...    ...   ...  \n",
       "27115    NaN    NaN    NaN    NaN   NaN  \n",
       "27116    NaN    NaN    NaN    NaN   NaN  \n",
       "27117    NaN    NaN    NaN    NaN   NaN  \n",
       "27118    NaN    NaN    NaN    NaN   NaN  \n",
       "27119    NaN    NaN    NaN    NaN   NaN  \n",
       "\n",
       "[27120 rows x 59 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('main_file.csv').iloc[:,1:]\n",
    "com_col = ['Phase','RID','VISCODE']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "323674d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RID', 'hypertension', 'OSA', 'anxiety', 'depression', 'PTGENDER',\n",
       "       'PTETHCAT', 'PTRACCAT', 'AGE', 'PTID', 'Phase', 'VISCODE', 'DX',\n",
       "       'ABETA', 'TAU', 'PTAU', 'ABETA_bl', 'TAU_bl', 'PTAU_bl', 'DXCHANGE',\n",
       "       'NPIK1', 'NPIK2', 'NPIK3', 'NPIK4', 'NPIK5', 'NPIK6', 'NPIK7', 'NPIK8',\n",
       "       'NPIK9A', 'NPIK9B', 'NPIK9C', 'NPIKTOT', 'NPIKSEV', 'insomnia', 'index',\n",
       "       'GDSATIS', 'GDDROP', 'GDEMPTY', 'GDBORED', 'GDSPIRIT', 'GDAFRAID',\n",
       "       'GDHAPPY', 'GDHELP', 'GDHOME', 'GDMEMORY', 'GDALIVE', 'GDWORTH',\n",
       "       'GDENERGY', 'GDHOPE', 'GDBETTER', 'GDTOTAL', 'GDCAT', 'LIMMTOTAL',\n",
       "       'AVTOT1', 'AVTOT2', 'AVTOT3', 'AVTOT4', 'AVTOT5', 'DX_bl'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af451113",
   "metadata": {},
   "source": [
    "### Sleep vs Diagnosis(MCI, AD, NC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a168c0",
   "metadata": {},
   "source": [
    "Quick recap:\n",
    "- ADNI1: DXCURREN 1=NL; 2=MCI; 3=AD\n",
    "- ADNIGO/2: DXCHANGE    \n",
    "    1=Stable: NL to NL;    \n",
    "    2=Stable: MCI to MCI;  \n",
    "    3=Stable: Dementia to Dementia;   \n",
    "    4=Conversion: NL to MCI;   \n",
    "    5=Conversion: MCI to Dementia; \n",
    "    6=Conversion: NL to Dementia;  \n",
    "    7=Reversion: MCI to NL;   \n",
    "    8=Reversion: Dementia to MCI;   \n",
    "    9=Reversion: Dementia to NL    \n",
    "- ADNI3: DIAGNOSIS 1=CN; 2=MCI; 3=Dementia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44d63ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(len(col_lst)-1, 1,figsize=(8, 60))\n",
    "for i in range(len(col_lst)-1):\n",
    "    sns.histplot(data=sleep_dxch['NPIK1', 'NPIK2', 'NPIK3', 'NPIK4', 'NPIK5', 'NPIK6', 'NPIK7', 'NPIK8',\n",
    "       'NPIK9A', 'NPIK9B', 'NPIK9C', 'NPIKTOT', 'NPIKSEV', 'insomnia','OSA'], x=\"DXCHANGE\", multiple=\"dodge\", shrink=.8, ax=axes[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242de69f",
   "metadata": {},
   "source": [
    "#### drop column 'NPIKSEV', otherwise we get no samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b9b829bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phase</th>\n",
       "      <th>RID</th>\n",
       "      <th>VISCODE</th>\n",
       "      <th>DXCHANGE</th>\n",
       "      <th>NPIK1</th>\n",
       "      <th>NPIK2</th>\n",
       "      <th>NPIK3</th>\n",
       "      <th>NPIK4</th>\n",
       "      <th>NPIK5</th>\n",
       "      <th>NPIK6</th>\n",
       "      <th>NPIK7</th>\n",
       "      <th>NPIK8</th>\n",
       "      <th>NPIK9A</th>\n",
       "      <th>NPIK9B</th>\n",
       "      <th>NPIK9C</th>\n",
       "      <th>NPIKTOT</th>\n",
       "      <th>insomnia</th>\n",
       "      <th>OSA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADNI2</td>\n",
       "      <td>8</td>\n",
       "      <td>v06</td>\n",
       "      <td>CN-CN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADNI2</td>\n",
       "      <td>8</td>\n",
       "      <td>v41</td>\n",
       "      <td>CN-MCI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADNI2</td>\n",
       "      <td>31</td>\n",
       "      <td>v06</td>\n",
       "      <td>CN-CN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADNI2</td>\n",
       "      <td>31</td>\n",
       "      <td>v11</td>\n",
       "      <td>CN-CN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADNI2</td>\n",
       "      <td>31</td>\n",
       "      <td>v21</td>\n",
       "      <td>CN-CN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>6890</td>\n",
       "      <td>y1</td>\n",
       "      <td>MCI-MCI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>6891</td>\n",
       "      <td>y1</td>\n",
       "      <td>AD-AD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>6897</td>\n",
       "      <td>y1</td>\n",
       "      <td>MCI-MCI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>6947</td>\n",
       "      <td>y1</td>\n",
       "      <td>MCI-MCI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>6962</td>\n",
       "      <td>y1</td>\n",
       "      <td>AD-AD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1131 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Phase   RID VISCODE DXCHANGE  NPIK1  NPIK2  NPIK3  NPIK4  NPIK5  NPIK6  \\\n",
       "0     ADNI2     8     v06    CN-CN    1.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1     ADNI2     8     v41   CN-MCI    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2     ADNI2    31     v06    CN-CN    0.0    1.0    0.0    0.0    0.0    1.0   \n",
       "3     ADNI2    31     v11    CN-CN    0.0    1.0    0.0    0.0    0.0    1.0   \n",
       "4     ADNI2    31     v21    CN-CN    0.0    0.0    0.0    1.0    0.0    0.0   \n",
       "...     ...   ...     ...      ...    ...    ...    ...    ...    ...    ...   \n",
       "1212  ADNI3  6890      y1  MCI-MCI    0.0    1.0    0.0    0.0    0.0    0.0   \n",
       "1213  ADNI3  6891      y1    AD-AD    1.0    1.0    0.0    1.0    0.0    0.0   \n",
       "1214  ADNI3  6897      y1  MCI-MCI    0.0    0.0    0.0    1.0    0.0    0.0   \n",
       "1218  ADNI3  6947      y1  MCI-MCI    0.0    1.0    0.0    0.0    0.0    0.0   \n",
       "1220  ADNI3  6962      y1    AD-AD    0.0    1.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "      NPIK7  NPIK8  NPIK9A  NPIK9B  NPIK9C  NPIKTOT  insomnia  OSA  \n",
       "0       0.0    0.0     3.0     2.0     0.0      6.0       1.0  0.0  \n",
       "1       1.0    0.0     4.0     2.0     1.0      8.0       1.0  0.0  \n",
       "2       0.0    0.0     2.0     1.0     0.0      2.0       1.0  0.0  \n",
       "3       0.0    0.0     2.0     1.0     0.0      2.0       1.0  0.0  \n",
       "4       0.0    0.0     3.0     1.0     1.0      3.0       1.0  0.0  \n",
       "...     ...    ...     ...     ...     ...      ...       ...  ...  \n",
       "1212    0.0    0.0     4.0     1.0     1.0      4.0       1.0  1.0  \n",
       "1213    1.0    0.0     4.0     2.0     3.0      8.0       1.0  0.0  \n",
       "1214    0.0    1.0     1.0     1.0     1.0      1.0       1.0  0.0  \n",
       "1218    1.0    0.0     1.0     1.0     1.0      1.0       1.0  0.0  \n",
       "1220    0.0    1.0     3.0     2.0     2.0      6.0       1.0  0.0  \n",
       "\n",
       "[1131 rows x 18 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_lst = [ 'DXCHANGE','NPIK1', 'NPIK2', 'NPIK3', 'NPIK4', 'NPIK5', 'NPIK6', 'NPIK7', 'NPIK8',\n",
    "       'NPIK9A', 'NPIK9B', 'NPIK9C', 'NPIKTOT',  'insomnia','OSA']\n",
    "sleep_dxch = df[com_col + col_lst].set_index(['Phase', 'RID', 'VISCODE']).dropna(how='any',axis=0).reset_index()\n",
    "sleep_dxch = sleep_dxch[sleep_dxch['VISCODE']!='bl']\n",
    "sleep_dxch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1782d6df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phase</th>\n",
       "      <th>RID</th>\n",
       "      <th>VISCODE</th>\n",
       "      <th>NPIK1</th>\n",
       "      <th>NPIK2</th>\n",
       "      <th>NPIK3</th>\n",
       "      <th>NPIK4</th>\n",
       "      <th>NPIK5</th>\n",
       "      <th>NPIK6</th>\n",
       "      <th>NPIK7</th>\n",
       "      <th>NPIK8</th>\n",
       "      <th>NPIK9A</th>\n",
       "      <th>NPIK9B</th>\n",
       "      <th>NPIK9C</th>\n",
       "      <th>NPIKTOT</th>\n",
       "      <th>insomnia</th>\n",
       "      <th>OSA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DXCHANGE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AD-AD</th>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AD-MCI</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CN-AD</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CN-CN</th>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CN-MCI</th>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCI-AD</th>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCI-CN</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCI-MCI</th>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Phase  RID  VISCODE  NPIK1  NPIK2  NPIK3  NPIK4  NPIK5  NPIK6  \\\n",
       "DXCHANGE                                                                  \n",
       "AD-AD       159  159      159    159    159    159    159    159    159   \n",
       "AD-MCI        2    2        2      2      2      2      2      2      2   \n",
       "CN-AD         6    6        6      6      6      6      6      6      6   \n",
       "CN-CN       291  291      291    291    291    291    291    291    291   \n",
       "CN-MCI       38   38       38     38     38     38     38     38     38   \n",
       "MCI-AD       80   80       80     80     80     80     80     80     80   \n",
       "MCI-CN       39   39       39     39     39     39     39     39     39   \n",
       "MCI-MCI     516  516      516    516    516    516    516    516    516   \n",
       "\n",
       "          NPIK7  NPIK8  NPIK9A  NPIK9B  NPIK9C  NPIKTOT  insomnia  OSA  \n",
       "DXCHANGE                                                                \n",
       "AD-AD       159    159     159     159     159      159       159  159  \n",
       "AD-MCI        2      2       2       2       2        2         2    2  \n",
       "CN-AD         6      6       6       6       6        6         6    6  \n",
       "CN-CN       291    291     291     291     291      291       291  291  \n",
       "CN-MCI       38     38      38      38      38       38        38   38  \n",
       "MCI-AD       80     80      80      80      80       80        80   80  \n",
       "MCI-CN       39     39      39      39      39       39        39   39  \n",
       "MCI-MCI     516    516     516     516     516      516       516  516  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sleep_dxch.groupby('DXCHANGE').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9018ac3",
   "metadata": {},
   "source": [
    "drop DXCHANGE groups 'AD-MCI','CN-AD', then undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "eaf0970c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phase</th>\n",
       "      <th>RID</th>\n",
       "      <th>VISCODE</th>\n",
       "      <th>DXCHANGE</th>\n",
       "      <th>NPIK1</th>\n",
       "      <th>NPIK2</th>\n",
       "      <th>NPIK3</th>\n",
       "      <th>NPIK4</th>\n",
       "      <th>NPIK5</th>\n",
       "      <th>NPIK6</th>\n",
       "      <th>NPIK7</th>\n",
       "      <th>NPIK8</th>\n",
       "      <th>NPIK9A</th>\n",
       "      <th>NPIK9B</th>\n",
       "      <th>NPIK9C</th>\n",
       "      <th>NPIKTOT</th>\n",
       "      <th>insomnia</th>\n",
       "      <th>OSA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ADNI2</td>\n",
       "      <td>55</td>\n",
       "      <td>v11</td>\n",
       "      <td>MCI-MCI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ADNI2</td>\n",
       "      <td>61</td>\n",
       "      <td>v21</td>\n",
       "      <td>MCI-AD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ADNI2</td>\n",
       "      <td>112</td>\n",
       "      <td>v31</td>\n",
       "      <td>MCI-MCI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ADNI2</td>\n",
       "      <td>112</td>\n",
       "      <td>v41</td>\n",
       "      <td>MCI-AD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>112</td>\n",
       "      <td>init</td>\n",
       "      <td>MCI-AD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>6871</td>\n",
       "      <td>y1</td>\n",
       "      <td>MCI-MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>6888</td>\n",
       "      <td>y1</td>\n",
       "      <td>MCI-MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>6890</td>\n",
       "      <td>y1</td>\n",
       "      <td>MCI-MCI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>6897</td>\n",
       "      <td>y1</td>\n",
       "      <td>MCI-MCI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>6947</td>\n",
       "      <td>y1</td>\n",
       "      <td>MCI-MCI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>596 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Phase   RID VISCODE DXCHANGE  NPIK1  NPIK2  NPIK3  NPIK4  NPIK5  NPIK6  \\\n",
       "6     ADNI2    55     v11  MCI-MCI    0.0    0.0    0.0    1.0    0.0    0.0   \n",
       "9     ADNI2    61     v21   MCI-AD    0.0    1.0    0.0    0.0    0.0    0.0   \n",
       "17    ADNI2   112     v31  MCI-MCI    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "18    ADNI2   112     v41   MCI-AD    0.0    1.0    0.0    1.0    0.0    0.0   \n",
       "19    ADNI3   112    init   MCI-AD    0.0    1.0    1.0    1.0    1.0    0.0   \n",
       "...     ...   ...     ...      ...    ...    ...    ...    ...    ...    ...   \n",
       "1206  ADNI3  6871      y1  MCI-MCI    1.0    1.0    0.0    0.0    0.0    0.0   \n",
       "1210  ADNI3  6888      y1  MCI-MCI    1.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1212  ADNI3  6890      y1  MCI-MCI    0.0    1.0    0.0    0.0    0.0    0.0   \n",
       "1214  ADNI3  6897      y1  MCI-MCI    0.0    0.0    0.0    1.0    0.0    0.0   \n",
       "1218  ADNI3  6947      y1  MCI-MCI    0.0    1.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "      NPIK7  NPIK8  NPIK9A  NPIK9B  NPIK9C  NPIKTOT  insomnia  OSA  \n",
       "6       0.0    0.0     1.0     1.0     0.0      1.0       1.0  0.0  \n",
       "9       0.0    0.0     1.0     1.0     1.0      1.0       1.0  0.0  \n",
       "17      1.0    0.0     4.0     1.0     2.0      4.0       1.0  0.0  \n",
       "18      0.0    0.0     4.0     1.0     1.0      4.0       1.0  0.0  \n",
       "19      1.0    0.0     4.0     2.0     3.0      8.0       1.0  0.0  \n",
       "...     ...    ...     ...     ...     ...      ...       ...  ...  \n",
       "1206    0.0    0.0     2.0     1.0     1.0      2.0       1.0  0.0  \n",
       "1210    0.0    0.0     3.0     1.0     2.0      3.0       1.0  0.0  \n",
       "1212    0.0    0.0     4.0     1.0     1.0      4.0       1.0  1.0  \n",
       "1214    0.0    1.0     1.0     1.0     1.0      1.0       1.0  0.0  \n",
       "1218    1.0    0.0     1.0     1.0     1.0      1.0       1.0  0.0  \n",
       "\n",
       "[596 rows x 18 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sleep_dxch_2g = sleep_dxch.loc[sleep_dxch['DXCHANGE'].isin(['MCI-AD','MCI-MCI'])]\n",
    "sleep_dxch_2g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3f4fde84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phase</th>\n",
       "      <th>RID</th>\n",
       "      <th>VISCODE</th>\n",
       "      <th>DXCHANGE</th>\n",
       "      <th>NPIK1</th>\n",
       "      <th>NPIK2</th>\n",
       "      <th>NPIK3</th>\n",
       "      <th>NPIK4</th>\n",
       "      <th>NPIK5</th>\n",
       "      <th>NPIK6</th>\n",
       "      <th>NPIK7</th>\n",
       "      <th>NPIK8</th>\n",
       "      <th>NPIK9A</th>\n",
       "      <th>NPIK9B</th>\n",
       "      <th>NPIK9C</th>\n",
       "      <th>NPIKTOT</th>\n",
       "      <th>insomnia</th>\n",
       "      <th>OSA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADNI2</td>\n",
       "      <td>8</td>\n",
       "      <td>v06</td>\n",
       "      <td>CN-CN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADNI2</td>\n",
       "      <td>8</td>\n",
       "      <td>v41</td>\n",
       "      <td>CN-MCI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADNI2</td>\n",
       "      <td>31</td>\n",
       "      <td>v06</td>\n",
       "      <td>CN-CN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADNI2</td>\n",
       "      <td>31</td>\n",
       "      <td>v11</td>\n",
       "      <td>CN-CN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADNI2</td>\n",
       "      <td>31</td>\n",
       "      <td>v21</td>\n",
       "      <td>CN-CN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>6890</td>\n",
       "      <td>y1</td>\n",
       "      <td>MCI-MCI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>6891</td>\n",
       "      <td>y1</td>\n",
       "      <td>AD-AD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>6897</td>\n",
       "      <td>y1</td>\n",
       "      <td>MCI-MCI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>6947</td>\n",
       "      <td>y1</td>\n",
       "      <td>MCI-MCI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>6962</td>\n",
       "      <td>y1</td>\n",
       "      <td>AD-AD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1123 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Phase   RID VISCODE DXCHANGE  NPIK1  NPIK2  NPIK3  NPIK4  NPIK5  NPIK6  \\\n",
       "0     ADNI2     8     v06    CN-CN    1.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1     ADNI2     8     v41   CN-MCI    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2     ADNI2    31     v06    CN-CN    0.0    1.0    0.0    0.0    0.0    1.0   \n",
       "3     ADNI2    31     v11    CN-CN    0.0    1.0    0.0    0.0    0.0    1.0   \n",
       "4     ADNI2    31     v21    CN-CN    0.0    0.0    0.0    1.0    0.0    0.0   \n",
       "...     ...   ...     ...      ...    ...    ...    ...    ...    ...    ...   \n",
       "1212  ADNI3  6890      y1  MCI-MCI    0.0    1.0    0.0    0.0    0.0    0.0   \n",
       "1213  ADNI3  6891      y1    AD-AD    1.0    1.0    0.0    1.0    0.0    0.0   \n",
       "1214  ADNI3  6897      y1  MCI-MCI    0.0    0.0    0.0    1.0    0.0    0.0   \n",
       "1218  ADNI3  6947      y1  MCI-MCI    0.0    1.0    0.0    0.0    0.0    0.0   \n",
       "1220  ADNI3  6962      y1    AD-AD    0.0    1.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "      NPIK7  NPIK8  NPIK9A  NPIK9B  NPIK9C  NPIKTOT  insomnia  OSA  \n",
       "0       0.0    0.0     3.0     2.0     0.0      6.0       1.0  0.0  \n",
       "1       1.0    0.0     4.0     2.0     1.0      8.0       1.0  0.0  \n",
       "2       0.0    0.0     2.0     1.0     0.0      2.0       1.0  0.0  \n",
       "3       0.0    0.0     2.0     1.0     0.0      2.0       1.0  0.0  \n",
       "4       0.0    0.0     3.0     1.0     1.0      3.0       1.0  0.0  \n",
       "...     ...    ...     ...     ...     ...      ...       ...  ...  \n",
       "1212    0.0    0.0     4.0     1.0     1.0      4.0       1.0  1.0  \n",
       "1213    1.0    0.0     4.0     2.0     3.0      8.0       1.0  0.0  \n",
       "1214    0.0    1.0     1.0     1.0     1.0      1.0       1.0  0.0  \n",
       "1218    1.0    0.0     1.0     1.0     1.0      1.0       1.0  0.0  \n",
       "1220    0.0    1.0     3.0     2.0     2.0      6.0       1.0  0.0  \n",
       "\n",
       "[1123 rows x 18 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sleep_dxch_drop = sleep_dxch[(sleep_dxch['DXCHANGE']!='AD-MCI')] \n",
    "sleep_dxch_drop = sleep_dxch_drop[sleep_dxch_drop['DXCHANGE']!='CN-AD']\n",
    "sleep_dxch_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e36c691",
   "metadata": {},
   "source": [
    "### oversampling and undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1380b63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sleep_dxch_2g\n",
    "y = sleep_dxch_2g['DXCHANGE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "35d72c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1032 [('AD-AD', 558), ('AD-MCI', 558), ('CN-AD', 558), ('CN-CN', 558), ('CN-MCI', 558), ('MCI-AD', 558), ('MCI-CN', 558), ('MCI-MCI', 558)]\n"
     ]
    }
   ],
   "source": [
    "# oversampling\n",
    "ros = RandomOverSampler(random_state=450)\n",
    "X_oversampled, y_oversampled = ros.fit_resample(X, y)\n",
    "print(len(X_oversampled),sorted(Counter(y_resampled).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "145b7438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 Resampled dataset shape Counter({'MCI-AD': 80, 'MCI-MCI': 80})\n"
     ]
    }
   ],
   "source": [
    "# undersampling\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=432)\n",
    "X_undersampled, y_unsampled = rus.fit_resample(X, y)\n",
    "print(len(X_undersampled),'Resampled dataset shape %s' % Counter(y_unsampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c0966c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phase</th>\n",
       "      <th>RID</th>\n",
       "      <th>VISCODE</th>\n",
       "      <th>NPIK1</th>\n",
       "      <th>NPIK2</th>\n",
       "      <th>NPIK3</th>\n",
       "      <th>NPIK4</th>\n",
       "      <th>NPIK5</th>\n",
       "      <th>NPIK6</th>\n",
       "      <th>NPIK7</th>\n",
       "      <th>NPIK8</th>\n",
       "      <th>NPIK9A</th>\n",
       "      <th>NPIK9B</th>\n",
       "      <th>NPIK9C</th>\n",
       "      <th>NPIKTOT</th>\n",
       "      <th>insomnia</th>\n",
       "      <th>OSA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DXCHANGE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MCI-AD</th>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCI-MCI</th>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Phase  RID  VISCODE  NPIK1  NPIK2  NPIK3  NPIK4  NPIK5  NPIK6  \\\n",
       "DXCHANGE                                                                  \n",
       "MCI-AD       80   80       80     80     80     80     80     80     80   \n",
       "MCI-MCI      80   80       80     80     80     80     80     80     80   \n",
       "\n",
       "          NPIK7  NPIK8  NPIK9A  NPIK9B  NPIK9C  NPIKTOT  insomnia  OSA  \n",
       "DXCHANGE                                                                \n",
       "MCI-AD       80     80      80      80      80       80        80   80  \n",
       "MCI-MCI      80     80      80      80      80       80        80   80  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_undersampled.groupby(['DXCHANGE']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd46c83",
   "metadata": {},
   "source": [
    "### logistic regression, diagnosis changes as the target variable.\n",
    "use dataframe sleep_dxch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "019785d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbfgs_L2,C:0.001, Training set score:0.547, Test set score: 0.344\n",
      "lbfgs_L2,C:0.01, Training set score:0.688, Test set score: 0.594\n",
      "lbfgs_L2,C:0.1, Training set score:0.695, Test set score: 0.656\n",
      "lbfgs_L2,C:1, Training set score:0.711, Test set score: 0.688\n",
      "lbfgs_L2,C:10, Training set score:0.703, Test set score: 0.656\n",
      "lbfgs_L2,C:100, Training set score:0.695, Test set score: 0.656\n",
      "saga_L1,C:0.001, Training set score:0.539, Test set score: 0.344\n",
      "saga_L1,C:0.01, Training set score:0.539, Test set score: 0.344\n",
      "saga_L1,C:0.1, Training set score:0.672, Test set score: 0.500\n",
      "saga_L1,C:1, Training set score:0.695, Test set score: 0.656\n",
      "saga_L1,C:10, Training set score:0.703, Test set score: 0.656\n",
      "saga_L1,C:100, Training set score:0.695, Test set score: 0.656\n",
      "newton-cg_L2,C:0.001, Training set score:0.547, Test set score: 0.344\n",
      "newton-cg_L2,C:0.01, Training set score:0.688, Test set score: 0.594\n",
      "newton-cg_L2,C:0.1, Training set score:0.695, Test set score: 0.656\n",
      "newton-cg_L2,C:1, Training set score:0.711, Test set score: 0.688\n",
      "newton-cg_L2,C:10, Training set score:0.703, Test set score: 0.656\n",
      "newton-cg_L2,C:100, Training set score:0.695, Test set score: 0.656\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(X_undersampled,test_size=0.2)   \n",
    "lst = [ 'NPIK1', 'NPIK2', 'NPIK3',\n",
    "       'NPIK4', 'NPIK5', 'NPIK6', 'NPIK7', 'NPIK8', 'NPIK9A', 'NPIK9B',\n",
    "       'NPIK9C', 'NPIKTOT', 'insomnia', 'OSA']\n",
    "X_train = train[lst]\n",
    "y_train = train['DXCHANGE']\n",
    "X_test = test[lst]\n",
    "y_test = test['DXCHANGE']\n",
    "## data scaling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train_scaled,X_test_scaled\n",
    "# logistic regression\n",
    "C_lst = [0.001,0.01,0.1,1,10,100]\n",
    "for i in range(len(C_lst)):\n",
    "    logreg = LogisticRegression(C=C_lst[i],solver='lbfgs',multi_class='auto',penalty='l2',max_iter=10000).fit(X_train_scaled,y_train)\n",
    "    print('lbfgs_L2,C:{}, Training set score:{:.3f}, Test set score: {:.3f}'.format(C_lst[i],logreg.score(X_train_scaled,y_train),logreg.score(X_test_scaled,y_test)))\n",
    "    \n",
    "for i in range(len(C_lst)):\n",
    "    logreg = LogisticRegression(C=C_lst[i],solver='saga',multi_class='auto',penalty='l1',max_iter=10000).fit(X_train_scaled,y_train)\n",
    "    print('saga_L1,C:{}, Training set score:{:.3f}, Test set score: {:.3f}'.format(C_lst[i],logreg.score(X_train_scaled,y_train),logreg.score(X_test_scaled,y_test)))\n",
    "    \n",
    "for i in range(len(C_lst)):\n",
    "    logreg = LogisticRegression(C=C_lst[i],solver='newton-cg',multi_class='auto',penalty='l2',max_iter=10000).fit(X_train_scaled,y_train)\n",
    "    print('newton-cg_L2,C:{}, Training set score:{:.3f}, Test set score: {:.3f}'.format(C_lst[i],logreg.score(X_train_scaled,y_train),logreg.score(X_test_scaled,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031d5673",
   "metadata": {},
   "source": [
    "## best score: newton-cg_L2,C:1, Training set score:0.711, Test set score: 0.688"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ae097d",
   "metadata": {},
   "source": [
    "### PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "646512b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origianl shape: (128, 14)\n",
      "Reduced shape: (128, 4)\n",
      "explained variance: [2.68004048 2.03851159 1.51702881 1.18115052]\n",
      "explained variance ratio: [0.1899359  0.14447041 0.10751264 0.08370877]\n",
      "Origianl shape: (128, 14)\n",
      "Reduced shape: (128, 4)\n",
      "PCA components: \n",
      "[[-0.0139345   0.01300685  0.08026685  0.19481503  0.00449014  0.07830122\n",
      "   0.14247195  0.03860954  0.38330796  0.51974313  0.40682264  0.57503758\n",
      "   0.09647229  0.0690153 ]\n",
      " [ 0.03760583  0.49490189  0.32667741  0.26544189  0.34520443  0.43071006\n",
      "  -0.24181802 -0.14579305 -0.29607154  0.07942256  0.04799743 -0.09212237\n",
      "   0.07060659  0.28693153]\n",
      " [-0.6250225  -0.02741596  0.37162561  0.06404444  0.20170869  0.01567682\n",
      "   0.45914737  0.35977299  0.03601286 -0.22308985  0.08522864 -0.1256898\n",
      "   0.10083985 -0.03010563]\n",
      " [ 0.12258757 -0.14387289  0.19273961  0.27101592 -0.03319081 -0.27209191\n",
      "  -0.37620449  0.42695963 -0.38220878  0.13764096  0.30969364 -0.06667706\n",
      "   0.10683739 -0.4218008 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Principal components')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA(n_components=4) #keep the first two principal components of the data\n",
    "pca.fit(X_train_scaled) # fit PCA model to sleep-diagnosis_change data\n",
    "X_pca = pca.transform(X_train_scaled)  #transform data onto the first two principal components\n",
    "print(\"Origianl shape: {}\".format(str(X_train_scaled.shape)))\n",
    "print(\"Reduced shape: {}\".format(str(X_pca.shape)))\n",
    "# Explained variance is the amount of variance explained by each of the selected components.\n",
    "print(\"explained variance: {}\".format(pca.explained_variance_))\n",
    "print(\"explained variance ratio: {}\".format(pca.explained_variance_ratio_))\n",
    "\n",
    "plt.bar(range(1,len(pca.explained_variance_ratio_ )+1),pca.explained_variance_ratio_ )\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Components')\n",
    "plt.plot(range(1,len(pca.explained_variance_ )+1),\n",
    "         np.cumsum(pca.explained_variance_ratio_),\n",
    "         c='red',\n",
    "         label=\"Cumulative Explained Variance ratio\")\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "# The component 1 can explain about 20% of the variance, conponent 2 can explain about 11.7%,... \n",
    "# It needs almost 10 principal components to explain at least 90% of the variance. \n",
    "pca = PCA(n_components=4) \n",
    "pca.fit(X_train_scaled) # fit PCA model to sleep-diagnosis_change data\n",
    "X_pca = pca.transform(X_train_scaled)  #transform data onto the first two principal components\n",
    "print(\"Origianl shape: {}\".format(str(X_train_scaled.shape)))\n",
    "print(\"Reduced shape: {}\".format(str(X_pca.shape)))\n",
    "# plot\n",
    "plt.figure(figsize=(8,8))\n",
    "mglearn.discrete_scatter(X_pca[:,0],X_pca[:,1],train['DXCHANGE'])\n",
    "plt.legend(train['DXCHANGE'].unique(),loc='best')\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.xlabel(\"First principal component\")\n",
    "plt.ylabel('Seconde principal component')\n",
    "\n",
    "print('PCA components: \\n{}'.format(pca.components_))    # PCA components\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.matshow(pca.components_,cmap='viridis')\n",
    "plt.yticks([0,1,2,3],['First component','Seconde component','Third component','Fourth component'])\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(X_train.columns)),X_train.columns,rotation=60,ha='left')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Principal components')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "64813e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn model with PCA data. Training set f1-score:0.752, Test set f-score: 0.464\n",
      "logistic with PCA data. C:0.001, Training set f1-score:0.699, Test set f1-score: 0.512\n",
      "logistic with PCA data. C:0.01, Training set f1-score:0.723, Test set f1-score: 0.500\n",
      "logistic with PCA data. C:0.1, Training set f1-score:0.658, Test set f1-score: 0.713\n",
      "logistic with PCA data. C:1, Training set f1-score:0.673, Test set f1-score: 0.713\n",
      "logistic with PCA data. C:10, Training set f1-score:0.673, Test set f1-score: 0.713\n",
      "logistic with PCA data. C:100, Training set f1-score:0.673, Test set f1-score: 0.713\n",
      "Decision tree with unscaled data. tree depth: 1.000. f1-score on training data: 0.648 f1-score on test data: 0.474\n",
      "Decision tree with unscaled data. tree depth: 2.000. f1-score on training data: 0.657 f1-score on test data: 0.784\n",
      "Decision tree with unscaled data. tree depth: 3.000. f1-score on training data: 0.735 f1-score on test data: 0.746\n",
      "Decision tree with unscaled data. tree depth: 4.000. f1-score on training data: 0.790 f1-score on test data: 0.616\n",
      "Decision tree with unscaled data. tree depth: 5.000. f1-score on training data: 0.820 f1-score on test data: 0.649\n",
      "Decision tree with unscaled data. tree depth: 6.000. f1-score on training data: 0.844 f1-score on test data: 0.680\n",
      "Decision tree with unscaled data. tree depth: 7.000. f1-score on training data: 0.891 f1-score on test data: 0.527\n",
      "Decision tree with unscaled data. tree depth: 8.000. f1-score on training data: 0.930 f1-score on test data: 0.616\n",
      "Decision tree with unscaled data. tree depth: 9.000. f1-score on training data: 0.938 f1-score on test data: 0.585\n",
      "Decision tree with unscaled data. tree depth: 10.000. f1-score on training data: 0.946 f1-score on test data: 0.556\n",
      "Decision tree with unscaled data. tree depth: 11.000. f1-score on training data: 0.961 f1-score on test data: 0.556\n",
      "Decision tree with unscaled data. tree depth: 12.000. f1-score on training data: 0.977 f1-score on test data: 0.556\n",
      "Decision tree with unscaled data. tree depth: 13.000. f1-score on training data: 0.977 f1-score on test data: 0.556\n",
      "Random forest with unscaled data. 50 trees. f1-score on training data: 0.977 f1-score on test data: 0.562\n",
      "Random forest with unscaled data. 60 trees. f1-score on training data: 0.977 f1-score on test data: 0.536\n",
      "Random forest with unscaled data. 70 trees. f1-score on training data: 0.977 f1-score on test data: 0.562\n",
      "Random forest with unscaled data. 80 trees. f1-score on training data: 0.977 f1-score on test data: 0.590\n",
      "Random forest with unscaled data. 90 trees. f1-score on training data: 0.977 f1-score on test data: 0.562\n",
      "Random forest with unscaled data. 100 trees. f1-score on training data: 0.977 f1-score on test data: 0.562\n",
      "Random forest with unscaled data. 110 trees. f1-score on training data: 0.977 f1-score on test data: 0.590\n",
      "Random forest with unscaled data. 120 trees. f1-score on training data: 0.977 f1-score on test data: 0.590\n",
      "Random forest with unscaled data. 130 trees. f1-score on training data: 0.977 f1-score on test data: 0.590\n",
      "Random forest with unscaled data. 140 trees. f1-score on training data: 0.977 f1-score on test data: 0.562\n",
      "Random forest with unscaled data. 150 trees. f1-score on training data: 0.977 f1-score on test data: 0.590\n",
      "Random forest with unscaled data. 160 trees. f1-score on training data: 0.977 f1-score on test data: 0.562\n",
      "Random forest with unscaled data. 170 trees. f1-score on training data: 0.977 f1-score on test data: 0.562\n",
      "Random forest with unscaled data. 180 trees. f1-score on training data: 0.977 f1-score on test data: 0.562\n",
      "Random forest with unscaled data. 190 trees. f1-score on training data: 0.977 f1-score on test data: 0.562\n",
      "Decision tree with PCA data. tree depth: 1.000 f1-score on training data: 0.691 f1-score on test data: 0.552\n",
      "Decision tree with PCA data. tree depth: 2.000 f1-score on training data: 0.734 f1-score on test data: 0.653\n",
      "Decision tree with PCA data. tree depth: 3.000 f1-score on training data: 0.758 f1-score on test data: 0.791\n",
      "Decision tree with PCA data. tree depth: 4.000 f1-score on training data: 0.828 f1-score on test data: 0.767\n",
      "Decision tree with PCA data. tree depth: 5.000 f1-score on training data: 0.891 f1-score on test data: 0.682\n",
      "Decision tree with PCA data. tree depth: 6.000 f1-score on training data: 0.953 f1-score on test data: 0.649\n",
      "Decision tree with PCA data. tree depth: 7.000 f1-score on training data: 0.977 f1-score on test data: 0.750\n",
      "Decision tree with PCA data. tree depth: 8.000 f1-score on training data: 0.977 f1-score on test data: 0.682\n",
      "Decision tree with PCA data. tree depth: 9.000 f1-score on training data: 0.977 f1-score on test data: 0.682\n",
      "Decision tree with PCA data. tree depth: 10.000 f1-score on training data: 0.977 f1-score on test data: 0.682\n",
      "Decision tree with PCA data. tree depth: 11.000 f1-score on training data: 0.977 f1-score on test data: 0.682\n",
      "Decision tree with PCA data. tree depth: 12.000 f1-score on training data: 0.977 f1-score on test data: 0.682\n",
      "Decision tree with PCA data. tree depth: 13.000 f1-score on training data: 0.977 f1-score on test data: 0.682\n",
      "Decision tree with scaled data. tree depth: 1.000. f1-score on training data: 0.648 f1-score on test data: 0.474\n",
      "Decision tree with scaled data. tree depth: 2.000. f1-score on training data: 0.657 f1-score on test data: 0.784\n",
      "Decision tree with scaled data. tree depth: 3.000. f1-score on training data: 0.735 f1-score on test data: 0.746\n",
      "Decision tree with scaled data. tree depth: 4.000. f1-score on training data: 0.790 f1-score on test data: 0.616\n",
      "Decision tree with scaled data. tree depth: 5.000. f1-score on training data: 0.820 f1-score on test data: 0.649\n",
      "Decision tree with scaled data. tree depth: 6.000. f1-score on training data: 0.844 f1-score on test data: 0.680\n",
      "Decision tree with scaled data. tree depth: 7.000. f1-score on training data: 0.891 f1-score on test data: 0.527\n",
      "Decision tree with scaled data. tree depth: 8.000. f1-score on training data: 0.930 f1-score on test data: 0.616\n",
      "Decision tree with scaled data. tree depth: 9.000. f1-score on training data: 0.938 f1-score on test data: 0.585\n",
      "Decision tree with scaled data. tree depth: 10.000. f1-score on training data: 0.946 f1-score on test data: 0.556\n",
      "Decision tree with scaled data. tree depth: 11.000. f1-score on training data: 0.961 f1-score on test data: 0.556\n",
      "Decision tree with scaled data. tree depth: 12.000. f1-score on training data: 0.977 f1-score on test data: 0.556\n",
      "Decision tree with scaled data. tree depth: 13.000. f1-score on training data: 0.977 f1-score on test data: 0.556\n",
      "Random forest with scaled data. 50 trees. f1-score on training data: 0.977 f1-score on test data: 0.598\n",
      "Random forest with scaled data. 60 trees. f1-score on training data: 0.977 f1-score on test data: 0.573\n",
      "Random forest with scaled data. 70 trees. f1-score on training data: 0.977 f1-score on test data: 0.598\n",
      "Random forest with scaled data. 80 trees. f1-score on training data: 0.977 f1-score on test data: 0.625\n",
      "Random forest with scaled data. 90 trees. f1-score on training data: 0.977 f1-score on test data: 0.625\n",
      "Random forest with scaled data. 100 trees. f1-score on training data: 0.977 f1-score on test data: 0.598\n",
      "Random forest with scaled data. 110 trees. f1-score on training data: 0.977 f1-score on test data: 0.625\n",
      "Random forest with scaled data. 120 trees. f1-score on training data: 0.977 f1-score on test data: 0.625\n",
      "Random forest with scaled data. 130 trees. f1-score on training data: 0.977 f1-score on test data: 0.625\n",
      "Random forest with scaled data. 140 trees. f1-score on training data: 0.977 f1-score on test data: 0.598\n",
      "Random forest with scaled data. 150 trees. f1-score on training data: 0.977 f1-score on test data: 0.625\n",
      "Random forest with scaled data. 160 trees. f1-score on training data: 0.977 f1-score on test data: 0.598\n",
      "Random forest with scaled data. 170 trees. f1-score on training data: 0.977 f1-score on test data: 0.598\n",
      "Random forest with scaled data. 180 trees. f1-score on training data: 0.977 f1-score on test data: 0.598\n",
      "Random forest with scaled data. 190 trees. f1-score on training data: 0.977 f1-score on test data: 0.598\n",
      "Decision tree with PCA data. tree depth: 1.000 f1-score on training data: 0.691 f1-score on test data: 0.552\n",
      "Decision tree with PCA data. tree depth: 2.000 f1-score on training data: 0.734 f1-score on test data: 0.653\n",
      "Decision tree with PCA data. tree depth: 3.000 f1-score on training data: 0.758 f1-score on test data: 0.791\n",
      "Decision tree with PCA data. tree depth: 4.000 f1-score on training data: 0.828 f1-score on test data: 0.767\n",
      "Decision tree with PCA data. tree depth: 5.000 f1-score on training data: 0.891 f1-score on test data: 0.682\n",
      "Decision tree with PCA data. tree depth: 6.000 f1-score on training data: 0.953 f1-score on test data: 0.649\n",
      "Decision tree with PCA data. tree depth: 7.000 f1-score on training data: 0.977 f1-score on test data: 0.750\n",
      "Decision tree with PCA data. tree depth: 8.000 f1-score on training data: 0.977 f1-score on test data: 0.682\n",
      "Decision tree with PCA data. tree depth: 9.000 f1-score on training data: 0.977 f1-score on test data: 0.682\n",
      "Decision tree with PCA data. tree depth: 10.000 f1-score on training data: 0.977 f1-score on test data: 0.682\n",
      "Decision tree with PCA data. tree depth: 11.000 f1-score on training data: 0.977 f1-score on test data: 0.682\n",
      "Decision tree with PCA data. tree depth: 12.000 f1-score on training data: 0.977 f1-score on test data: 0.682\n",
      "Decision tree with PCA data. tree depth: 13.000 f1-score on training data: 0.977 f1-score on test data: 0.682\n",
      "Random forest with unscaled data. 50 trees. f1-score on training data: 0.977 f1-score on test data: 0.682\n",
      "Random forest with unscaled data. 60 trees. f1-score on training data: 0.977 f1-score on test data: 0.660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest with unscaled data. 70 trees. f1-score on training data: 0.977 f1-score on test data: 0.625\n",
      "Random forest with unscaled data. 80 trees. f1-score on training data: 0.977 f1-score on test data: 0.660\n",
      "Random forest with unscaled data. 90 trees. f1-score on training data: 0.977 f1-score on test data: 0.590\n",
      "Random forest with unscaled data. 100 trees. f1-score on training data: 0.977 f1-score on test data: 0.625\n",
      "Random forest with unscaled data. 110 trees. f1-score on training data: 0.977 f1-score on test data: 0.590\n",
      "Random forest with unscaled data. 120 trees. f1-score on training data: 0.977 f1-score on test data: 0.619\n",
      "Random forest with unscaled data. 130 trees. f1-score on training data: 0.977 f1-score on test data: 0.619\n",
      "Random forest with unscaled data. 140 trees. f1-score on training data: 0.977 f1-score on test data: 0.653\n",
      "Random forest with unscaled data. 150 trees. f1-score on training data: 0.977 f1-score on test data: 0.619\n",
      "Random forest with unscaled data. 160 trees. f1-score on training data: 0.977 f1-score on test data: 0.585\n",
      "Random forest with unscaled data. 170 trees. f1-score on training data: 0.977 f1-score on test data: 0.619\n",
      "Random forest with unscaled data. 180 trees. f1-score on training data: 0.977 f1-score on test data: 0.653\n",
      "Random forest with unscaled data. 190 trees. f1-score on training data: 0.977 f1-score on test data: 0.653\n",
      "MLP with scaled data. f1-score on training data: 0.977 f1-score on test data: 0.555\n",
      "MLP with PCA. f1-score on training data: 0.930 f1-score on test data: 0.562\n"
     ]
    }
   ],
   "source": [
    "# knn\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "knn = KNeighborsClassifier(n_neighbors=4)    \n",
    "knn.fit(X_pca,y_train)\n",
    "print('knn model with PCA data. Training set f1-score:{:.3f}, Test set f-score: {:.3f}'.format(f1_score(knn.predict(X_pca),y_train,average='weighted'),f1_score(knn.predict(X_test_pca),y_test,average='weighted')))\n",
    "\n",
    "# logistic regression on pca data\n",
    "for i in range(len(C_lst)):     \n",
    "    logreg = LogisticRegression(C=C_lst[i],solver='lbfgs',multi_class='auto',penalty='l2',max_iter=100000).fit(X_pca,y_train)\n",
    "    print('logistic with PCA data. C:{}, Training set f1-score:{:.3f}, Test set f1-score: {:.3f}'.format(C_lst[i],f1_score(logreg.predict(X_pca),y_train,average='weighted'),f1_score(logreg.predict(X_test_pca),y_test,average='weighted')))\n",
    "    \n",
    "# decision tree and random forest with unscaled data \n",
    "for i in range(1,14):\n",
    "    tree = DecisionTreeClassifier(random_state=0,max_depth=i)\n",
    "    tree.fit(X_train,y_train)\n",
    "    print('Decision tree with unscaled data. tree depth: {:.3f}. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'\n",
    "          .format(i,f1_score(tree.predict(X_train),y_train,average='weighted'),f1_score(tree.predict(X_test),y_test,average='weighted')))\n",
    "for m in range(5,20):    \n",
    "    forest = RandomForestClassifier(n_estimators=m*10,random_state=5862)\n",
    "    forest.fit(X_train,y_train)\n",
    "    print('Random forest with unscaled data. {} trees. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'\n",
    "          .format(m*10,f1_score(forest.predict(X_train),y_train,average='weighted'),f1_score(forest.predict(X_test),y_test,average='weighted')))\n",
    "    \n",
    "# decision tree with PCA data \n",
    "for i in range(1,14):\n",
    "    tree = DecisionTreeClassifier(random_state=0,max_depth=i)\n",
    "    tree.fit(X_pca,y_train)\n",
    "    print('Decision tree with PCA data. tree depth: {:.3f} f1-score on training data: {:.3f} f1-score on test data: {:.3f}'.format(i,f1_score(tree.predict(X_pca),y_train,average='weighted'),f1_score(tree.predict(X_test_pca),y_test,average='weighted')))\n",
    "\n",
    "# decision tree and random forest with scaled data \n",
    "for i in range(1,14):\n",
    "    tree = DecisionTreeClassifier(random_state=0,max_depth=i)\n",
    "    tree.fit(X_train_scaled,y_train)\n",
    "    print('Decision tree with scaled data. tree depth: {:.3f}. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'\n",
    "          .format(i,f1_score(tree.predict(X_train_scaled),y_train,average='weighted'),f1_score(tree.predict(X_test_scaled),y_test,average='weighted')))\n",
    "for m in range(5,20):    \n",
    "    forest = RandomForestClassifier(n_estimators=m*10,random_state=5862)\n",
    "    forest.fit(X_train_scaled,y_train)\n",
    "    print('Random forest with scaled data. {} trees. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'\n",
    "          .format(m*10,f1_score(forest.predict(X_train_scaled),y_train,average='weighted'),f1_score(forest.predict(X_test_scaled),y_test,average='weighted')))\n",
    "    \n",
    "# decision tree and random forest with PCA data \n",
    "for i in range(1,14):\n",
    "    tree = DecisionTreeClassifier(random_state=0,max_depth=i)\n",
    "    tree.fit(X_pca,y_train)\n",
    "    print('Decision tree with PCA data. tree depth: {:.3f} f1-score on training data: {:.3f} f1-score on test data: {:.3f}'.format(i,f1_score(tree.predict(X_pca),y_train,average='weighted'),f1_score(tree.predict(X_test_pca),y_test,average='weighted')))    \n",
    "for m in range(5,20):    \n",
    "    forest = RandomForestClassifier(n_estimators=m*10,random_state=5862)\n",
    "    forest.fit(X_pca,y_train)\n",
    "    print('Random forest with unscaled data. {} trees. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'\n",
    "          .format(m*10,f1_score(forest.predict(X_pca),y_train,average='weighted'),f1_score(forest.predict(X_test_pca),y_test,average='weighted')))    \n",
    "    \n",
    "# MLP with scaled data\n",
    "mlp = MLPClassifier(solver='lbfgs',random_state=0,hidden_layer_sizes = [8,10],max_iter=10000).fit(X_train_scaled,y_train)\n",
    "mlp.fit(X_train_scaled,y_train)\n",
    "print('MLP with scaled data. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'.format(f1_score(mlp.predict(X_train_scaled),y_train,average='weighted'),f1_score(mlp.predict(X_test_scaled),y_test,average='weighted')))\n",
    "    \n",
    "    \n",
    "# MLP with PCA \n",
    "mlp = MLPClassifier(solver='lbfgs',random_state=0,hidden_layer_sizes = [18,10,5],max_iter=20000).fit(X_pca,y_train)\n",
    "mlp.fit(X_pca,y_train)\n",
    "print('MLP with PCA. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'.format(f1_score(mlp.predict(X_pca),y_train,average='weighted'),f1_score(mlp.predict(X_test_pca),y_test,average='weighted')))    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56651f07",
   "metadata": {},
   "source": [
    "Decision tree with unscaled data. tree depth: 6.000. f1-score on training data: 0.844 f1-score on test data: 0.680\n",
    "Random forest with unscaled data. 50 trees. f1-score on training data: 0.977 f1-score on test data: 0.682"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2de6828",
   "metadata": {},
   "source": [
    "### feature selections from previous work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c30879",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a670079b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6394a929",
   "metadata": {},
   "source": [
    "## use dataframe sleep_dx, target_variable 'DX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bce9650",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1359e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(sleep_dx.dropna(axis=0,how='any'),test_size=0.2)    \n",
    "X_train = train[lst]\n",
    "y_train = train['DX']\n",
    "X_test = test[lst]\n",
    "y_test = test['DX']\n",
    "## data scaling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train_scaled,X_test_scaled\n",
    "# logistic regression\n",
    "C_lst = [0.001,0.01,0.1,1,10,100]\n",
    "for i in range(len(C_lst)):\n",
    "    logreg = LogisticRegression(C=C_lst[i],solver='lbfgs',multi_class='auto',penalty='l2',max_iter=10000).fit(X_train_scaled,y_train)\n",
    "    print('lbfgs_L2,C:{}, Training set score:{:.3f}, Test set score: {:.3f}'.format(C_lst[i],logreg.score(X_train_scaled,y_train),logreg.score(X_test_scaled,y_test)))\n",
    "    \n",
    "for i in range(len(C_lst)):\n",
    "    logreg = LogisticRegression(C=C_lst[i],solver='saga',multi_class='auto',penalty='l1',max_iter=10000).fit(X_train_scaled,y_train)\n",
    "    print('saga_L1,C:{}, Training set score:{:.3f}, Test set score: {:.3f}'.format(C_lst[i],logreg.score(X_train_scaled,y_train),logreg.score(X_test_scaled,y_test)))\n",
    "    \n",
    "for i in range(len(C_lst)):\n",
    "    logreg = LogisticRegression(C=C_lst[i],solver='newton-cg',multi_class='auto',penalty='l2',max_iter=10000).fit(X_train_scaled,y_train)\n",
    "    print('newton-cg_L2,C:{}, Training set score:{:.3f}, Test set score: {:.3f}'.format(C_lst[i],logreg.score(X_train_scaled,y_train),logreg.score(X_test_scaled,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc59068c",
   "metadata": {},
   "source": [
    "#### after trying different solvers for multi_class labels: 'saga','lbfgs','sag','newton-cg' with possible penalty ('l2' or 'l1'), all logistic models work not that good on our data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f21fbc",
   "metadata": {},
   "source": [
    "### PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791cdb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10) #keep the first two principal components of the data\n",
    "pca.fit(X_train_scaled) # fit PCA model to sleep-diagnosis_change data\n",
    "X_pca = pca.transform(X_train_scaled)  #transform data onto the first two principal components\n",
    "print(\"Origianl shape: {}\".format(str(X_train_scaled.shape)))\n",
    "print(\"Reduced shape: {}\".format(str(X_pca.shape)))\n",
    "# Explained variance is the amount of variance explained by each of the selected components.\n",
    "print(\"explained variance: {}\".format(pca.explained_variance_))\n",
    "print(\"explained variance ratio: {}\".format(pca.explained_variance_ratio_))\n",
    "\n",
    "plt.bar(range(1,len(pca.explained_variance_ratio_ )+1),pca.explained_variance_ratio_ )\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Components')\n",
    "plt.plot(range(1,len(pca.explained_variance_ )+1),\n",
    "         np.cumsum(pca.explained_variance_ratio_),\n",
    "         c='red',\n",
    "         label=\"Cumulative Explained Variance ratio\")\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "# The component 1 can explain about 20% of the variance, conponent 2 can explain about 11.7%,... \n",
    "# It needs almost 10 principal components to explain at least 90% of the variance. \n",
    "pca = PCA(n_components=4) \n",
    "pca.fit(X_train_scaled) # fit PCA model to sleep-diagnosis_change data\n",
    "X_pca = pca.transform(X_train_scaled)  #transform data onto the first two principal components\n",
    "print(\"Origianl shape: {}\".format(str(X_train_scaled.shape)))\n",
    "print(\"Reduced shape: {}\".format(str(X_pca.shape)))\n",
    "# plot\n",
    "plt.figure(figsize=(8,8))\n",
    "mglearn.discrete_scatter(X_pca[:,0],X_pca[:,1],train['DX'])\n",
    "plt.legend(train['DX'].unique(),loc='best')\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.xlabel(\"First principal component\")\n",
    "plt.ylabel('Seconde principal component')\n",
    "\n",
    "print('PCA components: \\n{}'.format(pca.components_))    # PCA components\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.matshow(pca.components_,cmap='viridis')\n",
    "plt.yticks([0,1],['First component','Seconde component'])\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(X_train.columns)),X_train.columns,rotation=60,ha='left')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Principal components')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9abb439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "knn = KNeighborsClassifier(n_neighbors=4)    \n",
    "knn.fit(X_pca,y_train)\n",
    "print('knn model with PCA data. Training set f1-score:{:.3f}, Test set f-score: {:.3f}'.format(f1_score(knn.predict(X_pca),y_train,average='weighted'),f1_score(knn.predict(X_test_pca),y_test,average='weighted')))\n",
    "\n",
    "# logistic regression on pca data\n",
    "for i in range(len(C_lst)):     \n",
    "    logreg = LogisticRegression(C=C_lst[i],solver='lbfgs',multi_class='auto',penalty='l2',max_iter=100000).fit(X_pca,y_train)\n",
    "    print('logistic with PCA data. C:{}, Training set f1-score:{:.3f}, Test set f1-score: {:.3f}'.format(C_lst[i],f1_score(logreg.predict(X_pca),y_train,average='weighted'),f1_score(logreg.predict(X_test_pca),y_test,average='weighted')))\n",
    "    \n",
    "# decision tree\n",
    "for i in range(1,14):\n",
    "    tree = DecisionTreeClassifier(random_state=0,max_depth=i)\n",
    "    tree.fit(X_train,y_train)\n",
    "    print('Decision tree with unscaled data. tree depth: {:.3f}. f1-score on training data: {:.3f} f1-score on test data: {}'.format(i,f1_score(tree.predict(X_train),y_train,average='weighted'),f1_score(tree.predict(X_test),y_test,average='weighted')))\n",
    "    \n",
    "# decision tree with PCA data \n",
    "for i in range(1,14):\n",
    "    tree = DecisionTreeClassifier(random_state=0,max_depth=i)\n",
    "    tree.fit(X_pca,y_train)\n",
    "    print('Decision tree with PCA data. tree depth: {:.3f} f1-score on training data: {:.3f} f1-score on test data: {}'.format(i,f1_score(tree.predict(X_pca),y_train,average='weighted'),f1_score(tree.predict(X_test_pca),y_test,average='weighted')))\n",
    "    \n",
    "# MLP with scaled data\n",
    "mlp = MLPClassifier(solver='lbfgs',random_state=0,hidden_layer_sizes = [8,10],max_iter=10000).fit(X_train_scaled,y_train)\n",
    "mlp.fit(X_train_scaled,y_train)\n",
    "print('MLP with scaled data. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'.format(f1_score(mlp.predict(X_train_scaled),y_train,average='weighted'),f1_score(mlp.predict(X_test_scaled),y_test,average='weighted')))\n",
    "    \n",
    "    \n",
    "# MLP with PCA \n",
    "mlp = MLPClassifier(solver='lbfgs',random_state=0,hidden_layer_sizes = [18,10,5],max_iter=20000).fit(X_pca,y_train)\n",
    "mlp.fit(X_pca,y_train)\n",
    "print('MLP with PCA. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'.format(f1_score(mlp.predict(X_pca),y_train,average='weighted'),f1_score(mlp.predict(X_test_pca),y_test,average='weighted')))    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d3e0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP with scaled data\n",
    "mlp = MLPClassifier(solver='lbfgs',random_state=0,hidden_layer_sizes = [8,12],max_iter=10000).fit(X_train_scaled,y_train)\n",
    "mlp.fit(X_train_scaled,y_train)\n",
    "print('MLP with scaled data. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'.format(f1_score(mlp.predict(X_train_scaled),y_train,average='weighted'),f1_score(mlp.predict(X_test_scaled),y_test,average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1932fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a08c3fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08de443e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5be298",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f00f425c",
   "metadata": {},
   "source": [
    "## use dataframe sleep_dxbl, target_variable 'DX_bl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8756088",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_dxbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba9ee9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(sleep_dxbl.dropna(axis=0,how='any'),test_size=0.2)    \n",
    "X_train = train[lst]\n",
    "y_train = train['DX_bl']\n",
    "X_test = test[lst]\n",
    "y_test = test['DX_bl']\n",
    "## data scaling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train_scaled,X_test_scaled\n",
    "# logistic regression\n",
    "C_lst = [0.001,0.01,0.1,1,10,100]\n",
    "for i in range(len(C_lst)):\n",
    "    logreg = LogisticRegression(C=C_lst[i],solver='lbfgs',multi_class='auto',penalty='l2',max_iter=10000).fit(X_train_scaled,y_train)\n",
    "    print('lbfgs_L2,C:{}, Training set score:{:.3f}, Test set score: {:.3f}'.format(C_lst[i],logreg.score(X_train_scaled,y_train),logreg.score(X_test_scaled,y_test)))\n",
    "    \n",
    "for i in range(len(C_lst)):\n",
    "    logreg = LogisticRegression(C=C_lst[i],solver='saga',multi_class='auto',penalty='l1',max_iter=10000).fit(X_train_scaled,y_train)\n",
    "    print('saga_L1,C:{}, Training set score:{:.3f}, Test set score: {:.3f}'.format(C_lst[i],logreg.score(X_train_scaled,y_train),logreg.score(X_test_scaled,y_test)))\n",
    "    \n",
    "for i in range(len(C_lst)):\n",
    "    logreg = LogisticRegression(C=C_lst[i],solver='newton-cg',multi_class='auto',penalty='l2',max_iter=10000).fit(X_train_scaled,y_train)\n",
    "    print('newton-cg_L2,C:{}, Training set score:{:.3f}, Test set score: {:.3f}'.format(C_lst[i],logreg.score(X_train_scaled,y_train),logreg.score(X_test_scaled,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cda469",
   "metadata": {},
   "source": [
    "#### after trying different solvers for multi_class labels: 'saga','lbfgs','sag','newton-cg' with possible penalty ('l2' or 'l1'), all logistic models work not that good on our data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e9d74d",
   "metadata": {},
   "source": [
    "### PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78af1545",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10) #keep the first two principal components of the data\n",
    "pca.fit(X_train_scaled) # fit PCA model to sleep-diagnosis_change data\n",
    "X_pca = pca.transform(X_train_scaled)  #transform data onto the first two principal components\n",
    "print(\"Origianl shape: {}\".format(str(X_train_scaled.shape)))\n",
    "print(\"Reduced shape: {}\".format(str(X_pca.shape)))\n",
    "# Explained variance is the amount of variance explained by each of the selected components.\n",
    "print(\"explained variance: {}\".format(pca.explained_variance_))\n",
    "print(\"explained variance ratio: {}\".format(pca.explained_variance_ratio_))\n",
    "\n",
    "plt.bar(range(1,len(pca.explained_variance_ratio_ )+1),pca.explained_variance_ratio_ )\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Components')\n",
    "plt.plot(range(1,len(pca.explained_variance_ )+1),\n",
    "         np.cumsum(pca.explained_variance_ratio_),\n",
    "         c='red',\n",
    "         label=\"Cumulative Explained Variance ratio\")\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "# The component 1 can explain about 20% of the variance, conponent 2 can explain about 11.7%,... \n",
    "# It needs almost 10 principal components to explain at least 90% of the variance. \n",
    "pca = PCA(n_components=4) \n",
    "pca.fit(X_train_scaled) # fit PCA model to sleep-diagnosis_change data\n",
    "X_pca = pca.transform(X_train_scaled)  #transform data onto the first two principal components\n",
    "print(\"Origianl shape: {}\".format(str(X_train_scaled.shape)))\n",
    "print(\"Reduced shape: {}\".format(str(X_pca.shape)))\n",
    "# plot\n",
    "plt.figure(figsize=(8,8))\n",
    "mglearn.discrete_scatter(X_pca[:,0],X_pca[:,1],train['DX_bl'])\n",
    "plt.legend(train['DX_bl'].unique(),loc='best')\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.xlabel(\"First principal component\")\n",
    "plt.ylabel('Seconde principal component')\n",
    "\n",
    "print('PCA components: \\n{}'.format(pca.components_))    # PCA components\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.matshow(pca.components_,cmap='viridis')\n",
    "plt.yticks([0,1,2,3],['First component','Seconde component','Third component','Fourth component'])\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(X_train.columns)),X_train.columns,rotation=60,ha='left')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Principal components')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773d6cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "knn = KNeighborsClassifier(n_neighbors=4)    \n",
    "knn.fit(X_pca,y_train)\n",
    "print('knn model with PCA data. Training set f1-score:{:.3f}, Test set f-score: {:.3f}'.format(f1_score(knn.predict(X_pca),y_train,average='weighted'),f1_score(knn.predict(X_test_pca),y_test,average='weighted')))\n",
    "\n",
    "# logistic regression on pca data\n",
    "for i in range(len(C_lst)):     \n",
    "    logreg = LogisticRegression(C=C_lst[i],solver='lbfgs',multi_class='auto',penalty='l2',max_iter=100000).fit(X_pca,y_train)\n",
    "    print('logistic with PCA data. C:{}, Training set f1-score:{:.3f}, Test set f1-score: {:.3f}'.format(C_lst[i],f1_score(logreg.predict(X_pca),y_train,average='weighted'),f1_score(logreg.predict(X_test_pca),y_test,average='weighted')))\n",
    "    \n",
    "# decision tree\n",
    "for i in range(1,14):\n",
    "    tree = DecisionTreeClassifier(random_state=0,max_depth=i)\n",
    "    tree.fit(X_train,y_train)\n",
    "    print('Decision tree with unscaled data. tree depth: {:.3f}. f1-score on training data: {:.3f} f1-score on test data: {}'.format(i,f1_score(tree.predict(X_train),y_train,average='weighted'),f1_score(tree.predict(X_test),y_test,average='weighted')))\n",
    "    \n",
    "# decision tree with PCA data \n",
    "for i in range(1,14):\n",
    "    tree = DecisionTreeClassifier(random_state=0,max_depth=i)\n",
    "    tree.fit(X_pca,y_train)\n",
    "    print('Decision tree with PCA data. tree depth: {:.3f} f1-score on training data: {:.3f} f1-score on test data: {}'.format(i,f1_score(tree.predict(X_pca),y_train,average='weighted'),f1_score(tree.predict(X_test_pca),y_test,average='weighted')))\n",
    "    \n",
    "# MLP with scaled data\n",
    "mlp = MLPClassifier(solver='lbfgs',random_state=0,hidden_layer_sizes = [8,10],max_iter=10000).fit(X_train_scaled,y_train)\n",
    "mlp.fit(X_train_scaled,y_train)\n",
    "print('MLP with scaled data. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'.format(f1_score(mlp.predict(X_train_scaled),y_train,average='weighted'),f1_score(mlp.predict(X_test_scaled),y_test,average='weighted')))\n",
    "    \n",
    "    \n",
    "# MLP with PCA \n",
    "mlp = MLPClassifier(solver='lbfgs',random_state=0,hidden_layer_sizes = [18,10,5],max_iter=20000).fit(X_pca,y_train)\n",
    "mlp.fit(X_pca,y_train)\n",
    "print('MLP with PCA. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'.format(f1_score(mlp.predict(X_pca),y_train,average='weighted'),f1_score(mlp.predict(X_test_pca),y_test,average='weighted')))    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf4806d",
   "metadata": {},
   "source": [
    "### neurobat.csv\n",
    "The Neuropsychological Assessment Battery (NAB; Stern & White, 2003) is a comprehensive test battery that assesses five cognitive domains (Attention, Language, Memory, Spatial, and Executive Functions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57db9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "neubat_s = pd.read_csv('neurobat_short.csv',sep=',').iloc[:,1:].drop(['RAVLT_perc_forgetting'],axis=1).replace(-1, np.NaN).replace(-4, np.NaN)\n",
    "neubat_s = neubat_s.dropna(subset=neubat_s.columns[3:],how='all').dropna(axis=1, how='all')\n",
    "neubat_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74474c89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neubat_s.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b050359",
   "metadata": {},
   "source": [
    "### brain volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5647826c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('main_file.csv').iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69aa4986",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7101bae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_neub_ss_dxch = neubat_ss.merge(sleep_dxch,how='inner',on=com_col)\n",
    "sleep_neub_ss_dxch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630b1d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "neubat_ss = pd.read_csv('neurobat_supershort.csv').dropna(how='any').iloc[:,1:]\n",
    "neubat_ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce175bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick check PCA\n",
    "\n",
    "def PCA_(df_X,n):\n",
    "    # data scaling\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(df_X)\n",
    "    X_scaled = scaler.transform(df_X)\n",
    "    pca = PCA(n_components=n)\n",
    "    pca.fit(X_scaled)\n",
    "    X_pca = pca.transform(X_scaled)\n",
    "    print(\"Origianl shape: {}\".format(str(X_scaled.shape)))\n",
    "    print(\"Reduced shape: {}\".format(str(X_pca.shape)))\n",
    "    print(\"explained variance: {}\".format(pca.explained_variance_))\n",
    "    print(\"explained variance ratio: {}\".format(pca.explained_variance_ratio_))\n",
    "    plt.bar(range(1,len(pca.explained_variance_ratio_ )+1),pca.explained_variance_ratio_ )\n",
    "    plt.ylabel('Explained variance ratio')\n",
    "    plt.xlabel('Components')\n",
    "    plt.plot(range(1,len(pca.explained_variance_ )+1),\n",
    "             np.cumsum(pca.explained_variance_ratio_),\n",
    "             c='red',\n",
    "             label=\"Cumulative Explained Variance ratio\")\n",
    "    plt.legend(loc='upper left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016e2bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_(neubat_ss.iloc[:,3:],4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411782d8",
   "metadata": {},
   "source": [
    "### sleep vs brain volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de96d7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_brain_v = pd.read_csv('sleep_brain_v.csv').iloc[:,1:]\n",
    "sleep_brain_v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd3a312",
   "metadata": {},
   "source": [
    "#### sleep vs brainvolume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba890480",
   "metadata": {},
   "source": [
    "NPIKTOT has no data to any of the brain volume data or biomarkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787f4660",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_brain_v.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af41903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_lst = ['NPIK1', 'NPIK2', 'NPIK3', 'NPIK4',\n",
    "       'NPIK5', 'NPIK6', 'NPIK7', 'NPIK8', 'NPIK9A', 'NPIK9B', 'NPIK9C',\n",
    "       'NPIKTOT', 'NPIKSEV', 'insomnia', 'OSA','ratio_ABETA_bl', 'ratio_TAU_bl',\n",
    "       'ratio_PTAU_bl']\n",
    "cat_lst = ['ratio_Ventricles_bl','ratio_Hippocampus_bl', 'ratio_WholeBrain_bl', 'ratio_Entorhinal_bl',\n",
    "       'ratio_Fusiform_bl', 'ratio_ICV_bl', 'ratio_ABETA_bl', 'ratio_TAU_bl',\n",
    "       'ratio_PTAU_bl']\n",
    "new_cat_lst = ['Ventricles_reduction_per_year','Hippocampus_reduction_per_year','wholebrain_reduction_per_year','Entorhinal_reduction_per_year',\n",
    "               'Fusiform_reduction_per_year','ICV_reduction_per_year','ABETA_reduction_per_year','TAU_reduction_per_year','PTAU_reduction_per_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d46bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.set_theme(style=\"ticks\")\n",
    "#sns.pairplot(sleep_brain_v[sleep_lst + new_cat_lst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746d4466",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=54, ncols=3, figsize=(18,280))\n",
    "axes = axes.ravel()  # array to 1D\n",
    "for j in range(len(sleep_lst)):\n",
    "    for i in range(len(cat_lst)):\n",
    "        axes[i+j*9].scatter(sleep_brain_v[sleep_lst[j]], sleep_brain_v[cat_lst[i]])\n",
    "        axes[i+j*9].set(title=f'{sleep_lst[j]} vs {cat_lst[i]}', xlabel=None)   \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f00f82b",
   "metadata": {},
   "source": [
    "NPIKSEV, insomnia, OSA have data available to correlate to "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee40f6dc",
   "metadata": {},
   "source": [
    "NPIKSEV vs brain volume ratio to baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f470319",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_brain_v = sleep_brain_v.drop(['NPIK1', 'NPIK2', 'NPIK3', 'NPIK4',\n",
    "       'NPIK5', 'NPIK6', 'NPIK7', 'NPIK8', 'NPIK9A', 'NPIK9B', 'NPIK9C',\n",
    "       'NPIKTOT'],axis=1)\n",
    "sleep_brain_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f166fb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_brain_red = sleep_brain_v.dropna(how='any',axis=0).reset_index().drop(['index'],axis=1)  # reduced\n",
    "sleep_brain_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fa7c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_brain_red.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb6df37",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"ticks\")\n",
    "sns.pairplot(sleep_brain_red[['NPIKSEV', 'insomnia', 'OSA',\n",
    "       'ratio_Ventricles_bl', 'ratio_Hippocampus_bl', 'ratio_WholeBrain_bl',\n",
    "       'ratio_Entorhinal_bl', 'ratio_Fusiform_bl', 'ratio_ICV_bl',\n",
    "       'ratio_ABETA_bl', 'ratio_TAU_bl', 'ratio_PTAU_bl']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0749972d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_brain_red.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d55f0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = train_test_split(sleep_brain_red,random_state=586,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffccbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7227c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9636cbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[['NPIKSEV', 'insomnia', 'OSA',\n",
    "       'ratio_ABETA_bl', 'ratio_TAU_bl', 'ratio_PTAU_bl']]\n",
    "X_test = test[['NPIKSEV', 'insomnia', 'OSA',\n",
    "       'ratio_ABETA_bl', 'ratio_TAU_bl', 'ratio_PTAU_bl']]\n",
    "y_lst = ['Ventricles_reduction_per_year', 'Hippocampus_reduction_per_year',\n",
    "       'wholebrain_reduction_per_year', 'Entorhinal_reduction_per_year',\n",
    "       'Fusiform_reduction_per_year', 'ICV_reduction_per_year',\n",
    "       'ABETA_reduction_per_year', 'TAU_reduction_per_year',\n",
    "       'PTAU_reduction_per_year','ratio_Ventricles_bl', 'ratio_Hippocampus_bl', 'ratio_WholeBrain_bl',\n",
    "       'ratio_Entorhinal_bl', 'ratio_Fusiform_bl', 'ratio_ICV_bl',\n",
    "       'ratio_ABETA_bl', 'ratio_TAU_bl', 'ratio_PTAU_bl']\n",
    "alpha_lst = [0.01,0.1,1,10]\n",
    "for i in range(len(y_lst)):\n",
    "    y_train = train[y_lst[i]]\n",
    "    y_test = test[y_lst[i]]\n",
    "    for j in range(len(alpha_lst)):\n",
    "        \n",
    "        ridge = Ridge(alpha = alpha_lst[j]).fit(X_train,y_train)\n",
    "        print('{}: target feature {}: alpha = {}; training set score: {:.3f}; test set score {:.3f}'.format('Ridge',y_lst[i],alpha_lst[j],lr.score(X_train,train_whole_brain),lr.score(X_test,test_whole_brain)))\n",
    "        lasso = Lasso(alpha = alpha_lst[j]).fit(X_train,y_train)\n",
    "        print('{}: target feature {}: alpha = {}; training set score: {:.3f}; test set score {:.3f}'.format('Lasso',y_lst[i],alpha_lst[j],lr.score(X_train,train_whole_brain),lr.score(X_test,test_whole_brain)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa934b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data to use PCA\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d796f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3) #keep the first two principal components of the data\n",
    "pca.fit(X_train_scaled) # fit PCA model to sleep-diagnosis_change data\n",
    "X_pca = pca.transform(X_train_scaled)  #transform data onto the first two principal components\n",
    "plt.bar(range(1,len(pca.explained_variance_ratio_ )+1),pca.explained_variance_ratio_ )\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Components')\n",
    "plt.plot(range(1,len(pca.explained_variance_ )+1),\n",
    "             np.cumsum(pca.explained_variance_ratio_),\n",
    "             c='red',\n",
    "             label=\"Cumulative Explained Variance ratio\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# The component 1 can explain about 20% of the variance, conponent 2 can explain about 11.7%,... \n",
    "# It needs almost 10 principal components to explain at least 90% of the variance. \n",
    "pca = PCA(n_components=3) \n",
    "pca.fit(X_train_scaled) # fit PCA model to sleep-diagnosis_change data\n",
    "X_pca = pca.transform(X_train_scaled)  #transform data onto the first two principal components\n",
    "print(\"Origianl shape: {}\".format(str(X_train_scaled.shape)))\n",
    "print(\"Reduced shape: {}\".format(str(X_pca.shape)))\n",
    "# plot\n",
    "plt.figure(figsize=(8,8))\n",
    "mglearn.discrete_scatter(X_pca[:,0],X_pca[:,1],train['wholebrain_reduction_per_year'])\n",
    "plt.legend(train['wholebrain_reduction_per_year'].unique(),loc='best')\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.xlabel(\"First principal component\")\n",
    "plt.ylabel('Seconde principal component')\n",
    "\n",
    "print('PCA components: \\n{}'.format(pca.components_))    # PCA components\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.matshow(pca.components_,cmap='viridis')\n",
    "plt.yticks([0,1,2,3],['First component','Seconde component','Third component','Fourth component'])\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(X_train.columns)),X_train.columns,rotation=60,ha='left')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Principal components')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5fc12b",
   "metadata": {},
   "source": [
    "## try to use all variables to predict diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c461ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_file = pd.read_csv('main_file.csv',sep=',')\n",
    "main_2 = main_file[com_col + ['DX','DXCHANGE']]\n",
    "sleep_bio_brain_dx = sleep_brain_v.merge(main_2,how='left',on=com_col).dropna(axis=1, how='all')\n",
    "sleep_bio_brain_dx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1209347",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sleep_bio_brain_dx = sleep_bio_brain_dx.dropna(how='any',axis=0)\n",
    "train,test = train_test_split(sleep_bio_brain_dx,random_state=586,test_size=0.25)\n",
    "X_train = train.drop(['Phase', 'RID', 'VISCODE','PTID','DX','DXCHANGE'],axis=1)\n",
    "X_test = test.drop(['Phase', 'RID', 'VISCODE','PTID','DX','DXCHANGE'],axis=1)\n",
    "y_lst = ['DX','DXCHANGE']\n",
    "for j in range(len(y_lst)):\n",
    "    y_train = train[y_lst[j]]\n",
    "    y_test = test[y_lst[j]]\n",
    "    print('target feature: {}'.format(y_lst[j]))\n",
    "    for i in range(1,14):\n",
    "        tree = DecisionTreeClassifier(random_state=5850,max_depth=i,criterion='gini')\n",
    "        tree.fit(X_train,y_train)\n",
    "        print('    Decision tree with unscaled data. tree depth: {:.3f}. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'\n",
    "              .format(i,f1_score(tree.predict(X_train),y_train,average='weighted'),f1_score(tree.predict(X_test),y_test,average='weighted')))\n",
    "        forest = RandomForestClassifier(n_estimators = 200, random_state = 560)\n",
    "        forest.fit(X_train,y_train)\n",
    "        print('    Random forest with unscaled data. n_estimators: 200. tree depth: {:.3f}. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'\n",
    "              .format(i,f1_score(forest.predict(X_train),y_train,average='weighted'),f1_score(forest.predict(X_test),y_test,average='weighted')))\n",
    "    # MLP with unscaled data\n",
    "    mlp = MLPClassifier(solver='lbfgs',random_state=785,hidden_layer_sizes = [100,100],max_iter=40000)\n",
    "    mlp.fit(X_train,y_train)\n",
    "    print('    -MLP with uscaled data. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'\n",
    "      .format(f1_score(mlp.predict(X_train),y_train,average='weighted'),f1_score(mlp.predict(X_test),y_test,average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbe89a0",
   "metadata": {},
   "source": [
    "For the target feature DXCHANGE tree depth of 3 works best. \n",
    "\n",
    "with f1-score on training data: 0.786 f1-score on test data: 0.606"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aec8238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled data \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "for j in range(len(y_lst)):\n",
    "    y_train = train[y_lst[j]]\n",
    "    y_test = test[y_lst[j]]\n",
    "    print('target feature: {}'.format(y_lst[j]))\n",
    "    for i in range(2,14):\n",
    "        tree = DecisionTreeClassifier(random_state=5850,max_depth=i,criterion='gini')\n",
    "        tree.fit(X_train_scaled,y_train)\n",
    "        print('    Decision tree with scaled data. tree depth: {:.3f}. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'\n",
    "              .format(i,f1_score(tree.predict(X_train_scaled),y_train,average='weighted'),f1_score(tree.predict(X_test_scaled),y_test,average='weighted')))\n",
    "        forest = RandomForestClassifier(n_estimators = 200, random_state = 560)\n",
    "        forest.fit(X_train_scaled,y_train)\n",
    "        print('    Random forest with scaled data. n_estimators: 200. tree depth: {:.3f}. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'\n",
    "              .format(i,f1_score(forest.predict(X_train_scaled),y_train,average='weighted'),f1_score(forest.predict(X_test_scaled),y_test,average='weighted')))\n",
    "    # MLP with scaled data\n",
    "    mlp = MLPClassifier(solver='lbfgs',random_state=785,hidden_layer_sizes = [200,200],max_iter=40000)\n",
    "    mlp.fit(X_train_scaled,y_train)\n",
    "    print('    -MLP with uscaled data. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'\n",
    "      .format(f1_score(mlp.predict(X_train_scaled),y_train,average='weighted'),f1_score(mlp.predict(X_test_scaled),y_test,average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d6f377",
   "metadata": {},
   "source": [
    " DXCHANGE: Decision tree with scaled data. tree depth: 3.000. f1-score on training data: 0.786 f1-score on test data: 0.606\n",
    " \n",
    " DX: Decision tree with scaled data. tree depth: 2.000. f1-score on training data: 0.778 f1-score on test data: 0.487"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f605dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "pca = PCA(n_components=X_train_scaled.shape[1]) #keep the first two principal components of the data\n",
    "pca.fit(X_train_scaled) # fit PCA model to sleep-diagnosis_change data\n",
    "X_pca = pca.transform(X_train_scaled)  #transform data onto the first two principal components\n",
    "plt.bar(range(1,len(pca.explained_variance_ratio_ )+1),pca.explained_variance_ratio_ )\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Components')\n",
    "plt.plot(range(1,len(pca.explained_variance_ )+1),\n",
    "             np.cumsum(pca.explained_variance_ratio_),\n",
    "             c='red',\n",
    "             label=\"Cumulative Explained Variance ratio\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(8,8))\n",
    "mglearn.discrete_scatter(X_pca[:,0],X_pca[:,1],train['DXCHANGE'])\n",
    "plt.legend(train['DXCHANGE'].unique(),loc='best')\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.xlabel(\"First principal component\")\n",
    "plt.ylabel('Seconde principal component')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(18,18))\n",
    "plt.matshow(pca.components_,cmap='viridis')\n",
    "plt.yticks([0,1,2,3,4,5,6],['First component','Seconde component','Third component','Fourth component','Fifth component','Sixth component','seventh component'])\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(X_train.columns)),X_train.columns,rotation=60,ha='left')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Principal components')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02c1830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree with PCA data \n",
    "\n",
    "for k in range(len(y_lst)):\n",
    "    y_train = train[y_lst[k]]\n",
    "    y_test = test[y_lst[k]]\n",
    "    print('- target feature: {}'.format(y_lst[k]))\n",
    "    max_f1_test = 0\n",
    "    max_n_component = 0\n",
    "    tree_depth = 0\n",
    "    _f1_train = 0\n",
    "    for j in range(2,X_train_scaled.shape[1]):\n",
    "        pca = PCA(n_components=j) # keep the first j principal components of the data\n",
    "        pca.fit(X_train_scaled) # fit PCA model to sleep-diagnosis_change data\n",
    "        X_pca = pca.transform(X_train_scaled)  #transform data onto the first two principal components\n",
    "        X_test_pca = pca.transform(X_test_scaled)\n",
    "        #print('   - Decision tree with PCA {} components:'.format(j))\n",
    "        \n",
    "        for i in range(1,14):\n",
    "            tree = DecisionTreeClassifier(random_state=580,max_depth=i,criterion='gini')\n",
    "            tree.fit(X_pca,y_train)\n",
    "            f1_score_test = f1_score(tree.predict(X_test_pca),y_test,average='weighted')\n",
    "            f1_score_train = f1_score(tree.predict(X_pca),y_train,average='weighted')\n",
    "            #print('        - tree depth: {:.3f}. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'.format(i,f1_score_train,f1_score_test))\n",
    "            forest = RandomForestClassifier(n_estimators = 200, random_state = 560)\n",
    "        forest.fit(X_pca,y_train)\n",
    "        print('    Random forest with pca data. n_estimators: 200. tree depth: {:.3f}. f1-score on training data: {:.3f} f1-score on test data: {:.3f}'\n",
    "              .format(i,f1_score(forest.predict(X_pca),y_train,average='weighted'),f1_score(forest.predict(X_test_pca),y_test,average='weighted')))\n",
    "        if f1_score_test >= max_f1_test:\n",
    "                max_f1_test = f1_score_test\n",
    "                _f1_train = f1_score_train\n",
    "                max_n_component = j\n",
    "                tree_depth = i\n",
    "    print('The decision tree model predicting target feature {} with {:.3f} components, tree-depth of {} has the best f1-score on test set {:.3f}, on train set{:.3f}.'\n",
    "          .format(y_lst[k],max_n_component,tree_depth, max_f1_test,_f1_train))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dc3e2b",
   "metadata": {},
   "source": [
    "To predict feature DX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8079a821",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['DX']\n",
    "y_test = test['DX']\n",
    "clf = tree.DecisionTreeClassifier(random_state=580,max_depth=5,criterion='gini')\n",
    "clf = clf.fit(X_pca,y_train)\n",
    "fig = plt.figure(figsize=(20,15))\n",
    "tree.plot_tree(clf,fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0c199a",
   "metadata": {},
   "source": [
    "To predict feature DXCHANGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa8d603",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train,test = train_test_split(sleep_bio_brain_dx,random_state=586,test_size=0.25)\n",
    "X_train = train.drop(['Phase', 'RID', 'VISCODE','PTID','DX','DXCHANGE'],axis=1)\n",
    "X_test = test.drop(['Phase', 'RID', 'VISCODE','PTID','DX','DXCHANGE'],axis=1)\n",
    "feature_list = ['NPIKSEV', 'insomnia', 'OSA', 'ratio_Ventricles_bl',\n",
    "       'ratio_Hippocampus_bl', 'ratio_WholeBrain_bl', 'ratio_Entorhinal_bl',\n",
    "       'ratio_Fusiform_bl', 'ratio_ICV_bl', 'ratio_ABETA_bl', 'ratio_TAU_bl',\n",
    "       'ratio_PTAU_bl', 'Ventricles_reduction_per_year',\n",
    "       'Hippocampus_reduction_per_year', 'wholebrain_reduction_per_year',\n",
    "       'Entorhinal_reduction_per_year', 'Fusiform_reduction_per_year',\n",
    "       'ICV_reduction_per_year', 'ABETA_reduction_per_year',\n",
    "       'TAU_reduction_per_year', 'PTAU_reduction_per_year']\n",
    "y_train = train['DXCHANGE']\n",
    "y_test = test['DXCHANGE']\n",
    "clf = tree.DecisionTreeClassifier(random_state=5850,max_depth=3,criterion='gini')\n",
    "clf.fit(X_train,y_train)\n",
    "r = export_text(clf, feature_names=feature_list)\n",
    "print(r)\n",
    "fig = plt.figure(figsize=(20,15))\n",
    "tree.plot_tree(clf,fontsize=15,feature_names=feature_list)\n",
    "\n",
    "print('    Decision tree with unscaled data. tree depth: 2. f1-score on training data: {0.786} f1-score on test data: {0.606}')        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
