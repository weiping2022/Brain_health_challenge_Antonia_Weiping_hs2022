{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20f5d23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.tree import export_text\n",
    "import mglearn\n",
    "from dashboard_one import *\n",
    "from dash_model_two import *\n",
    "from feature_selection import *\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b74b94",
   "metadata": {},
   "source": [
    "### brain_volume_ratio_to_baseline_____VS_____diagnosischanges from every visit\n",
    "\n",
    "\n",
    "#### sleep_brain_dxch.csv\n",
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fef6c499",
   "metadata": {},
   "outputs": [],
   "source": [
    "com_col = ['Phase', 'RID', 'VISCODE','PTID']\n",
    "target = 'DXCHANGE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "769bd041",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RID</th>\n",
       "      <th>Phase</th>\n",
       "      <th>VISCODE</th>\n",
       "      <th>PTID</th>\n",
       "      <th>NPIK1</th>\n",
       "      <th>NPIK2</th>\n",
       "      <th>NPIK3</th>\n",
       "      <th>NPIK4</th>\n",
       "      <th>NPIK5</th>\n",
       "      <th>NPIK6</th>\n",
       "      <th>...</th>\n",
       "      <th>ratio_PTAU_bl</th>\n",
       "      <th>Ventricles_reduction_per_year</th>\n",
       "      <th>Hippocampus_reduction_per_year</th>\n",
       "      <th>wholebrain_reduction_per_year</th>\n",
       "      <th>Entorhinal_reduction_per_year</th>\n",
       "      <th>Fusiform_reduction_per_year</th>\n",
       "      <th>ICV_reduction_per_year</th>\n",
       "      <th>ABETA_reduction_per_year</th>\n",
       "      <th>TAU_reduction_per_year</th>\n",
       "      <th>PTAU_reduction_per_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>m06</td>\n",
       "      <td>011_S_0002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>m36</td>\n",
       "      <td>011_S_0002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>m60</td>\n",
       "      <td>011_S_0002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>m66</td>\n",
       "      <td>011_S_0002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>m72</td>\n",
       "      <td>011_S_0002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19432</th>\n",
       "      <td>7083</td>\n",
       "      <td>ADNI3</td>\n",
       "      <td>sc</td>\n",
       "      <td>126_S_7083</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19433</th>\n",
       "      <td>7085</td>\n",
       "      <td>ADNI3</td>\n",
       "      <td>sc</td>\n",
       "      <td>941_S_7085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19434</th>\n",
       "      <td>7088</td>\n",
       "      <td>ADNI3</td>\n",
       "      <td>sc</td>\n",
       "      <td>033_S_7088</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19435</th>\n",
       "      <td>7092</td>\n",
       "      <td>ADNI3</td>\n",
       "      <td>sc</td>\n",
       "      <td>021_S_7092</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19436</th>\n",
       "      <td>7100</td>\n",
       "      <td>ADNI3</td>\n",
       "      <td>sc</td>\n",
       "      <td>033_S_7100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19437 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RID  Phase VISCODE        PTID  NPIK1  NPIK2  NPIK3  NPIK4  NPIK5  \\\n",
       "0         2  ADNI1     m06  011_S_0002    NaN    NaN    NaN    NaN    NaN   \n",
       "1         2  ADNI1     m36  011_S_0002    NaN    NaN    NaN    NaN    NaN   \n",
       "2         2  ADNI1     m60  011_S_0002    NaN    NaN    NaN    NaN    NaN   \n",
       "3         2  ADNI1     m66  011_S_0002    NaN    NaN    NaN    NaN    NaN   \n",
       "4         2  ADNI1     m72  011_S_0002    NaN    NaN    NaN    NaN    NaN   \n",
       "...     ...    ...     ...         ...    ...    ...    ...    ...    ...   \n",
       "19432  7083  ADNI3      sc  126_S_7083    NaN    NaN    NaN    NaN    NaN   \n",
       "19433  7085  ADNI3      sc  941_S_7085    NaN    NaN    NaN    NaN    NaN   \n",
       "19434  7088  ADNI3      sc  033_S_7088    NaN    NaN    NaN    NaN    NaN   \n",
       "19435  7092  ADNI3      sc  021_S_7092    NaN    NaN    NaN    NaN    NaN   \n",
       "19436  7100  ADNI3      sc  033_S_7100    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "       NPIK6  ...  ratio_PTAU_bl  Ventricles_reduction_per_year  \\\n",
       "0        NaN  ...            NaN                            NaN   \n",
       "1        NaN  ...            NaN                            NaN   \n",
       "2        NaN  ...            NaN                            NaN   \n",
       "3        NaN  ...            NaN                            NaN   \n",
       "4        NaN  ...            NaN                            NaN   \n",
       "...      ...  ...            ...                            ...   \n",
       "19432    NaN  ...            NaN                            NaN   \n",
       "19433    NaN  ...            NaN                            NaN   \n",
       "19434    NaN  ...            NaN                            NaN   \n",
       "19435    NaN  ...            NaN                            NaN   \n",
       "19436    NaN  ...            NaN                            NaN   \n",
       "\n",
       "       Hippocampus_reduction_per_year  wholebrain_reduction_per_year  \\\n",
       "0                                 NaN                            NaN   \n",
       "1                                 NaN                            NaN   \n",
       "2                                 NaN                            NaN   \n",
       "3                                 NaN                            NaN   \n",
       "4                                 NaN                            NaN   \n",
       "...                               ...                            ...   \n",
       "19432                             NaN                            NaN   \n",
       "19433                             NaN                            NaN   \n",
       "19434                             NaN                            NaN   \n",
       "19435                             NaN                            NaN   \n",
       "19436                             NaN                            NaN   \n",
       "\n",
       "       Entorhinal_reduction_per_year  Fusiform_reduction_per_year  \\\n",
       "0                                NaN                          NaN   \n",
       "1                                NaN                          NaN   \n",
       "2                                NaN                          NaN   \n",
       "3                                NaN                          NaN   \n",
       "4                                NaN                          NaN   \n",
       "...                              ...                          ...   \n",
       "19432                            NaN                          NaN   \n",
       "19433                            NaN                          NaN   \n",
       "19434                            NaN                          NaN   \n",
       "19435                            NaN                          NaN   \n",
       "19436                            NaN                          NaN   \n",
       "\n",
       "       ICV_reduction_per_year  ABETA_reduction_per_year  \\\n",
       "0                         NaN                       NaN   \n",
       "1                         NaN                       NaN   \n",
       "2                         NaN                       NaN   \n",
       "3                         NaN                       NaN   \n",
       "4                         NaN                       NaN   \n",
       "...                       ...                       ...   \n",
       "19432                     NaN                       NaN   \n",
       "19433                     NaN                       NaN   \n",
       "19434                     NaN                       NaN   \n",
       "19435                     NaN                       NaN   \n",
       "19436                     NaN                       NaN   \n",
       "\n",
       "      TAU_reduction_per_year  PTAU_reduction_per_year  \n",
       "0                        NaN                      NaN  \n",
       "1                        NaN                      NaN  \n",
       "2                        NaN                      NaN  \n",
       "3                        NaN                      NaN  \n",
       "4                        NaN                      NaN  \n",
       "...                      ...                      ...  \n",
       "19432                    NaN                      NaN  \n",
       "19433                    NaN                      NaN  \n",
       "19434                    NaN                      NaN  \n",
       "19435                    NaN                      NaN  \n",
       "19436                    NaN                      NaN  \n",
       "\n",
       "[19437 rows x 37 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sleep_brain_dxch = pd.read_csv('sleep_brain_dxch.csv').iloc[:,1:].drop(['NPIKSEV'],axis=1)\n",
    "sleep_brain_dxch = sleep_brain_dxch[sleep_brain_dxch[target].notna()].reset_index().drop(['index'],axis=1)   # keep the rows where DXCHANGE is not nan\n",
    "sleep_brain_dxch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51ce40a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19437 entries, 0 to 19436\n",
      "Data columns (total 37 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   RID                             19437 non-null  int64  \n",
      " 1   Phase                           19437 non-null  object \n",
      " 2   VISCODE                         17886 non-null  object \n",
      " 3   PTID                            19350 non-null  object \n",
      " 4   NPIK1                           924 non-null    float64\n",
      " 5   NPIK2                           923 non-null    float64\n",
      " 6   NPIK3                           922 non-null    float64\n",
      " 7   NPIK4                           922 non-null    float64\n",
      " 8   NPIK5                           922 non-null    float64\n",
      " 9   NPIK6                           923 non-null    float64\n",
      " 10  NPIK7                           923 non-null    float64\n",
      " 11  NPIK8                           921 non-null    float64\n",
      " 12  NPIK9A                          925 non-null    float64\n",
      " 13  NPIK9B                          924 non-null    float64\n",
      " 14  NPIK9C                          925 non-null    float64\n",
      " 15  NPIKTOT                         924 non-null    float64\n",
      " 16  insomnia                        11303 non-null  float64\n",
      " 17  OSA                             19435 non-null  float64\n",
      " 18  DXCHANGE                        19437 non-null  object \n",
      " 19  ratio_Ventricles_bl             5967 non-null   float64\n",
      " 20  ratio_Hippocampus_bl            5192 non-null   float64\n",
      " 21  ratio_WholeBrain_bl             6211 non-null   float64\n",
      " 22  ratio_Entorhinal_bl             4896 non-null   float64\n",
      " 23  ratio_Fusiform_bl               4896 non-null   float64\n",
      " 24  ratio_ICV_bl                    6544 non-null   float64\n",
      " 25  ratio_ABETA_bl                  841 non-null    float64\n",
      " 26  ratio_TAU_bl                    1032 non-null   float64\n",
      " 27  ratio_PTAU_bl                   720 non-null    float64\n",
      " 28  Ventricles_reduction_per_year   5967 non-null   float64\n",
      " 29  Hippocampus_reduction_per_year  5192 non-null   float64\n",
      " 30  wholebrain_reduction_per_year   6211 non-null   float64\n",
      " 31  Entorhinal_reduction_per_year   4896 non-null   float64\n",
      " 32  Fusiform_reduction_per_year     4896 non-null   float64\n",
      " 33  ICV_reduction_per_year          6544 non-null   float64\n",
      " 34  ABETA_reduction_per_year        841 non-null    float64\n",
      " 35  TAU_reduction_per_year          1032 non-null   float64\n",
      " 36  PTAU_reduction_per_year         720 non-null    float64\n",
      "dtypes: float64(32), int64(1), object(4)\n",
      "memory usage: 5.5+ MB\n"
     ]
    }
   ],
   "source": [
    "sleep_brain_dxch.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81696451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RID', 'Phase', 'VISCODE', 'PTID', 'NPIK1', 'NPIK2', 'NPIK3', 'NPIK4',\n",
       "       'NPIK5', 'NPIK6', 'NPIK7', 'NPIK8', 'NPIK9A', 'NPIK9B', 'NPIK9C',\n",
       "       'NPIKTOT', 'insomnia', 'OSA', 'DXCHANGE', 'ratio_Ventricles_bl',\n",
       "       'ratio_Hippocampus_bl', 'ratio_WholeBrain_bl', 'ratio_Entorhinal_bl',\n",
       "       'ratio_Fusiform_bl', 'ratio_ICV_bl', 'ratio_ABETA_bl', 'ratio_TAU_bl',\n",
       "       'ratio_PTAU_bl', 'Ventricles_reduction_per_year',\n",
       "       'Hippocampus_reduction_per_year', 'wholebrain_reduction_per_year',\n",
       "       'Entorhinal_reduction_per_year', 'Fusiform_reduction_per_year',\n",
       "       'ICV_reduction_per_year', 'ABETA_reduction_per_year',\n",
       "       'TAU_reduction_per_year', 'PTAU_reduction_per_year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sleep_brain_dxch.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1b7f3e",
   "metadata": {},
   "source": [
    "### brain_biomarker______VS______DXCHANGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9b829bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "col_lst = [ 'DXCHANGE','ratio_Ventricles_bl',\n",
    "       'ratio_Hippocampus_bl', 'ratio_WholeBrain_bl', 'ratio_Entorhinal_bl',\n",
    "       'ratio_Fusiform_bl', 'Ventricles_reduction_per_year',\n",
    "       'Hippocampus_reduction_per_year', 'wholebrain_reduction_per_year',\n",
    "       'Entorhinal_reduction_per_year', 'Fusiform_reduction_per_year',\n",
    "       'ICV_reduction_per_year']\n",
    "bio_lst = [ 'ratio_ABETA_bl', 'ratio_TAU_bl','ratio_PTAU_bl']\n",
    "brain_dxch = sleep_brain_dxch[com_col + col_lst].set_index(['Phase', 'RID', 'VISCODE','PTID']).dropna(how='any',axis=0).reset_index()\n",
    "#biomarkers to dxch\n",
    "bio_dxch = sleep_brain_dxch[com_col + bio_lst].set_index(['Phase', 'RID', 'VISCODE','PTID']).dropna(how='any',axis=0).reset_index()\n",
    "df = brain_dxch.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c75224ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Phase                             0\n",
       "RID                               0\n",
       "VISCODE                           0\n",
       "PTID                              0\n",
       "DXCHANGE                          0\n",
       "ratio_Ventricles_bl               0\n",
       "ratio_Hippocampus_bl              0\n",
       "ratio_WholeBrain_bl               0\n",
       "ratio_Entorhinal_bl               0\n",
       "ratio_Fusiform_bl                 0\n",
       "Ventricles_reduction_per_year     0\n",
       "Hippocampus_reduction_per_year    0\n",
       "wholebrain_reduction_per_year     0\n",
       "Entorhinal_reduction_per_year     0\n",
       "Fusiform_reduction_per_year       0\n",
       "ICV_reduction_per_year            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df.isna())   # check nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af84a781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phase</th>\n",
       "      <th>RID</th>\n",
       "      <th>VISCODE</th>\n",
       "      <th>PTID</th>\n",
       "      <th>ratio_Ventricles_bl</th>\n",
       "      <th>ratio_Hippocampus_bl</th>\n",
       "      <th>ratio_WholeBrain_bl</th>\n",
       "      <th>ratio_Entorhinal_bl</th>\n",
       "      <th>ratio_Fusiform_bl</th>\n",
       "      <th>Ventricles_reduction_per_year</th>\n",
       "      <th>Hippocampus_reduction_per_year</th>\n",
       "      <th>wholebrain_reduction_per_year</th>\n",
       "      <th>Entorhinal_reduction_per_year</th>\n",
       "      <th>Fusiform_reduction_per_year</th>\n",
       "      <th>ICV_reduction_per_year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DXCHANGE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AD-AD</th>\n",
       "      <td>406</td>\n",
       "      <td>406</td>\n",
       "      <td>406</td>\n",
       "      <td>406</td>\n",
       "      <td>406</td>\n",
       "      <td>406</td>\n",
       "      <td>406</td>\n",
       "      <td>406</td>\n",
       "      <td>406</td>\n",
       "      <td>406</td>\n",
       "      <td>406</td>\n",
       "      <td>406</td>\n",
       "      <td>406</td>\n",
       "      <td>406</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AD-MCI</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CN-AD</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CN-CN</th>\n",
       "      <td>1561</td>\n",
       "      <td>1561</td>\n",
       "      <td>1561</td>\n",
       "      <td>1561</td>\n",
       "      <td>1561</td>\n",
       "      <td>1561</td>\n",
       "      <td>1561</td>\n",
       "      <td>1561</td>\n",
       "      <td>1561</td>\n",
       "      <td>1561</td>\n",
       "      <td>1561</td>\n",
       "      <td>1561</td>\n",
       "      <td>1561</td>\n",
       "      <td>1561</td>\n",
       "      <td>1561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CN-MCI</th>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCI-AD</th>\n",
       "      <td>471</td>\n",
       "      <td>471</td>\n",
       "      <td>471</td>\n",
       "      <td>471</td>\n",
       "      <td>471</td>\n",
       "      <td>471</td>\n",
       "      <td>471</td>\n",
       "      <td>471</td>\n",
       "      <td>471</td>\n",
       "      <td>471</td>\n",
       "      <td>471</td>\n",
       "      <td>471</td>\n",
       "      <td>471</td>\n",
       "      <td>471</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCI-CN</th>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCI-MCI</th>\n",
       "      <td>1819</td>\n",
       "      <td>1819</td>\n",
       "      <td>1819</td>\n",
       "      <td>1819</td>\n",
       "      <td>1819</td>\n",
       "      <td>1819</td>\n",
       "      <td>1819</td>\n",
       "      <td>1819</td>\n",
       "      <td>1819</td>\n",
       "      <td>1819</td>\n",
       "      <td>1819</td>\n",
       "      <td>1819</td>\n",
       "      <td>1819</td>\n",
       "      <td>1819</td>\n",
       "      <td>1819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Phase   RID  VISCODE  PTID  ratio_Ventricles_bl  \\\n",
       "DXCHANGE                                                    \n",
       "AD-AD       406   406      406   406                  406   \n",
       "AD-MCI        4     4        4     4                    4   \n",
       "CN-AD         7     7        7     7                    7   \n",
       "CN-CN      1561  1561     1561  1561                 1561   \n",
       "CN-MCI      103   103      103   103                  103   \n",
       "MCI-AD      471   471      471   471                  471   \n",
       "MCI-CN      132   132      132   132                  132   \n",
       "MCI-MCI    1819  1819     1819  1819                 1819   \n",
       "\n",
       "          ratio_Hippocampus_bl  ratio_WholeBrain_bl  ratio_Entorhinal_bl  \\\n",
       "DXCHANGE                                                                   \n",
       "AD-AD                      406                  406                  406   \n",
       "AD-MCI                       4                    4                    4   \n",
       "CN-AD                        7                    7                    7   \n",
       "CN-CN                     1561                 1561                 1561   \n",
       "CN-MCI                     103                  103                  103   \n",
       "MCI-AD                     471                  471                  471   \n",
       "MCI-CN                     132                  132                  132   \n",
       "MCI-MCI                   1819                 1819                 1819   \n",
       "\n",
       "          ratio_Fusiform_bl  Ventricles_reduction_per_year  \\\n",
       "DXCHANGE                                                     \n",
       "AD-AD                   406                            406   \n",
       "AD-MCI                    4                              4   \n",
       "CN-AD                     7                              7   \n",
       "CN-CN                  1561                           1561   \n",
       "CN-MCI                  103                            103   \n",
       "MCI-AD                  471                            471   \n",
       "MCI-CN                  132                            132   \n",
       "MCI-MCI                1819                           1819   \n",
       "\n",
       "          Hippocampus_reduction_per_year  wholebrain_reduction_per_year  \\\n",
       "DXCHANGE                                                                  \n",
       "AD-AD                                406                            406   \n",
       "AD-MCI                                 4                              4   \n",
       "CN-AD                                  7                              7   \n",
       "CN-CN                               1561                           1561   \n",
       "CN-MCI                               103                            103   \n",
       "MCI-AD                               471                            471   \n",
       "MCI-CN                               132                            132   \n",
       "MCI-MCI                             1819                           1819   \n",
       "\n",
       "          Entorhinal_reduction_per_year  Fusiform_reduction_per_year  \\\n",
       "DXCHANGE                                                               \n",
       "AD-AD                               406                          406   \n",
       "AD-MCI                                4                            4   \n",
       "CN-AD                                 7                            7   \n",
       "CN-CN                              1561                         1561   \n",
       "CN-MCI                              103                          103   \n",
       "MCI-AD                              471                          471   \n",
       "MCI-CN                              132                          132   \n",
       "MCI-MCI                            1819                         1819   \n",
       "\n",
       "          ICV_reduction_per_year  \n",
       "DXCHANGE                          \n",
       "AD-AD                        406  \n",
       "AD-MCI                         4  \n",
       "CN-AD                          7  \n",
       "CN-CN                       1561  \n",
       "CN-MCI                       103  \n",
       "MCI-AD                       471  \n",
       "MCI-CN                       132  \n",
       "MCI-MCI                     1819  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(target).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae317f9",
   "metadata": {},
   "source": [
    "- try different combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b631153b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2290, 16)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to distinguish MCI to AD or stay in MCI   --> As the previous challenge group used\n",
    "df_2g = df.loc[df[target].isin(['MCI-AD','MCI-MCI'])].reset_index().drop(['index'],axis=1)\n",
    "df_2g.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4cf4b57d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2422, 16)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to distinguish MCI to AD or stay in MCI or get back to CN\n",
    "df_3g = df.loc[df[target].isin([ 'MCI-MCI', 'MCI-AD', 'MCI-CN',])].reset_index().drop(['index'],axis=1)\n",
    "df_3g.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70429218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1664, 16)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to distinguish CN to MCI or stay in CN\n",
    "df_2gg = df.loc[df[target].isin(['CN-MCI', 'CN-CN'])].reset_index().drop(['index'],axis=1)\n",
    "df_2gg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19827eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4086, 16)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combination bl of CN or MCI, 5 groups\n",
    "df_5g = df.loc[brain_dxch[target].isin(['CN-MCI', 'MCI-MCI', 'MCI-AD', 'MCI-CN','CN-CN'])].reset_index().drop(['index'],axis=1)\n",
    "df_5g.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "23461b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4492, 16)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6 labels\n",
    "df_6g = df.loc[brain_dxch[target].isin(['CN-MCI', 'AD-AD', 'MCI-MCI', 'MCI-AD', 'MCI-CN','CN-CN'])].reset_index().drop(['index'],axis=1)\n",
    "df_6g.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39783bf",
   "metadata": {},
   "source": [
    "### undersampling and modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdd62ca",
   "metadata": {},
   "source": [
    "- functions\n",
    "    - models(df,drop_lst,target) : under sampling, split, scale, pca, models\n",
    "    - cv_models(df,drop_lst,target,k): under sampling, NOT SPLIT, scale, pca, models with cross-validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c356c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_lst = ['Phase', 'RID', 'VISCODE', 'PTID',target]\n",
    "\n",
    "k=10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916eb3f2",
   "metadata": {},
   "source": [
    "# - 'MCI-AD': 471, 'MCI-MCI': 471"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5895d717",
   "metadata": {},
   "source": [
    "-  MCI-AD': 471, 'MCI-MCI': 471\n",
    "- original dataset: random forest 90trees. f1-score on training data: 1.000 f1-score on test data: 0.783, 10-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcc70e4b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After undersampling data size is 942 ; Resampled dataset shape Counter({'MCI-AD': 471, 'MCI-MCI': 471})\n",
      "\n",
      "6 principle components are needed to explain 90% of the data\n",
      "\n",
      "Output dataframes sequence: X_train,X_test,X_train_scaled,X_test_scaled,X_train_pca,X_test_pca,y_train,y_test\n",
      "- Using original dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, Training set f1-score:0.673, Test set f1-score: 0.640\n",
      "          - saga_L1, Training set f1-score:0.660, Test set f1-score: 0.692\n",
      "          - newton-cg_L2, Training set f1-score:0.673, Test set f1-score: 0.640\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, Training set f1-score:0.753, Test set f1-score: 0.736\n",
      "          - saga_L1, Training set f1-score:0.673, Test set f1-score: 0.640\n",
      "          - newton-cg_L2, Training set f1-score:0.753, Test set f1-score: 0.736\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, Training set f1-score:0.729, Test set f1-score: 0.758\n",
      "          - saga_L1, Training set f1-score:0.734, Test set f1-score: 0.743\n",
      "          - newton-cg_L2, Training set f1-score:0.729, Test set f1-score: 0.758\n",
      "       - C = 1\n",
      "          - lbfgs_L2, Training set f1-score:0.750, Test set f1-score: 0.774\n",
      "          - saga_L1, Training set f1-score:0.748, Test set f1-score: 0.768\n",
      "          - newton-cg_L2, Training set f1-score:0.750, Test set f1-score: 0.774\n",
      "       - C = 10\n",
      "          - lbfgs_L2, Training set f1-score:0.754, Test set f1-score: 0.758\n",
      "          - saga_L1, Training set f1-score:0.750, Test set f1-score: 0.736\n",
      "          - newton-cg_L2, Training set f1-score:0.754, Test set f1-score: 0.758\n",
      "       - C = 100\n",
      "          - lbfgs_L2, Training set f1-score:0.747, Test set f1-score: 0.736\n",
      "          - saga_L1, Training set f1-score:0.748, Test set f1-score: 0.725\n",
      "          - newton-cg_L2, Training set f1-score:0.747, Test set f1-score: 0.736\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, Training set f1-score:0.748, Test set f1-score: 0.730\n",
      "          - saga_L1, Training set f1-score:0.747, Test set f1-score: 0.725\n",
      "          - newton-cg_L2, Training set f1-score:0.747, Test set f1-score: 0.730\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. f1-score on training data: 0.745 f1-score on test data: 0.651\n",
      "          - tree depth: 2.000. f1-score on training data: 0.745 f1-score on test data: 0.651\n",
      "          - tree depth: 3.000. f1-score on training data: 0.786 f1-score on test data: 0.735\n",
      "          - tree depth: 4.000. f1-score on training data: 0.818 f1-score on test data: 0.736\n",
      "          - tree depth: 5.000. f1-score on training data: 0.855 f1-score on test data: 0.721\n",
      "          - tree depth: 6.000. f1-score on training data: 0.884 f1-score on test data: 0.706\n",
      "          - tree depth: 7.000. f1-score on training data: 0.915 f1-score on test data: 0.652\n",
      "          - tree depth: 8.000. f1-score on training data: 0.948 f1-score on test data: 0.632\n",
      "          - tree depth: 9.000. f1-score on training data: 0.972 f1-score on test data: 0.632\n",
      "          - tree depth: 10.000. f1-score on training data: 0.983 f1-score on test data: 0.637\n",
      "          - tree depth: 11.000. f1-score on training data: 0.991 f1-score on test data: 0.627\n",
      "          - tree depth: 12.000. f1-score on training data: 0.997 f1-score on test data: 0.620\n",
      "          - tree depth: 13.000. f1-score on training data: 0.999 f1-score on test data: 0.625\n",
      "          - tree depth: 14.000. f1-score on training data: 1.000 f1-score on test data: 0.647\n",
      "    - Random forest\n",
      "          - 5trees. f1-score on training data: 0.955 f1-score on test data: 0.719\n",
      "          - 10trees. f1-score on training data: 0.992 f1-score on test data: 0.709\n",
      "          - 15trees. f1-score on training data: 0.993 f1-score on test data: 0.725\n",
      "          - 20trees. f1-score on training data: 1.000 f1-score on test data: 0.735\n",
      "          - 25trees. f1-score on training data: 1.000 f1-score on test data: 0.741\n",
      "          - 30trees. f1-score on training data: 0.999 f1-score on test data: 0.735\n",
      "          - 35trees. f1-score on training data: 1.000 f1-score on test data: 0.751\n",
      "          - 40trees. f1-score on training data: 1.000 f1-score on test data: 0.741\n",
      "          - 45trees. f1-score on training data: 1.000 f1-score on test data: 0.746\n",
      "          - 50trees. f1-score on training data: 1.000 f1-score on test data: 0.741\n",
      "          - 55trees. f1-score on training data: 1.000 f1-score on test data: 0.751\n",
      "          - 60trees. f1-score on training data: 1.000 f1-score on test data: 0.741\n",
      "          - 65trees. f1-score on training data: 1.000 f1-score on test data: 0.741\n",
      "          - 70trees. f1-score on training data: 1.000 f1-score on test data: 0.751\n",
      "          - 75trees. f1-score on training data: 1.000 f1-score on test data: 0.741\n",
      "          - 80trees. f1-score on training data: 1.000 f1-score on test data: 0.735\n",
      "          - 85trees. f1-score on training data: 1.000 f1-score on test data: 0.746\n",
      "          - 90trees. f1-score on training data: 1.000 f1-score on test data: 0.746\n",
      "          - 95trees. f1-score on training data: 1.000 f1-score on test data: 0.741\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. f1-score on training data: 0.835 f1-score on test data: 0.730\n",
      "          - hidden layer size[20, 20]. f1-score on training data: 0.825 f1-score on test data: 0.725\n",
      "          - hidden layer size[100, 100]. f1-score on training data: 0.946 f1-score on test data: 0.709\n",
      "          - hidden layer size[50, 50, 50]. f1-score on training data: 0.891 f1-score on test data: 0.662\n",
      "- Using scaled dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, Training set f1-score:0.743, Test set f1-score: 0.736\n",
      "          - saga_L1, Training set f1-score:0.673, Test set f1-score: 0.640\n",
      "          - newton-cg_L2, Training set f1-score:0.743, Test set f1-score: 0.736\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, Training set f1-score:0.757, Test set f1-score: 0.742\n",
      "          - saga_L1, Training set f1-score:0.735, Test set f1-score: 0.709\n",
      "          - newton-cg_L2, Training set f1-score:0.757, Test set f1-score: 0.742\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, Training set f1-score:0.753, Test set f1-score: 0.742\n",
      "          - saga_L1, Training set f1-score:0.751, Test set f1-score: 0.757\n",
      "          - newton-cg_L2, Training set f1-score:0.753, Test set f1-score: 0.742\n",
      "       - C = 1\n",
      "          - lbfgs_L2, Training set f1-score:0.747, Test set f1-score: 0.730\n",
      "          - saga_L1, Training set f1-score:0.750, Test set f1-score: 0.741\n",
      "          - newton-cg_L2, Training set f1-score:0.747, Test set f1-score: 0.730\n",
      "       - C = 10\n",
      "          - lbfgs_L2, Training set f1-score:0.747, Test set f1-score: 0.730\n",
      "          - saga_L1, Training set f1-score:0.747, Test set f1-score: 0.730\n",
      "          - newton-cg_L2, Training set f1-score:0.747, Test set f1-score: 0.730\n",
      "       - C = 100\n",
      "          - lbfgs_L2, Training set f1-score:0.747, Test set f1-score: 0.730\n",
      "          - saga_L1, Training set f1-score:0.747, Test set f1-score: 0.730\n",
      "          - newton-cg_L2, Training set f1-score:0.747, Test set f1-score: 0.730\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, Training set f1-score:0.747, Test set f1-score: 0.730\n",
      "          - saga_L1, Training set f1-score:0.747, Test set f1-score: 0.730\n",
      "          - newton-cg_L2, Training set f1-score:0.747, Test set f1-score: 0.730\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. f1-score on training data: 0.745 f1-score on test data: 0.651\n",
      "          - tree depth: 2.000. f1-score on training data: 0.745 f1-score on test data: 0.651\n",
      "          - tree depth: 3.000. f1-score on training data: 0.786 f1-score on test data: 0.735\n",
      "          - tree depth: 4.000. f1-score on training data: 0.818 f1-score on test data: 0.736\n",
      "          - tree depth: 5.000. f1-score on training data: 0.855 f1-score on test data: 0.721\n",
      "          - tree depth: 6.000. f1-score on training data: 0.884 f1-score on test data: 0.706\n",
      "          - tree depth: 7.000. f1-score on training data: 0.915 f1-score on test data: 0.652\n",
      "          - tree depth: 8.000. f1-score on training data: 0.948 f1-score on test data: 0.632\n",
      "          - tree depth: 9.000. f1-score on training data: 0.972 f1-score on test data: 0.632\n",
      "          - tree depth: 10.000. f1-score on training data: 0.983 f1-score on test data: 0.637\n",
      "          - tree depth: 11.000. f1-score on training data: 0.991 f1-score on test data: 0.627\n",
      "          - tree depth: 12.000. f1-score on training data: 0.997 f1-score on test data: 0.620\n",
      "          - tree depth: 13.000. f1-score on training data: 0.999 f1-score on test data: 0.625\n",
      "          - tree depth: 14.000. f1-score on training data: 1.000 f1-score on test data: 0.647\n",
      "    - Random forest\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          - 5trees. f1-score on training data: 0.955 f1-score on test data: 0.719\n",
      "          - 10trees. f1-score on training data: 0.992 f1-score on test data: 0.709\n",
      "          - 15trees. f1-score on training data: 0.993 f1-score on test data: 0.725\n",
      "          - 20trees. f1-score on training data: 1.000 f1-score on test data: 0.735\n",
      "          - 25trees. f1-score on training data: 1.000 f1-score on test data: 0.741\n",
      "          - 30trees. f1-score on training data: 0.999 f1-score on test data: 0.735\n",
      "          - 35trees. f1-score on training data: 1.000 f1-score on test data: 0.751\n",
      "          - 40trees. f1-score on training data: 1.000 f1-score on test data: 0.741\n",
      "          - 45trees. f1-score on training data: 1.000 f1-score on test data: 0.746\n",
      "          - 50trees. f1-score on training data: 1.000 f1-score on test data: 0.741\n",
      "          - 55trees. f1-score on training data: 1.000 f1-score on test data: 0.751\n",
      "          - 60trees. f1-score on training data: 1.000 f1-score on test data: 0.741\n",
      "          - 65trees. f1-score on training data: 1.000 f1-score on test data: 0.741\n",
      "          - 70trees. f1-score on training data: 1.000 f1-score on test data: 0.751\n",
      "          - 75trees. f1-score on training data: 1.000 f1-score on test data: 0.741\n",
      "          - 80trees. f1-score on training data: 1.000 f1-score on test data: 0.735\n",
      "          - 85trees. f1-score on training data: 1.000 f1-score on test data: 0.746\n",
      "          - 90trees. f1-score on training data: 1.000 f1-score on test data: 0.746\n",
      "          - 95trees. f1-score on training data: 1.000 f1-score on test data: 0.741\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. f1-score on training data: 1.000 f1-score on test data: 0.651\n",
      "          - hidden layer size[20, 20]. f1-score on training data: 1.000 f1-score on test data: 0.677\n",
      "          - hidden layer size[100, 100]. f1-score on training data: 1.000 f1-score on test data: 0.688\n",
      "          - hidden layer size[50, 50, 50]. f1-score on training data: 1.000 f1-score on test data: 0.662\n",
      "- Using 6 pca-components:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, Training set f1-score:0.745, Test set f1-score: 0.757\n",
      "          - saga_L1, Training set f1-score:0.673, Test set f1-score: 0.640\n",
      "          - newton-cg_L2, Training set f1-score:0.745, Test set f1-score: 0.757\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, Training set f1-score:0.753, Test set f1-score: 0.757\n",
      "          - saga_L1, Training set f1-score:0.737, Test set f1-score: 0.752\n",
      "          - newton-cg_L2, Training set f1-score:0.753, Test set f1-score: 0.757\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, Training set f1-score:0.752, Test set f1-score: 0.757\n",
      "          - saga_L1, Training set f1-score:0.751, Test set f1-score: 0.768\n",
      "          - newton-cg_L2, Training set f1-score:0.752, Test set f1-score: 0.757\n",
      "       - C = 1\n",
      "          - lbfgs_L2, Training set f1-score:0.754, Test set f1-score: 0.757\n",
      "          - saga_L1, Training set f1-score:0.752, Test set f1-score: 0.757\n",
      "          - newton-cg_L2, Training set f1-score:0.754, Test set f1-score: 0.757\n",
      "       - C = 10\n",
      "          - lbfgs_L2, Training set f1-score:0.754, Test set f1-score: 0.757\n",
      "          - saga_L1, Training set f1-score:0.754, Test set f1-score: 0.757\n",
      "          - newton-cg_L2, Training set f1-score:0.754, Test set f1-score: 0.757\n",
      "       - C = 100\n",
      "          - lbfgs_L2, Training set f1-score:0.754, Test set f1-score: 0.757\n",
      "          - saga_L1, Training set f1-score:0.754, Test set f1-score: 0.757\n",
      "          - newton-cg_L2, Training set f1-score:0.754, Test set f1-score: 0.757\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, Training set f1-score:0.754, Test set f1-score: 0.757\n",
      "          - saga_L1, Training set f1-score:0.754, Test set f1-score: 0.757\n",
      "          - newton-cg_L2, Training set f1-score:0.754, Test set f1-score: 0.757\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. f1-score on training data: 0.750 f1-score on test data: 0.688\n",
      "          - tree depth: 2.000. f1-score on training data: 0.750 f1-score on test data: 0.688\n",
      "          - tree depth: 3.000. f1-score on training data: 0.782 f1-score on test data: 0.698\n",
      "          - tree depth: 4.000. f1-score on training data: 0.806 f1-score on test data: 0.693\n",
      "          - tree depth: 5.000. f1-score on training data: 0.843 f1-score on test data: 0.668\n",
      "          - tree depth: 6.000. f1-score on training data: 0.874 f1-score on test data: 0.662\n",
      "          - tree depth: 7.000. f1-score on training data: 0.897 f1-score on test data: 0.663\n",
      "          - tree depth: 8.000. f1-score on training data: 0.923 f1-score on test data: 0.683\n",
      "          - tree depth: 9.000. f1-score on training data: 0.942 f1-score on test data: 0.673\n",
      "          - tree depth: 10.000. f1-score on training data: 0.956 f1-score on test data: 0.652\n",
      "          - tree depth: 11.000. f1-score on training data: 0.977 f1-score on test data: 0.663\n",
      "          - tree depth: 12.000. f1-score on training data: 0.991 f1-score on test data: 0.673\n",
      "          - tree depth: 13.000. f1-score on training data: 0.996 f1-score on test data: 0.677\n",
      "          - tree depth: 14.000. f1-score on training data: 1.000 f1-score on test data: 0.667\n",
      "    - Random forest\n",
      "          - 5trees. f1-score on training data: 0.959 f1-score on test data: 0.709\n",
      "          - 10trees. f1-score on training data: 0.983 f1-score on test data: 0.709\n",
      "          - 15trees. f1-score on training data: 0.991 f1-score on test data: 0.735\n",
      "          - 20trees. f1-score on training data: 0.993 f1-score on test data: 0.730\n",
      "          - 25trees. f1-score on training data: 0.997 f1-score on test data: 0.709\n",
      "          - 30trees. f1-score on training data: 0.997 f1-score on test data: 0.714\n",
      "          - 35trees. f1-score on training data: 1.000 f1-score on test data: 0.709\n",
      "          - 40trees. f1-score on training data: 1.000 f1-score on test data: 0.714\n",
      "          - 45trees. f1-score on training data: 1.000 f1-score on test data: 0.714\n",
      "          - 50trees. f1-score on training data: 1.000 f1-score on test data: 0.709\n",
      "          - 55trees. f1-score on training data: 1.000 f1-score on test data: 0.709\n",
      "          - 60trees. f1-score on training data: 1.000 f1-score on test data: 0.703\n",
      "          - 65trees. f1-score on training data: 1.000 f1-score on test data: 0.719\n",
      "          - 70trees. f1-score on training data: 1.000 f1-score on test data: 0.714\n",
      "          - 75trees. f1-score on training data: 1.000 f1-score on test data: 0.714\n",
      "          - 80trees. f1-score on training data: 1.000 f1-score on test data: 0.719\n",
      "          - 85trees. f1-score on training data: 1.000 f1-score on test data: 0.714\n",
      "          - 90trees. f1-score on training data: 1.000 f1-score on test data: 0.719\n",
      "          - 95trees. f1-score on training data: 1.000 f1-score on test data: 0.725\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. f1-score on training data: 1.000 f1-score on test data: 0.682\n",
      "          - hidden layer size[20, 20]. f1-score on training data: 1.000 f1-score on test data: 0.678\n",
      "          - hidden layer size[100, 100]. f1-score on training data: 1.000 f1-score on test data: 0.709\n",
      "          - hidden layer size[50, 50, 50]. f1-score on training data: 1.000 f1-score on test data: 0.688\n"
     ]
    }
   ],
   "source": [
    "models(df_2g,drop_lst,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43e5725c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After undersampling data size is 942 ; Resampled dataset shape Counter({'MCI-AD': 471, 'MCI-MCI': 471})\n",
      "\n",
      "6 principle components are needed to explain 90% of the data\n",
      "\n",
      "- Using original dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.710\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.333\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.710\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.722\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.332\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.722\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.726\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.714\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.726\n",
      "       - C = 1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.741\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.742\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.741\n",
      "       - C = 10\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.743\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.739\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.743\n",
      "       - C = 100\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.737\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.740\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.737\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.739\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.740\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.739\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. average weighted f1-score of 10-cross validation:0.703\n",
      "          - tree depth: 2.000. average weighted f1-score of 10-cross validation:0.711\n",
      "          - tree depth: 3.000. average weighted f1-score of 10-cross validation:0.742\n",
      "          - tree depth: 4.000. average weighted f1-score of 10-cross validation:0.746\n",
      "          - tree depth: 5.000. average weighted f1-score of 10-cross validation:0.733\n",
      "          - tree depth: 6.000. average weighted f1-score of 10-cross validation:0.719\n",
      "          - tree depth: 7.000. average weighted f1-score of 10-cross validation:0.708\n",
      "          - tree depth: 8.000. average weighted f1-score of 10-cross validation:0.699\n",
      "          - tree depth: 9.000. average weighted f1-score of 10-cross validation:0.682\n",
      "          - tree depth: 10.000. average weighted f1-score of 10-cross validation:0.693\n",
      "          - tree depth: 11.000. average weighted f1-score of 10-cross validation:0.688\n",
      "          - tree depth: 12.000. average weighted f1-score of 10-cross validation:0.669\n",
      "          - tree depth: 13.000. average weighted f1-score of 10-cross validation:0.671\n",
      "          - tree depth: 14.000. average weighted f1-score of 10-cross validation:0.675\n",
      "    - Random forest\n",
      "          - 5trees. average weighted f1-score of 10-cross validation:0.716\n",
      "          - 10trees. average weighted f1-score of 10-cross validation:0.742\n",
      "          - 15trees. average weighted f1-score of 10-cross validation:0.751\n",
      "          - 20trees. average weighted f1-score of 10-cross validation:0.750\n",
      "          - 25trees. average weighted f1-score of 10-cross validation:0.759\n",
      "          - 30trees. average weighted f1-score of 10-cross validation:0.753\n",
      "          - 35trees. average weighted f1-score of 10-cross validation:0.759\n",
      "          - 40trees. average weighted f1-score of 10-cross validation:0.753\n",
      "          - 45trees. average weighted f1-score of 10-cross validation:0.762\n",
      "          - 50trees. average weighted f1-score of 10-cross validation:0.762\n",
      "          - 55trees. average weighted f1-score of 10-cross validation:0.768\n",
      "          - 60trees. average weighted f1-score of 10-cross validation:0.765\n",
      "          - 65trees. average weighted f1-score of 10-cross validation:0.765\n",
      "          - 70trees. average weighted f1-score of 10-cross validation:0.766\n",
      "          - 75trees. average weighted f1-score of 10-cross validation:0.766\n",
      "          - 80trees. average weighted f1-score of 10-cross validation:0.766\n",
      "          - 85trees. average weighted f1-score of 10-cross validation:0.768\n",
      "          - 90trees. average weighted f1-score of 10-cross validation:0.773\n",
      "          - 95trees. average weighted f1-score of 10-cross validation:0.772\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. average weighted f1-score of 10-cross validation:0.707\n",
      "          - hidden layer size[20, 20]. average weighted f1-score of 10-cross validation:0.753\n",
      "- Using scaled dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.733\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.335\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.733\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.735\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.727\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.735\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.742\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.742\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.742\n",
      "       - C = 1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.738\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.740\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.738\n",
      "       - C = 10\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.739\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.739\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.739\n",
      "       - C = 100\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.739\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.739\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.739\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.739\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.739\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.739\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. average weighted f1-score of 10-cross validation:0.703\n",
      "          - tree depth: 2.000. average weighted f1-score of 10-cross validation:0.711\n",
      "          - tree depth: 3.000. average weighted f1-score of 10-cross validation:0.742\n",
      "          - tree depth: 4.000. average weighted f1-score of 10-cross validation:0.746\n",
      "          - tree depth: 5.000. average weighted f1-score of 10-cross validation:0.733\n",
      "          - tree depth: 6.000. average weighted f1-score of 10-cross validation:0.719\n",
      "          - tree depth: 7.000. average weighted f1-score of 10-cross validation:0.708\n",
      "          - tree depth: 8.000. average weighted f1-score of 10-cross validation:0.699\n",
      "          - tree depth: 9.000. average weighted f1-score of 10-cross validation:0.682\n",
      "          - tree depth: 10.000. average weighted f1-score of 10-cross validation:0.693\n",
      "          - tree depth: 11.000. average weighted f1-score of 10-cross validation:0.688\n",
      "          - tree depth: 12.000. average weighted f1-score of 10-cross validation:0.669\n",
      "          - tree depth: 13.000. average weighted f1-score of 10-cross validation:0.671\n",
      "          - tree depth: 14.000. average weighted f1-score of 10-cross validation:0.675\n",
      "    - Random forest\n",
      "          - 5trees. average weighted f1-score of 10-cross validation:0.716\n",
      "          - 10trees. average weighted f1-score of 10-cross validation:0.742\n",
      "          - 15trees. average weighted f1-score of 10-cross validation:0.751\n",
      "          - 20trees. average weighted f1-score of 10-cross validation:0.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          - 25trees. average weighted f1-score of 10-cross validation:0.759\n",
      "          - 30trees. average weighted f1-score of 10-cross validation:0.753\n",
      "          - 35trees. average weighted f1-score of 10-cross validation:0.759\n",
      "          - 40trees. average weighted f1-score of 10-cross validation:0.753\n",
      "          - 45trees. average weighted f1-score of 10-cross validation:0.762\n",
      "          - 50trees. average weighted f1-score of 10-cross validation:0.762\n",
      "          - 55trees. average weighted f1-score of 10-cross validation:0.768\n",
      "          - 60trees. average weighted f1-score of 10-cross validation:0.765\n",
      "          - 65trees. average weighted f1-score of 10-cross validation:0.765\n",
      "          - 70trees. average weighted f1-score of 10-cross validation:0.766\n",
      "          - 75trees. average weighted f1-score of 10-cross validation:0.766\n",
      "          - 80trees. average weighted f1-score of 10-cross validation:0.766\n",
      "          - 85trees. average weighted f1-score of 10-cross validation:0.768\n",
      "          - 90trees. average weighted f1-score of 10-cross validation:0.773\n",
      "          - 95trees. average weighted f1-score of 10-cross validation:0.773\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. average weighted f1-score of 10-cross validation:0.676\n",
      "          - hidden layer size[20, 20]. average weighted f1-score of 10-cross validation:0.679\n",
      "- Using 6 pca-components:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.733\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.333\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.733\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.738\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.736\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.738\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.746\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.745\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.746\n",
      "       - C = 1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.744\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.746\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.744\n",
      "       - C = 10\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.744\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.744\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.744\n",
      "       - C = 100\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.744\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.744\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.744\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.744\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.744\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.744\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. average weighted f1-score of 10-cross validation:0.740\n",
      "          - tree depth: 2.000. average weighted f1-score of 10-cross validation:0.740\n",
      "          - tree depth: 3.000. average weighted f1-score of 10-cross validation:0.735\n",
      "          - tree depth: 4.000. average weighted f1-score of 10-cross validation:0.736\n",
      "          - tree depth: 5.000. average weighted f1-score of 10-cross validation:0.720\n",
      "          - tree depth: 6.000. average weighted f1-score of 10-cross validation:0.715\n",
      "          - tree depth: 7.000. average weighted f1-score of 10-cross validation:0.721\n",
      "          - tree depth: 8.000. average weighted f1-score of 10-cross validation:0.704\n",
      "          - tree depth: 9.000. average weighted f1-score of 10-cross validation:0.695\n",
      "          - tree depth: 10.000. average weighted f1-score of 10-cross validation:0.672\n",
      "          - tree depth: 11.000. average weighted f1-score of 10-cross validation:0.677\n",
      "          - tree depth: 12.000. average weighted f1-score of 10-cross validation:0.665\n",
      "          - tree depth: 13.000. average weighted f1-score of 10-cross validation:0.652\n",
      "          - tree depth: 14.000. average weighted f1-score of 10-cross validation:0.661\n",
      "    - Random forest\n",
      "          - 5trees. average weighted f1-score of 10-cross validation:0.700\n",
      "          - 10trees. average weighted f1-score of 10-cross validation:0.717\n",
      "          - 15trees. average weighted f1-score of 10-cross validation:0.722\n",
      "          - 20trees. average weighted f1-score of 10-cross validation:0.727\n",
      "          - 25trees. average weighted f1-score of 10-cross validation:0.728\n",
      "          - 30trees. average weighted f1-score of 10-cross validation:0.732\n",
      "          - 35trees. average weighted f1-score of 10-cross validation:0.737\n",
      "          - 40trees. average weighted f1-score of 10-cross validation:0.734\n",
      "          - 45trees. average weighted f1-score of 10-cross validation:0.736\n",
      "          - 50trees. average weighted f1-score of 10-cross validation:0.740\n",
      "          - 55trees. average weighted f1-score of 10-cross validation:0.736\n",
      "          - 60trees. average weighted f1-score of 10-cross validation:0.742\n",
      "          - 65trees. average weighted f1-score of 10-cross validation:0.741\n",
      "          - 70trees. average weighted f1-score of 10-cross validation:0.733\n",
      "          - 75trees. average weighted f1-score of 10-cross validation:0.743\n",
      "          - 80trees. average weighted f1-score of 10-cross validation:0.739\n",
      "          - 85trees. average weighted f1-score of 10-cross validation:0.739\n",
      "          - 90trees. average weighted f1-score of 10-cross validation:0.741\n",
      "          - 95trees. average weighted f1-score of 10-cross validation:0.736\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. average weighted f1-score of 10-cross validation:0.654\n",
      "          - hidden layer size[20, 20]. average weighted f1-score of 10-cross validation:0.650\n"
     ]
    }
   ],
   "source": [
    "cv_models(df_2g,drop_lst,target,k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade44273",
   "metadata": {},
   "source": [
    "- Model selection:\n",
    "- original data, 10 fold-cv, randomforest: 90trees. average weighted f1-score of 10-cross validation:0.773"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e0322c5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After undersampling data size is 942 ; Resampled dataset shape Counter({'MCI-AD': 471, 'MCI-MCI': 471})\n",
      "\n",
      "6 principle components are needed to explain 90% of the data\n",
      "\n",
      "Features sorted by their score for each estimator \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_importance</th>\n",
       "      <th>importance_1</th>\n",
       "      <th>importance_2</th>\n",
       "      <th>importance_3</th>\n",
       "      <th>importance_4</th>\n",
       "      <th>importance_5</th>\n",
       "      <th>importance_6</th>\n",
       "      <th>importance_7</th>\n",
       "      <th>importance_8</th>\n",
       "      <th>importance_9</th>\n",
       "      <th>importance_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ratio_Ventricles_bl</th>\n",
       "      <td>0.159327</td>\n",
       "      <td>0.150249</td>\n",
       "      <td>0.161043</td>\n",
       "      <td>0.158686</td>\n",
       "      <td>0.162715</td>\n",
       "      <td>0.165677</td>\n",
       "      <td>0.161178</td>\n",
       "      <td>0.165262</td>\n",
       "      <td>0.162972</td>\n",
       "      <td>0.155120</td>\n",
       "      <td>0.150366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ratio_Hippocampus_bl</th>\n",
       "      <td>0.136827</td>\n",
       "      <td>0.132538</td>\n",
       "      <td>0.126803</td>\n",
       "      <td>0.142874</td>\n",
       "      <td>0.130629</td>\n",
       "      <td>0.133816</td>\n",
       "      <td>0.136048</td>\n",
       "      <td>0.142395</td>\n",
       "      <td>0.133748</td>\n",
       "      <td>0.137447</td>\n",
       "      <td>0.151971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hippocampus_reduction_per_year</th>\n",
       "      <td>0.110770</td>\n",
       "      <td>0.113573</td>\n",
       "      <td>0.117683</td>\n",
       "      <td>0.112072</td>\n",
       "      <td>0.116511</td>\n",
       "      <td>0.101235</td>\n",
       "      <td>0.116737</td>\n",
       "      <td>0.117184</td>\n",
       "      <td>0.114376</td>\n",
       "      <td>0.094910</td>\n",
       "      <td>0.103424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ratio_Fusiform_bl</th>\n",
       "      <td>0.107950</td>\n",
       "      <td>0.092536</td>\n",
       "      <td>0.102520</td>\n",
       "      <td>0.118003</td>\n",
       "      <td>0.117854</td>\n",
       "      <td>0.108285</td>\n",
       "      <td>0.101563</td>\n",
       "      <td>0.104112</td>\n",
       "      <td>0.122760</td>\n",
       "      <td>0.103169</td>\n",
       "      <td>0.108697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ventricles_reduction_per_year</th>\n",
       "      <td>0.092217</td>\n",
       "      <td>0.096775</td>\n",
       "      <td>0.106862</td>\n",
       "      <td>0.087076</td>\n",
       "      <td>0.086821</td>\n",
       "      <td>0.093955</td>\n",
       "      <td>0.092730</td>\n",
       "      <td>0.088357</td>\n",
       "      <td>0.098058</td>\n",
       "      <td>0.092347</td>\n",
       "      <td>0.079186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ratio_Entorhinal_bl</th>\n",
       "      <td>0.087345</td>\n",
       "      <td>0.098311</td>\n",
       "      <td>0.083478</td>\n",
       "      <td>0.080500</td>\n",
       "      <td>0.079974</td>\n",
       "      <td>0.088015</td>\n",
       "      <td>0.089990</td>\n",
       "      <td>0.085536</td>\n",
       "      <td>0.076976</td>\n",
       "      <td>0.101989</td>\n",
       "      <td>0.088680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ratio_WholeBrain_bl</th>\n",
       "      <td>0.069830</td>\n",
       "      <td>0.077025</td>\n",
       "      <td>0.067839</td>\n",
       "      <td>0.065892</td>\n",
       "      <td>0.067477</td>\n",
       "      <td>0.069879</td>\n",
       "      <td>0.067455</td>\n",
       "      <td>0.059750</td>\n",
       "      <td>0.064027</td>\n",
       "      <td>0.074751</td>\n",
       "      <td>0.084202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fusiform_reduction_per_year</th>\n",
       "      <td>0.064822</td>\n",
       "      <td>0.068592</td>\n",
       "      <td>0.064572</td>\n",
       "      <td>0.061275</td>\n",
       "      <td>0.066789</td>\n",
       "      <td>0.068943</td>\n",
       "      <td>0.062853</td>\n",
       "      <td>0.065817</td>\n",
       "      <td>0.062617</td>\n",
       "      <td>0.065568</td>\n",
       "      <td>0.061190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entorhinal_reduction_per_year</th>\n",
       "      <td>0.060557</td>\n",
       "      <td>0.057141</td>\n",
       "      <td>0.059594</td>\n",
       "      <td>0.063062</td>\n",
       "      <td>0.060453</td>\n",
       "      <td>0.062120</td>\n",
       "      <td>0.058626</td>\n",
       "      <td>0.066534</td>\n",
       "      <td>0.058880</td>\n",
       "      <td>0.060128</td>\n",
       "      <td>0.059028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wholebrain_reduction_per_year</th>\n",
       "      <td>0.060458</td>\n",
       "      <td>0.062661</td>\n",
       "      <td>0.058545</td>\n",
       "      <td>0.062129</td>\n",
       "      <td>0.058832</td>\n",
       "      <td>0.058018</td>\n",
       "      <td>0.059964</td>\n",
       "      <td>0.055737</td>\n",
       "      <td>0.058003</td>\n",
       "      <td>0.066587</td>\n",
       "      <td>0.064106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ICV_reduction_per_year</th>\n",
       "      <td>0.049898</td>\n",
       "      <td>0.050599</td>\n",
       "      <td>0.051062</td>\n",
       "      <td>0.048432</td>\n",
       "      <td>0.051944</td>\n",
       "      <td>0.050057</td>\n",
       "      <td>0.052857</td>\n",
       "      <td>0.049316</td>\n",
       "      <td>0.047583</td>\n",
       "      <td>0.047983</td>\n",
       "      <td>0.049150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                avg_importance  importance_1  importance_2  \\\n",
       "ratio_Ventricles_bl                   0.159327      0.150249      0.161043   \n",
       "ratio_Hippocampus_bl                  0.136827      0.132538      0.126803   \n",
       "Hippocampus_reduction_per_year        0.110770      0.113573      0.117683   \n",
       "ratio_Fusiform_bl                     0.107950      0.092536      0.102520   \n",
       "Ventricles_reduction_per_year         0.092217      0.096775      0.106862   \n",
       "ratio_Entorhinal_bl                   0.087345      0.098311      0.083478   \n",
       "ratio_WholeBrain_bl                   0.069830      0.077025      0.067839   \n",
       "Fusiform_reduction_per_year           0.064822      0.068592      0.064572   \n",
       "Entorhinal_reduction_per_year         0.060557      0.057141      0.059594   \n",
       "wholebrain_reduction_per_year         0.060458      0.062661      0.058545   \n",
       "ICV_reduction_per_year                0.049898      0.050599      0.051062   \n",
       "\n",
       "                                importance_3  importance_4  importance_5  \\\n",
       "ratio_Ventricles_bl                 0.158686      0.162715      0.165677   \n",
       "ratio_Hippocampus_bl                0.142874      0.130629      0.133816   \n",
       "Hippocampus_reduction_per_year      0.112072      0.116511      0.101235   \n",
       "ratio_Fusiform_bl                   0.118003      0.117854      0.108285   \n",
       "Ventricles_reduction_per_year       0.087076      0.086821      0.093955   \n",
       "ratio_Entorhinal_bl                 0.080500      0.079974      0.088015   \n",
       "ratio_WholeBrain_bl                 0.065892      0.067477      0.069879   \n",
       "Fusiform_reduction_per_year         0.061275      0.066789      0.068943   \n",
       "Entorhinal_reduction_per_year       0.063062      0.060453      0.062120   \n",
       "wholebrain_reduction_per_year       0.062129      0.058832      0.058018   \n",
       "ICV_reduction_per_year              0.048432      0.051944      0.050057   \n",
       "\n",
       "                                importance_6  importance_7  importance_8  \\\n",
       "ratio_Ventricles_bl                 0.161178      0.165262      0.162972   \n",
       "ratio_Hippocampus_bl                0.136048      0.142395      0.133748   \n",
       "Hippocampus_reduction_per_year      0.116737      0.117184      0.114376   \n",
       "ratio_Fusiform_bl                   0.101563      0.104112      0.122760   \n",
       "Ventricles_reduction_per_year       0.092730      0.088357      0.098058   \n",
       "ratio_Entorhinal_bl                 0.089990      0.085536      0.076976   \n",
       "ratio_WholeBrain_bl                 0.067455      0.059750      0.064027   \n",
       "Fusiform_reduction_per_year         0.062853      0.065817      0.062617   \n",
       "Entorhinal_reduction_per_year       0.058626      0.066534      0.058880   \n",
       "wholebrain_reduction_per_year       0.059964      0.055737      0.058003   \n",
       "ICV_reduction_per_year              0.052857      0.049316      0.047583   \n",
       "\n",
       "                                importance_9  importance_10  \n",
       "ratio_Ventricles_bl                 0.155120       0.150366  \n",
       "ratio_Hippocampus_bl                0.137447       0.151971  \n",
       "Hippocampus_reduction_per_year      0.094910       0.103424  \n",
       "ratio_Fusiform_bl                   0.103169       0.108697  \n",
       "Ventricles_reduction_per_year       0.092347       0.079186  \n",
       "ratio_Entorhinal_bl                 0.101989       0.088680  \n",
       "ratio_WholeBrain_bl                 0.074751       0.084202  \n",
       "Fusiform_reduction_per_year         0.065568       0.061190  \n",
       "Entorhinal_reduction_per_year       0.060128       0.059028  \n",
       "wholebrain_reduction_per_year       0.066587       0.064106  \n",
       "ICV_reduction_per_year              0.047983       0.049150  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = usampling_scale_data(df_2g,drop_lst,target)     \n",
    "X = res[0]\n",
    "y = res[3]\n",
    "clf = RandomForestClassifier(n_estimators =90, random_state = 5862)\n",
    "title_label = '10-fold crossvalidation of random forest with (90 trees)'\n",
    "feature_importance(X,y,clf,10,title_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d37f91",
   "metadata": {},
   "source": [
    "- 'MCI-AD': 132, 'MCI-CN': 132, 'MCI-MCI': 132}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03f26e77",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After undersampling data size is 396 ; Resampled dataset shape Counter({'MCI-AD': 132, 'MCI-CN': 132, 'MCI-MCI': 132})\n",
      "\n",
      "4 principle components are needed to explain 90% of the data\n",
      "\n",
      "Output dataframes sequence: X_train,X_test,X_train_scaled,X_test_scaled,X_train_pca,X_test_pca,y_train,y_test\n",
      "- Using original dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, Training set f1-score:0.515, Test set f1-score: 0.431\n",
      "          - saga_L1, Training set f1-score:0.484, Test set f1-score: 0.559\n",
      "          - newton-cg_L2, Training set f1-score:0.515, Test set f1-score: 0.431\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, Training set f1-score:0.566, Test set f1-score: 0.560\n",
      "          - saga_L1, Training set f1-score:0.499, Test set f1-score: 0.505\n",
      "          - newton-cg_L2, Training set f1-score:0.566, Test set f1-score: 0.560\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, Training set f1-score:0.634, Test set f1-score: 0.581\n",
      "          - saga_L1, Training set f1-score:0.635, Test set f1-score: 0.588\n",
      "          - newton-cg_L2, Training set f1-score:0.634, Test set f1-score: 0.581\n",
      "       - C = 1\n",
      "          - lbfgs_L2, Training set f1-score:0.630, Test set f1-score: 0.559\n",
      "          - saga_L1, Training set f1-score:0.623, Test set f1-score: 0.546\n",
      "          - newton-cg_L2, Training set f1-score:0.630, Test set f1-score: 0.559\n",
      "       - C = 10\n",
      "          - lbfgs_L2, Training set f1-score:0.642, Test set f1-score: 0.596\n",
      "          - saga_L1, Training set f1-score:0.645, Test set f1-score: 0.583\n",
      "          - newton-cg_L2, Training set f1-score:0.642, Test set f1-score: 0.596\n",
      "       - C = 100\n",
      "          - lbfgs_L2, Training set f1-score:0.667, Test set f1-score: 0.610\n",
      "          - saga_L1, Training set f1-score:0.645, Test set f1-score: 0.596\n",
      "          - newton-cg_L2, Training set f1-score:0.667, Test set f1-score: 0.600\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, Training set f1-score:0.661, Test set f1-score: 0.592\n",
      "          - saga_L1, Training set f1-score:0.645, Test set f1-score: 0.596\n",
      "          - newton-cg_L2, Training set f1-score:0.661, Test set f1-score: 0.592\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. f1-score on training data: 0.585 f1-score on test data: 0.523\n",
      "          - tree depth: 2.000. f1-score on training data: 0.686 f1-score on test data: 0.631\n",
      "          - tree depth: 3.000. f1-score on training data: 0.659 f1-score on test data: 0.526\n",
      "          - tree depth: 4.000. f1-score on training data: 0.683 f1-score on test data: 0.592\n",
      "          - tree depth: 5.000. f1-score on training data: 0.741 f1-score on test data: 0.596\n",
      "          - tree depth: 6.000. f1-score on training data: 0.789 f1-score on test data: 0.545\n",
      "          - tree depth: 7.000. f1-score on training data: 0.840 f1-score on test data: 0.635\n",
      "          - tree depth: 8.000. f1-score on training data: 0.898 f1-score on test data: 0.608\n",
      "          - tree depth: 9.000. f1-score on training data: 0.923 f1-score on test data: 0.624\n",
      "          - tree depth: 10.000. f1-score on training data: 0.955 f1-score on test data: 0.610\n",
      "          - tree depth: 11.000. f1-score on training data: 0.975 f1-score on test data: 0.636\n",
      "          - tree depth: 12.000. f1-score on training data: 0.981 f1-score on test data: 0.624\n",
      "          - tree depth: 13.000. f1-score on training data: 0.994 f1-score on test data: 0.649\n",
      "          - tree depth: 14.000. f1-score on training data: 1.000 f1-score on test data: 0.636\n",
      "    - Random forest\n",
      "          - 5trees. f1-score on training data: 0.953 f1-score on test data: 0.625\n",
      "          - 10trees. f1-score on training data: 0.991 f1-score on test data: 0.586\n",
      "          - 15trees. f1-score on training data: 1.000 f1-score on test data: 0.559\n",
      "          - 20trees. f1-score on training data: 1.000 f1-score on test data: 0.584\n",
      "          - 25trees. f1-score on training data: 1.000 f1-score on test data: 0.584\n",
      "          - 30trees. f1-score on training data: 1.000 f1-score on test data: 0.585\n",
      "          - 35trees. f1-score on training data: 1.000 f1-score on test data: 0.529\n",
      "          - 40trees. f1-score on training data: 1.000 f1-score on test data: 0.570\n",
      "          - 45trees. f1-score on training data: 1.000 f1-score on test data: 0.558\n",
      "          - 50trees. f1-score on training data: 1.000 f1-score on test data: 0.559\n",
      "          - 55trees. f1-score on training data: 1.000 f1-score on test data: 0.557\n",
      "          - 60trees. f1-score on training data: 1.000 f1-score on test data: 0.555\n",
      "          - 65trees. f1-score on training data: 1.000 f1-score on test data: 0.566\n",
      "          - 70trees. f1-score on training data: 1.000 f1-score on test data: 0.566\n",
      "          - 75trees. f1-score on training data: 1.000 f1-score on test data: 0.567\n",
      "          - 80trees. f1-score on training data: 1.000 f1-score on test data: 0.565\n",
      "          - 85trees. f1-score on training data: 1.000 f1-score on test data: 0.580\n",
      "          - 90trees. f1-score on training data: 1.000 f1-score on test data: 0.554\n",
      "          - 95trees. f1-score on training data: 1.000 f1-score on test data: 0.554\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. f1-score on training data: 0.794 f1-score on test data: 0.614\n",
      "          - hidden layer size[20, 20]. f1-score on training data: 0.766 f1-score on test data: 0.648\n",
      "          - hidden layer size[100, 100]. f1-score on training data: 0.799 f1-score on test data: 0.547\n",
      "          - hidden layer size[50, 50, 50]. f1-score on training data: 0.984 f1-score on test data: 0.551\n",
      "- Using scaled dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, Training set f1-score:0.637, Test set f1-score: 0.613\n",
      "          - saga_L1, Training set f1-score:0.516, Test set f1-score: 0.431\n",
      "          - newton-cg_L2, Training set f1-score:0.637, Test set f1-score: 0.613\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, Training set f1-score:0.614, Test set f1-score: 0.545\n",
      "          - saga_L1, Training set f1-score:0.516, Test set f1-score: 0.431\n",
      "          - newton-cg_L2, Training set f1-score:0.614, Test set f1-score: 0.545\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, Training set f1-score:0.627, Test set f1-score: 0.577\n",
      "          - saga_L1, Training set f1-score:0.607, Test set f1-score: 0.555\n",
      "          - newton-cg_L2, Training set f1-score:0.627, Test set f1-score: 0.577\n",
      "       - C = 1\n",
      "          - lbfgs_L2, Training set f1-score:0.650, Test set f1-score: 0.577\n",
      "          - saga_L1, Training set f1-score:0.647, Test set f1-score: 0.592\n",
      "          - newton-cg_L2, Training set f1-score:0.650, Test set f1-score: 0.577\n",
      "       - C = 10\n",
      "          - lbfgs_L2, Training set f1-score:0.662, Test set f1-score: 0.601\n",
      "          - saga_L1, Training set f1-score:0.661, Test set f1-score: 0.601\n",
      "          - newton-cg_L2, Training set f1-score:0.662, Test set f1-score: 0.601\n",
      "       - C = 100\n",
      "          - lbfgs_L2, Training set f1-score:0.661, Test set f1-score: 0.592\n",
      "          - saga_L1, Training set f1-score:0.664, Test set f1-score: 0.601\n",
      "          - newton-cg_L2, Training set f1-score:0.661, Test set f1-score: 0.592\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, Training set f1-score:0.661, Test set f1-score: 0.592\n",
      "          - saga_L1, Training set f1-score:0.664, Test set f1-score: 0.601\n",
      "          - newton-cg_L2, Training set f1-score:0.661, Test set f1-score: 0.592\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. f1-score on training data: 0.585 f1-score on test data: 0.523\n",
      "          - tree depth: 2.000. f1-score on training data: 0.686 f1-score on test data: 0.631\n",
      "          - tree depth: 3.000. f1-score on training data: 0.659 f1-score on test data: 0.526\n",
      "          - tree depth: 4.000. f1-score on training data: 0.683 f1-score on test data: 0.592\n",
      "          - tree depth: 5.000. f1-score on training data: 0.741 f1-score on test data: 0.596\n",
      "          - tree depth: 6.000. f1-score on training data: 0.789 f1-score on test data: 0.545\n",
      "          - tree depth: 7.000. f1-score on training data: 0.840 f1-score on test data: 0.635\n",
      "          - tree depth: 8.000. f1-score on training data: 0.898 f1-score on test data: 0.608\n",
      "          - tree depth: 9.000. f1-score on training data: 0.923 f1-score on test data: 0.624\n",
      "          - tree depth: 10.000. f1-score on training data: 0.955 f1-score on test data: 0.610\n",
      "          - tree depth: 11.000. f1-score on training data: 0.975 f1-score on test data: 0.636\n",
      "          - tree depth: 12.000. f1-score on training data: 0.981 f1-score on test data: 0.624\n",
      "          - tree depth: 13.000. f1-score on training data: 0.994 f1-score on test data: 0.649\n",
      "          - tree depth: 14.000. f1-score on training data: 1.000 f1-score on test data: 0.636\n",
      "    - Random forest\n",
      "          - 5trees. f1-score on training data: 0.953 f1-score on test data: 0.625\n",
      "          - 10trees. f1-score on training data: 0.991 f1-score on test data: 0.586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          - 15trees. f1-score on training data: 1.000 f1-score on test data: 0.559\n",
      "          - 20trees. f1-score on training data: 1.000 f1-score on test data: 0.584\n",
      "          - 25trees. f1-score on training data: 1.000 f1-score on test data: 0.584\n",
      "          - 30trees. f1-score on training data: 1.000 f1-score on test data: 0.585\n",
      "          - 35trees. f1-score on training data: 1.000 f1-score on test data: 0.529\n",
      "          - 40trees. f1-score on training data: 1.000 f1-score on test data: 0.570\n",
      "          - 45trees. f1-score on training data: 1.000 f1-score on test data: 0.558\n",
      "          - 50trees. f1-score on training data: 1.000 f1-score on test data: 0.559\n",
      "          - 55trees. f1-score on training data: 1.000 f1-score on test data: 0.557\n",
      "          - 60trees. f1-score on training data: 1.000 f1-score on test data: 0.555\n",
      "          - 65trees. f1-score on training data: 1.000 f1-score on test data: 0.566\n",
      "          - 70trees. f1-score on training data: 1.000 f1-score on test data: 0.566\n",
      "          - 75trees. f1-score on training data: 1.000 f1-score on test data: 0.567\n",
      "          - 80trees. f1-score on training data: 1.000 f1-score on test data: 0.565\n",
      "          - 85trees. f1-score on training data: 1.000 f1-score on test data: 0.580\n",
      "          - 90trees. f1-score on training data: 1.000 f1-score on test data: 0.554\n",
      "          - 95trees. f1-score on training data: 1.000 f1-score on test data: 0.554\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. f1-score on training data: 1.000 f1-score on test data: 0.578\n",
      "          - hidden layer size[20, 20]. f1-score on training data: 1.000 f1-score on test data: 0.541\n",
      "          - hidden layer size[100, 100]. f1-score on training data: 1.000 f1-score on test data: 0.534\n",
      "          - hidden layer size[50, 50, 50]. f1-score on training data: 1.000 f1-score on test data: 0.555\n",
      "- Using 4 pca-components:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, Training set f1-score:0.635, Test set f1-score: 0.613\n",
      "          - saga_L1, Training set f1-score:0.516, Test set f1-score: 0.431\n",
      "          - newton-cg_L2, Training set f1-score:0.635, Test set f1-score: 0.613\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, Training set f1-score:0.600, Test set f1-score: 0.538\n",
      "          - saga_L1, Training set f1-score:0.641, Test set f1-score: 0.629\n",
      "          - newton-cg_L2, Training set f1-score:0.600, Test set f1-score: 0.538\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, Training set f1-score:0.623, Test set f1-score: 0.550\n",
      "          - saga_L1, Training set f1-score:0.590, Test set f1-score: 0.534\n",
      "          - newton-cg_L2, Training set f1-score:0.623, Test set f1-score: 0.550\n",
      "       - C = 1\n",
      "          - lbfgs_L2, Training set f1-score:0.615, Test set f1-score: 0.558\n",
      "          - saga_L1, Training set f1-score:0.618, Test set f1-score: 0.558\n",
      "          - newton-cg_L2, Training set f1-score:0.615, Test set f1-score: 0.558\n",
      "       - C = 10\n",
      "          - lbfgs_L2, Training set f1-score:0.614, Test set f1-score: 0.567\n",
      "          - saga_L1, Training set f1-score:0.614, Test set f1-score: 0.567\n",
      "          - newton-cg_L2, Training set f1-score:0.614, Test set f1-score: 0.567\n",
      "       - C = 100\n",
      "          - lbfgs_L2, Training set f1-score:0.621, Test set f1-score: 0.567\n",
      "          - saga_L1, Training set f1-score:0.617, Test set f1-score: 0.567\n",
      "          - newton-cg_L2, Training set f1-score:0.621, Test set f1-score: 0.567\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, Training set f1-score:0.621, Test set f1-score: 0.567\n",
      "          - saga_L1, Training set f1-score:0.617, Test set f1-score: 0.567\n",
      "          - newton-cg_L2, Training set f1-score:0.621, Test set f1-score: 0.567\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. f1-score on training data: 0.650 f1-score on test data: 0.563\n",
      "          - tree depth: 2.000. f1-score on training data: 0.631 f1-score on test data: 0.587\n",
      "          - tree depth: 3.000. f1-score on training data: 0.678 f1-score on test data: 0.550\n",
      "          - tree depth: 4.000. f1-score on training data: 0.715 f1-score on test data: 0.599\n",
      "          - tree depth: 5.000. f1-score on training data: 0.748 f1-score on test data: 0.518\n",
      "          - tree depth: 6.000. f1-score on training data: 0.783 f1-score on test data: 0.509\n",
      "          - tree depth: 7.000. f1-score on training data: 0.802 f1-score on test data: 0.525\n",
      "          - tree depth: 8.000. f1-score on training data: 0.854 f1-score on test data: 0.490\n",
      "          - tree depth: 9.000. f1-score on training data: 0.893 f1-score on test data: 0.492\n",
      "          - tree depth: 10.000. f1-score on training data: 0.928 f1-score on test data: 0.540\n",
      "          - tree depth: 11.000. f1-score on training data: 0.946 f1-score on test data: 0.526\n",
      "          - tree depth: 12.000. f1-score on training data: 0.952 f1-score on test data: 0.536\n",
      "          - tree depth: 13.000. f1-score on training data: 0.959 f1-score on test data: 0.536\n",
      "          - tree depth: 14.000. f1-score on training data: 0.962 f1-score on test data: 0.529\n",
      "    - Random forest\n",
      "          - 5trees. f1-score on training data: 0.950 f1-score on test data: 0.542\n",
      "          - 10trees. f1-score on training data: 0.978 f1-score on test data: 0.539\n",
      "          - 15trees. f1-score on training data: 0.991 f1-score on test data: 0.491\n",
      "          - 20trees. f1-score on training data: 0.997 f1-score on test data: 0.555\n",
      "          - 25trees. f1-score on training data: 1.000 f1-score on test data: 0.504\n",
      "          - 30trees. f1-score on training data: 1.000 f1-score on test data: 0.516\n",
      "          - 35trees. f1-score on training data: 1.000 f1-score on test data: 0.524\n",
      "          - 40trees. f1-score on training data: 1.000 f1-score on test data: 0.526\n",
      "          - 45trees. f1-score on training data: 1.000 f1-score on test data: 0.526\n",
      "          - 50trees. f1-score on training data: 1.000 f1-score on test data: 0.544\n",
      "          - 55trees. f1-score on training data: 1.000 f1-score on test data: 0.533\n",
      "          - 60trees. f1-score on training data: 1.000 f1-score on test data: 0.540\n",
      "          - 65trees. f1-score on training data: 1.000 f1-score on test data: 0.540\n",
      "          - 70trees. f1-score on training data: 1.000 f1-score on test data: 0.526\n",
      "          - 75trees. f1-score on training data: 1.000 f1-score on test data: 0.540\n",
      "          - 80trees. f1-score on training data: 1.000 f1-score on test data: 0.516\n",
      "          - 85trees. f1-score on training data: 1.000 f1-score on test data: 0.529\n",
      "          - 90trees. f1-score on training data: 1.000 f1-score on test data: 0.529\n",
      "          - 95trees. f1-score on training data: 1.000 f1-score on test data: 0.516\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. f1-score on training data: 1.000 f1-score on test data: 0.438\n",
      "          - hidden layer size[20, 20]. f1-score on training data: 0.959 f1-score on test data: 0.501\n",
      "          - hidden layer size[100, 100]. f1-score on training data: 1.000 f1-score on test data: 0.564\n",
      "          - hidden layer size[50, 50, 50]. f1-score on training data: 1.000 f1-score on test data: 0.526\n"
     ]
    }
   ],
   "source": [
    "models(df_3g,drop_lst,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2de15359",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After undersampling data size is 396 ; Resampled dataset shape Counter({'MCI-AD': 132, 'MCI-CN': 132, 'MCI-MCI': 132})\n",
      "\n",
      "4 principle components are needed to explain 90% of the data\n",
      "\n",
      "- Using original dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.417\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.167\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.417\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.467\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.165\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.467\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.538\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.394\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.538\n",
      "       - C = 1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.584\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.596\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.584\n",
      "       - C = 10\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.607\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.605\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.607\n",
      "       - C = 100\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.597\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.602\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.597\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.607\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.602\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.607\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. average weighted f1-score of 10-cross validation:0.420\n",
      "          - tree depth: 2.000. average weighted f1-score of 10-cross validation:0.501\n",
      "          - tree depth: 3.000. average weighted f1-score of 10-cross validation:0.527\n",
      "          - tree depth: 4.000. average weighted f1-score of 10-cross validation:0.552\n",
      "          - tree depth: 5.000. average weighted f1-score of 10-cross validation:0.561\n",
      "          - tree depth: 6.000. average weighted f1-score of 10-cross validation:0.580\n",
      "          - tree depth: 7.000. average weighted f1-score of 10-cross validation:0.564\n",
      "          - tree depth: 8.000. average weighted f1-score of 10-cross validation:0.578\n",
      "          - tree depth: 9.000. average weighted f1-score of 10-cross validation:0.584\n",
      "          - tree depth: 10.000. average weighted f1-score of 10-cross validation:0.568\n",
      "          - tree depth: 11.000. average weighted f1-score of 10-cross validation:0.573\n",
      "          - tree depth: 12.000. average weighted f1-score of 10-cross validation:0.568\n",
      "          - tree depth: 13.000. average weighted f1-score of 10-cross validation:0.570\n",
      "          - tree depth: 14.000. average weighted f1-score of 10-cross validation:0.573\n",
      "    - Random forest\n",
      "          - 5trees. average weighted f1-score of 10-cross validation:0.584\n",
      "          - 10trees. average weighted f1-score of 10-cross validation:0.597\n",
      "          - 15trees. average weighted f1-score of 10-cross validation:0.590\n",
      "          - 20trees. average weighted f1-score of 10-cross validation:0.584\n",
      "          - 25trees. average weighted f1-score of 10-cross validation:0.609\n",
      "          - 30trees. average weighted f1-score of 10-cross validation:0.627\n",
      "          - 35trees. average weighted f1-score of 10-cross validation:0.620\n",
      "          - 40trees. average weighted f1-score of 10-cross validation:0.613\n",
      "          - 45trees. average weighted f1-score of 10-cross validation:0.609\n",
      "          - 50trees. average weighted f1-score of 10-cross validation:0.618\n",
      "          - 55trees. average weighted f1-score of 10-cross validation:0.621\n",
      "          - 60trees. average weighted f1-score of 10-cross validation:0.610\n",
      "          - 65trees. average weighted f1-score of 10-cross validation:0.618\n",
      "          - 70trees. average weighted f1-score of 10-cross validation:0.621\n",
      "          - 75trees. average weighted f1-score of 10-cross validation:0.610\n",
      "          - 80trees. average weighted f1-score of 10-cross validation:0.612\n",
      "          - 85trees. average weighted f1-score of 10-cross validation:0.606\n",
      "          - 90trees. average weighted f1-score of 10-cross validation:0.605\n",
      "          - 95trees. average weighted f1-score of 10-cross validation:0.597\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. average weighted f1-score of 10-cross validation:0.571\n",
      "          - hidden layer size[20, 20]. average weighted f1-score of 10-cross validation:0.592\n",
      "- Using scaled dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.529\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.165\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.529\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.564\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.307\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.564\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.578\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.563\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.578\n",
      "       - C = 1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.598\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.593\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.598\n",
      "       - C = 10\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.597\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.594\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.597\n",
      "       - C = 100\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.607\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.597\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.607\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.607\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.600\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.607\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. average weighted f1-score of 10-cross validation:0.420\n",
      "          - tree depth: 2.000. average weighted f1-score of 10-cross validation:0.501\n",
      "          - tree depth: 3.000. average weighted f1-score of 10-cross validation:0.527\n",
      "          - tree depth: 4.000. average weighted f1-score of 10-cross validation:0.552\n",
      "          - tree depth: 5.000. average weighted f1-score of 10-cross validation:0.561\n",
      "          - tree depth: 6.000. average weighted f1-score of 10-cross validation:0.580\n",
      "          - tree depth: 7.000. average weighted f1-score of 10-cross validation:0.564\n",
      "          - tree depth: 8.000. average weighted f1-score of 10-cross validation:0.578\n",
      "          - tree depth: 9.000. average weighted f1-score of 10-cross validation:0.584\n",
      "          - tree depth: 10.000. average weighted f1-score of 10-cross validation:0.568\n",
      "          - tree depth: 11.000. average weighted f1-score of 10-cross validation:0.573\n",
      "          - tree depth: 12.000. average weighted f1-score of 10-cross validation:0.568\n",
      "          - tree depth: 13.000. average weighted f1-score of 10-cross validation:0.570\n",
      "          - tree depth: 14.000. average weighted f1-score of 10-cross validation:0.573\n",
      "    - Random forest\n",
      "          - 5trees. average weighted f1-score of 10-cross validation:0.584\n",
      "          - 10trees. average weighted f1-score of 10-cross validation:0.597\n",
      "          - 15trees. average weighted f1-score of 10-cross validation:0.590\n",
      "          - 20trees. average weighted f1-score of 10-cross validation:0.584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          - 25trees. average weighted f1-score of 10-cross validation:0.609\n",
      "          - 30trees. average weighted f1-score of 10-cross validation:0.627\n",
      "          - 35trees. average weighted f1-score of 10-cross validation:0.620\n",
      "          - 40trees. average weighted f1-score of 10-cross validation:0.613\n",
      "          - 45trees. average weighted f1-score of 10-cross validation:0.609\n",
      "          - 50trees. average weighted f1-score of 10-cross validation:0.618\n",
      "          - 55trees. average weighted f1-score of 10-cross validation:0.621\n",
      "          - 60trees. average weighted f1-score of 10-cross validation:0.610\n",
      "          - 65trees. average weighted f1-score of 10-cross validation:0.618\n",
      "          - 70trees. average weighted f1-score of 10-cross validation:0.621\n",
      "          - 75trees. average weighted f1-score of 10-cross validation:0.610\n",
      "          - 80trees. average weighted f1-score of 10-cross validation:0.612\n",
      "          - 85trees. average weighted f1-score of 10-cross validation:0.606\n",
      "          - 90trees. average weighted f1-score of 10-cross validation:0.605\n",
      "          - 95trees. average weighted f1-score of 10-cross validation:0.597\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. average weighted f1-score of 10-cross validation:0.546\n",
      "          - hidden layer size[20, 20]. average weighted f1-score of 10-cross validation:0.572\n",
      "- Using 4 pca-components:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.546\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.167\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.546\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.582\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.423\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.582\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.587\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.574\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.587\n",
      "       - C = 1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.595\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.592\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.595\n",
      "       - C = 10\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.592\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.593\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.592\n",
      "       - C = 100\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.592\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.592\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.592\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.592\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.592\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.592\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. average weighted f1-score of 10-cross validation:0.434\n",
      "          - tree depth: 2.000. average weighted f1-score of 10-cross validation:0.535\n",
      "          - tree depth: 3.000. average weighted f1-score of 10-cross validation:0.507\n",
      "          - tree depth: 4.000. average weighted f1-score of 10-cross validation:0.552\n",
      "          - tree depth: 5.000. average weighted f1-score of 10-cross validation:0.541\n",
      "          - tree depth: 6.000. average weighted f1-score of 10-cross validation:0.531\n",
      "          - tree depth: 7.000. average weighted f1-score of 10-cross validation:0.522\n",
      "          - tree depth: 8.000. average weighted f1-score of 10-cross validation:0.530\n",
      "          - tree depth: 9.000. average weighted f1-score of 10-cross validation:0.523\n",
      "          - tree depth: 10.000. average weighted f1-score of 10-cross validation:0.521\n",
      "          - tree depth: 11.000. average weighted f1-score of 10-cross validation:0.500\n",
      "          - tree depth: 12.000. average weighted f1-score of 10-cross validation:0.513\n",
      "          - tree depth: 13.000. average weighted f1-score of 10-cross validation:0.499\n",
      "          - tree depth: 14.000. average weighted f1-score of 10-cross validation:0.505\n",
      "    - Random forest\n",
      "          - 5trees. average weighted f1-score of 10-cross validation:0.526\n",
      "          - 10trees. average weighted f1-score of 10-cross validation:0.559\n",
      "          - 15trees. average weighted f1-score of 10-cross validation:0.540\n",
      "          - 20trees. average weighted f1-score of 10-cross validation:0.550\n",
      "          - 25trees. average weighted f1-score of 10-cross validation:0.531\n",
      "          - 30trees. average weighted f1-score of 10-cross validation:0.528\n",
      "          - 35trees. average weighted f1-score of 10-cross validation:0.535\n",
      "          - 40trees. average weighted f1-score of 10-cross validation:0.532\n",
      "          - 45trees. average weighted f1-score of 10-cross validation:0.534\n",
      "          - 50trees. average weighted f1-score of 10-cross validation:0.535\n",
      "          - 55trees. average weighted f1-score of 10-cross validation:0.536\n",
      "          - 60trees. average weighted f1-score of 10-cross validation:0.532\n",
      "          - 65trees. average weighted f1-score of 10-cross validation:0.544\n",
      "          - 70trees. average weighted f1-score of 10-cross validation:0.539\n",
      "          - 75trees. average weighted f1-score of 10-cross validation:0.537\n",
      "          - 80trees. average weighted f1-score of 10-cross validation:0.535\n",
      "          - 85trees. average weighted f1-score of 10-cross validation:0.533\n",
      "          - 90trees. average weighted f1-score of 10-cross validation:0.546\n",
      "          - 95trees. average weighted f1-score of 10-cross validation:0.545\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. average weighted f1-score of 10-cross validation:0.514\n",
      "          - hidden layer size[20, 20]. average weighted f1-score of 10-cross validation:0.542\n"
     ]
    }
   ],
   "source": [
    "cv_models(df_3g,drop_lst,target,k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f6502c",
   "metadata": {},
   "source": [
    "- original or scaled data: random forest 30trees. average weighted f1-score of 10-cross validation:0.627"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3aa40ab3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After undersampling data size is 396 ; Resampled dataset shape Counter({'MCI-AD': 132, 'MCI-CN': 132, 'MCI-MCI': 132})\n",
      "\n",
      "4 principle components are needed to explain 90% of the data\n",
      "\n",
      "Features sorted by their score for each estimator \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_importance</th>\n",
       "      <th>importance_1</th>\n",
       "      <th>importance_2</th>\n",
       "      <th>importance_3</th>\n",
       "      <th>importance_4</th>\n",
       "      <th>importance_5</th>\n",
       "      <th>importance_6</th>\n",
       "      <th>importance_7</th>\n",
       "      <th>importance_8</th>\n",
       "      <th>importance_9</th>\n",
       "      <th>importance_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ratio_Hippocampus_bl</th>\n",
       "      <td>0.124549</td>\n",
       "      <td>0.122110</td>\n",
       "      <td>0.116214</td>\n",
       "      <td>0.131494</td>\n",
       "      <td>0.136193</td>\n",
       "      <td>0.139762</td>\n",
       "      <td>0.118202</td>\n",
       "      <td>0.120004</td>\n",
       "      <td>0.102687</td>\n",
       "      <td>0.130473</td>\n",
       "      <td>0.128354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hippocampus_reduction_per_year</th>\n",
       "      <td>0.108513</td>\n",
       "      <td>0.085286</td>\n",
       "      <td>0.107931</td>\n",
       "      <td>0.101582</td>\n",
       "      <td>0.109126</td>\n",
       "      <td>0.109992</td>\n",
       "      <td>0.117168</td>\n",
       "      <td>0.115306</td>\n",
       "      <td>0.114860</td>\n",
       "      <td>0.106536</td>\n",
       "      <td>0.117341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ratio_Entorhinal_bl</th>\n",
       "      <td>0.106374</td>\n",
       "      <td>0.114105</td>\n",
       "      <td>0.118017</td>\n",
       "      <td>0.112337</td>\n",
       "      <td>0.115996</td>\n",
       "      <td>0.098517</td>\n",
       "      <td>0.107383</td>\n",
       "      <td>0.088107</td>\n",
       "      <td>0.112095</td>\n",
       "      <td>0.109109</td>\n",
       "      <td>0.088072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ratio_Fusiform_bl</th>\n",
       "      <td>0.102563</td>\n",
       "      <td>0.118434</td>\n",
       "      <td>0.098382</td>\n",
       "      <td>0.082986</td>\n",
       "      <td>0.094712</td>\n",
       "      <td>0.094583</td>\n",
       "      <td>0.094412</td>\n",
       "      <td>0.103554</td>\n",
       "      <td>0.108425</td>\n",
       "      <td>0.109221</td>\n",
       "      <td>0.120918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ratio_Ventricles_bl</th>\n",
       "      <td>0.094203</td>\n",
       "      <td>0.093300</td>\n",
       "      <td>0.082849</td>\n",
       "      <td>0.100494</td>\n",
       "      <td>0.096691</td>\n",
       "      <td>0.092296</td>\n",
       "      <td>0.103198</td>\n",
       "      <td>0.105678</td>\n",
       "      <td>0.095929</td>\n",
       "      <td>0.082769</td>\n",
       "      <td>0.088828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ratio_WholeBrain_bl</th>\n",
       "      <td>0.087327</td>\n",
       "      <td>0.091245</td>\n",
       "      <td>0.106766</td>\n",
       "      <td>0.090611</td>\n",
       "      <td>0.082742</td>\n",
       "      <td>0.090013</td>\n",
       "      <td>0.075761</td>\n",
       "      <td>0.085319</td>\n",
       "      <td>0.082153</td>\n",
       "      <td>0.083304</td>\n",
       "      <td>0.085357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ventricles_reduction_per_year</th>\n",
       "      <td>0.082279</td>\n",
       "      <td>0.068089</td>\n",
       "      <td>0.075398</td>\n",
       "      <td>0.072277</td>\n",
       "      <td>0.079202</td>\n",
       "      <td>0.088894</td>\n",
       "      <td>0.086707</td>\n",
       "      <td>0.084244</td>\n",
       "      <td>0.086719</td>\n",
       "      <td>0.087293</td>\n",
       "      <td>0.093967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entorhinal_reduction_per_year</th>\n",
       "      <td>0.081048</td>\n",
       "      <td>0.087413</td>\n",
       "      <td>0.079996</td>\n",
       "      <td>0.086204</td>\n",
       "      <td>0.086039</td>\n",
       "      <td>0.077916</td>\n",
       "      <td>0.085950</td>\n",
       "      <td>0.085021</td>\n",
       "      <td>0.084262</td>\n",
       "      <td>0.075499</td>\n",
       "      <td>0.062179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wholebrain_reduction_per_year</th>\n",
       "      <td>0.077152</td>\n",
       "      <td>0.075091</td>\n",
       "      <td>0.069557</td>\n",
       "      <td>0.085270</td>\n",
       "      <td>0.069682</td>\n",
       "      <td>0.071551</td>\n",
       "      <td>0.077238</td>\n",
       "      <td>0.081795</td>\n",
       "      <td>0.075465</td>\n",
       "      <td>0.078956</td>\n",
       "      <td>0.086913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ICV_reduction_per_year</th>\n",
       "      <td>0.070679</td>\n",
       "      <td>0.080197</td>\n",
       "      <td>0.070352</td>\n",
       "      <td>0.068340</td>\n",
       "      <td>0.078641</td>\n",
       "      <td>0.073645</td>\n",
       "      <td>0.068021</td>\n",
       "      <td>0.064909</td>\n",
       "      <td>0.068226</td>\n",
       "      <td>0.065537</td>\n",
       "      <td>0.068926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fusiform_reduction_per_year</th>\n",
       "      <td>0.065313</td>\n",
       "      <td>0.064730</td>\n",
       "      <td>0.074537</td>\n",
       "      <td>0.068405</td>\n",
       "      <td>0.050976</td>\n",
       "      <td>0.062830</td>\n",
       "      <td>0.065959</td>\n",
       "      <td>0.066064</td>\n",
       "      <td>0.069178</td>\n",
       "      <td>0.071304</td>\n",
       "      <td>0.059145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                avg_importance  importance_1  importance_2  \\\n",
       "ratio_Hippocampus_bl                  0.124549      0.122110      0.116214   \n",
       "Hippocampus_reduction_per_year        0.108513      0.085286      0.107931   \n",
       "ratio_Entorhinal_bl                   0.106374      0.114105      0.118017   \n",
       "ratio_Fusiform_bl                     0.102563      0.118434      0.098382   \n",
       "ratio_Ventricles_bl                   0.094203      0.093300      0.082849   \n",
       "ratio_WholeBrain_bl                   0.087327      0.091245      0.106766   \n",
       "Ventricles_reduction_per_year         0.082279      0.068089      0.075398   \n",
       "Entorhinal_reduction_per_year         0.081048      0.087413      0.079996   \n",
       "wholebrain_reduction_per_year         0.077152      0.075091      0.069557   \n",
       "ICV_reduction_per_year                0.070679      0.080197      0.070352   \n",
       "Fusiform_reduction_per_year           0.065313      0.064730      0.074537   \n",
       "\n",
       "                                importance_3  importance_4  importance_5  \\\n",
       "ratio_Hippocampus_bl                0.131494      0.136193      0.139762   \n",
       "Hippocampus_reduction_per_year      0.101582      0.109126      0.109992   \n",
       "ratio_Entorhinal_bl                 0.112337      0.115996      0.098517   \n",
       "ratio_Fusiform_bl                   0.082986      0.094712      0.094583   \n",
       "ratio_Ventricles_bl                 0.100494      0.096691      0.092296   \n",
       "ratio_WholeBrain_bl                 0.090611      0.082742      0.090013   \n",
       "Ventricles_reduction_per_year       0.072277      0.079202      0.088894   \n",
       "Entorhinal_reduction_per_year       0.086204      0.086039      0.077916   \n",
       "wholebrain_reduction_per_year       0.085270      0.069682      0.071551   \n",
       "ICV_reduction_per_year              0.068340      0.078641      0.073645   \n",
       "Fusiform_reduction_per_year         0.068405      0.050976      0.062830   \n",
       "\n",
       "                                importance_6  importance_7  importance_8  \\\n",
       "ratio_Hippocampus_bl                0.118202      0.120004      0.102687   \n",
       "Hippocampus_reduction_per_year      0.117168      0.115306      0.114860   \n",
       "ratio_Entorhinal_bl                 0.107383      0.088107      0.112095   \n",
       "ratio_Fusiform_bl                   0.094412      0.103554      0.108425   \n",
       "ratio_Ventricles_bl                 0.103198      0.105678      0.095929   \n",
       "ratio_WholeBrain_bl                 0.075761      0.085319      0.082153   \n",
       "Ventricles_reduction_per_year       0.086707      0.084244      0.086719   \n",
       "Entorhinal_reduction_per_year       0.085950      0.085021      0.084262   \n",
       "wholebrain_reduction_per_year       0.077238      0.081795      0.075465   \n",
       "ICV_reduction_per_year              0.068021      0.064909      0.068226   \n",
       "Fusiform_reduction_per_year         0.065959      0.066064      0.069178   \n",
       "\n",
       "                                importance_9  importance_10  \n",
       "ratio_Hippocampus_bl                0.130473       0.128354  \n",
       "Hippocampus_reduction_per_year      0.106536       0.117341  \n",
       "ratio_Entorhinal_bl                 0.109109       0.088072  \n",
       "ratio_Fusiform_bl                   0.109221       0.120918  \n",
       "ratio_Ventricles_bl                 0.082769       0.088828  \n",
       "ratio_WholeBrain_bl                 0.083304       0.085357  \n",
       "Ventricles_reduction_per_year       0.087293       0.093967  \n",
       "Entorhinal_reduction_per_year       0.075499       0.062179  \n",
       "wholebrain_reduction_per_year       0.078956       0.086913  \n",
       "ICV_reduction_per_year              0.065537       0.068926  \n",
       "Fusiform_reduction_per_year         0.071304       0.059145  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAw4AAAHgCAYAAAAMkzqWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAC34UlEQVR4nOydd7gdRfnHP28ahDR6aELoBELvECCh9yIKhA4RFJAmItHgj2YQRFBURNEgTUIHaYaa0KQ3AQMiHRTpgURKSN7fH+8sd+/ec+85t55z7v1+nmefc3Z2dnfazsw788475u4IIYQQQgghREv0qnYAhBBCCCGEELWPBAchhBBCCCFEWSQ4CCGEEEIIIcoiwUEIIYQQQghRFgkOQgghhBBCiLJIcBBCCCGEEEKURYJDN8LMDjQzN7NR1Q6L6BzMbLSZPWRmn6S8PrDaYSpiZvOY2a/M7HUzm21mr7bhGVMrvc/MRtVqWtQDKe0uKri9amZTK7y/0+qdeszbjij/1cTMLjKzmrXTbmZrmNldZvZhKhsnVztMtUSp77kj/Zd51pVm9kBHPKunYWa7mtkXZrZ8tcNSjroQHHKNR3PHBp38/mPqqeHqTijtGzCz+YDrgAHAccB+wL0t+F/UzCaY2WQze7eSBsLMtjezv5nZTDP7wMyuNrOlWxnUE4AjgSuBA4FjWnm/6EGkjuDJZjas2mHpIFT+Owkz6wNcCywP/JioA6+raqDKkDqEJ1c5DCeb2a6d/I6NgD2AEwvux6WBoP+Y2efpd4qZ7dbMc3qZ2bFm9ryZfWZmb5jZ2WY2oMJwzJviO6q9cepK3P0G4BngzCoHpSx9qh2AVjIJuLWE+786+b3HAK8CF3Xye9rLpcAVwBfVDkgHcgz1kfZdwbrAvMBYd6+ksVwR+BHwBvAosF1Lns3s68A1wNPA8cAQIv0fMLN13P3fFYZzK+AZdz++Qv+i9lgR6KpR5zWAk4CpxLee516gPzCri8LSEaj8dx7LpOM4d/9NtQNTIbsCBwAnd9H7+gOzC24nARcDN3Tie08CnnL3KQX39Yjv+lbgPWB+4JvAdWb2f+5+WsH/L4CjgOuBs4Hh6XxNM9vS3eeUCce8KSwQdUo9cS5wsZmt4u7PVTswzVFvgsMT7n5ZtQPRkZhZX6C3u3/W3me5+2yaVhh1h5n1BuZy9/9VOyw1xiLp94MK/T8OLOzu75rZgsC7zXlM5fDXhJCxibvPSO5/Tc85GTi0FeF8vUK/dYOZDXL3T6odjq7A3T+vdhgAUieh3XVjF9Pu8t+TyloraW0dWBFmZsCArN6rZzqiL9FazGw5QmA+rkR49izh/5dEu/IDMzs99V0ws1WI2brr3H33nP9XgF8BewGXd0L4a+V7uw44H/gOkQ61ibvX/AGMIka/vl+B3z2B+4FPgP8BDwPfaMbfjUQF/zkhCd8ArFbw580cw3LXLyrx/APTtVE5t5OT2yrAOcCbREd/VLo+FzFC/BzRWH4E3ASsWWE6lXpn5rYF8H/Aa8CnKV02SH42S2k2E/gP8OMSz36VkN7XAu4GZhCV98VE57Tof0HgPKIj+kX6PQ9YoJkwb0lMPb9EjC5m7i2l/daEOsDLKU4fAbcDm5UIz9QUh8WImasPU3xvA1Yo4b8f8APgqVSOpgOPAd8t+BtCTC3+iyhH76bnL9OK8r0aMbryfsr3f6R39y6kf5O0aMU7FqSZspqub5mul8r7u1L8+1ZY/orHyTk/uwIPpPIzI/3fpbn8KuG+C/BkSqc3gFOJBsuBAytMi0WIRujllGfvAHcAW5UoL8sQszAf5NO7kjxL/r4GXEh8d9m7/gYckPNjxMzO34l662PgBWBilubE9/pfoE+J+GyT4n9MOu8FjCdG698mvr/XiQZpgRL3NykXKe5TS/j9FvB8isu/gKOBg2ha7yxGjBY+RXxrWRqdQONyfXIzZeaidH1Uqbwl1PV+StQXn6d4XgIsVfD31f0pnM8l/68BP2jF99Mnhf0fKS7vp/xftTXlv8Rzh2V+iDbpcaIuy+K/EvDbFO6sTXscOKTEs7K0XBE4nWhfPidmELcv4X9u4Czg3+mdjxB16kWUqFuATYnvZHry/wQx+9lcXTsspdFHqQxcBAwkyuePgFdSWj4BbFxBHkxtJn2z9qAtZeKIlKef07ieqrQfsQNwD9F/+JT4zq4jtSkthLnZuiql02fA3Dm3jdJ9HwC9cu7bJfc9Sn3PNJSvZtuOzD+wYYrLzBSfPwIDK/w+xqXnrNiKb+pWYE4hnj9Jz9mkRFmdCdxa5pmjKB3fVyv53pKfLYl+xEcpH/4OfKeZ961DlPH3Uhl6gah7+xT8rQJcDbxFQ9mcAuxQ4pmTgbcrTcdqHPU24zBPGjnN87knSdHMfkJk2mSiEzoH2A242sy+6+7n5e77LvERXkBk4rLEiOoDZraWu7+Y/O1HTJ29B0zI3d/s6G0F/JkorGcThfg/acR3MlFBXAr8huiUHpLCtKm7P9aOd54B9CamwvoRIwO3mdkBRAflghSuPYBTzewVbzq7swTRibyW6EytBRwMrGNm63qaITCzIUTnaDmi0/QEsCZwGLC5ma3nTaX7nwN9gT/Q0HEql/YHEtOelxCN5OJEx+YuMxvt7vcV3jGA6Ew9RDRcSxMdn7+Y2QhvGPXoRwgUo4gK5DKiAlkV+DqRN/l4Lpni+RywKHA48HBS73mNFjCzdYjKehYhWL0N7EQII6sD+ySvxxCNxKFEp2BaS89tA+um3wdLXHsI2BxYgYhjc9xL6Tz7O4CZHU7E8XkaGogDgRvM7NvufkFLAUw6sdcSnZJTgS+JzuCOLcas8TOGEcLKUKLcPEaUiw2IBuOOnPeBRN48QNQrC6dnVJRnSR/7DqJc/hb4J/FNrwZsQgjdEDrBpxKDBL8jBhOWBnYmBhNmJb/nAdsCNxeitX9Ki2wkrh+hanYt8BeiwV0XGAuMNLO13b3V6oxmdgyRt08T38886T3vlPC+GvGtXE905PoS5fcMQhj7dvJ3HfHNFMv1Sy2Eow/xfW5M1ENnEzrvhwFbp+/uzcJt3yHyfCLRIdgXONPM3nT3SkYws7rxDkIAW4TodD5oZpu4+5OUKf9l2JVQxzifKAMfJ/dRRIf9ZqKjPYBQ87jAzBZ095+WeNbFRJn5OVEWjiG+sRXc/dWcv0npvTcR6bkskR+vFB9oZjsRefk2kd6fEKO/fzSzZdx9fOGWAcQA071Ep3Jdoq2YmxC61idmOPsC3wduMrOlSrQLeSYQ3+KPiPYqq9/fbWOZOAZYgGhz3iYGIiruR5jZZsTg4zOEwPIRITBvSbR9/0xh7kV87/vl3v23FuJ5N6HatDHR3kLUv3OA+Yi29PGcuxOd0FK8m957KZFezdWxaxBl7E9EPTKKqC/mUNlM82aEQPnP5jyY2fxEH2RBogxvC0zxxjMk66Z3PpK/190/M7OnaGinmmMacCzxDV5Pw/qX4kzSrpT43szs0HT+EJF3M4mBqfPNbFnPqR+a2fbpHf8iytsHhPB1KpGe30z+FiDylPTs11IarEN8B7cUwvYgsI2ZreTuz5eJb3WotuRSyUHzUqQDVyQ/a6Xz00vcfwNRMAbl3AaU8DeckAZ/W3B/lRKjb+naV9J9wf1Amp9xmEpTifTYdG2bgvtgYhSj5PsreGfm9gTQL+e+c3L/Elg3596PmHV4sEQaOGlUs0S4x+XcJiS3wwt+j0jup5UI3wvAPCXi1FLal8rDoUSjfWvBfWp6zw8K7scX050YOW6uLOVHe84lBMDVC36WSuWtSbko8bwHUh6slnMz4KoUhi1ayt9WfEPlZhx+na4PL3Ht8HRt6wrf1STPiAZvBlHJDi6U75eIjsi8hfx6NXfeO30H7wEL5tyHEBWxU8GMAzHK1eQ7K5G3WXn5SVvzjOg8NylzJZ73BPCPMn7mJ+qmqwrug4jG7cZCWPqXeMZYCqOTyb1JuSjmIaE3PJMYnZ0n575EytdivdMfsBJhuJQQjBatpFxTYsaBGExx4GcFvzsk90tL3P/vQvmah+hUPVh8Z4kwZDNaV+bjlPL3S+C+cuW/hWcPS8+eRelvr1Qd1yuVz0azgDS0LzcXwrlucv9pzm3rZvJ9V5qOSPcmvrGPgMVy7v2Ib2E2sHyJb+f4wrOvIzqFjxXCnbVF364gvZqUh3aUiQ8ozJbTin4EoTXgxWeUuO+ifHpWEMfF03Mn5NzuTu+fTq4+IQSIv1fwPbdU93vKlw0K7rekcll21iGVjyfK+HkvK1vpuVcDCxX8PAP8t5n7s/q1X5n3DKOZmT5a+N6IAYzPgMtL3HduKufLpvO5CWHzXprvy40qlO89Wgp37v59k//dKy0zXX3UhVWlHBcQlXj++Em6tg+R2Beb2YL5gxgVGERIgwC4+0wI3UYzG5zTAX+BkAI7k1+6+5cFt32JkdjHC2HvR4xyjTSz/u145/neeJQxG615yN0fzRyTn0eI0ZoiHxMSep7fJve8hYTdiLQsjm78nqg8SllTON9buaYhy0MAMxuYJPvZxLRyqTycQ6io5MlGAvLx3YeYWj+1xDvnpPdZ8ncv8FYhz2YSIxZbtxR+M1uYmGG60d2/GpX0qD1OT6clLU90AvOk31K67Z8V/LSFrYhRyF+5ezaaSvr/a2J0f8sW7l+bUPv5k7u/l7t/OjGKU5Y04rUtMNndbyte99KL7n5eeEZr8mx6+h2d7muO6cDiZjayOQ/u/gExMryzmc2bu/QNIl8uzvl1d/80hbd3sjKyIA1lvS3129bpPeflv1OPUdw/lwjvpylNMLN+ZjZ/CsNtRMd3nTaEIWM34ltuNNru7rcQqlG7mFmxbfuTu3+U8/s/4hutxPRhlp8TsjilZ/yd6KSPNLOFWhmHIre4e5NZxEIdN3eq4+YnZkIHE6pMRc4thPNRQjDPx3XX9HtW4X03EG1gnrVJs6qeM5CQ2oqziPzcpXDPbOK7znMfIdT+zt1nFdyhsrxojraUiUvcvThb1pp+RPZ9755mPDoEd38LeJGYTcDM5k7vvJ1ob7ZI7vMSI9t3l3pOK3nQ3R8quN1NqOgNq+D+hSi/7uTrhFrlwUSfpj9RhvPMQ+k2CDqmHcoo9b19g5jhnVgi728iyvkWye9WxCDln4B5C34zAz5Z+5+Vk+3MrBjfUryffltqM6pKvakqvejudzZzbThRKbU0tTM0+2NmawKnEaMPRTNfr7QjjJVQajpvOPEhtaQCtSBpOrUNvJw/cfcPo+9bMq4fElO4TZ7hhUWT7v65mb1MqB9kLA08VhSO3P1LM3uBGNUp0uwUZ3OY2bLE7MY2xIhoo9eVuOXf3nThWPaR5uO7PGEdoqVFZgule7am+TwrZ/0hM3NaSv3nH+n+ZUpc6wyyzuBcJa7NnfeTBNghBT/Ts85qM7QU12fTb0txza6V+r7/0cJ9eZYj6ognK/T/br6zmag4z9z9NTObAPyQUEd8ilA9uDovrBOqFzcA95nZv4kR21uAawrC/iXA7oTKTCaU7098r43Ul8xsD0IdcU1CHSTPfM1FuAValf6pIzUuhS9L9/aGIWNp4lv+sMS154jO1II0VqF6uYTf9yldz5V63xxKqwc+S3Sal6Z96qsl6z8zG0jMJOxBCM5FSqVjqbh+QOO4LkPEqdR7pxHrJDLa8u3+p0T9meVXozYn1xZVkhfN0ZYy0Vw7XGk/4jdE3v+WUHu7n1BvmuTu7SkLEJ32sWY2iJgxmju5zQX8JKnTjiI6sx0hODT3fUBl+eI0/cYbe3DPmw7/k5lNAu43s5Vz+fY/mu8wN2qH2klzeQ/QXB8TGvI+83thOb/ufo+ZXULMrO5jZo+md1zp7qXariwdS/VhaoJ6ExxawoiE3o7mLQs9B2BmSxKS+8eE8PACMUrswC+J0c/20lLalir4RkzTfa+F+9pTGTWXJq2xwtRcQW6xwqiQVlUGqUG9lxD6fkmk3SdEY/hD0mhNgZbiWoxDuY82838nbbe73BHp1lFkI4mL07SDtHj6fSv97kmMtOQ5iJZN5rY3ri1VppU+u7UVcnPfacW4+4lmdiGhMrEJsQbneDP7mbufkPw8mITgbYDR6dgbONHMRqbZBoiRrHeJzvgFqR7bjBjB/UqgtzCreyUxc3g0MdjwGaFyMpm27d/T2vQ/h4a9DCYQHbZZxKDBmW0MQ0vvK0d7rM11xXfaXP13ObGG5wKivvuAUI/anlCJKJWOzcXVmvnfkr9yfpujpfSuJHytpS33Nvd9V9SPcPf3zWxd4rveiliL8gvgFDPb3t1LrRerlLuJdUCbErMN/3b3581sLmLEfQOijZtNrLdqL61pG0vxLjET1houJtbJfJ1YewTRDq1sZnMVBymJdug9b8P6rBK0VLfvT6hrl+Llgt/jiRmtUuRn5w4ws7OI73YkMagz3syO8aZmhbN0bK/w2Wl0J8HhRUIN4fVSU74FdiOEg529YHM4TQUXC2xLHY0PKP3BtHak+EViFPvuZlQmaoFlzaxf/sNNFdnSNB6heRlY0cz65Gcd0ijkCpQe3WiO5tJ+C2Ih2sHu3qgTmxa3tYd/AsObqbwy3iV0fge3MAtWjiwdVilxbSWiU9CatGoP2Qj4hjQdcdmAELKzUZrbiIYyTzmb09li11VoWPCXsXL6bSmu2f3DS1wr5VaKF4nytGaF/kvR6jxz95cJtY1fJ7WD2wgzhGdnqhIeZiCvTUd+IflYkjpJmrG7HDjazJYBxhAN2MU0Zj9CUBidVysys1JqLZWST//iCGep9N8PuNfd98o7WphtLNLakbWXgG3NbN4SM0IrE2X1vSZ3tZ2XCKFuOE0XOmdlt8NnqZMqyo6Efv53CtdaUuurhJeI2dJSBg+K5ST/7Rap5NvtCjqqTLSmH4GHQY2p6cDMViPWHZxIDBZA20aO7073bUHUydk393ei7dmCGGB4IqlrVptngU3NrFcr+i+Z6nW+//QoUS7Xo0GFLVPXWoMWNjzN0daR+swgznsVtOmZ35mVtv/u/iyRTj9L3/bDwBlmdl5etZCYoYWG2byao97WOLTEpen3dIt9ABpR0DHOpGsr+DmEBjvReWbQvDT9T2BDM/tK785ih9+DKgx3xiXp3SVnHMxsaCn3LmYwsVA2z+HJ/Yac2w2EEPStgt9Dkvv1rXhnc2nfXB5uTfvXqPyZUAE4sXghrW3I9OH/DKxnZt8o9ZAyeu2kTuPfgJ3MbEThHT9Mp61Jq/ZwDzHK8q00m5OFZXViSvzqTC/Z3f/j7ncWjuZGaDLuIGb1jkzT79nzBxEj0zNobNGoyOOE5ayDLGdZLemMfqfZu3Kkkfu/ErqmTTpeWd6WeUbFeWZmQyyspeXv/4yGGZ35kr+ipTiIBdPQtOxnQsL+ROf8BXd/uOBnNtF4flW/p/A1Kc+t4A7CEMARhbpuCWJ2pMhsmn6bA4hR8iKZxZNKRyxvIOI2rvD87Qih8MYOHny5If3+MF9GUv7vDNzfAaoppWiujluUpnVra/lL+j0+72ixu/CKBb9PEIYJDjKzRXJ++9JgXOIvVJcb6JgyUXE/opnv9nniO8mX5WxPnIpH5NM6rmcJwXEdkuCQOphTCYs9q1C5mlJLfZiOYCqx/mPlvKOZDci3Jzn33oSxFIi1RhlXkoywFG45hJhpabKeqgStrU8yriIGjU+xEutJU32eqfLeRsyijiuVr2bWP2vnLNZ3NeprJ+H2FSJOcxdu34BYIF5ca1QzdJsZB3d/1MxOAk4BnjKzq4mpokWJxV3bEwuNIToP/wMuNbPfELqXGyc/L9E0XR4i9A1PIxr9OcBNaeHabwhznXeb2aWErv0hhJWBUkJIc5xLjOKeZWabExXCx8SitC1II4iteF5n8BJwUmowHyfS9WCisswvOv4ZUbGdZ2ZrETrlaxKjpy+k65VSMu0JG9tvA2dbmNh8kxiR2I9QW1q1TTEMziXMa56YpqJvJ9J/FaJRzTqd44lyc5WZXZXC+gVhVWl7Io0OLPOuo4lO+31mlpn23JEY4bzc3Yuj863CzLLOYtbZWy3ndm+md+rus8zsaKLivs/M/kAIhMcSI1wntScc7v6Rmf2AGEV/2MwuSpcOJEZYvt3SyJm7zzazY4nK/ZEUvi+J8vc+8Z1UwneJjv9fzexiIo/6E8Lmq4St/nJUmmejCZWia4lyP4P4Zr4FPJxrGKaZ2UPECFRWZx1KlKUrCunwpJk9Q+TLYGJ9RJFriLUQdyfd2r7EYtg2LypMeug/JhaL/y09dx5CaHuRprM41wDfNrMriRmsoTTkVZFHie96fBp0mQm8UkIgyriIMFd5Qvr27yXK0OHEXhel0qTNuPsd6fveC5jPzG6mwRzrZ4RZxw7H3T8xs9uBfc3sUyKdliJUWF6hHWsC3P02M7sJOCB1fCYT5li/TXRYR+T8zjaz7xIC8aNmdgGhFron0ck53RvMl1eLi+iAMtHKfsQfkuB8O9He9yfSZBAxEJjxEFHv/NbMMktFD7t7uVmqu4m6Jvufd/9mCfeWeAjY0sxOIIRAd/crytzTGq4lVBC3p/FI+fLAPWZ2DVEHfkCoHI0h2tKLPWc23d2fSXXqd83sOkI9M9s5+h4q2PwtqZD9C9jLzF4i8n+mu99U5r43zewwYv+Kaak/9xox2LkqUYeuTFj7m2lm+xMC6wsW6qj/Ivp/KxHqV7sRAtX+wLFmdn3yM4tQMd2GsJL31drAJGRtQstrJ6qP14Bpp3IHrdsAbgdCGvyAkB7fIASFwwr+NqVhg5ePiMWIIyix8RSxWOfa9Mw5KSzDctePp2GDp2lEA3kgTU0Unly8t/CePsQH8ijReM4kGuU/U4EpzGbe2cQtd62kiTZKmI+j6QZwMwmB61JgaIlnLEQsGnuT+FDeJDqNC5YLc6VpT5hDnJzC8UkK3ybNhL9Jvib3YZQw3UaMAoyn8WZ8j9LUxOw8hK3vZ4iRpk9SGfgDsH6F5Xt1ogLKyuw0Sm8m1mJaNfNsb+E4uYT/HYlG5n8pXa8hmaBrxTtfpXkTursRHfesfP8N2LWEv+by6+uETmn2bZ9G6zeAW5ywxPQ60Tn/L9H4b1Hu/a3JM0KF73fp2scpvtMIa11Dcv7GER2dd3LxuhpYq5l3H5fiOxv4WjN+DqFhs7L/EDry81Ohqcbm8pDoWL5AwwZwx1B6A7h5CBWr11IYXkzx3KJUXhGdvn+k/PgqPJTfAO7ldM87RF20VMFfyfvTtYuo0EwmDRvATUtx/yDl/6ol/JZMu2aeO4xmvsV0fUGiI/PvlI7PpLw9sESan0wz7UupMBEd3bMJwTcTTLZpLl2Izs4dRFn+jBgQ+lYrvt0mYW6pDDaTHi3lZ7vLRM5P2X4EURfdSMNGe+8SndvdC8/qRQjcb9IwG1i2riIGrxx4qeC+fHL/gtImzEt9z8sTddzH6bq35L9cfjUT3luBZ0qU3/OIvV8+IPoC76VytA+lTTb3Juq4rJ55i1gzVdFmdOkZ6xGmgrO1q69W8r0lPxsTQvI7KY3/TeyTcRy5zeqS3xHEwPFbNLQlfyP6BPMnP2sQM8X/SuH5OKXHccBchecdkMI3otK4VuOwFFghWsTMXiU+vlFVDooQQgghaggz25DoNG/lbV/316Mxs8eB19z969UOS0t0pzUOQgghhBCii/GwInUlJfY/EuVJ64tWpTJ12aqiGQdREZpxEEIIIYTo2WjGQQghhBBCCFEWzTgIIYQQQgghytJtzLGWY8EFF/Rhw4Z1+XtnzpzJgAEDuvy91URx7hkozj2DnhbnnhZfUJx7Copz1/H444+/5+4LdfmLu4AeIzgMGzaMxx57rMvfO3XqVEaNGtXl760minPPQHHuGfS0OPe0+ILi3FNQnLsOM3uty1/aRWiNgxBCCCGEEKIsEhyEEEIIIYQQZZHgIIQQQgghhCiLBAchhBBCCCFEWSQ4CCGEEEIIIcoiwUEIIYQQQghRFgkOQgghhBBCiLJIcBBCCCGEEEKURYKDEEIIIYQQoixdJjiY2fxmdr2ZzTSz18xs72b8jTCz28zsPTPzFp63vJl9ZmaXdV6ohRBCCCGEENC1Mw7nAV8AQ4F9gPPNbJUS/mYBVwFjK3jeox0aQiGEEEIIIURJ+nTFS8xsALA7MMLdZwD3m9mNwH7AuLxfd38BeMHMlmvheXsBHwF/A5r1J4QQQgghhOgYzL1ZbaCOe4nZmsDf3L1/zu37wGbuvlMz9ywHvOjuVnAfDDwGbEHMSizn7vs284xDgUMBhg4duvYVV1zREdFpFTNmzGDgwIFd/t5qojj3DBTnnkFPi3NPiy8ozj0FxbnrGD169OPuvk6Xv7gL6JIZB2AgML3gNh0Y1IZnnQZMdPc3zKxFj+5+AXABwDrrrOOjRo1qw+vKUy4c5egK4a0rmTp1Kp2V1rWK4twzUJy7Pz0tvqA49xQUZ9ERdNUahxnA4ILbYOCT1jzEzNYAtgR+0THB6hjcvdljqRNubvF6dxMahBBCCCFE96SrZhz+CfQxs+Xd/cXktjrwXCufMwoYBryeRvkHAr3NbGV3X6uDwiqEEEIIIYQo0CUzDu4+E7gOONXMBpjZxsAuwKVFvxbMDfRL53Ob2Vzp8gXAssAa6fgdcAuwTWfHQQghhBBCiJ5MV5pjPRzoD7wDTAIOc/fnzGxJM5thZksmf0sBn9IwG/Ep8AKAu//P3d/ODkIF6jN3f7cL4yGEEEIIIUSPo6tUlXD3D4BdS7i/TqgcZeevAhWtNnb3kzsmdEIIIYQQQoiW6MoZByGEEEIIIUSdIsFBCCGEEEIIURYJDkIIIYQQQoiySHAQQgghhBBClEWCgxBCCCGEEKIsEhyEEEIIIYQQZZHgIIQQQgghhCiLBAchhBBCCCFEWSQ4CCGEEEIIIcoiwUEIIYQQQghRFgkOQgghhBBCiLJIcBBCCCGEEEKURYKDEEIIIYQQoiwSHIQQQgghhBBlkeAghBBCCCGEKIsEByGEEEIIIURZJDgIIYQQQgghyiLBQQghhBBCCFEWCQ5CCCGEEEKIskhwEEIIIYQQQpRFgoMQQgghhBCiLBIchBBCCCGEEGWR4CCEEEIIIYQoS59qB6AeWP2U25n+6aw23z9s3C1tum9I/748fdLWbX6vEEIIIYQQHYUEhwqY/uksXj1jhzbdO3XqVEaNGtWme9sqcAghhBBCCNHRSFVJCCGEEEIIURYJDkIIIYQQQoiySHAQQgghhBBClEWCgxBCCCGEEKIsEhyEEEIIIYQQZZHgIIQQQgghhCiLBAchhBBCCCFEWSQ4CCGEEEIIIcoiwUEIIYQQQghRFgkOQgghhBBCiLJIcBBCCCGEEEKURYKDEEIIIYQQoiwSHIQQQgghhBBlkeAghBBCCCGEKIsEByGEEEIIIURZJDgIIYQQQgghyiLBQQghhBBCCFEWCQ5CCCGEEEKIsvSpdgDqgUHDx7HqxePa/oCL2/pegB3a/l4hhBBCCCE6CAkOFfDJtDN49Yy2deCnTp3KqFGj2nTvsHG3tOk+IYQQQgghOhqpKgkhhBBCCCHKIsFBCCGEEEIIURYJDkIIIYQQQoiySHAQQgghhBBClEWCgxBCCCGEEKIsEhyEEEIIIYQQZZHgIIQQQgghhCiLBAchhBBCCCFEWSQ4CCGEEEIIIcoiwUEIIYQQQghRFgkOQgghhBBCiLJIcBBCCCGEEEKUpcsEBzOb38yuN7OZZvaame3djL8RZnabmb1nZl64NpeZTUz3f2JmT5rZdl0TAyF6FmbW4jF69OgWrwshhBCie9GVMw7nAV8AQ4F9gPPNbJUS/mYBVwFjS1zrA7wBbAYMAX4MXGVmwzojwEL0ZNy9xWOpE25u8boQQgghuhd9uuIlZjYA2B0Y4e4zgPvN7EZgP2Bc3q+7vwC8YGbLFZ/j7jOBk3NON5vZK8DawKudE3ohhBBCCCGEdcXIoJmtCfzN3fvn3L4PbObuOzVzz3LAi+7erM6DmQ0FXgPWcPfnS1w/FDgUYOjQoWtfccUVbQr/gZNnctG2A9p074wZMxg4cGCXv7eatCfO9UpPjHO9ls/20BPzuafFuafFFxTnnoLi3HWMHj36cXdfp8tf3AV0yYwDMBCYXnCbDgxq6wPNrC/wZ+DiUkIDgLtfAFwAsM466/ioUaPa9rLJt9DWe6dOndrme9vz3mrSrjjXKT0xzvVaPttDT8znnhbnnhZfUJx7Coqz6Ai6ao3DDGBwwW0w8ElbHmZmvYBLiTUT321f0IQQQgghhBDl6CrB4Z9AHzNbPue2OvBcax9kYa5lIrHIend3n9UxQRRCCCGEEEI0R5cIDmlR83XAqWY2wMw2BnYhZg0aYcHcQL90PreZzZXzcj4wHNjJ3T/t/NALIYQQQgghumqNA8DhwIXAO8D7wGHu/pyZLQn8A1jZ3V8HlgJeyd33KbEAepiZLQV8G/gceDtnK/7b7v7nzgz8sHG3tP3myW27d0j/vm1/pxBCCCGEEB1IlwkO7v4BsGsJ99eJxdPZ+atASUtK7v5ac9c6k1fP2KHN9w4bd0u77hdCCCGEEKIW6MoZByHqlo7YCVmbogkhhBCinunKnaOFqFvau4uyhAYhhBBC1DuacRBtor0j8OpICyGEEELUF5pxEG1Co+9CCCGEED0LCQ5CCCGEEEKIskhwEEIIIYQQQpRFgoMQQgghhBCiLBIchBBCCCGEEGWR4CCEEEIIIYQoi8yxipKsfsrtTP90VpvvHzbuljbdN6R/X54+aes2v1cIIYQQQnQOEhxESaZ/OotXz9ihTfdOnTqVUaNGtenetgocQgghhBCic5GqkhBCCCGEEKIsEhyEEEIIIYQQZZHgIIQQQgghhCiL1jgIkdCCcCGEEEKI5pHgIERCC8KFEEIIIZpHqkpCCCGEEEKIskhwEEIIIYQQQpSlYlUlMxsOfANYxN2PMLOVgH7u/vdOC50QQgghhBCiJqhoxsHMvgncAywO7JecBwLndFK4hBBCCCGEEDVEpapKpwJbu/t3gNnJ7Wlg9U4JlRBCCCGEEKKmqFRwWJgQFAA89+ulvQshhBBCCCG6E5UKDo/ToKKUsRfwSMcGRwghhBBCCFGLVLo4+ijgdjMbCwwws9uAFQDtWiWEEEIIIUQPoCLBwd2fT1aUdgRuBt4Abnb3GZ0ZOCGEEEIIIURtUJHgYGaLA/9z96tybvOZ2WLu/u9OC50QXcig4eNY9eJxbX/AxW19L0DbdqwWQgghhOgqKlVVugE4GPgw57YE8Edg/Q4OkxBV4ZNpZ/DqGW3rwE+dOpVRo0a16d5h425p031CCCGEEF1JpYujV3D3Z/IO6Xyljg+SEEIIIYQQotaodMbhXTNbzt3/lTmY2XLA+50TLFFtpLYjhBBCCCHyVCo4XAhca2bjgZeBZYHTCFUl0Q2R2o4QQgghhMhTqeBwBjAL+DnwNcKq0h+BczopXEKILmD1U25n+qez2nx/WwW9If378vRJsuYshBBC1BOVmmOdA5yVDiFEN2H6p7M0sySEEEKIiqh0xgEzWxFYHRiYd3f3Czs6UEIIIYQQQojaotJ9HH4E/B/wNPC/3CUn1j8IIYQQQgghujGVmmM9BljP3dd399G5Y/NODJsQQogqMWnSJEaMGMEWW2zBiBEjmDRpUrWDJIQQospUqqr0KfB8ZwZECCFEbTBp0iTGjx/PxIkTmT17Nr1792bs2LEAjBkzpsqhE0IIUS0qnXH4MfBrM1vUzHrlj84MnBBCiK5nwoQJTJw4kdGjR9OnTx9Gjx7NxIkTmTBhQrWDJoQQoopUOuNwUfr9Vs7NiDUOvTsyQKJ2aJflm8ltN9MphKgu06ZNY+TIkY3cRo4cybRp06oUIiGEELVApYLD0p0aClFztNVEJ4TA0Z77hRDVZfjw4dx///2MHj36K7f777+f4cOHVzFUQgghqk2l+zi81tkBEUIIURuMHz+esWPHfrXGYcqUKYwdO1aqSkII0cNpzT4OOwObAQsSakoAuPv+nRAuIYQQVSJbAH3kkUcybdo0hg8fzoQJE7QwWgghejiV7uNwEvAd4Argm8Dvgb2BKzsvaEII0bWYWXlPLeDuHRSS6jNmzBjGjBnTrh3ChRBCdC8qtYp0MLCVux8LfJF+dwKGdVbAhBCiq3H3Fo+lTri5xetCCCFEd6ZSwWFed382/f/CzPq6+yOE6pIQQgghhBCim1PpGoeXzGwVd38OeBY4zMw+BD7svKAJIYQQQgghaoVKBYcTgQXS/3HA5cBA4IjOCJQQQgghhBCitqjUHOutuf+PAMt1WoiEEEIIIYQQNUdFaxzM7INm3N/p2OAIIYQQQgghapFKF0f3LTqYWV+gd8cGRwghhBBCCFGLtKiqZGb3AQ7MbWb3Fi4vAfytswImhBBCCCGEqB3KrXH4I7FL9LrAxJy7A/8F7u6kcAkhhBBCCCFqiBYFB3e/2Mx6AzsAV7j7510TrPqi3G6zdmbL92vjKCGEEEIIUeuUXePg7rOBzYFZnR+c+qSlnWSnTJlSdjdaIYQQQgghap1KF0dfDHynMwMihBBCCCGEqF0q3QBuPeBIM/sB8AaxxgEAd9+0MwImhBBCCCGEqB0qFRz+kA4hAK3rEEIIIYToaVS6c/TFnR0QUV+01PGfOnUqo0aN6rrACCGEEEKITqfSGQfM7CBgP2Bx4C3gUnf/Uyvun58w6bo18B7wQ3e/vIS/EcDZwNrAAu5ubXmOEG1h2Lhb2n7z5LbdO6R/k/0Vu4xBw8ex6sXj2v6ANg4pDBoOYaxNCCGEEPVCRYKDmY0H9ic69K8BSwE/MLPF3H1Che86D/gCGAqsAdxiZk+7+3MFf7OAq4DfAje04zlCtIpXz2h7R3bYuFvadX+1+GTaGW0Od3tmltoloAkhhBCiKlQ64/AtYJS7v5Y5mNltwL1AWcHBzAYAuwMj3H0GcL+Z3UjMYDQa7nT3F4AXzGy59jxHCCGEEEII0XFUKjgMAN4tuL0P9K/w/hWA2e7+z5zb08BmFd7fpueY2aHAoQBDhw5l6tSprXxd+5kxY0ZV3ltNemKcgbqNc1vD3d587mnpVa/0tO+5p8UXFOeeguIsOoJKBYfJwJ/NbBzwOqGqNAG4rcL7BwLTC27TgUEV3t+m57j7BcAFAOuss45XY8FuT1wo3BPjzORb6jPO7Qh3u/K5ium1+im3M/3Ttu9neeDkmW26b0j/vjx90tZtfm+16Gnfc0+LLyjOPQXFWXQElQoO3wV+Q4zu9yPWIVwJHFXh/TOAwQW3wcAnFd7f0c8RQvRQpn86S+s6hBBCiDZQ0c7R7v6xu+8PzAMsAvR39/3d/aMK3/NPoI+ZLZ9zWx1o7YLmjnqOEEIIIYQQohW0xhzr8sAewGLAv83sKnd/sZJ73X2mmV0HnGpm3yKsIe0CbFTiPQbMRcxsYGZzxyP889Y8RwghhBBCCNFxVDTjYGZ7A08CqwEzgVWBJ5J7pRxOLKZ+B5gEHObuz5nZkmY2w8yWTP6WAj6lYRbhU+CFcs9pRTiEEEIIIYQQraTSGYefANu7+72Zg5ltAlwKVLT5mrt/AOxawv11YtFzdv4qYEV/5Z4jhBBCCCGE6DwqmnEgrBY9WHB7iDDTKoQQQgghhOjmVCo4nAOcntYbYGb9CXOs53RWwIQQQgghhBC1Q6WqSocT1pSONrMPgfkIdaL/mNlhmSd3X7KZ+4UQQgghhBB1TKWCw76dGgohhBBCCCFETVOR4ODu93R2QIQQQgghhBC1S0WCg5n1AcYAa5KzgATg7od2QriEEEIIIYQQNUSlqkqXEXs3/BX4b+cFRwghhBBCCFGLVCo4bAt8zd0/6czACCGEEEIIIWqTSs2x/gOYvzMDIoQQQgghhKhdWmNV6Y9mdjsFVSV3v6TDQyWEEEIIIYSoKSoVHA4ENiH2b/g05+6ABAchhBBCCCG6OZUKDkcDa7r7tM4MjBCi6xk27pa23zy5bfcO6d+37e9sJ4OGj2PVi8e1/QEXt/W9ADu0/b1CCCFElalUcPgv8HpnBkQI0fW8ekbbO7LDxt3SrvurxSfTzmhzuKdOncqoUaPadG+7BDQhhBCiBqhUcPgF8GczOwN4J3/B3V/u8FAJIYQQnYSZtet+d++gkAghRH1RqeBwXvrdueDuQO+OC44QQgjRubTU8a/XmTQhhOgKKhIc3L1Ss61CCCGEEEKIbogEAiGEEEIIIURZWpxxMLNLCXWkZnH3/Ts0REIIIYQQQoiao5yq0r+6JBRCCCGEEEKImqZFwcHdT+mqgAghhBBCCCFqF61xEEIIIYQQQpRFgoMQQgghhBCiLJXu4yCEEKIbos3QhBBCVIpmHIQQogfj7i0eS51wc4vXhRBC9BwqEhwsOMTM7jazvye3Tc1sj84NnhBCCCGEEKIWqFRV6VRgK+CXwO+S25vAL4CrOj5YQgghOoLVT7md6Z/Oatczho27pU33Denfl6dP2rpd7xZCCFE7VCo4HAis6e7vmdn5ye0VYJlOCZUQQogOYfqns3j1jB3afP/UqVMZNWpUm+5tq8AhhBCiNqlUcOgNzEj/M6XWgTk3IYSoG9rVoZ3c9tF3IYQQop6pVHD4K3COmR0LseYBOA24qbMCJoQQnUF7Rt+HjbulXfcLIYQQ9UylVpWOBRYFpgNDiJmGpYATOilcQgghhBBCiBqi7IyDmfUGvgGMAQYTAsMb7v52J4dNCCGEEEIIUSOUnXFw99nAOe7+mbu/4+6PSmgQQgghhBCiZ1GpqtJNZrZTp4ZECCGEEEIIUbNUujh6buAaM3sQeIMGy0q4+/6dETAhaomwB1DGz5ktX9cuu0IIIYSoZyoVHJ5NhxA9knKd/vbYuhdCCCGEqAcqEhzc/ZTODogQQgghOodKZk1bQjOmQgioUHAws82bu+bud3dccIQQQoj2sfoptzP901ltvr89GwQO6d+Xp0/aus33dxYtdfy1P4kQolIqVVWaWDhfCOgHvAks06EhEkIIIdrB9E9ntbkj3F61w3btSi46FM2yCNHxVKqqtHT+PO3tcCLwSWcESgghhBCiPWiWRYiOp1JzrI1IeztMAH7QscER9cykSZMYMWIEW2yxBSNGjGDSpEnVDpIQQgghhOggKlVVKsVWwJyOCoiobyZNmsT48eOZOHEis2fPpnfv3owdOxaAMWPGVDl0QgjRvdG6DiFEV1Dp4uhGezcA8xB7OxzRGYES9ceECROYOHEio0eP/kpHeOLEiRx55JESHIQQXcqg4eNY9eJxbX/Axe15N0DXq8BoXYcQoiuodMZh38L5TOCf7v5xB4dH1CnTpk1j5MiRjdxGjhzJtGnTqhQiIQR0QCca2tyRrlYn+pNpZ6gTLYQQnUClgsO67v7zoqOZfc/dz+ngMIk6ZPjw4dx///2MHj36K7f777+f4cOHVzFUQoj2dKKhfR1pdaKFEKJ7Uang8H9AE8GBsKwkwUEwfvx4xo4d+9UahylTpjB27FgmTJhQ7aAJIUS3pyeqZwkhup4WBYfcxm+9zWw0kDeKvAwyxyoS2TqGI488kmnTpjF8+HAmTJig9Q1CCNEFSD1LCNEVlJtxyDZ+mxu4MOfuwNvAkZ0RKFGfjBkzhjFjxrS7ERJCCCGEELVHi4JDtvGbmV3i7vt3TZCEEEIIIYQQtUZFG8BJaBBCCCGEEKJnU+k+DoOBk4HNgAXJrXVw9yU7JWRCCCGEEEKImqFSq0q/BZYATgUuI/Z1OB64tpPCJYSoMmZW3s+ZzV9z9+Yv1ijdNc7tXrw6uW33D+nft33vFUIIUVNUKjhsDQx39/fNbLa7/8XMHgNuAn7RecETQlSLcp3g7rgIvjvGuT17OEAIHe19hhBCiO5BRWsckr/p6f8MM5sX+A+wXGcESgghhBBCCFFbVDrj8DSxvuEu4D7gPGAG8M9OCpcQQgghhBCihqh0xuEQ4NX0/yjgU2BeQNaWhBBCCCGE6AFUNOPg7i/n/r8LfKvTQiSEEEIIIYSoOSo1x2qEsDAGWNDdVzOzTYFF3P2qzgygEEIIIUSR1U+5nemfzmrz/W21Njakf1+ePmnrNr+3q5k0aRITJkxg2rRpDB8+nPHjxzNmzJhqB0vUKZWucTgV2Ar4JfC75PYmYVGpIsHBzOYHJhIWmt4Dfujulzfj91jgBKA/YfL1MHf/PF0bRpiH3RD4HLgGOMbdv6wwLkIIIYSoc6Z/OqvNFr/aYyGt3eaNu5BJkyYxfvx4Jk6cyOzZs+nduzdjx44FkPAg2kSlaxwOBHZ09yuAzF7hK8AyrXjXecAXwFBgH+B8M1ul6MnMtgHGAVsAw9I7Tsl5+S3wDrAosAaxaPvwVoRDCCGEEKLbM2HCBCZOnMjo0aPp06cPo0ePZuLEiUyYMKHaQRN1SqWCQ2/CihI0CA4Dc24tYmYDgN2BH7v7DHe/H7gR2K+E9wOAie7+nLt/CJxGCC4ZSwNXuftn7v42MBloIoAIIYQQQvRkpk2bxsiRIxu5jRw5kmnTplUpRKLeqVRV6VbgnKRClK15OI3YAK4SVgBmu3vefGtm4rXIKsBfCv6GmtkC7v4+cC6wl5lNBeYDtgN+XOqlZnYocCjA0KFDmTp1aoXB7ThmzJhRlfdWE8W5Z6A49xzqMc5tDXNH5HG10ktxrpz2xrlevokll1yS3/zmN6y55ppfxfnJJ59kySWXrJs4tIeeWmd3Ku5e9gAGAzcAnwGzgZnA9cCgCu/fBHi74HYIMLWE35eAbXPnfYlZjmHpfDjwOPBlcr8IsHJhWHvttb0aTJkypSrvrSaKc89Ace4ZLHXCzdUOQqtpT5jbm8fVSi/FuXW0J8719E1cfvnlvvTSS/vdd9/td9xxh999992+9NJL++WXX17toHUJ1aqzgce8gv5xPR4tzjiY2SLu/ra7fwzsamYLA0sBb3ioCVXKjCR85BkMfFKB3+z/J2bWC7gN+D2wEaEudSFwJvCDVoRHCCGEEKJbky2APvLII7+yqjRhwgQtjBZtptwah+LO0L9z90dbKTRkz+ljZsvn3FYHnivh97l0Le/vvx5qSvMDXwN+4+6fJ7c/Adu3MjxCCCGEEN2eMWPG8Oyzz3LXXXfx7LPPSmgQ7aLcGgcrnI9qy0vcfaaZXQecambfIqwh7ULMGhS5BLjIzP4M/Ac4kVBHwt3fM7NXgMPM7OfEjMMBxDoIIYQQQogeSyxBbTuhZSNE85QTHDqyBB1OqBW9A7xP7M3wnJktCfwDWNndX3f3yWb2M2AKDfs4nJR7zteJ/SROINZbTAGO7cBwCiGEEHVHu/YXmNz2e4f079v294oOpaWO/7Bxt7R53wshMsoJDn3MbDQNMw/Fc9z97kpe5O4fALuWcH+dmDnIu50DnNPMc56ijTMfQgghRHekPR1CdSiFEJVSTnB4h5glyHi/cO60bhM4IYQQQgghRB3SouDg7sO6KBxCCCGEEEKIGqbSnaOFEEIIIYQQPRgJDkIIIYQQQoiySHAQQgghhBBClKXc4mghhBCi7pBp0u7PoOHjWPXicW1/wMVtfS+ArFCJnokEByGEEN0KmSbtGXwy7Yw259XUqVMZNWpUm+5tl1AqRJ0jwUEIIXowlew0a2c2f007zQohRM9BaxyEEKIH4+4tHlOmTGnxuqgPzKzZ47Uzd2zxeiXCpRCiZyDBQQghhOjmtEc4lIAohMiQ4CCEEEIIIYQoi9Y4CCGEEEKIuqMj1Og0o9Y6NOMghBBCCCHqjnIqdkudcLPU8DoYCQ5CCCGEEEKIskhwEEIIIYQQQpRFgoMQQgghhBCiLBIchBBCCCGEEGWRVSUhhBBCiDpg9VNuZ/qns9p8/7Bxt7TpviH9+/L0SVu3+b2i+yDBQQghhBB1SVs7wgBMbnsnulpM/3QWr56xQ5vunTp1KqNGjWrTve1KZ9GtkOAghBBCiLqjrR1oiI5we+4XoqeiNQ5CCCGEEEKIskhwEEIIIYQQQpRFgoMQQgghhBCiLBIchBBCCCGEEGWR4CCEEEIIIYQoiwQHIYQQQgghRFkkOAghhBBCCCHKIsFBCCGEEEIIURZtACeEEEKIboeZtXz9zJbvd/cODI0Q3QPNOAghhBCi2+HuzR5Tpkxp8bqEBiFKoxkHIYQQQghRk6x+yu1M/3RWm+8fNu6WNt03pH9fnj5p6za/t7siwUEIIYQQog4YNHwcq148ru0PuLit7wXYoe3vbQfTP53Fq2e07d1Tp05l1KhRbbq3rQJHd0eCgxBCCCFEHfDJtDPUiRZVRYKDEEKIHoUWzYp6pl2d+MltV9sRAiQ4CCGE6GG01PFvz6isEJ1NW2cbIASO9twvBMiqkhBCCCGEEKICJDgIIYQQQgghyiLBQQghhBBCCFEWCQ5CCCGEEEKIsmhxtBBCCCGEqEl64t4VtYwEByGEEEIIUZNo74raQqpKQgghhBBCiLJIcBBCCCGEEEKURapKQgghhBDdAO2KLjobzTgIIYQQQnQD3L3ZY8qUKS1el9AgKkGCgxBCCCGEEKIsEhyEEEIIIYQQZZHgIIQQQgghhCiLFkcLIYQQQoiapV17Kkxu271D+vdt+zu7MRIchBBCiB7IpEmTmDBhAtOmTWP48OGMHz+eMWPGVDtYQjSirZu/QQgc7blfNEWCgxBCCNHDmDRpEuPHj2fixInMnj2b3r17M3bsWAAJD0KIZtEaByGEEKKHMWHCBCZOnMjo0aPp06cPo0ePZuLEiUyYMKHaQRNC1DASHIQQQogexrRp0xg5cmQjt5EjRzJt2rQqhUgIUQ9IcBBCCCF6GMOHD+f+++9v5Hb//fczfPjwKoVICFEPSHAQQgghehjjx49n7NixTJkyhS+//JIpU6YwduxYxo8fX+2gCSFqGC2OFkIIIXoY2QLoI4888iurShMmTNDCaCFEi3TZjIOZzW9m15vZTDN7zcz2bsHvsWb2tplNN7MLzWyuwvW9zGxaetZLZrZJ58dACCGE6D6MGTOGZ599lrvuuotnn31WQoMQoixdqap0HvAFMBTYBzjfzFYpejKzbYBxwBbAMGAZ4JTc9a2AM4GDgEHApsDLnRx2IYQQQgghejRdIjiY2QBgd+DH7j7D3e8HbgT2K+H9AGCiuz/n7h8CpwEH5q6fApzq7g+5+xx3f8vd3+rkKAghhBBCCNGj6aoZhxWA2e7+z5zb00CTGYfk9nTB31AzW8DMegPrAAuZ2b/M7E0z+42Z9e+0kAshhBBCCCEwd+/8l8QahKvdfZGc2yHAPu4+quD3JeAId5+czvsSKk5Lp9+3gMeBnYBZwF+Aqe7exBSEmR0KHAowdOjQta+44oqOj1wZZsyYwcCBA7v8vdVEce4ZKM49g54W554WX1Ccewo9Mc4HTp7JRdsO6PL3jh49+nF3X6fLX9wFdJVVpRnA4ILbYOCTCvxm/z8B5qT/v3b3/wCY2TnAiUATwcHdLwAuAFhnnXV81KhRbQx+25k6dSrVeG81UZx7Bopzz6CnxbmnxRcU555CT4wzk2/peXHuZLpKcPgn0MfMlnf3F5Pb6sBzJfw+l65dlfP3X3d/H8DM3gQ6f5pECCGEEELULGZW3s+ZLV/vCs2b7kSXrHFw95nAdcCpZjbAzDYGdgEuLeH9EmCsma1sZvMRswkX5a7/CTjSzBZO148Bbu7M8AshhBBCiNrC3Vs8pkyZUtaPaB1daY71cKA/8A4wCTjM3Z8zsyXNbIaZLQmQ1jb8DJgCvJaOk3LPOQ14lJjFmAY8CUzoslgIIYQQQgjRA+mynaPd/QNg1xLurwMDC27nAOc085xZhBByeMeHUgghhBBCCFGKrpxxEEIIIYQQQtQpEhyEEEIIIYQQZZHgIIQQQgghhCiLBAchhBBCCCFEWSQ4CCGEEEIIIcoiwUEIIYQQQghRFgkOQgghhBBCiLJIcBBCCCGEEEKURYKDEEIIIYQQoiwSHIQQQgghhBBlkeAghBBCCCGEKIsEByGEEEIIIURZJDgIIYQQQgghyiLBQQghhBBCCFEWCQ5CCCGEEEKIskhwEEIIIYQQQpRFgoMQQgghhBCiLBIchBBCCCGEEGWR4CCEEEIIIYQoiwQHIYQQQgghRFkkOAghhBBCCCHKIsFBCCGEEEJ0GyZNmsSIESPYYostGDFiBJMmTap2kLoNfaodACGEEEIIITqCSZMmMX78eCZOnMjs2bPp3bs3Y8eOBWDMmDFVDl39oxkHIYQQQgjRLZgwYQITJ05k9OjR9OnTh9GjRzNx4kQmTJhQ7aB1CyQ4CCGEEEKIbsG0adMYOXJkI7eRI0cybdq0KoWoeyHBQQghhBBCdAuGDx/O/fff38jt/vvvZ/jw4VUKUfdCgoMQQgghhOgWjB8/nrFjxzJlyhS+/PJLpkyZwtixYxk/fny1g9Yt0OJoIYQQQgjRLcgWQB955JFMmzaN4cOHM2HCBC2M7iAkOAghhBBCiG7DmDFjGDNmDFOnTmXUqFHVDk63QqpKQgghhBBCiLJIcBBCCCGEEEKURYKDEEIIIYQQoiwSHIQQQgghhBBlkeAghBBCCCGEKIsEByGEEEIIIURZJDgIIYQQQgghyiLBQQghhBBCCFEWCQ5CCCGEEEKIspi7VzsMXYKZvQu8VoVXLwi8V4X3VhPFuWegOPcMelqce1p8QXHuKSjOXcdS7r5QFd7b6fQYwaFamNlj7r5OtcPRlSjOPQPFuWfQ0+Lc0+ILinNPQXEWHYFUlYQQQgghhBBlkeAghBBCCCGEKIsEh87ngmoHoAoozj0Dxbln0NPi3NPiC4pzT0FxFu1GaxyEEEIIIYQQZdGMgxBCCCGEEKIsEhyEEEIIIYQQZZHgIIQQQgghhCiLBAfRKsxsnvTbu9phEUIIIYQQXYcEB1ExZrYG8I6Z9XP32dUOjxBClMPMrNph6G701IEjM+uxfSYLemz8uxvt+YZVCETFuPtTwL+AX0LPrkS7is5ooM3sdDPbuKOfWyuY2SZm9lMzm7faYakGZvZ1M9s2/e+R36iZ9Tazc8xsoLu7hIeOIauP3H22mQ01s22Se7dPXzMzd5+T/s/fE+KcYWa9PZhjZguZ2dBqh6kUPVWgbQ1Zm5C+4bnNbMHWPqNHNiqiXRwGfMfMVkiVSI+pPLuSQgM90Mz26cDHrwSc24HPqzVmAYcC6/e08mlmfYGNgV8BZB2dnkaaEd0e+F1y6lHloLPIZprNbG3gOWDP5N7t7bonAbS/mU0C/gDMW+UgdRm5fD8IeBJYvbohaky+M5zO965uiGqXnPC7B/AisFZrn6F9HEQTzGwAMK+7v2Vmfd19VuH65cDX3H2TNAqjQtRJmNmawKXAs8AB7v55O57VKwl7fYEPgO+6+8UdFNSaIBfH84ElgEPc/e1qh6srMbOlgSuAa939Z1maVDtcXU3q3D4ErOXuz6iuaj3FNDOzfsBfgZlE+epW9UdLmNnWwFbAAOB4d59Z5SB1GWa2AnAq8D/gl+7+9yoHqSRp9Px8YCSwBvCOvvnGmNkwYCywHPA7d7+ntc/QjINohJkNBm4CDjCzAZnQYGYr57wdD6xjZjunURiVo3ZSHBk3s15m9nvgLGCSu+/VWqHBzObKnp2mmufkBMEfAz9N+V23mFmf9Nsvc0q/JwLDgR0yP92ZwhT9a0TjeYSZLdDdZwaTINxIBzt1eB8nhO4/Qs8YFe9IMvWUvJu7fwHcAWxD6j90t7KV6t5Sbdo3iRn3f7r7zFyd023I2ooSl4YCywOrufvfayHuJdrM7wE3Au+6+6Lu/t+e/s030/YNB7Yj8vKetvTf1OETX5Ea24+B24ANgFXMbDszexWYZGZXmtmO7v4W0aE9D3quOkRHYWZ9SjTQc4CphFrRvG145g7AOWa2XNJNnZ2eOyv9/hL4HPhhuwJfJZJ+9W+Bw+GrDg1A71SO3yc6jN8BlqlSMDsNi3Ucp5vZ/NAwRZ/+zwFuJlRJzqxSELsEMzsUONrM5svpYOdHyccR9dieyb/avArJ6UCfaGbfTTM4uPsZwD+Ar5lZ/+7UOcsGWFI5WsrMlreGtVK/AR4AFoFGdU63IPtuUr7Pm9r+4enyI4R61kJmtqS7f1GtbymnxlssdzcBSwGLmln/Lg9YDZEJVe7+ZRIGNzOzJdPlO4DLgP+Z2RqprLcqL1WJilL8EugH7ERMaX0b2AN4CbjSzBYCTgYwsx+mX5WlNpI+7t5mdko6tk/uk4B7gUFmtlQrH9sPGAZsCqGbamYPmNlpZvb15Ocw4HtmtmzHxKRL+YyYNt8oNXJLmtkDwCWEUJt1cAD27YYNySziu1wbwMw2MLNLzewHZra2u78H/ALYNp1315nBBYBtgRUBzOy7wI2po7uOu78DnE5a06NBjsoxs4OB14ENga8DvzCz3dPlnwF7A6tUKXidQuo0z2VmfwIeAy4GbrawJPg0MZizjJmNhu4125J1xM3sROBVQuh+2Mz2Ar4gVNQeIA02Vetbyq9jSO3ZZmng4EWi/p8fWKgaYasVcnl5CPAfok93n5mNdfcvCeFhGrBf8t+qvOyODYloI1nnIqnEXEBMzS7t7re5+wvu/iPgUeAXqaAdD5xqZoPVILcdM/sG0UCvD6wA/NzMjk2XfweMADZpZgq5JO5+PfAMsLGZTSAEwEuBgcDlZrapu08G7gF+3mGR6QLSyNh04AbACbWrXwN3AVcDXzezP6ZG/USig1NTi/naQ4r/Q8BVwJGp/FxJqChtBvzezHZw9zuAyaRZh+70jeY6bD8jBMidzOwsYF+ic7cF8Bczm9fdTwdmmtlp6V61eznSiGQjtSMLXfFNgMPcfQd33xz4J3ACfDWo8Qow1urYelmxLJjZEOA6YBAhjG5H1DF/SF7+DMwGtjKzIanNrEvhoUTcLXU0NwM2cffNgO8BxwCj3P014BpgNTPbPN3T5VaMzGy4mT1E1PsrAROIwQGAUwi1qt2sBtSpuoqUd0XVrYOBbwF7uPuawHHAKWkg6TminlwuG6hsVb3o7jp0lDyITuvtwIo5t02ITu786fwRYtFu1cNb6wehf987+59++xCjAYfk/J0KfAgMSue/IBqsNSp8T6/0uxbRkX6WaAiy6+cCD6b/SxGj91tWO33akJ69gO8TwuylOffhwBPAnun8OuDCrMzW+5HL3/kJ88hTgG8kt/kIgf6NXFpMA/bO39sdjlw67EKMhD4ALJa7fhtwQ/q/G7Ggd4F0btUOfy0c+fIADAH6p/99gBHp/zKEUP5mKm+nJvd1U92xebXj0YZ4f1UXl7h2EGEcBGAUISDNBrZKbvundnG/asejHfHvnftvuf8bE8YEIGaTpgBfEgOJC6Y65zzgvq4OZ3YOHE0MXmZuuwHvZm0YoZ76BLBqtdO5GmmUc18rV2YXJ2Zj5hBqSn2ARYHfEgNw87TqndWOtI6uP8o1mrkGee3UGB8K9EtuuwC3AgPT+VzVjk89HCUa6Plz58um38WI6eDXgTeIRdFZw/2PlA/5Cn+RCt77HeAt4MCC+wxg2/T/kvT8uulM0SB4LU/ott5fuH4ecFP6v0aK70bVDncHxj8TQA8h1qrsk7s2CHgc2D+dnwL8u9ph7uT0OJfo2G6cc1s6pc3S6fwJ4Lpqh7UWj/S9PAFcT6gv9E3uaxEDD2cBfVNH401gqXR9+2qHvZ3xXgY4BzgQWD+5zZWOS4B/E6pwfyR1lgmrSmdQ4UBOrR7A3MRM7S+BYwvXDgPeIUapR6U8H5OubUzDQEWntBnF5wIL5f4vS+roAj8lLAQ+ATye8zMtxatftdO5C/PzREJ7YO+C+17Af9O11YHpwK7p2s7Avq19l6ZsexiWW4hryRpJEU8qDR5WSe4lOienmdkqhH7jW8ToHe7+ealpMtEYb7CdfBYxS/PntJ5hiLu/ZGFC82rgZXdfklAv2dPM1nX3l4kZiQu8Qb/zZ0TelCQ37Xg9oY60pqWFtImHiAoYd98f2CErF/VAFlYPvdarCFWUb+S83AssZmEZ7ClgQ3f/W9eHtNPIvtE/AE8DI6zBQtYcoqGYO53/Hti1qwPYFeTK+R8IgXs1S9bEiNHwp4m1PhCN5He7NIA1SE4dyazBettSRBm5GdgR+EnyvjLwnLsf72FYoS+hM70zgLvfmn9mLZOp1eTUsvYBHiaMT2xK1MnreajqjgS+Rpgdn0yUpY3N7DvuPtPdx6V6pS4oqhRZrGt7ghiJfhI4yGLTzIUt1oPtCOzu7mcTgy59gZ3NbFF3f8Ddr4HOs1SW66PsZWbPAJdZLNJfyd1fStcmEUZcNiQEnJUsLCtB7C9ytnezBezQqPxm3/HXzOwRYHOSmXUzm5iu9SPWp37H3b9PzLTNAo5NfY8b3f2y1oZBgkMPw2Mhbh8zOxc43ZoxVZlrkM8mKs2ticbkLnc/JF9heKKzw15v5Bvo9PtjYvR7S0InczngouT9a8Asdz8inS9KVOzfBHD3B/LPIvQ7F7FmNobzBusy/yU6AysRKiyY2Xrp+Xdnz3T3V2pJ97u5clnwk6XFncALwHEWi4T7AgcAt3iyte7uzxTuqWlKNPSNwu3unvNzGlFOsoWrXxL5+6/k99/u/kjnhrjjSR3bFnWoc+X8WaIc7AJk38RaRBv3TPL7prv/u5bKeTVIZWdpYr3TQEKwOszdXycWxW5E1E0Qe6EMS53KvxPC6Dbu/uviM7so+G3GGyzLzUnlaldiQOZgdz8YeJ9YH9SPWHQ/jOiMZrN6exE6/kD91CXQaEFxVva3Ah5w96977MXxR6LzvSpRf2wAbGdm2xGzK6cA49z9P50VxuJ3mQaCxhPqqD8hZlIvSOk+OJ1/391fIFQy70ph7gM84+5v1FMeVYo3rFXL4rYp8Jq7b+6xnutkQhDckvhehwGbmdkIYj3IccAPPNYJxoNam05dMYWio3oHDSodmfrRjsRo5E1E5dG/hXuze44mRurmzl0rqVeno0kaLgssnP5fD2yd/q9HqAA8RXRudiNGv/6Y3P5KMzr5QJ/0ezwxhTywTN73JaZtPyMavn8BP6x22lSYfstQwXQzsRj2eULl6lZCWKr7NQ2EQDCoAn+XEg3+H4gR4YmVpFutHlnZTf/nbikuNF7zcTvwEbEm6D/k1g711IPCuhZCoPor0dlaKaXTksC1qW04MruP6JwdROhBH9HSc2v9IISkK4m1GfMTa2CWIFRxniYEzHWT35WImboX0jGyVNmsp4NQyfpF+n8KMau9FA3rV8bk/H6TGFj6F3BwV8WdUBFbOf0/i9hoD0I97AZiLcNSqQw/TpjIvZrYAXn1aqdxF+blUcCF6f84QiCYn5h9fwc4Lud3DKFy/ibwfx3y/mongI6uPYiNoY7NnQ9uwW+TSiI1JnVZcXZB2hYXci1ObEizF7Fo9XlCP/TPwHuE1A9hOrU3IchNBI4uPpfmF7O9CpzWQpiyTtXmwC3EiOyAaqdVqbJWiOOqqdF6KqXhkObuS7/9U0PzY2CZUmlVTwehV/1i6syMLlfmCAsw/yNGUZevdvjbEN+NSpVLYqTxJWBSlg7N1Uvp9xBCNW9z6lhw6uS0nh94m4bFz/cQ6m0nkQaHiPVWRwPzlbi/LgeNCOHoZmKEdlD6vh4mVG+PzvnbLfd/ROEZdVef5OrI7wBXpv+ZhcQZwOk5vzvQsCZooVLP6cBwFQXaQYRBlu+l8/sJa4CHEu3lJHKDKMD2xBqNP5Drx9Rr+WxlXn4LuDj9P5kwHfwB8KcsLQiLYFleLk5uPWp787LqCaGjc4/UoToO+Ho6/y3REds2/U5OBW94iXv75P7X1ehSLRzE6MmDwM7pfFJqoM/OOknAPKnBXqrE/VmnML+weiXC3Fx2bQdiJmGZCsIzNP/sWmkEaSwIDUjHscQ+BQsQMzMT8uEvdT9pZidzq5cyW6IBXYPYvG3v1txP7AT6lVsdxf9bhOWweXJu6xBqCpcQuxT/OnUemnRkS5ShRXL/u20nohXpu0aqc4bk3K4Bfpz+b0mo4mxAdN72JdaL/KTQ2aiL8lSI+3aF8ydJVgBTuzid1LlKbmcTMy9LFu6ru3JE7L2xYO78CBoMbqxGdMxPzF0/nJix3alacSdm5c9J/48k2sup5CwkpXBmlp96VSOcVcjLLWksNH0XuD39X5IYlPxh7vo3iEG34kLpDmn3q54gOjr3SIXqEkIS7UssJDqbEBrOJjqerwGH5u4pjpyfTSyGq4mOZq0ehFrNlcByObffAlen/0sQo8J7J7+7EzMGvytUCk0aaMJCzF2ELfUnCHvqmWWre4CrWghX38J5TeZjKmevEzMyD5FGvIjR4weI0fRSo819SrjVZBwLYWzOjN62hJC5ePpmv5M6Ac2prhXzt+46ePl8I8w+XkaoHG2Uu/YEcEEL9/YtPKfmy0AXpekoYsOnyTRYcPsZobOe+TmCECbuTB2OnaoR1g6O9/qEGdXDiUXOEFZ4rsr5uYJQb7swtYN3UhAa6vVI38vlJItrhAD5EQ0j0nsSQtIUYvbhGXJmu7sgfIMJNZtdc257AvcR5kIXJNSRziQWsK+Qrk2lMFBWz3VehWl1H6ExsGM6X5RQK1w+nY9N7ea9RD/hdWJxe+eEp9oJoqMTMjU6Hmvlznch9APzuor9c/+vB/ZK//PqImOJadyHaGa0V0ejdF8yfbz302A/eT9CVzbb92JnQl3sZmJ68ZslnlMcgV4lNQK/JEYM9ib2JshUnZZNDeRmhfvyedmbWN8ypAbSqdFsAKGidRwhQG1BjD5/TOMR0t8TalzL5tOp8JwdgU2rHb8W4j2sGfdDien2fQgVkZXT9/oXQk3nFuDvxC62A3P3NVIbJOln19uRymYvYqOpXZLbNoRO7p45f2uncr5G4f78zOg8RIex244+NpeGJdzyZaNvqpuuIdZXHQbcU+KeZQvndd0hA3YihPCrUhk7hBjMmS9dH0KMvu9LbHJW9/GmYTZ6kRTf/xDGTeYn1gN8M+d3ELHB6Fb5ckMXCN3EWoWTCRWbkamMbpXKaNZerki0ddcTsyE/rXb6VilPBxMzsA8T6yHnIwZX8mp18xEqn18v3NvheVn1BNHRzgwsPdp6HzGSkm12NITYVOxqGnTeViCms/6eCuOw3P2bEp3afxIWNKoez1o5KumQEKpHU4m1DTuRNlsr+FmscN6ruQqbsHCyc+78WGLk6HFgleT2W2L2ohdNO5RHAJ8SixyrOgpL407eRoRgdRYxJb1t7to/gTNy58sTagZHESpgeYFh3XTtFmpw/UYK4/4pD7JZIkvf5SRihPdHxOjgvSl+A4iZljWS/y2JUcFMxS2fjpsRAsYl1EGHp7lviJgF/RMxMzdPKheTaTyTMAl4KntOoZz/gFggvmO149iFadnseo/iOaHieDgxsv699M0s2sw9NS94VRrGVJ7uJQYkfgI8Wib96iHupcJdsm5P7cUNhLrfjTTs31NK2OzQuFfyPGJd2tVEx3g+om1btOBnYRrPytd8HrUmL5vLu3Q939Z9i2j3j0ntRpaXpfqBTdw6LMzVTjQdbcy4xqPJ8wGjaRAKRqSOxC40WODZlLCScHQ6349Q//he4bmLEeo0x1c7jrV0FD/slhpsks1rkt4hoUe7ct5PLt+y0dZ8fo4mdPp3T+d9CMsyywB/SxXGfkRH+Re5++6msU7rKEJX/gpaWARfhbScJ8Xxv4QgsCZhCSJv1SPTu84vdD6enCCb0u8qYhH1GtWOVwXxfgU4KXc+gtyoLyHMzyHpHdMwcrgU0eBfQGOd80WJmatnye3uXstHofyvQ4z2LpA7v480M0rMHNxB44WrgwlrOPlOxA6pvvs9rdwBtZ4PGgtNOxALnpeo4L7jUjr/mzpUyylRF38HWKHMPQsTgsPdhB37dco9t1aPQr7vSwjMLXYSifb/llS//LQr4lvu+TS0l33St/4mYXr1GXIzjflnUUNr8zoojYoz74fQgqXL5G8MMTs/B/h1VcJd7YTT0c4MDLNpXxB6be/ToHL00+SW6XYOTB2Xp4gp/340VWXJOiqdJqnW+0FYRXqTli3dZJXcN4jpxC+BzXPXexGqAr8q5MGg1AH4kFBn+pxYIJzppB4H/Cnn/6nU+G9dIgy/J3bPrGqHkqYjmXMRgtTdWZqkhuMkwvZ23u9fKaFOka6NSvmwTy03JOm7yoT3HYlZh2Hp/NtZfhKdmveAc3P3rkmYG/wolYd8h+GY9Ky60EUvNJBLpbrpLWIW5Q4aVBPOJFQTRqS0Oyr5adLBTeXmHkKNb6lqx7FK6boE0ZH4EzC2kjxI6boasYlnZh66Zr+hFuKzTIr3Eykdmhtxz+rjQYRa4HRgi2qHv51xXzLVHw+SU7Eqc8/ShPBwNRWYeO6gcC5AaC8cV4HfzOLgFzQMHtRduWxDGg0mBIZniHWPzc3I5uv/RYmNZC+hCoOCVU80HRVmVNNRlmGE7fbLSaMnRMfybmIR6VxEx/IMYhZhh+R3LI1HpWtetaEWjlQB7kts2PbtSvOKENjeIC0+zzXeaxX8DSNGwi4mjbITwsXtNKyXuJHoQC5KbPr1h2IDSFLrKNXR6qp0Sr99mitbxNT0HGKhftaoL02ozP0o52+p1NDl1+Nk6TeIGja3SdN1HEPS71QaFstvlNLhTWLviRWS+9cINaU+xKLor+Wekze/2rcz49BR6ZAPe2okpwC/Sm4Lpbj/OZ0vmq7/INVhKxEGB4rlvF/6Xa6z41ArB6VVS/ZJZeiOUmnezHMyQfZ3pHVStX4U6xJCWLoLuKkNz7qTBpOfNd8xLeY7YTThUmLGdqsKn5HVm/sTG2N2WtxzdfpexOLn31BmFD137wLELOo19ZI/HZCXFxBqxk0GAFt6BrGQ/KGqxKPaCamjgkwq3WBsQKga/bPgfh7J8gixiOYGYoX9K+Q2sdHR6vQelTp4z9OgZ96i0EVSKyH01y9J/4sC4EbA4ul/tr/DgNz1a1LF2ys1lpMJlYQ7s/tKPbcKabYk0fG/uOC+CjHC9UvSxlLJ/W3ghHyap07QOxTWf9TDQaxDaWL1iFh/8TdgQjpfmujoZXsSXAfcXygP9xKDAMUZwZoV8suVP2JE7VZiZHi7nPvhqczPIS3uT26P0TAj1URArHZ5r3Jaj6Tx4M9VRGerpKnaQhnKC3IPkRaj1+pBY+H7K5VOYrbhRmKdxrzlygQ5QZ5QAz212nGrIO7FtmJoLh2+ScxMZ6a+m9X5J2dEItU//8jSrKPyqFg3EeqoHxDCzRrlwpiPL6GycwtdNCvSVXlZ+PaG5P4flNIpm2WpNC8XJNRUF+nIsFYUn2onqI4KMyo+xB+QdP9SQdyfsJiQt3G8TXLrnbtvw8Kzemyj28o035ywWJSN0J1K6AavXua+rxpoYrbnOkJ3szjasCahr31aOl+aUE/aIudnFNGRHJPO5yOtl6ilvCRUoy4quI0mZltOJdYnvA6cl659k9h8aLGc/4UJIWPrwnNqeiEcMYr+VPYd5vJ+nxT/ccSM0jzJ/XfAE+n/ooQVrtuIjtC7VDCtX0sHjTt3xc7OKqns/wnYOLn1IWYabiem59cnptwfzN13Fo1nWmqinFc5nTciOn1PEyoq5yb3NYgFz9uUSieabq64CLHI8i3qRMWLWMx9TypHI5PbNwl1xm+0cF9RWNo51Tu7VDtOrYj7LoQRkztSXTo8xWsi8JcW7iuunVuRmKW5mA6arSyk7cqEQJepHe5HDLatV+4ZhXCeDkysdrp3Ul5mA743ELt3L0poJfwh5UvWRjRZU1lIo8VTm/EXqjDzXvWE1FEiU5paxVkqNQy3pg/xJ4S0uWAqbNfk/K6cCubCJZ6rtQuVpf9qREfwOWJU7qqU1osQgsNRlFiEWeLjHkmMpL5Bwy6t85DUiFLlfxwhWKyX3H4GvFR47mWpYpm34F7VDjWxu3M2q3JeVtkTVn6MUJPL6+yvQcw0bJbOHyk2ENWOUxvS4KsFfiWuTQK+U+oe4BMa1NeGprTZg7Rzb/7ZtXrQWGBYDPgj0bHZLstLYrBjDnByPp0Idcpbc/dflvwdWO141cJRouMwNzEjeUQ6X4SYRc5MMv+e6EQsUrgvb31rSUJIfYIatT7WTFr8kphZ2JKYLbiW0O/vncrcb2hYy5cJ7cW6eEfg58SsbZOF0bV6ELv/Ppu+lw2ITvUDxBrFTQi1vgOS3/z3mM/3lQlzpj8G1uyEMA4gDHC8Tcx8PUHqfxDt5VnNlbdCOAcTapqfAvtVO+07IZ1GAi8QVg43TmX3GsJM7jbkTObTuP+XT6OFCXXpY6lQtakzjl6ImsGCXu4+x93dzLYws10Iiwg/dPftiQpzFcJW73vEuoVNzexaM9ufWOPwODFy2Qh3/7LrYlMfmFmpb+AA4Dp3X8XdNyBG+X/m7m8TFfDWREcv/5w+Hsw2s6Fmdhsh1N0EvODuz5rZjwkB8C9m9n13n02MMn9MjE5DVO5zmdkxuccfDRzu7h/l35nurwpmdjChgmXJaRKwnpm9S6ilzEdagJ/8m7s/Rej4H5XuOQw4yMxWyp6b0i97Zj1gEN+WmW1sZkeaWX8zW5jo3L3VyHP6vokO9W/MbD53/6+7P+XuV7n7Z2bWOz1zTldHpjVk4TOzs4iR8N5Enl9jZuul8nkFoXa0SOH2ZYAFU5r9lBgFHk18M6Tn9rj2KZf3Xri0NDETeV46P5QYUPpvOh9PLCj/hpn1yW7K6nwz+xXRAX3Y3ddy95mdF4u2kQ93Ou+VvqNVgO3d/U5CQFqPUGObTQy6LEoIBqR2s3euLl7KzCYT5ep5d5/k7o91ZbwqoVTc09/1gGvd/QbiO1qGGNhahpitu42oQ4e4+5zsvlQfzWVmE4nZqRfc/TR3f7Kd4Sz1TY4hhP5l3H1HwsLZhWY2APg/Yp3WWoXnZOU8K5+nkjanI1SULm1POKtJFrcS55sRmw+e5+4PEDOvo4m8fIiYVdrGzIalcvxVXqbn/JQwU96bWCN2e5dEqAQ9rmKuZVJlNyd1PCYQ07BHEJVen+TnFqKR3tTMViUEhcuIUYXliA7mUSUaHpEj91HOKbgvSEyx/i6dn0ioCz2bvJxHfLh7JL+k52Qf95nAi8DLxNTwEcD6ZjaOUM/YhBhBO9jM9nD3F4np42XNbBd3/5xY+HxO1pi4+/vuPquWOlLufqG7j3H3z5LT9kQD/6a77+vuHxAjR/OY2cq58vgg0NfM+rv748D67v584dk1X3ZzDd9sM1vbzPYC+hOC33B3f4eGzZXyDDazBd39fEKIGlp8djUFwtZgZoPM7I/EmoRV3f0gdx9HqNYdnLy9RewIvouZLZ0bvHiAWPtxEdE5+qm731NoMGtacOpI0qCRZXlvZvuY2YlmtlbqgH0K3GNmp5vZm8To5TLufrGZLZYGkS4hBLQ5uefuZWafEiqXI9z9uC6PXBlKdJDWNLN+Kf/nEELT4CSgPkHMsO+Z7rmVGCTbwMyGJrcsDX9FdK6nufsC7v7HLo5aWUrEfSszWy5X9jcAPjazfQkLev0I9bLniQGn24lNETdNz8mE+WOI9WJDiHIyrp3h/GpQs8TlA4C/uvv/zGzHFJaPiRmQKUSn+AdmtlB2Qy6P9jSzN9I9q7v7c/U6wFniG87KZDYQtlryNtrMXicEhvXd/TF3n06sWxxMrIvL5+UYM/s3oaq4vrvvV/U2wmtgCqcnHzSdkv46YZf+/3JuTxNTlNmi3JUI9ZkfEXsGbEBMcx2drjfSbdTROL3zaU6MlvyK2G17keR2FTGy9SoxFbxics/2ydiX6Nzn1Up2AD4j9FCXS27rAAcSi5/mAONz/s9O71mGmKr8BTFqP2+6vlG106qZ9MvWzmRWbb5HdGLWJEZU/kqDCs5qxGLur/TViUVvh1c7Hh2UFn2JKefXgLOS202ktR6EesF/UtnIZl+uAo6pdtg7MA2OSHHaJOf2S8Ic9MIpznMTU/JXlrh/ydz/mlbN6qL0nI8QAKYR1qQeSXVDr1S3vEHOBC+xzu1nLTxvN2K0vupxqyDuuxEzKE8RQvWuhGrnlUTn+FoaTBnPB+ydlSGaqnGeRQzI1MU+FYRg9yQx6PQsMRg4gDDpPSeVg7Vy/g8hOphGsmSXu7YxsVZs4w4KW17lazWiL7Jjrk4/n2gP7ydmG7L1eFl7ugLRKR6ae85ixOj5S6T9irrLQRiAuItQ3bo/lds+NKzrew3YMud/L5KVxWJ5JdrV+8jtEF0LR9UD0FMPCusYcu5LEtYSrs25bUPos26Q3QOcQKx5WDFVrkelAjYsXe/xiwnLpP98qUGeRggJfwPuTNd+TXT4Dsz535mYhZi3meetSdrqnYYO5aupARuQ3vPTnP+liJHZo9L5LqmyX63aaVNJec2Vw78Rutf9CPOZJxKLGLMFctsTnemHiU7PdZSx/lKLB6FfXTQJei+hPnBwzm311DDslM5PSXG/PZWpq8nZ3abOOss0XeC/NKFj/uvUGbiU6OhkKkonJH8bErMP25eKd/G5PfEgBhgeJVlgS27rE1anNieszUwidonfgFjT8AZpcXDum6y3MrUk8N0Un82I9WQ/TPFejVDLup+0X0EqS08RHdZ5cs/JW12aq6vj0ca49yP01W+lYeBv9VSHnkZoEtxGtFHzEkYW7iRmblfKPaeR+edOCGdvooObzWw9QsMI+fFEn+VXOf+LJX8l9xEiOtd1ZQSiFWl0LWmQkFjI/gIxyLs+IRBmFhbnT9/z38kJhelaTX/DVQ9ATzxo3AHbIFWMq9Fgg38c8FbhnmvTh5jZyR9E4111V00VzNHVjl+tH4QgNjWlVzZyvgAx2nVEqqwvJDq8WxEjXl+ZS8s9p4kZuuT+N6IDMDbntiehbpDf8fYYYhp3/VTp1HxjR6ha3Uta9EvMfr1MGhFJjd6NJEtRyW1uYkRltZxb3Qi2hIrZ9cRI254pf1cgZgc/pukeHecRMy3zpjKySCpzq9Rp/K0YXhpbPNqVGLSYTXRqM8sgPySEphUJYfoc1U8tpvPC6Vu6j5xwTXQ67kn/VyAEtUuJmdKa38ujgnjvSgysPFdwv40QDvoSbeQ/CeHiNdKAS70fqd05k9jDJ29Nb29idnZNopN9DTHo8hzwiy4O4xKE1sP1NBjxWDadTyIGjK4gOsXbEoNH7wDnkrP4QzcfHEj1/XkpL3fLuX+dELRWJawh3Zvy8/mUZnVndrbqAeipBzHifR2hn/lXQj3pu+la71Q5npjzvzyxA/F2hefkdwMdVu141cNBzNDcSkwLL5dz/wbwbvrfn+gonpsa6iZWIWg8hZuvIPcmZzUn534fcGnufK7UaCySc6uZkYZc2eqVGu9fpwZhHCFcZYLuL4ip2UVSOTyQGG1uYsGDTh4Z6+D4f9VhBr5DLN77kJzFD0J95Dc0nkUYnL7f4yiYyqMZYbPWDtKARvqfL+c7p+/mLmKmafWUTj8lhKX8d7ATIUAPSed138ntxPTORsq/Rxi3yJtc/gaxlm3RnFu36pAR1rjuydcZxNqXj0gdK0Jffw0aW5mp+W+pgrivlr6T0wvu/wL2yfKYEDLyAmWX5TshqM4gWcRLbsOJWdTliVn1HxLC7E3A2tVO1y7Ow6ydWJcYlDyj4P48aR8jov+xAI3VNOvqG66ZxZbdmWZW2R9IjFYu6u7bEXrBu5vZTh4LX44HxpnZEACPRbQ7uPtf88/ytIDG3We7+6udHJW6J1nc+B9h3vQdYhSAZMnnOeDfZraWu3/q7j8ippGPdPeZxXz0WBg7zMyuI6xI/Dwt6rucGJVew8wG5245CtjHzNZL93/u7id4WGvKnlkzC0JzZWsO0TAsTmxcdoa7/4NoyCEsuiwOfDOV3fuIBfzLlnim11IcS5FbsOg557kIfdyriJG2jB8TaxjWT/eau39MrGH5yN2/yD/bw2JarcffCIHgZ2khd7bYb11CfWIcMYr2MhHP4cQI2kfELBpmtgphOeoJYqYNd5+VrvWodidbWFrGW/atnUMIYgea2fLp2hLAe+7+n8yzu39RXIxZj+TS5QZiw7CdU/mDGLx5GOiTFuZO97A+9qXVgeWxXDzK8TzRHm1vZsvl3P9F7OtDyuMP3P1DC2tTXZLvuTbvROB9YHEz65vcPibqxOHuPtPdf0qs39rJ3R9P4ewR33qurXiCMEm7uoVlucx9GlG+AT71MHjyepZG9fYN94hMrSaFVfa7Jss5s4mO5dGpEtyH6IAsDuxlZvO7+1XER3lZ9ix3vy17ZpdHpE4oV1FleeHu1xNrEHYzs83SB74KocP5TM5/Zhq3F8m0aO5dKxDT6S8TqmRbApPMbBAx+rI9YVEpM9n5JLFpz4jCc6ryHRY7NCUE3FXN7AwLc6lDCeHhIDM7xsyeBi42sx8mQexnwPFmNsLdXwK+7e7XdGF02k2uI5ZZs9gPONTMlnf3cwlTyAsRCxOzb/shYjT4O2a2aNZQuPuv3H1idWLSPlIcriUMA/wMvqpztibWAV1LzKitTAjeg4iFnQ8Dm5nZ3YTweLe7f7uU8NRVcak2qVPgnjOVmdwb1eGpjsm+v5OJGa6LzezCdN7kW0rP9aJ7rWAFE6OlyA1OPEG0ibsC55vZhsRM3hvu/mGxzNR6RysNUHnBrWS7nb6Pu4j1Knea2cFmdgNhJfGhnL+sbpnTUflerPNLhG12KsOvEabfDyPW7wF8QcP6vcx/Vnf2rodBkkoolUal8jLX15tMzM5cnvp8vyVmzx6BxgNS9ZpGEhw6mdQgLG9mfyNG5+Y2s/mAR919eipUPyZW3GcLaMak2/ckNq1p8syuCX39kOucz8k6gMm9SRnPVQTnAmsDfzKzC4hRn2s9TJ9azv+qhN7+wHS+jpn1I8y0vuDu30+CyNbE6OABqSG8k6ho8zbsD3X3C/PhqUbFUejQDE/hKDbGCxHps4W7v0AIPbOJdQ7/Ryz0/aGZrZDidA9hWQp3/zSfD/VA1hEzs0XM7FxCjWx74GELU6KPERZP1jazDXLf4Q+JvF+7+Mx6in/+W/Ew73kesFUurgsCi1qYhvwvMTK+krs/TKiy3Qo4YU1keXc/KT23xc5JdyRfH6Xz8cC1Zna4hSliL9ZNuUGNGwn11XcIVbjF0kBSXWA5G/0WJnv3NLM1W/CfpcMlxCDMasTeNRPd/VudHuAOJBf3bLDwCDM7xMwGt9Rup8GWicBMYoH4ZMLE8ZudFM5skKQSASwL90mEGua1ZnYGMUP/GPB6CUG4pgW7SrCGmee86dg9zGxAqbzMCXbPErPSnxFqy+8B63pojXQPvAb0pbrTQenFsqcDPy/hvhTRIV0tne9BTHVdTB1anqmFg1CPuIfo9C2Y3JpdiEro1t5IjCY32Q065+95wrLFS0SlMA/wLWJUNq8DPh74W/q/ODEyu0PhWU0Wm1YprQbTsGPvOoSFj5PJrecghNorCfvRxfsXTPEfXu24tCMNsnUcmS7qN4jd2U/P+bklpVNvQp/3akKgX45YvPk1oqNc9fi0MQ0a7bKbcx+Q4jc1nY8m1mT9E1g25+9Q0sJOclbHUnpVvZxXOW1XSHXRFKLj9QQN5npLtRXZWofViBnRbXN5VFf6/ITd+ZmERaTpJOtPzfjNvr8DibUzY4ppUk8HsSndE4T1o2nEaP3q+biWuGdxoq/wl5xbv04IW36H6VHErPl4kglwcmtIinlADHC+RpgBXq/a6dxFeTmEEOT+RWgj3EQz60lz5XhxYqD4ws7My2odmnHoIKwZncuktvItQp2BNFKdMYuwh7ylmf2c6PROIKz3fNgV4e4umNlwMzuasIJ0BdFo3QClZ2hyo1wXEBXD3KTRcjPrneWnmc2V/D1PqKhc7+67eajnzCQ6UtvmHv03YF4zW8jd3wI29Ni07ys80f5Ytx2LXaxfIoSGIR6b0HxBzCQcm/N6RfrdwczmMbP5zWw9M/sZMTr4CGFuLntuXdQp1rC5XqYqkeXHi4Re8ZI578cRe1Xs4jFqdCUhLGQ70L6V3OtqhiEjFcfZZra0mf3SzMaZ2UYeuwv/Cviame3psZnTFcRGVLPNbDUzu4OwRPZeetZHaTCzl8e6qx4zO1qcWTGz0cSszUhip+NTiI7xPma2ocdsX6l1U3O5+9+JAY0fmNlSKY9qUqWhWObNbEEzu50wL7u9u48kOsQnWax9aYkrCd35TSxUQSG3oV0tUiL+lxGLif/s7hsS+1P0Jnb1HujuXqqeSO3FZGCAmX03OXf4Zmip3A00s4OAnxDmQIcDV1qoGH3Z3AyCu19NCLRruPsjKb5lVdLqhRJ5+VNCULjd3ZcjZpbnBfa0tP40f0+WtykvpxJ9gSPStUYqm3VNtSWX7nYQlkROJwpYtkHKXwidb0j28GkwWXgQMcJyD7GzZ/acuhpd6uI0LtqSX4FQk/gXaSSUUJ34GDikhefMlX6PINSKtqGp2clsBGEXQm3gbBo2aRtK7O1wDSEgAPwJOLPEu2pm5JXQTZ9DiY13iIW+M2lsbvMYYuRsM2KR8E9SmV692nFpS9wL53sTKgIHZdeIPVLezOcZMcNwB8myDWEVbWhXhLmD4t1i+SMWO/+Hho0JHyXZWScWRv4j5/diomP0BC1sPtbdj1zdkB/BtVy9shChDvkqjS0i/Qb4e4nnFeu1JQgjA2tUO64tpEGp0ekFiTUy7wEDc+73pe+olIW6vKWknQid//06OrwdHPeSMyGprZgDHJtzO4SwothkI69C3BdM39tt5DYY7chwEqqz5xF7Q2UzWv2J3dwnNhe3LDzEGoeXKVh4rOejhbzcIeXluEJe3kFhX5/sObl6YSBhgvoqupkGSdUD0F2O9OFNTB/Ub4jp2QfTtZ+na8vn/G+R+2jnyrmX3BhOR1NhioYO/FzEYsIPaSx8HUHoYs9buK83ual/QvC4haZ2tP9BzEhkO2GuQXQCdqBh/4flk5+nCcHlTmDxaqdVuTQkRlGuybmvRNqtnLAzfXHu2ihCmLiM6DDn96KoC/OiKay7EXq5ixCC5e+ImaQfEh3hB4mNi+YhOjln5u6dh7CKsTeNBYq6UMcBFkq/c5cKL6GSdGL6359YpPop0fmdl5hJ+0m63jfFO2+Ctu7USdqRlkeSTMwW3I9K6XQlofLWl1ABvJncZlfExk/vAkek836FMnUk0VnZihra2yXl+bwl3PsQaxL2JZm3JsxSfkLatC25bU7MTm6Wvzf3vx8haO1LiU5ZtQ+aUc1J+X4WocbTP7lNASbl/Awm2olfk8xwUjBPTAgM1xAb3LVbrYWCehuNhbj9iMGRb+fcNkrlbqUsv9Nvr8JzehMzj8fXQ93XTNosT2mhdy/CctwWNKg6/wW4teDvGqJflw0O9ymk0WFEnbp9qbqi3o+qB6Aej1KNJGGR52EaOpQDCFWQE4kNkC5NleY3gIsI02bFPRl6TONbYTofSmnd+kOI0c5bgO8Tnb1508d8QcHvP4DfZembrwQJFbI5xNqFbAZoEWKE/cb0ntMJ/dxl0vU/EJ3urCO2UHrmYsRituy9NVmh5hqDocRC511SYzYT+GG6NpywCvFtQlfzJ6kS3KrwrJoUGJoLF7APMX1shCrSPTQIn4sQqoO/Tue7ESNy+X0+VunMcHdCOmQjX0cS5jzz15agYXfvBYgZuwNp3IG9kQZ75PsRKlwLF9O6Vst6J6brn1J9n1/b9H+EyscmwBnEiPGZ6do4Yl1Uvn44HphceO4WhCD7FLnOdS0cRMfoYdJ6rVzZ2ozogN5AqOP+Ddg7XTsLeKTwnJtTuRpUKGtHEYvB76KEcFLtI4XvdGIUOYv7gqk+eZDYx+SpLE8JU9RzgE1yz9iNECi2Lzx7Z6Kv8BS5TTLbEMY1gT1LuK+dwnkVoQo9lBgIOY9YkD4k5/di4In0vxeNBbt1iIGzS0kCUj0eqT48j8YDH/Omb/RZYhPLhwkLchADi7NoLARvR/QttqKxwLAh0Td5jRoUfjssDasdgHo6aKrGkt+4a6tU2Ibl3DYnOmR9U8V7BtEBu5C0A7SOFtN7ArBxwW1s+rg3Jjr+1wI3pms7p0p8y5z/rQmTdnPn3DZKz5ieKoRsk50FUoXyDrmFfMTumPem/wsSAuAZhOWTG8mpISQ/NS0A0iA8nJIat6tIglDOz/cJwWw6Mbo0sKvD2QHxzDao65N+hxLrWFZO5SIrNycTI8B/omHEsD/Rmb65xHPrpqNMGiUm1iVkG7rdQXRUnqBhJ9jrgD/m4wj8EZiQzucHNq12fKqQfi0ZVsjK1wBi0GLP3LXdic7axsAyRIfs7GaeM5DocP+H3AhwtQ8aOshZfbFYCT+/Iu0Sn8rIIcR+Hv2IQYenSRtfJT9DaTwrvBXRAfs7MLLacc6F66uNVbM8KuFne2BKIR/fomEm6Q9Ee5QXMPMb+w1L+f4mqQ1qZ5j3AX5QcFs/fevHEOspp6ayugiwKTGa/p2c/yVTORyWc5uXaCM+AI6vdt50QDluIvQQAv8DufNsVvD4dP5Lmu5svnHu/3xEX+QD4PvVjnOnp2m1A1AvB41HR7YgVB7uJyxmrEDYM3+UNEJOSOtLpYpzo9y9jab8qh2vWjkK6VtUScqrcv06a6jS+arEItUDCOHs58AtzbyjHzHiM5MYUb+UwnbvxEjCs8D4nNtShNrGzul8a2KE6Q+lGpRaPwpp/V/CfCwp/fIjTPMCSzeXL7V4EB3eRYgR36NyjUYvYhH8jYT1sq8RQtMbqTFdNxfnLJ9XImc9qN6OFM8r0v/DCNWRvYl1DAMJSy+3Eh3bFUmWb2gQniaTRo97+pHq+Px3szVpnUL6bv5NUj1NbosSA0SHpPPvETOVyxae25tQYxnXmeFvR7znLpwvSMw+DUpl6BYa1u9Zis89wI+T2xHA/yi9rmFpwhhBzQhLhfA1mU0DDga+nv7vSQxKDcnVM0cBL+XKxZysfi08px/wC3JtWTvD2pylpsNprHa6GrGm8qfpPDOrvWK+TOb+n0jMNF5IHc8ypLgUy/IYYkPTLC/vITQIsrzcG3g3/Z8n5eWRzTz7fKI/0CHrUmr9qAsLKLWAu7uZZTbMxxDTlqcQowZ/IKaY/0VskLWuhwWMlQib5k/mnpPZ9a673QI7E09fn8XutP0zdzMbAbySWTAg1hl8mLv1RWL6ex13/xK4HRhoaXfm3HP6eFg1eCQ9/wB338/dP8n7ITqR1wNrmtnSKWyvETMMl6bz2wl98EPcfUYt2akvWrhoxnqH5/z9APilxeZlX6Y0zPx95O6v5Kzk1LR1E/jKQtDbxOzfN4ELkqWQOYTwNy8xU/gG0Rh+6u6j3P3RVNauBdYys7nd/Xl3f6keLEU1E8Z/A980syHufj4xiHEecKW7Z6pofYADPfbp+D+ig3uzmb1CdBj+WuK5PQozO5PQT+9nZvuY2beIEfLlzOzg9M1cT5guzjaC+g8hjGU7x18G7Othr/8rPCxPfezuZ3RVfCrFzHYCzjazudP5qsQgyu8IwwgziPIzLH8bMYMwKJ1fR4xoz8zXRSmNXnH35d39950fm9ZhZosTebpvOv96urQTYQVxfmIA6r+EepGn63cAcyz2tvmSNLNZeHav1BYd7+4/bmc4VzKzQbn2c4iZPZ+zXrU6MZOetQXPEIugl0jnU4j2cN3smR6WvbL24R1gA3c/2N0/bU9Yq0Xqt51PCAKZtTOI2bGvm9lAYlClF9E2ZFavngXeNLOVPawobkP0NfLPztr+Y1J/4LMuiFL1qbbkUqsHpdcx7EVInTfm3JYhRl3GEyOdlxN2zi8npmwPz77pasep1g/iQ76X2Fn5GzSoSbxBst5CjOj8u3DfhcA56f9ASi9czK9tKC4MHk7MHo1N55sQ6kk/zvkZkPwsC83PjlQx7YojY1sTo4NW6nrB75PkFvLV80HjGb01CF3T80iWaYgp50x3dW5ilOk2ooPzPnBqtePQjrivQthXz1SzliA6Mkem842JdS15dYn9ic7DZul8MULg2qSrwl2LB9EB7pP7/2oqS28SgxRZXfR++r8k0YmckNJ9DUINZaPCc2uivigX9/S7TfouLiIGwM5N7pcDV6X/mxLtXF6X/0Zg/2rHo51xH0io9zxO7MPwJiEk7UKs59iHmDW4gbCcs0a67xjgkuae28FhXZNQjRlBzLz/ONX51wH3JD8bEANtK+TuO5xkuCWdL1XtdO/kPB1IDIpMJm1YRwi226b6f5fkbyoxQLhqOt+f2BC20/Oy3o6qB6DWDgqbcxELi/rnzu8kFnBlFUwfwpTj9YR1nyHAlunjrFnrOrVy5BvodH4PoSf6H9JaBWKtyKys8iMEs8sI++jLE3qkexWfW+JdpRYG/4YYVTmrEKZjUgNYk3rdqdH4PTl94eT+jZR2DxMdlz+28IwsPdYjpq+bWJmo14MGIXEzouPzAiH07Uvo62aWTRYiOtx7khYL5++v1aOZ8n0vOdOBqXH8A6FWl6kfXQ3cXbjvGmI2bcnmykhPOmisqjE3IXC9kOqlxfL+iNH1s9L5Nqn+up/oaB5d7bi0tkwV4r4gMZP+GUlvP7kvTQhSmbW5nxMzuVel3wepw85osf4jLDzNAW4ouJ+TvpdFUz18CaFtcBsxy7d9J4czn0dXEmsYPqdBH38JYnZ1x3T+Z2JwaE2iE/1nQgWppOnx7nAU6y1io9c5wB0F99+n9JiP6OtdQwiKVxMDSdn6x26TNh2SvtUOQLUPQiI/tIT7Kulje4UQFDILGWukArhhzu9RxJR+yc6qCl2zaV9soFdNaf0myYIPDQLaZNLaBUIF7LLUSL8C/Ki176RhYfDVJLNrBX8rErMOezcX5iqn3RIU7LsTAtGtWcOVGooPCf325nRgu42wUCa9st2fbyPU2Qbky1c+f+vpeyVnZIEQGm8mRtSydRpHAY/l/CyVOhXb59xGEYJyTZTtWjkIa2JXEiO6RgjiJ9PYCs22RMd6iXTen1h83y/np27KUwrv/IQu/zbEeoYrCUs0X5mNJWZW7iME776prjmGUHurehzaGf8TiDVzyxGz4FOB4bnr6xIzDd+jYV3HaHK7XXdSuBqtuSDULm8hVKa+VfB7EvB6+t87+budmDW7hjpcm9fGNDuYmDlYB/hRatPXzl0fTqhuHZrycjBhbv0wuqEZ1Q5L12oHoCqRbvzx7URuZChV/FlleVg634mQ6DPp8zJi1PtAorN2ByU2Qqq3BqOK+TGeEBhGpfPfE4uN8tOri6cGOr8AcUkazwaVTe9C3v8XOKhwfatUwRg1aBYwhfGrBoQYVc5UJ0YQliDyC5q/Tewt0rfEc4ojbHVRXlsTbhpmHhZOafEuITCuXcJvXcQ/hXUIYSjgslwcdyJ2uf4eoZN/aCofn9DYQMNJwIfVjkOtHMV8J0aS7yNmcDYnWc8jzGm+SAw25Qc97iSn+pFzrztBjLCm9kmqg9dObscRnc2tcv76EDrgJ1NiQWidxn1LomN9GzEbbYSgfTFwYfKTfWvjiMGsbUo8p1MHYwhh9f7UVg0g1qlNofE+Uf2JWaHx6XxAqgOXyfmp6VnVdqbRuoQBm8eJzS2NEAT/lOrNrzRLCBWvuylh1asey3GXpG+1A1DVyJdex7A8McLwMY1HGX4ITEv/B6Tr2WY/f+rsyqI7HCUa6IGEOtDDxKjnwsl9fWIUYH8am1H9NdHZL05DZhu6VdShpEF3+QDgg/R/CWLWaDqwRyXPqUL67UVah5Fz+x0x1boYMRNzE7B5PtyEKla+0S+m36+Bg6sdvzaUn4rXceTu2Yecxax6Poi1CPeR1NFSGb6bWKy6EaE+OY7Q2/1V7r5svc4yhefVRDmv9pHStYkZ3nTtL6m+n4dQ2dmSGMDYsivD2EHxLH5PyxKDYJmFsayTvBghoJ5B4zVEe6b6p+5mV0qFk9iktYkpTWIzxHtJdvkJwXIwYVFxWBeGuTcxU/4mMZOYzXL1JYS448lZr0r5M4eCRSsKG8PV+9FMXp5LifVqxGDvdcBO6XwIoe3wZxo2vqu4PempR9UDUJVIR0X4exrMyA0hVF4y01x7E6ZVxxTu+wjYOv0/gVi0u2DuuqTT1uXDxqT9EUpcO5NQI1qVmG3YN7mXGuFp78LgDwh9xl9WO01aCOdgohN4LzF9/jmhHrA9YQlo/9SwXE+oEWQ7Wi5GjIhmG9jlG/69iRG2c+iAnUo7Ic7tXsdR5vl12TDQeNZsTWIQ47h0fh4Nm9itSwjatxEdvx6/d0wznYw+6ftZM50fn76jvsX7CBXGB4mBjc8oseFWPR1EJzgbsDkeeDqXJvlytjeh7vJbYmCtTd9cLR3EbNzGuXx9g4bOY99cni+c2qN/pDbp82p8S4TxlXuzMCa3LIz7E8LDaoRgsDuhyjQm76+7HinOG6b/ixEzy5lp/LyK3aKEOer7iAGA96jD9TjVPmrezGB7acZM4eeEnu+mZvY1d59OrLY/PV2/hTBbNsrMvpaeM4jY2fFDAHc/E3BCHUDmVQuUMgOa3PfNmbabDxhsZvNm9+TuOxv4kljc+SLJpJy732Zma5rZ75P5TDyrOcy+YWb/IbaMvzHd+9X1QjgyM2qZVZk13P2YdK1P0X+1cfePiTK5IRG/Xd39SXe/lVBF2ppQmzuX0Nu8xsx2Ixq6T4gOJO4+x8zWNrMHCf3P9dz9ex7mAWuNd4Hz3f3ZzMHMhhLhHuvu6xN24nc3s8NaKHNN3JM5yCbloh7Ilfde7v4kcDSwjZmdSqj4LZ7qtUcJNYYRhIDZN/+cWjIj3NmY2fZZnpeI91BCKN88nc8h6p6h6d5e6b6lPczW7kMsCB7q7ld2URTahJn1Tb+9i/E2s2UJ4xDHJacXgdcz08xEh4tkrvIKom5ZELjd3b+Ve07NlqNkNrVJHZD6BQcBtyRT3S8QawUys6S9U54PJuqh/yMWRE8jdN/fzz2nM8O/ZTKLC9EGDqYhX76qw9z9EmIh+5nAF6S1N+4+KV2vy7ouT84scK+Cad8+RD/sIjNb3N3/TQhRa2Z+Ul4OJKyDnUmsBfucsKD0WvbcLotMvVNtyaUrDmJaObMqkkmeWxFqRpkOYD9CmDgwne9MSPd3ElZnriD05eanQdVlF6KRWaLacayVg9AnnCf9L6oODSJG8n5LVILbEFP/m6br2dT48sQIwhBis70FC8/plIXB1NDC2GLYktuWxKK8B2i8a/laKV1/kEuf0wmzieMLz1iCWE+yYWeFvYPi3ynrOLrTkS+rxN4yTxCL/ybQMPpm6TtbvdrhrWI6rZnq7uNybpuRWyBKLP69LfldgBDSj8nKWUrfP5KzvFXr5YsYKf+QpjN2mWGAXsQsw3WEMZC1Uz3y3YL/Q0kWAqmjDUyJQZPzaKy+Myz3f0lCtS/bDG08MYuZn2n6LvCNEs/ukHwn1Euzma4ms77pe746hXUFwmrVqIKfRVLbNYRYpL1+tdO+E/LyQgqmUQkhNuuLrUn00c5I5ycRfYt8O/lNYLcSz67pclyLR9UD0CWRjAZ1YvqfrxSOJfTa10jnxxMqEJmQcToxwnA5McI0OHdv1qk5utQH3xOP1OA+AVyQc9uQ2CAnO98pfdCZHezriZGsbFpxe2Ih3oqFZ2frGLp1hxKaqF3tT+jYDsul8USSrXAahK0fEOYQt8vdm2/k+xTdavGgh6/jKOZXc+Wi6J6+je2IUbQ5zTSQNZ33nZiW86Z6+h5g0eT2NHBTzk9fYhQyM626WypnTxGDR/+hsPapHg6i05nZ9O+T4vh90tqxVG/m98E5OtXhvydG5F9J9cqQfDlqrjzWwkFjYwEv0KCOlKlbbZZLj28Qawa+RnS870x5fgoxQDONho59h+q+p3L5e+CunNuCWd2WzldM5fawdH4xMfORxWEJYgB0ZOHZ3WIdQy4v1yZMsmft/R7EQOF66bwvYWr7YUIIHpbS5QVi8PCmlM+bFPKy7tOoGke3nprJTaEeB4wxs1XcfVa6tg3R2VqR6Jzh7mcB/yOmJSE6tX8H/u7u33f3j7OpX+LDxN3P9dpU86gGHxP2obfO7Vz5PeCqbBrQ3W8ibF5vS3SCTyJmhK42s9uJRuxWj6njPN8kOn5zPH3xwFnAsWa2GKFa8BCxYDGbxv09sQB7VPaQrEx42iHZzH5tZgd3XBK0nUwlIv0fmXbvPYEQcG9L5fd9YtZhGTPbyRt2c76IiOsS2VSuh1pS9v9LaNi5vBZJagHDgAPM7BAz+9zM1iTUzuYmZlxeJPJ6i6SO4yn//07YM2+kNmhme5vZa0Sjc1mXR6qVZFPwufK5tZktWLyekfsWcPe/0mAVZ0jx2bWc951Brs75iFBHfJ1IH4hO8VZmtnbyM4sQUHcys23c/XqiI3IcMRCyqLtf1cVRaDM5dcvDgHXNbPdUpv5GLJpdBsBDDfBeYLiZbe7u5xKGQGYQs8f/5+57eKjzku7J18G1SL6t+TtwqJnNRaxbnAmMNrMBKT3uJgwFnJniuAsxyDAPsUnocA91wK++tY6KeyqXVwFuZgcm592AO3Pt1AvEgvWdzGx5oj34BLjUzCYRKjnvE/maf7Z3k+/dzKy3uz9OzCj8MrnfT+TRJmY2JH2/DxBC3wnu/ioxS3gR0cd7htin5j5olJfdIY26nmpLLp190CCx3kJIoMsRi7teJUYb9iAEhF2Svx2IEbtsg6hxxIxD3VnN6Oo0Tv8HEVP6t6bzuQhLRfvn/KxNfORH0yD5r0HasKbE87v1wmAam3ZchVjfcTZplCm5307MNCxCdArPJASlVdPvSsBC1S4LHZAWOxCd/LdpPHtyFtHxX4wQBK8jRpd2S2XpehqrJKxNLGK9k9BFr3rcmolvhywAz9VzvYFB1Y5XLR1E5/lmQuB+gaS2RQxSPJHzN5iYubqOnEW93PWanKVsId59iFmoi4EXc+4PExaSBqXzZYmR9UuA+Zp5Vt2pcxCCz4mpLvlmcjuUxu19b2KDxBmUMLzRWflOwwxwb0IYmErSaCDWW56X8zs3oWr3E9JCX0J9ei8KltG660Golu9O9M12T26HEUJVfobmdGJmYY+cW16ls66+4Vo9qh6ATo9gw4ZfixCLhr4gRlGy60sSqjIXkaZjyVnKSNcnZx9tteNTywexaPUeooP7OQ3rDX5A7Kg5KNfBeZYYAdq2xHNK6fd36w4lMUq2PjGi/stc2vUHfkFYcHmZhjU4S6V4v0DO1Ga6VrNqBBXkc49Zx5EL6xoFt7as17HCb82s16ly+p5AzHCOJGYPHgMuT9fmIyzlfS+db07olJ9DiU0h6+kgLNb9l1BV+jPR4crW8+1A7EM0Ouf/bqKd27rwnLpT5SAGVqYQ6mhHpbj+nVifOIgQGH9FgznTU4gO6G8Lz+nU7yfVaX8h9lx5J1cORwOzabznwpWE1addSzyndz3mU4VpNJAYHHyD0F54nWgj+xIC1F8IIXhY8v8jYq3SBTQWGAzVhx2XL9UOQJdEskF4OBF4KefeN/3umSrNUYX7sk7uxhRsIetoksb7pAZ6U2Jk4C7gydz1F4kp4PlThXk5oRK2VIln9bgOJTEN+wS5hYmE6bhHSbrYhG7rfTTo3Patx3JZrMDpYes48mGH7rtep4vTslSd0YvoJH4v57ZrqkP2SOd7EypuzxAqH002garlg5wuO407SmeSRq1T2foWMZgzX3K7MNUlvyZmLH+er1fr5aD0XkybAA/nzuciZpezNmJzQuf9AULAeJA0S92F4V6T6AQfRwx43UUsfB6erl9NzDTOQwhCvyDaufULz+k2neFm8nJNGs8KDiFmFH6SzrckZuNvS+nzGLk1lTo6Ka+qHYB2BT4qzbJTqIUK9QPg2PQ/q3DnqcdKs0ppXrKTQpgInZg7H07skfCjdL4poZf4DKGj+fWW8imd95gOJTFjMh04Kud2AHBD7vx8QsVuL3IjytTR6HIhX0YSiy+fI2aqXgBWSdd2SuVlp5z/hYmR+ENo3Omu6cWaJdJAC8A7L213JQnW6fwxGqv8LUyo5NwMzJXcVgR2LJTNmq0rSoWRGJnNrNn1JmzU/zR33YiO8mW5dNgj1ZuHF55b898Sjdv0XsByufONCSF70Zzb2PT9ZPs0LEms5Tih8NwOVclq7nnEmr1bc+erEDPImRGX/qk+vI+YLfoRJQYNusNRLG/kBhMJ4yp/p/Gu2LsSa1WWSuerE7s//5xk2KYz8lJHLo+qHYBWBbahA9ho2omwRPA1GmYQmlT6uXv3JhZAL1rCj6azKs+LMcTeAZlpvz8SC8yy63MBJxPTxNko11BidGWunL9e+d/0v6d2KH9K7D0xfzrfNTUaOxGjKr8jWZGotwOt48ji2K3X63RhOjYaZSfUb14nRpD/Raj7zQ98B3ij4PdawpDDj0s8t+5mb4gO01OEEYGDUvk5m1g7s2CWXoQZ7Dmkma3m0rSWj2J9TszEvUZ0sC8ndP+XSd9Pfl3dSulbO58S6zjo5E4mYf53JA2b7Z0APFjwcyjR5o1K50sQ7eXwnJ+az6N25OUuxCZ79xH7i2yU8vJ2kooW0UdbhWTsopnnSmDo7LyrdgAqDmiMGBxZwv0XwFuEjuIdVDDlmCrZHaodp3o4KHS+idGcfxIdn0eJUZJ1UwX3ATGSkzXQZ6SGqskHTm5xWM6tx3YoUzz7EwLTDqmCNEL4ugP4XcFv3QhEhbLUo9ZxNJMO3Xq9ThekX74+ykbZLwUOSf8XIWYULgYGpDL1R8IAwyopHQ+msLak1g9KmNhM382dhDW5/Yg1GqcQA2nPJ7fM9OoEYpHtmYVn1EVntPjNE2sBHiKEhQUIi1nvpP+/IASJUcnvnoSZ70kUjAd0dF1CY6F+KKEG/Xr6fYQQIOZNdcDInN+9iJH0+0s9s57rvJbSKJ1vQGgo7EgYsDmaUEnqRQyY/YGGGditiTUMz1MQAuulLNf7UfUAVBzQ0KFfqOA2JlWaixDTzdcS0mrJTiQNndW6G1WqUprnK8BsFPznNF5cfj7wWPp/J6GbuTuxWc31KY82Lfce1KHMwj+GsAD2tZzb3KXypN4OetA6jlz8etx6nS5K1/40LCxdHXgruc9LCAzTaVjHsBqhkvMIsXbkiGqHvw3xzdfF6xImmoelNMhmYzckZlvuSOffIwZ47iAGy+4CFqh2XNoQ97yguBBhyCRb7P675L5E+k4+JWaghxNt1dvErPV7dPImiIVwZn2NA0mqten8dELYWS79/xcxozyQ2KzuJHKj69VO+05Oo37Azwg15m8Df0juc6fveg5h8WsE0S94i5hV+x+wdrXj0pOPqgegokA2LmxL0KAec1lW2NJ5H2La8oB0nq9sm6yHoJvqDHZw2vclpP3JxAj/88Sofz9iFuAjko5sypuziA7RW8CJFb6jx3UoW0gLI0ZadqepHm9dNyT0kHUcWT4WznvMep3OTlOiozU+dS4GE7MKdxGWZ/6b2oVsJmLl3P0r0FhNsm7KUwrvXIRa2hOEStIyhMne5VL9+C4NQme/9LsMcDiFtS/FtrAeDsJE8U8IK4gDiJHo7xMd8A/TeW+iH5B9TxsQazm6bMdrQj3uJWJA82EaTMEeQajI/ZYGgy3nEYLd2+m7H9iZYauVg1ig/ov0zQ4khMFTiEX87xKzQwskv5kK+paEgLFA7jkaBK5G/lU7AM0GLEaU8h2MPsRU853AmOT203TMk/N3GmmnzPy9uf8LA+dWO371cBBTwZnefaYrey8hRPw7fdzZ+oW1aNhxe7FCnrTYQNODOpQVpnvdjQq2Im7ddh1HLo49fr1OJ6fvXakDtk86X4zoTP6XxgujjyQGMorqDPXYaZ6XUOF8Ddgv5/6X9P2cScO+DPMDx1B6HV/dxT2FezPCROlfc9/Efinut9HYdOkp5ATvnHundjKJkfGDic7wlsnt58QM8tOEKs5myf1rJCEh5Vc+/N36Oyf2ZPhXyrdsIGTblJePAGvl/B5OCbXyzs5LHS0ftbxz9PrAPmZ2kJmdTqghPUfoCm5kZgMJ1ZZVk9+MLwg9zq92z/SGXVgnECPmi2c76nZVZOqUXYkP9y13f8/MBhCV4saE8PYNd/8w7Xp5JDHCAvAfd/+fmfVOuxZ7Sy9x938TozCrmtn8yXk6sLOZ7ZR2lDZC9eAKd5+dPTP/v7vgsTt0k12CuwmnEiNHG6b4/SW5HQW87O7fcfdHoP7in9vtdY6ZrWJmZxPrE37m7qu4+2ZEx+97ZrYIIYQ/AIw3s1XN7CGiE3GAu//Bczv0eu3v1tvpZOlLzDa8TIxUZvXHdcTC6P8zs/3M7F6iTE129w/zz/G0q3gtYWYLt1TePXYZfhBwQkUpS48zCVXO25LbboQlqaWIOjR7frYjec3FvUKeJNapLOvuntqVS4lv6BlgOTPb0MyeJNYH/av4gKwf0BayXcjL1EnbEYJCX3e/M93zDLAyoT62prvfY2arEQMoy6VwfeDuL1vQqwd8588RA8ArZHni7pOJgaPngdlmtoKZ3U2sbX0jf3PK+zbnpegAqi25FA8aRhPmIqbu/keoqCyX3HcgTBXuR8xCXEg0GIcQU5kvA3sVnrk/IXDcC6xY7TjW+kHDNO+yxCLDc2kYGViS0CGeQujQ3pHSdtd2vrNbLwzW0Sj/uvM6Dq3XaV/6VTQiTgw0XEqavUlu8xPWan4FHF/tuLQizmMJtcwlm7metYnzEjMo19DY1OiBxMDabURHdY/ODnOV0mkNQgX2mzm3ZQj1viuJfQ+6JN/z32Yuf/qkfLiYtHYpfd//R6wxOZBQTfoAOLna6VnlvNyMUOP6Vs5tAULwuiZ9D2dVO5w6Sh9Zga86Ztbbc6MhZtafaFCXBa50959mo9dmdhahA38isejpUMJ019cI29U3pGcYoVd4GqHjeX1XxqmWKaZ3C/6OJjbUudDdb01uRqgSLQl85u4/66AwjQH2Bb7j7m8kt7nd/bP0v5e7z+mId4nqkcrPG4TljOs8VUJphM69ViqlNmBmVxC69Be6+2+S26LEor633X0nM7uUGDU+yt2fNLO+hE76zGqFu9pUmvdZHWBmKxBrRP4MXJTVEcmP5cpUH6/x0ck0k/sYYYLyAnef1YLfLYn27hF3/3nh2jLu/nLuvObryxLtfrMz1GbWDzieGBhctXBtHuALb9AuqKh9a0U45yf2/7jF3c8vcT0rl7sSC9fPcfe/5K4fRuxUviQwIWvfuhOtqb/NbAhwGKGitKvHjFp2bRDxoE/SeYfmpWg/VVdVyk+hmtkAM9vezIa7+6eECbVTgF3MbM1cgZxELM7dm+i4nkNM76+fFxqS/yvdfT4JDUGmopV9iKkyLuUvm5LNLFVsbmYLQaoZ3C9y91MzoSFTC2snVxAWUtbLlYvPcmGu6UZQVEb6Lld392vzjYx3D3Wc7xGDHfm6dWtC3W+ndD6DGORYMambfOnuMzPVvq4Nbm2Q5b2ZbWNmk81sneb8pbrgn8Rs6DcJK0N5P57UPmpepSF1imYSs7qHEkJnS9xLCBkbmtla2TMAMqEhrzLXWeFuL7n8ydqhZeGruqGkSpC7f0EIip+Y2WnJX6a+9qm7f5mLe5s7ms18g72JHbj/W8pPltap//EqsH0Wp+R+vruf7qGK+UZ3+9az9jl9e4tkql3N4e7TiRmy94mN+PJpOsPdPyn2VUTtUDXBIStYuYriBMKazA+Bh8zsIGKxzBPANEKHnnTPE8TU30Y06AnOTM/pnX+uu7/bJRGqE3If92ZmdhewQynhIWt8U/r9hVhLslvRX0c20N28QylyeDddx+Far9MmzGyQmU0iVE/vBf5bwWDEbwlrNO8VL6TBjZpMy1RlZm1vlve/IwTKA9MMRMn7Uuf5bqIju366t1HHqhY7Wma2rJl9M/3vleWPmQ0zs78Bd5jZ5WY2Chra7xK8TqgCbWpm/bK45r+h9oY1a/tyYc/awRnERo3NxTHL018QA2DblSrDKf7d4lvP97fMbIiZ3UqoMV9uZsuVuf05YCqwmpnNm8tDreuqcaoiOFhuCtXMdk7TeJsBW7v7JsQU1uHAVu7+GqE3uHpqeLdOow1nECotz+efXYuVZrWx3MIuM+tnZr8h9luYQugZluu83UAIcE8XL3R0A91dO5SiNN20Yei2C8A7gtwocZ4VCGtii6eR2Tdopn1KnZRe7v6Ju+/j7tM6NcAdSJph8DRzsgCwYC49TibMMDc325J1qB4DjvUSKjO1SCrjm5EWdSenPhaqqYcSaxY3J7QIvmVmKyZPTfI/9RsucffNkhDVUeHLnx8CnGZmyyenrPN/A7CImQ0oVW/lZh2eIiyoTS81oOY1PBPUWryx5sJoYlH6tsDiwFG5vGxuBulyYh3YR10VZtF+qrbGIY2qHEfYYT4ReNTdH7TQXT0X2IbQKRxH2isA+G66/SfufmF6TlmrPaIBMxtG6AZ/PU0XYmaD3f3j9L9Relod6MkKUWuY1us0Ies85GaZh2edfjPbnLDRfznRgdyDWDB+E/AXz+n952ars8GnutKBTunwa8IQxJuESd6feKirXUXMQhzh7k1mUsysbzEt6qEclWhXhhH5+yqxI/BbZrYBsSbxdXcfX+IZvYE5ufLTqDy1MVz5Qcy1Catn2xGGVhYnBi8/TNePIGbddwQ+L/Vea1jrUBf50hbyeWlm+wE/IjRAvgYc6u7/MLONiL7dVODXxbRKeen5NFJfrn6o1ozDMMICwnBgMXf/VRIaDiAsKN1P7IK5FSG9zvZYx7CTuy+TCQ3QbUcs20WJEZSVzOwKi0VHnxPWOf7PzI4ys2eAiWb2gyRANBIaCs/p2wXBF6I70OPX66R653AL09lfzU6a2Xpm9hQwycyuNrND3f1uQmhYF9gCmEDY7f8uYQgjmzHtnVQY5pjZ5mZ2LrHotCYpURcvTFiKW46GTbBGEJZ3IFR11yfWlPXK3dcrdUZnpfPNzGyReilH/9/eeYfLVZbr+36SSImUBAhIPb/woyT0FpQSCL1IEySRXqUEUEB6j3IQCAgKHJoooIcDwhFQWuhdFKV3NBRRkN5BIDznj/db2SvDDiEh2TOz93tf11x7z5o136w1a81a39uetxz32STdIGmI7WeJff6UaOaG7XuICPhiKilL1e+lMg7LOGtK2mBqRLvLebS0pLsIxaMT6VBAeh+4UNLwsvq1REO5Oct2dBYtrH7rn04ksta2aMK0pMGKQvB1CGnZZ4hIWd+yzt3E9ziE+M7GpzXXjuWnkpaQtF41blfvUzJlNMVwKBeNZ4BliS7ESJqFsOa3s/2fRD4hhHU/f3nfo2XdbvWDnNp08gOcneixsIftF4mC8xkJtaTDiaYrWxB1DJ3doL8h6QJg8S7biSRpY8pvcGn37HqdgYQBsEy1QNJ8ZdlZRI3aacBZklZ1qFDtafubtn9PyK2+S9QxVIbHOEXx5RVECuvYzjzzrUC5hjYe64+J/drQ9jNEx+PBwM6SlrL9N6IA+CDi+6PhWjxU0tNEWlPLprmp8/qUT4n9HVWen1SWbapQRYJoLvoasGcZw7XjPlBRl/drSm3IFGyXGv5uR0hDX2v7G8Bxth8uUYYtgEeAEyR9m45+GavBhPdZdfSMGqeo1zmTCftLtS01g2GcpNklrUNEBH8L3G/7QtuHERKq2xQHJUTGSF9gC0kzuYNxkmZRKNDdQRSdJ21EM1WVRhIFXvMAOFJlViCKddck0pVOAA52TWKurNs2YelmIGkGSTtKWqIsuo+4GW0uaRHbvyNyZLcs/18DvAM8BRPcoPtLuoS4mD/hyN1MkuQL4B5cr1OiKtcSXtqRKopshO7+zLbPsv0+HYpIC5S//RTN804jcspvdC2XXdLxRIrLv4ABtn/aBbszSSRNX/72bphEfk3SoYpavt5lQvpbYPrijLmYKPK+hUjZBTiamKRO3zDOlcDlRL+PNYoTqCVxKBxJ0ghJQ8uyNwnv9CBJw8t9/GTCu79IWeevRHOwy2x/Unn2FXV5DxIT1XkcDcOmZLsaDY5NiAaNx9Y+vzLWXiHScH5GHJt9ifSl98s642sH3SEDexjhFJ2PuO+2Pe6oY1gGeIzooXUmIaldF1Y5jDC2livRsWeJLu+PUb6zMs6RRErYx0Qvn8um/V4kUxU3sYkEERY8F+hXnm9CnGh/I3I8q/V6XCOkyfgOP9MwCViY6MC4F9C3LBtEqFGcW54PAJYnmlS9SeQX96qNMYpQgzkfmLHZ+5mPfOSj9R+EM6p+HRlI5LEPL8+3I1KStiMmHrcSHWQhvJMDgXMIqdVFGsY+nWhwtnCz97Nhu9Ym+nT0aVj+DcLDfiXwMjH5nLO8tgUxQZ6uPL+G8L5v2cn4u5Zr9DmNn9Eqj8b7EGEMvEykHb9CNK5boLw2Cniotu5NhJpW//K83lxtEGEw3ATMOxW2cx7CKTkHkS72AdGNeoJ9aJxzEE1kLyvH6BedjLsF4Xi7F1i+2cfjS35Hjfveh4i0/I4JG7btA7zasO4FRAfouToZdyBwD2FQLd3s/czHlzhHmvrhkS7zNFEkVnUrnqNhnTQaOv/u1HCBXZNQrqhuTAeUm+9KtfW3LxfhFQhv1g+JMO2SDWPvR6QvLdkV+5KPfOSjPR+163bj9WgJYI3y/4+IlITZgbmAt4F/AhvU1t+aaIgHoa5ULe9NR9f66Zq9vxP5DhajdEEnDKeZiO7gvySKayEMpcuqiVf5Tq4kul1vSQhWbEPU/FXjVvs9DFiw2fv5OftfP+4zEilo1wAblWVLERKyB5XjOV+ZYB9eXl+rfBezdDL2XMCgqbitvYnu09sDKxJ5+Ot/3vq1/xck6lPWbVhnCBEh2rbZx2IKv5PKudiHiXRuL/OJfwO7V8e8fJePERGbar35y299nk7GmA1Yudn7m4+pcM40fQNgp3KizdawvNMTOB+f+f5mJaICrxL65w8SheXTEV6Co4GvlXW3JDxXt5TnM9XG6VW7UfXqqu3PRz7y0V6PMmn4ClHIu1rDazMSOfxvE6p5s5QJyWPAQWWdI8oEbHiZjP2GiEps3DBWS98D+KxndiFgvvL/eYR3ekjt9Z8Qed9zE6qBVxPylWOBtSY2bjs8ynG+kZBJX7A6LwgP/yVEWsoYYFhZvkuZiA5owrauQqSGrQ38hWjaOEP13dfugxsCi7fDuTiF30NvIvp3e8Py6Yj6k9FMmPnxR8Lg7Vtbtm45z790NCgf7fNoeudoYtL7fduv1xc66xg+gz6rcrQtERZ80fYchOfmduKGPT8Rkh1KFN7NVP4/gUhPwva7ZZyq+O6TsrwtlDqSJOl6HHwMfEJMJursRUQz57F9MvB+ua6cCOwkaZAjn/xiYGOiSPp9YAlHQXT9c1rqHlDVMZT/+9iuF8fOTeTvn1gW7Ul4oeudoC8m0rG2sT0G2ArYxaEUeFMZp20kKWsFxpsSk+8ngWNsj7V9u0IZ6R6iHmVhInqwmaR+hDGxG/BqrVagS0RPbN8FfEQYOH8CNiXundXrVe+F4WWbJzgXG7ezjWuY9iD2b6NqgaQFCefjgkRU8BBJZ5WXjyLO2SWr9W1fTxhh364PnAI23ZumGw7lJtQtioimFZWGmSfUPO5N5M8uTnj5KDfz/yJuxJvavoZIV1qH6Lg5gCisu7I+fqvdoJMkaV1UZJltj7b9b0lfK8sFbEZ4MN9V9ByonBHnEykiIyXNaPs8YAcip3/Hsn7LTjaKUswrktaHjsllUYmCmBxfCswvaR1HQffRwOiiGIij6d8TwKqSFrb9tu3byjhVQXXLGQ1FyWmu8v/4YljbLsfsIMJwGOOQHP5KORc2BU6x/T1HoexHRArb0rbftX1Buf9XjdO68j60K7A7kT72HjBK0u7A4oomsw8TUZRHGt/YuJ2teMwmRlGmmrU8nQv4iu23JS1bzsGVgUdsb277FEIOf4ik7Yqx+wjwXUmz1YbdwA0iBTmn6N403XBIJk7lySgXV5cL2smSViJCp1cTN6uh1fqOhkrjiAs0hCLEcGAF21s5mgy1q4ckSZImUq4xVS+BGSSNBM6QNIjwpr8OvAjhyFDo8Ff9X44CvkuHPKttv1X8Ir1adbJRtu0dwks+qizbSNJTwO8kHUL0IrgeuJ+IumB7NFF8e2BtuJ8RkrNP1z/DnXQYbgUUPZcOp+y37Y+K6tUQSfOWY1ap5PQr63xcJtNLACMkrS3pVsIzvWdlLDUTR1PGW4lUm1GEAXEQcXxOA84ok+eXm7aRUxlJ6xIqVrOURacAC0i6H/g5Idk+gFrfFIcE/i1EpAHCGN6WWnfzYiR32uk76Z7kgW5ROgmF70ooFsxLSKHtXl46EZhD0g619V+g9MEoKUiv2B6rjiZCbeMhSZKk65mYc6E4MHoppETPIopc5wSG2n6PMBw2kVTJbH8KLKzo03A38C3bf6jGqv62eHpkFQ34LjBY0kFEz6GDiDzwbxEe7LeICWj/cr0G+D5wuKQFyhgv236xjZw3LxB1GUtJWqUYSfcTvTjukbS8o3nfH4BhkhaqvXdXQjnrJ0Rd3cGNBlOTOYI4dgNsH0+kle1se1HbZ0H3SrmxfX0xhv5eFm1AyCDPY3t52y8Qv98XJK1emydcT5z3s9p+kMhmuL6T8Vv5N5xMRdJwaDFqIetKB3tvRYfG/kSI9zuEATG0hMQfJ6TszpP0E0mnEDUOVzaOXYyI/HEnSfK5VJMGla7PFSVVZ7/y9HDb9xKFzptKWphoTLYgcHrxyu9LSHIuUca9rozT8hPnyoNavOwzKXL2DyAKgLF9he3/IYq7VwFWBe4i+t5sJ2l221cBW9l+vj52qztvaumxnxDH70/EsR1IiG2sS/ToOFzSUoQBtSiwWpXOZPs5Qr1oOdtVpKZl5hy2PyDqUg4px2pcSamaoOlZEzdxqqCGGpKSubAZ8CiRmvSMpOo3fQ9RtL59iTZBpDpfavstgJKy1Ba/4WTa0DI/4iRwR+7sQEKqdhuimHl/IpQI0QToFaIjY1+iruFuQvbuHmAxl2K7JEmSyUVSP0mjgb3L85XLBGQ7IrXjftv/KKv/FJgB2LpMvHYjevHsQOS5b1R5cCtafeIMHR5URSPNO4immecQHvev1la9mJhsbUR8D1cRheNVh+FLunCzvxTFXuhdpccCFKNnDGE0zOEOIZPDy98NSyThZmAEsGw1nu0PihOsdzFEWs1xdT4hA/xafWE3MRiqY1l959VEfwci3eg92/dQBGok9bf9JNFba07gCkkPEJGJixrHb4ffcDJtSMOhyXRmtUsaQ+RaHm97JSLk+zzRcbN3uTnfQugib+XocHk6EWq90fazqimAJEmSTCbvEKoqq0u6nZgMDyRSVB4HvlKLjr5FSLCuKmk924/bPpBI+1jD9t0lvamlPZSVl71h2c8Ix83vbW9aFu9HOG0GARQD6hpgOWAz2w8TRd+Xd9nGTyGSvlr+ji/OdnSqXlTS9yWtUZxTNxAOq8G1dV8hvNbfLMOdQTi0Xm38nOLNb7mJZtnfbinOUjuWAyRdSGQiQNQazQGsV+YJFxNF+yeU991JqCTtDBxqewnbD3T5DiQtSxoOTaSxjqHGZcTF+H0A2zcSetObEp00IS7kLwMrSJqB0NC+Gzi7vOff03brkyTpTtRSGVTzuK5HdI6fzfbfbD9GXHu+wYSyjBcQ95MNVVRbHAXFdbnnlps4VtS97A157bcQDpnZauvdTnjgT6qt97/ENfpJANuvd2aItBKShhI1DFVqbHX8DyVqFlYgauh+SqTKngu8BBxWG2Ys8A9J09t+yfa2tv/WhbuR1KilJVV/v0tkLgi4TVLfcnyuJ/pULGP7TaIOZQNJQyDmD7bvs31tGafb1HokXx618LW8xyBpD6KJyk3VRVfSo8D1tvcrzxckQooXA7+y/U5Z9lx1k5e0JuH5G2p7bNfvSZIk7UgxFqq6htltvyZpSUKOcXng58WBgaQBRF7/NcDZtt8uywcDLzemfbQS9f2cyOsnEmka/wCOtf2BpHOIhnfH1q7PcxIRmbaILHRGiRw8AVxi+/CybDZCPeoHth8qKbNXE5Hs70nam6gLOJswOn5MKCWdXxu3VwumJPVIJP0GuMj2FeV5f9tvlCjS5URq8ymEJO2vgCdtH92s7U3ag4w4dCGdhME3lvQ8UcewC3CapG3Ky3sCe0taDKAYApUsWqVYMraEIitvwJ1EI6U0GpIkmSTVNal42odIehD4raTDSsrNeUS/mG2rtJaSonIJ0bNh5WqskqL0WisVwDZSM44mSOWU1F/SHUSd2FVEc7pfSVqUiCxUhb9VD4uXCXW7VRrGadkIQyOOerrvAQer9GmgdAIuRsM3CaPhHWJfAX5HRLY3IOR316obDWXcNBqmIY2/r/o5V87joyWtVDIRPiWa7m0s6SbgAoUy1qdEevP6RDfvj4Fd02hIvggte4HvblSh8Nrz2YjUo2NtD7X9dSKkuKukOUs4/Do6OpFC5BfvUwqYxlNFHGx/ZPuNab0vSZJ0D4rBMKuk4cAWwC8JHft9JO3iKIS9mtB+HwGRF+8odn6KkG9sHLMlJ44lc2iAQnluSFm2UDGIBgEf2V7f9mXA2oCBHWw/RaRnbQAsXY1nex/bB9Q/o5XTseCzKSeOJqE3EAYiwMPAGpJuIIyFM21/3fbjklZ2FEqfDuxu+7h2qV/pDqhD5etTSTNLOlfS/A3n3ALEObqF7Q+JLIV3iC7RNxGRwr0Ig+/3RMTpjTLuu/XPSZKJkalKXYiig+juhELHH4Hlbf+55ASfAWxCGA832q68QC8SnRnHNGu7kyRpTxpTc4oDY1zDOlsDvwbOt71zWXYwsDqhnPM4cCjhjX6YMCCG2b6/a/Zi6iLpOuI6uyjR8GpTYDFi8rxALfVzR8JwWEPRHfsGIs//TEdzO1U1EY3faavRyXkw0PYz5f/FgIeANW3fLuki4vjOU1v/TOJedEK9fm5SqV/J1EfSYUSB/n1EncLmwEOVQ7Gct1sQ5+k1xajr447GjTcBP7J9a6aVJVNCWpZdhKTdiO6aSxL5shSjYUGig+U4Qv/8dmAjSSva/hfRoKbpnTaTJGk/aqk5VXpjNSkerJDI7GX7IqJYcq7aW08HehPpSCLyoC8EpgO+XhkN7eCdVEfRb9XB+kHC69qL2JfnCSWg+wmpyopbCfGJhWy/RHS9PqOagFXfbasbDTDBebCTpL8CF0q6SNIwR8H7WRRhDcJI/FjSLyWdJOmflMajbhDdSKOh65A0l6SnCcN9bdvrlXPvBCJTYeay6k2EHPKI4qzsAwyUtKukZwjRlYdgfPQio0XJZNHyF/12o7MfoaR+hAHwHdvb276jdsFdDnjU9g62XyVSAv4FrAVg+0rbH+aPO0mSKUGhrHJD+X8RSfcAlxJCC5UW/7GEqkolMfoe0VhyPWB922/aPtP2jrafUEeDrJbxVpZUJDU+r03sq2vunwkVpMeBucuysUSTsx0lrVSWbUTk9D8LYPueUlPW8tfiidyHhgEjCQ3/fYj7zOVlcnkIMJekPRyN2zYhimffJyS/N7H9SjvsezfmFWBG4BhHB+eKI4n5wlLlfP874YBckMhW+JioZdgZONL2xu7oxZHGXzLZZKrSVGRiIWtJI4gQ7/8rN1y7o7nQD4g+DecQ3r23iDqG57puy5MkaXcmljYiaVciZ/8wQnbxT0QEYRCRMrmN7Usl/Rr4D9tDa+89H/il7dtqqTktl95Q3yZJM7tIwZbnSxJ9cZ4GbrZ9saLL9fmEksyFtt8vUZmjgGFEXvhsRMHoLV26M5NJmczPSNw3TlDIfH/SyXr7AhvbXqu27C/AH2zvrVD3+wnw1cbzqHxGr3aIrnRnJK1KdOleH3iXSHGem1AC+yuwfzHwFiYkdR8HtgbeqGoYyjgtn16XtC4ZcZiKFG/UdJKOlXS4pG+Vlx4D3pC0WPmxTgfjm++cQuTNrg3cWTw7z5XX8/gkSfKFqKWjVKk5fcpLfycmw3MA85Si1g+AFYk0hipF6WBg2eLoqNjJ9m318VvJaNCEBaMzSbqAmFhRrsXDCY/snwmJ1YskDXF0Or6BiKgsXoZ72fYewBrAIbb/f6sbDTCBx/jHkraqjAZJe0narUQUILpaP63SZ6NwDNEIrK+j4P0ZItownmKUOSeazcfRnO0tIlr4AqGw+G1CBWwIsHM53kMJdbCzgVfdUfhcRQrzWCZTTEYcpiKSlgCuBB4g6hlGED/cS4ADCNWOvWrr/wC4uoT++9Qu+OkNSJJkslCIKRwL3Gv7nFqEoC+RuvAgUV91FXAcoaYy0va9kgYUT+WJRIHwd2rjtnwBrKJg9AfAzYSx866k/YkIwom2jyvrnUXUNSyrjp4FTwCfEA3P9nGtS+7EvPethKL52r8lHUjUbqxJpKJ9BMwKPELcfxYg7kd7EE4qS9qJ8F5vZ/ujaqym7EjyhVAU6j9NRBfOrS0fSTSOXYHoMbJNqV9JkqlKGg5TQD1sW7+plgv3INu7lOcrE7m03wb6Ec1yxhI3t72I3NntHUXQlffMrX6TTpKk9SjXjx8SuczHEI2f3pW0AHAqka//n0Qd1S62f1PetyGwnO1jm7HdX4ZiLN1J5OLv0DDpX46QFH3Y9q5lWW/gTcqkS9E9eX0i+nKQ21QpqkLRF+h+4A7bJyn6UPwIeMr2EZLOJrzUdxAyu+cB19oeVRtjfG+PLt+B5AshaTSRuTCKSEOq5iCzAINt/7G2bssb/kl7kakwk0n1IyxGQ3/CIKgYQOSaVlGDu4kL9EjbVwPbETnFKwI/dqgi/Kt6s+1P8weeJMmUUK4fRxC1DCOB4yRN51ANGkDkQY8kPOx9JA2U9HPg50SKyvhJoxr0/luYesHoA9VCSfMS3vbzgKUlLQLjUzQOBk6W1M/2HcBRttexfX+7pIc2Hh9JW0r6FdEgdGNKIbhDovMGonB2LULG81oide2/iYj3qPpY5f6W96HW5ihCirUq5K/mJm9XRkMtLSmPZTJVyYjDFCLpVEIp6a9EBGE0sDcht3qC7SfKetsTvRvWLnnFjeNkWlKSJFMVSRsQk4uXgd0Ir/oI2xsqutOvBXyNKLDc29EJuS1pKBh9h5CS3YXQsn8SOAL40Pbutfc8Tjh0bqkta7trcambe0zSnIQE53xEE79PbA8v68wMnAx8DBxv++/FM/2h7Y/KOi1X8J58PiXNbGdgE2fj16QLScNhMpG0PqFpvQHwfSKn8DtEY6RjiNSkmwnN69eKR29slWNbGycv1EmSTDMkzU3k8P+TiC6/DXzP9vvl9f7VhKMdJ811FE3dDCxL1HPsa/uf5bXNgAOB40rkty1qFxqp1ayI6K1xGbAKsLntuySdR0S0r6YUxNu+vbx3M2Bf4CTbV9XG6g1kpLsNKefBsrbva/a2JD2LNBwmQr2OoWH5rcTFen/bp5XQ9jJEStKShHby4YSCxfTEBT6LlJIk6TIqx4SkwYRKzo/LS7O6JlVaX7fLN3IqMrGC0fLaisBwImvjwNrytttvSXMAM9l+VtJBRJH7LUQK0gjinn6EpP8iegSt4o6mf4vbfrRZ254kSfegz6RX6XnUbijjivLGQOA5R4O2PYic0Y8rr5WkB4lmOdvbPkbSfYQ0Wl/blzdrP5Ik6ZlUE2LbjwOPS5qhPH+nccLcbpPnzrD9UlFMWkrSV22/V4rCzyRSdPa3PbbhPW213wr57lFEVGVlotv3HESx8/rAwkQtC0Ta7CfA9kTqEpXRkMWySZJ8GdqiEGxaUSsE3L94pYCOG4qk3Qnt71OAP0gaVmoXfgNsScjbVQV3/YEXy/PXbY+pjIY2KjRMkqQbUSv2/WFVBNtuE+bJ4CiiL8Pqkk4h0kefs71ZZTS0S/FzZzi6eR8J9JV0HFGj8iEhsfoccQ9aQ9KG5RivB1zRyThpNCRJMsW07UV0alC7gPYDXqqWSxos6WRCD3tZopDwcmC0ogvpkUQR2qmShikavS1GSK129jltmzucJEn7Uos8VHKNau4WTTuK+MQPiT4Vg4FlbI+ECRRm2tposv06sC2RHrsSsBER2b6UuEdB3IsAbrT9Rnc+5kmSdD09usZB0vzAurbPK89nsf22pM2JnOBXba9SW38McJ/tQyXtDJxFyP0tBYy2fUWX70SSJEkCjDeMlq6kWbtr8W8R6VgD2J/ow7BJWf511zT8kyRJpjY9JuLQ6HUpz1cDDpS0sqTVgBuLEslVwEXA9JIG1t52IbANgO1fAH8hmgkNs32FCtN+b5IkSZJGSguCB8qluLftcd3NaACwfR1wBiG3O1DSfGV5peHfY+7tSZJ0LT3m4tJ48yjPbwduJPos3EV0VB1RtK2vIZoi7VF725vAQ5JmLc+PATYHViyF0u6ON6kkSZJ2olyKu22KaClwfh5Yl4iav1B/vd1TspIkaV16jOEgaR5JPy0RhSri8ALRPXMgoVJxGLC7pEG27yUMi60lnVrqGH4B/MX2WwC2xxBNdw6hdIxOkiRJkmlJzUH1mO0XU4AjSZKuosfUOJQL6/OEcXCJ7Q/L8iFEk6QnbW9Q6hieJJq7zQucSsjdPQDcUorQxjdMkvQfwCK2b+jiXUqSJEmSJEmSLqPHRBxK2Ho4kXrUW1JvSWcC1xGRhUp+dT+iG/TqJfx7JfAscLPtSyX1Kjro48q4z6XRkCRJkiRJknR3eozhAGD7LuAt4DKiP8OcRLRgR+B/iWY5/yDqHQ4tBWZjyrJNJc1l+9PMH02SJEmSJEl6Gj3KcCjsCKwKHGl7C9uvleV3EgoVxwN7AgcUI+Fl4DYiXWn1JmxvkiRJkiRJkjSdHlPjUEfSaGA6YFRpqFMVS28IfFKKnut1DNMDC9l+tGkbnSRJkiRJkiRNpKcaDjMCDwH7AtekhGqSJEmSJEmSfD49MVUJ2x8AxxEyqv2auzVJkiRJkiRJ0vr0yIgDjE9NWtb2fc3eliRJkiRJkiRpdXqs4ZAkSZIkSZIkyRenR6YqJUmSJEmSJEkyeaThkCRJkiRJkiTJJEnDIUmSJEmSJEmSSZKGQ5IkSZIkSZIkkyQNhyRJkiRJkiRJJkkaDkmSJEmSJEmSTJI0HJIkSZIkSZIkmST/B72JIwSXHGRJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = usampling_scale_data(df_3g,drop_lst,target)     \n",
    "X = res[0]\n",
    "y = res[3]\n",
    "clf = RandomForestClassifier(n_estimators = 30, random_state = 5862)\n",
    "title_label = '10-fold crossvalidation of random forest with (30 trees)'\n",
    "feature_importance(X,y,clf,k,title_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fd218d",
   "metadata": {},
   "source": [
    "- 'CN-CN': 103, 'CN-MCI': 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "05248ca1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After undersampling data size is 206 ; Resampled dataset shape Counter({'CN-CN': 103, 'CN-MCI': 103})\n",
      "\n",
      "5 principle components are needed to explain 90% of the data\n",
      "\n",
      "Output dataframes sequence: X_train,X_test,X_train_scaled,X_test_scaled,X_train_pca,X_test_pca,y_train,y_test\n",
      "- Using original dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, Training set f1-score:0.677, Test set f1-score: 0.623\n",
      "          - saga_L1, Training set f1-score:0.677, Test set f1-score: 0.623\n",
      "          - newton-cg_L2, Training set f1-score:0.677, Test set f1-score: 0.623\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, Training set f1-score:0.677, Test set f1-score: 0.623\n",
      "          - saga_L1, Training set f1-score:0.677, Test set f1-score: 0.623\n",
      "          - newton-cg_L2, Training set f1-score:0.677, Test set f1-score: 0.623\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, Training set f1-score:0.640, Test set f1-score: 0.593\n",
      "          - saga_L1, Training set f1-score:0.677, Test set f1-score: 0.623\n",
      "          - newton-cg_L2, Training set f1-score:0.640, Test set f1-score: 0.593\n",
      "       - C = 1\n",
      "          - lbfgs_L2, Training set f1-score:0.622, Test set f1-score: 0.619\n",
      "          - saga_L1, Training set f1-score:0.677, Test set f1-score: 0.669\n",
      "          - newton-cg_L2, Training set f1-score:0.622, Test set f1-score: 0.619\n",
      "       - C = 10\n",
      "          - lbfgs_L2, Training set f1-score:0.659, Test set f1-score: 0.694\n",
      "          - saga_L1, Training set f1-score:0.665, Test set f1-score: 0.741\n",
      "          - newton-cg_L2, Training set f1-score:0.659, Test set f1-score: 0.694\n",
      "       - C = 100\n",
      "          - lbfgs_L2, Training set f1-score:0.666, Test set f1-score: 0.716\n",
      "          - saga_L1, Training set f1-score:0.648, Test set f1-score: 0.739\n",
      "          - newton-cg_L2, Training set f1-score:0.666, Test set f1-score: 0.716\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, Training set f1-score:0.648, Test set f1-score: 0.716\n",
      "          - saga_L1, Training set f1-score:0.642, Test set f1-score: 0.716\n",
      "          - newton-cg_L2, Training set f1-score:0.648, Test set f1-score: 0.716\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. f1-score on training data: 0.684 f1-score on test data: 0.720\n",
      "          - tree depth: 2.000. f1-score on training data: 0.720 f1-score on test data: 0.716\n",
      "          - tree depth: 3.000. f1-score on training data: 0.729 f1-score on test data: 0.642\n",
      "          - tree depth: 4.000. f1-score on training data: 0.778 f1-score on test data: 0.606\n",
      "          - tree depth: 5.000. f1-score on training data: 0.842 f1-score on test data: 0.714\n",
      "          - tree depth: 6.000. f1-score on training data: 0.891 f1-score on test data: 0.690\n",
      "          - tree depth: 7.000. f1-score on training data: 0.897 f1-score on test data: 0.644\n",
      "          - tree depth: 8.000. f1-score on training data: 0.945 f1-score on test data: 0.619\n",
      "          - tree depth: 9.000. f1-score on training data: 0.970 f1-score on test data: 0.714\n",
      "          - tree depth: 10.000. f1-score on training data: 0.988 f1-score on test data: 0.619\n",
      "          - tree depth: 11.000. f1-score on training data: 1.000 f1-score on test data: 0.667\n",
      "          - tree depth: 12.000. f1-score on training data: 1.000 f1-score on test data: 0.667\n",
      "          - tree depth: 13.000. f1-score on training data: 1.000 f1-score on test data: 0.667\n",
      "          - tree depth: 14.000. f1-score on training data: 1.000 f1-score on test data: 0.667\n",
      "    - Random forest\n",
      "          - 5trees. f1-score on training data: 0.957 f1-score on test data: 0.738\n",
      "          - 10trees. f1-score on training data: 0.963 f1-score on test data: 0.714\n",
      "          - 15trees. f1-score on training data: 0.994 f1-score on test data: 0.644\n",
      "          - 20trees. f1-score on training data: 0.994 f1-score on test data: 0.666\n",
      "          - 25trees. f1-score on training data: 1.000 f1-score on test data: 0.690\n",
      "          - 30trees. f1-score on training data: 1.000 f1-score on test data: 0.666\n",
      "          - 35trees. f1-score on training data: 1.000 f1-score on test data: 0.667\n",
      "          - 40trees. f1-score on training data: 1.000 f1-score on test data: 0.694\n",
      "          - 45trees. f1-score on training data: 1.000 f1-score on test data: 0.691\n",
      "          - 50trees. f1-score on training data: 1.000 f1-score on test data: 0.716\n",
      "          - 55trees. f1-score on training data: 1.000 f1-score on test data: 0.714\n",
      "          - 60trees. f1-score on training data: 1.000 f1-score on test data: 0.691\n",
      "          - 65trees. f1-score on training data: 1.000 f1-score on test data: 0.667\n",
      "          - 70trees. f1-score on training data: 1.000 f1-score on test data: 0.667\n",
      "          - 75trees. f1-score on training data: 1.000 f1-score on test data: 0.691\n",
      "          - 80trees. f1-score on training data: 1.000 f1-score on test data: 0.690\n",
      "          - 85trees. f1-score on training data: 1.000 f1-score on test data: 0.690\n",
      "          - 90trees. f1-score on training data: 1.000 f1-score on test data: 0.667\n",
      "          - 95trees. f1-score on training data: 1.000 f1-score on test data: 0.667\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. f1-score on training data: 0.902 f1-score on test data: 0.647\n",
      "          - hidden layer size[20, 20]. f1-score on training data: 0.726 f1-score on test data: 0.691\n",
      "          - hidden layer size[100, 100]. f1-score on training data: 0.793 f1-score on test data: 0.738\n",
      "          - hidden layer size[50, 50, 50]. f1-score on training data: 0.988 f1-score on test data: 0.770\n",
      "- Using scaled dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, Training set f1-score:0.641, Test set f1-score: 0.600\n",
      "          - saga_L1, Training set f1-score:0.677, Test set f1-score: 0.623\n",
      "          - newton-cg_L2, Training set f1-score:0.641, Test set f1-score: 0.600\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, Training set f1-score:0.622, Test set f1-score: 0.619\n",
      "          - saga_L1, Training set f1-score:0.677, Test set f1-score: 0.623\n",
      "          - newton-cg_L2, Training set f1-score:0.622, Test set f1-score: 0.619\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, Training set f1-score:0.677, Test set f1-score: 0.694\n",
      "          - saga_L1, Training set f1-score:0.659, Test set f1-score: 0.644\n",
      "          - newton-cg_L2, Training set f1-score:0.677, Test set f1-score: 0.694\n",
      "       - C = 1\n",
      "          - lbfgs_L2, Training set f1-score:0.642, Test set f1-score: 0.716\n",
      "          - saga_L1, Training set f1-score:0.653, Test set f1-score: 0.741\n",
      "          - newton-cg_L2, Training set f1-score:0.642, Test set f1-score: 0.716\n",
      "       - C = 10\n",
      "          - lbfgs_L2, Training set f1-score:0.642, Test set f1-score: 0.716\n",
      "          - saga_L1, Training set f1-score:0.642, Test set f1-score: 0.716\n",
      "          - newton-cg_L2, Training set f1-score:0.642, Test set f1-score: 0.716\n",
      "       - C = 100\n",
      "          - lbfgs_L2, Training set f1-score:0.648, Test set f1-score: 0.716\n",
      "          - saga_L1, Training set f1-score:0.648, Test set f1-score: 0.716\n",
      "          - newton-cg_L2, Training set f1-score:0.648, Test set f1-score: 0.716\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, Training set f1-score:0.642, Test set f1-score: 0.716\n",
      "          - saga_L1, Training set f1-score:0.642, Test set f1-score: 0.716\n",
      "          - newton-cg_L2, Training set f1-score:0.642, Test set f1-score: 0.716\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. f1-score on training data: 0.684 f1-score on test data: 0.720\n",
      "          - tree depth: 2.000. f1-score on training data: 0.720 f1-score on test data: 0.716\n",
      "          - tree depth: 3.000. f1-score on training data: 0.729 f1-score on test data: 0.642\n",
      "          - tree depth: 4.000. f1-score on training data: 0.778 f1-score on test data: 0.606\n",
      "          - tree depth: 5.000. f1-score on training data: 0.842 f1-score on test data: 0.714\n",
      "          - tree depth: 6.000. f1-score on training data: 0.891 f1-score on test data: 0.690\n",
      "          - tree depth: 7.000. f1-score on training data: 0.897 f1-score on test data: 0.644\n",
      "          - tree depth: 8.000. f1-score on training data: 0.945 f1-score on test data: 0.619\n",
      "          - tree depth: 9.000. f1-score on training data: 0.970 f1-score on test data: 0.714\n",
      "          - tree depth: 10.000. f1-score on training data: 0.988 f1-score on test data: 0.619\n",
      "          - tree depth: 11.000. f1-score on training data: 1.000 f1-score on test data: 0.667\n",
      "          - tree depth: 12.000. f1-score on training data: 1.000 f1-score on test data: 0.667\n",
      "          - tree depth: 13.000. f1-score on training data: 1.000 f1-score on test data: 0.667\n",
      "          - tree depth: 14.000. f1-score on training data: 1.000 f1-score on test data: 0.667\n",
      "    - Random forest\n",
      "          - 5trees. f1-score on training data: 0.957 f1-score on test data: 0.738\n",
      "          - 10trees. f1-score on training data: 0.963 f1-score on test data: 0.714\n",
      "          - 15trees. f1-score on training data: 0.994 f1-score on test data: 0.644\n",
      "          - 20trees. f1-score on training data: 0.994 f1-score on test data: 0.666\n",
      "          - 25trees. f1-score on training data: 1.000 f1-score on test data: 0.690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          - 30trees. f1-score on training data: 1.000 f1-score on test data: 0.666\n",
      "          - 35trees. f1-score on training data: 1.000 f1-score on test data: 0.667\n",
      "          - 40trees. f1-score on training data: 1.000 f1-score on test data: 0.694\n",
      "          - 45trees. f1-score on training data: 1.000 f1-score on test data: 0.691\n",
      "          - 50trees. f1-score on training data: 1.000 f1-score on test data: 0.716\n",
      "          - 55trees. f1-score on training data: 1.000 f1-score on test data: 0.714\n",
      "          - 60trees. f1-score on training data: 1.000 f1-score on test data: 0.691\n",
      "          - 65trees. f1-score on training data: 1.000 f1-score on test data: 0.667\n",
      "          - 70trees. f1-score on training data: 1.000 f1-score on test data: 0.667\n",
      "          - 75trees. f1-score on training data: 1.000 f1-score on test data: 0.691\n",
      "          - 80trees. f1-score on training data: 1.000 f1-score on test data: 0.690\n",
      "          - 85trees. f1-score on training data: 1.000 f1-score on test data: 0.690\n",
      "          - 90trees. f1-score on training data: 1.000 f1-score on test data: 0.667\n",
      "          - 95trees. f1-score on training data: 1.000 f1-score on test data: 0.667\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. f1-score on training data: 1.000 f1-score on test data: 0.667\n",
      "          - hidden layer size[20, 20]. f1-score on training data: 1.000 f1-score on test data: 0.596\n",
      "          - hidden layer size[100, 100]. f1-score on training data: 1.000 f1-score on test data: 0.574\n",
      "          - hidden layer size[50, 50, 50]. f1-score on training data: 1.000 f1-score on test data: 0.673\n",
      "- Using 5 pca-components:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, Training set f1-score:0.641, Test set f1-score: 0.593\n",
      "          - saga_L1, Training set f1-score:0.656, Test set f1-score: 0.708\n",
      "          - newton-cg_L2, Training set f1-score:0.641, Test set f1-score: 0.593\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, Training set f1-score:0.640, Test set f1-score: 0.619\n",
      "          - saga_L1, Training set f1-score:0.656, Test set f1-score: 0.708\n",
      "          - newton-cg_L2, Training set f1-score:0.640, Test set f1-score: 0.619\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, Training set f1-score:0.635, Test set f1-score: 0.644\n",
      "          - saga_L1, Training set f1-score:0.610, Test set f1-score: 0.579\n",
      "          - newton-cg_L2, Training set f1-score:0.635, Test set f1-score: 0.644\n",
      "       - C = 1\n",
      "          - lbfgs_L2, Training set f1-score:0.622, Test set f1-score: 0.644\n",
      "          - saga_L1, Training set f1-score:0.629, Test set f1-score: 0.644\n",
      "          - newton-cg_L2, Training set f1-score:0.622, Test set f1-score: 0.644\n",
      "       - C = 10\n",
      "          - lbfgs_L2, Training set f1-score:0.622, Test set f1-score: 0.619\n",
      "          - saga_L1, Training set f1-score:0.622, Test set f1-score: 0.619\n",
      "          - newton-cg_L2, Training set f1-score:0.622, Test set f1-score: 0.619\n",
      "       - C = 100\n",
      "          - lbfgs_L2, Training set f1-score:0.622, Test set f1-score: 0.619\n",
      "          - saga_L1, Training set f1-score:0.622, Test set f1-score: 0.619\n",
      "          - newton-cg_L2, Training set f1-score:0.622, Test set f1-score: 0.619\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, Training set f1-score:0.622, Test set f1-score: 0.619\n",
      "          - saga_L1, Training set f1-score:0.622, Test set f1-score: 0.619\n",
      "          - newton-cg_L2, Training set f1-score:0.622, Test set f1-score: 0.619\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. f1-score on training data: 0.629 f1-score on test data: 0.738\n",
      "          - tree depth: 2.000. f1-score on training data: 0.685 f1-score on test data: 0.714\n",
      "          - tree depth: 3.000. f1-score on training data: 0.713 f1-score on test data: 0.667\n",
      "          - tree depth: 4.000. f1-score on training data: 0.751 f1-score on test data: 0.716\n",
      "          - tree depth: 5.000. f1-score on training data: 0.826 f1-score on test data: 0.475\n",
      "          - tree depth: 6.000. f1-score on training data: 0.885 f1-score on test data: 0.501\n",
      "          - tree depth: 7.000. f1-score on training data: 0.921 f1-score on test data: 0.547\n",
      "          - tree depth: 8.000. f1-score on training data: 0.957 f1-score on test data: 0.626\n",
      "          - tree depth: 9.000. f1-score on training data: 0.976 f1-score on test data: 0.527\n",
      "          - tree depth: 10.000. f1-score on training data: 0.988 f1-score on test data: 0.549\n",
      "          - tree depth: 11.000. f1-score on training data: 0.994 f1-score on test data: 0.501\n",
      "          - tree depth: 12.000. f1-score on training data: 1.000 f1-score on test data: 0.501\n",
      "          - tree depth: 13.000. f1-score on training data: 1.000 f1-score on test data: 0.501\n",
      "          - tree depth: 14.000. f1-score on training data: 1.000 f1-score on test data: 0.501\n",
      "    - Random forest\n",
      "          - 5trees. f1-score on training data: 0.963 f1-score on test data: 0.619\n",
      "          - 10trees. f1-score on training data: 0.951 f1-score on test data: 0.642\n",
      "          - 15trees. f1-score on training data: 0.994 f1-score on test data: 0.619\n",
      "          - 20trees. f1-score on training data: 0.994 f1-score on test data: 0.642\n",
      "          - 25trees. f1-score on training data: 1.000 f1-score on test data: 0.642\n",
      "          - 30trees. f1-score on training data: 1.000 f1-score on test data: 0.642\n",
      "          - 35trees. f1-score on training data: 1.000 f1-score on test data: 0.642\n",
      "          - 40trees. f1-score on training data: 1.000 f1-score on test data: 0.618\n",
      "          - 45trees. f1-score on training data: 1.000 f1-score on test data: 0.642\n",
      "          - 50trees. f1-score on training data: 1.000 f1-score on test data: 0.642\n",
      "          - 55trees. f1-score on training data: 1.000 f1-score on test data: 0.618\n",
      "          - 60trees. f1-score on training data: 1.000 f1-score on test data: 0.642\n",
      "          - 65trees. f1-score on training data: 1.000 f1-score on test data: 0.642\n",
      "          - 70trees. f1-score on training data: 1.000 f1-score on test data: 0.642\n",
      "          - 75trees. f1-score on training data: 1.000 f1-score on test data: 0.618\n",
      "          - 80trees. f1-score on training data: 1.000 f1-score on test data: 0.618\n",
      "          - 85trees. f1-score on training data: 1.000 f1-score on test data: 0.618\n",
      "          - 90trees. f1-score on training data: 1.000 f1-score on test data: 0.644\n",
      "          - 95trees. f1-score on training data: 1.000 f1-score on test data: 0.570\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. f1-score on training data: 1.000 f1-score on test data: 0.595\n",
      "          - hidden layer size[20, 20]. f1-score on training data: 1.000 f1-score on test data: 0.547\n",
      "          - hidden layer size[100, 100]. f1-score on training data: 1.000 f1-score on test data: 0.547\n",
      "          - hidden layer size[50, 50, 50]. f1-score on training data: 1.000 f1-score on test data: 0.579\n"
     ]
    }
   ],
   "source": [
    "models(df_2gg,drop_lst,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ad548232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After undersampling data size is 206 ; Resampled dataset shape Counter({'CN-CN': 103, 'CN-MCI': 103})\n",
      "\n",
      "6 principle components are needed to explain 90% of the data\n",
      "\n",
      "- Using original dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.413\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.344\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.413\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.410\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.328\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.410\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.604\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.323\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.604\n",
      "       - C = 1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.607\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.654\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.607\n",
      "       - C = 10\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.594\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.569\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.594\n",
      "       - C = 100\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.573\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.561\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.573\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.561\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.561\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.561\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. average weighted f1-score of 10-cross validation:0.682\n",
      "          - tree depth: 2.000. average weighted f1-score of 10-cross validation:0.618\n",
      "          - tree depth: 3.000. average weighted f1-score of 10-cross validation:0.557\n",
      "          - tree depth: 4.000. average weighted f1-score of 10-cross validation:0.565\n",
      "          - tree depth: 5.000. average weighted f1-score of 10-cross validation:0.548\n",
      "          - tree depth: 6.000. average weighted f1-score of 10-cross validation:0.556\n",
      "          - tree depth: 7.000. average weighted f1-score of 10-cross validation:0.551\n",
      "          - tree depth: 8.000. average weighted f1-score of 10-cross validation:0.529\n",
      "          - tree depth: 9.000. average weighted f1-score of 10-cross validation:0.533\n",
      "          - tree depth: 10.000. average weighted f1-score of 10-cross validation:0.520\n",
      "          - tree depth: 11.000. average weighted f1-score of 10-cross validation:0.522\n",
      "          - tree depth: 12.000. average weighted f1-score of 10-cross validation:0.516\n",
      "          - tree depth: 13.000. average weighted f1-score of 10-cross validation:0.511\n",
      "          - tree depth: 14.000. average weighted f1-score of 10-cross validation:0.521\n",
      "    - Random forest\n",
      "          - 5trees. average weighted f1-score of 10-cross validation:0.484\n",
      "          - 10trees. average weighted f1-score of 10-cross validation:0.497\n",
      "          - 15trees. average weighted f1-score of 10-cross validation:0.508\n",
      "          - 20trees. average weighted f1-score of 10-cross validation:0.522\n",
      "          - 25trees. average weighted f1-score of 10-cross validation:0.512\n",
      "          - 30trees. average weighted f1-score of 10-cross validation:0.523\n",
      "          - 35trees. average weighted f1-score of 10-cross validation:0.549\n",
      "          - 40trees. average weighted f1-score of 10-cross validation:0.559\n",
      "          - 45trees. average weighted f1-score of 10-cross validation:0.563\n",
      "          - 50trees. average weighted f1-score of 10-cross validation:0.551\n",
      "          - 55trees. average weighted f1-score of 10-cross validation:0.557\n",
      "          - 60trees. average weighted f1-score of 10-cross validation:0.554\n",
      "          - 65trees. average weighted f1-score of 10-cross validation:0.564\n",
      "          - 70trees. average weighted f1-score of 10-cross validation:0.545\n",
      "          - 75trees. average weighted f1-score of 10-cross validation:0.555\n",
      "          - 80trees. average weighted f1-score of 10-cross validation:0.544\n",
      "          - 85trees. average weighted f1-score of 10-cross validation:0.541\n",
      "          - 90trees. average weighted f1-score of 10-cross validation:0.537\n",
      "          - 95trees. average weighted f1-score of 10-cross validation:0.539\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. average weighted f1-score of 10-cross validation:0.545\n",
      "          - hidden layer size[20, 20]. average weighted f1-score of 10-cross validation:0.605\n",
      "- Using scaled dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.588\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.334\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.588\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.580\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.339\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.580\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.575\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.613\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.575\n",
      "       - C = 1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.570\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.561\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.570\n",
      "       - C = 10\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.555\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.560\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.555\n",
      "       - C = 100\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.555\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.555\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.555\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.555\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.555\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.555\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. average weighted f1-score of 10-cross validation:0.682\n",
      "          - tree depth: 2.000. average weighted f1-score of 10-cross validation:0.618\n",
      "          - tree depth: 3.000. average weighted f1-score of 10-cross validation:0.557\n",
      "          - tree depth: 4.000. average weighted f1-score of 10-cross validation:0.565\n",
      "          - tree depth: 5.000. average weighted f1-score of 10-cross validation:0.548\n",
      "          - tree depth: 6.000. average weighted f1-score of 10-cross validation:0.556\n",
      "          - tree depth: 7.000. average weighted f1-score of 10-cross validation:0.551\n",
      "          - tree depth: 8.000. average weighted f1-score of 10-cross validation:0.529\n",
      "          - tree depth: 9.000. average weighted f1-score of 10-cross validation:0.533\n",
      "          - tree depth: 10.000. average weighted f1-score of 10-cross validation:0.520\n",
      "          - tree depth: 11.000. average weighted f1-score of 10-cross validation:0.522\n",
      "          - tree depth: 12.000. average weighted f1-score of 10-cross validation:0.516\n",
      "          - tree depth: 13.000. average weighted f1-score of 10-cross validation:0.511\n",
      "          - tree depth: 14.000. average weighted f1-score of 10-cross validation:0.521\n",
      "    - Random forest\n",
      "          - 5trees. average weighted f1-score of 10-cross validation:0.484\n",
      "          - 10trees. average weighted f1-score of 10-cross validation:0.497\n",
      "          - 15trees. average weighted f1-score of 10-cross validation:0.508\n",
      "          - 20trees. average weighted f1-score of 10-cross validation:0.522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          - 25trees. average weighted f1-score of 10-cross validation:0.512\n",
      "          - 30trees. average weighted f1-score of 10-cross validation:0.523\n",
      "          - 35trees. average weighted f1-score of 10-cross validation:0.549\n",
      "          - 40trees. average weighted f1-score of 10-cross validation:0.559\n",
      "          - 45trees. average weighted f1-score of 10-cross validation:0.563\n",
      "          - 50trees. average weighted f1-score of 10-cross validation:0.551\n",
      "          - 55trees. average weighted f1-score of 10-cross validation:0.557\n",
      "          - 60trees. average weighted f1-score of 10-cross validation:0.554\n",
      "          - 65trees. average weighted f1-score of 10-cross validation:0.564\n",
      "          - 70trees. average weighted f1-score of 10-cross validation:0.545\n",
      "          - 75trees. average weighted f1-score of 10-cross validation:0.555\n",
      "          - 80trees. average weighted f1-score of 10-cross validation:0.544\n",
      "          - 85trees. average weighted f1-score of 10-cross validation:0.541\n",
      "          - 90trees. average weighted f1-score of 10-cross validation:0.537\n",
      "          - 95trees. average weighted f1-score of 10-cross validation:0.539\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. average weighted f1-score of 10-cross validation:0.580\n",
      "          - hidden layer size[20, 20]. average weighted f1-score of 10-cross validation:0.570\n",
      "- Using 6 pca-components:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.575\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.344\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.575\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.579\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.334\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.579\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.589\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.591\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.589\n",
      "       - C = 1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.556\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.576\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.556\n",
      "       - C = 10\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.560\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.556\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.560\n",
      "       - C = 100\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.560\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.560\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.560\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.560\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.560\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.560\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. average weighted f1-score of 10-cross validation:0.557\n",
      "          - tree depth: 2.000. average weighted f1-score of 10-cross validation:0.532\n",
      "          - tree depth: 3.000. average weighted f1-score of 10-cross validation:0.570\n",
      "          - tree depth: 4.000. average weighted f1-score of 10-cross validation:0.585\n",
      "          - tree depth: 5.000. average weighted f1-score of 10-cross validation:0.554\n",
      "          - tree depth: 6.000. average weighted f1-score of 10-cross validation:0.519\n",
      "          - tree depth: 7.000. average weighted f1-score of 10-cross validation:0.552\n",
      "          - tree depth: 8.000. average weighted f1-score of 10-cross validation:0.545\n",
      "          - tree depth: 9.000. average weighted f1-score of 10-cross validation:0.541\n",
      "          - tree depth: 10.000. average weighted f1-score of 10-cross validation:0.537\n",
      "          - tree depth: 11.000. average weighted f1-score of 10-cross validation:0.534\n",
      "          - tree depth: 12.000. average weighted f1-score of 10-cross validation:0.528\n",
      "          - tree depth: 13.000. average weighted f1-score of 10-cross validation:0.525\n",
      "          - tree depth: 14.000. average weighted f1-score of 10-cross validation:0.529\n",
      "    - Random forest\n",
      "          - 5trees. average weighted f1-score of 10-cross validation:0.546\n",
      "          - 10trees. average weighted f1-score of 10-cross validation:0.568\n",
      "          - 15trees. average weighted f1-score of 10-cross validation:0.588\n",
      "          - 20trees. average weighted f1-score of 10-cross validation:0.584\n",
      "          - 25trees. average weighted f1-score of 10-cross validation:0.561\n",
      "          - 30trees. average weighted f1-score of 10-cross validation:0.571\n",
      "          - 35trees. average weighted f1-score of 10-cross validation:0.576\n",
      "          - 40trees. average weighted f1-score of 10-cross validation:0.584\n",
      "          - 45trees. average weighted f1-score of 10-cross validation:0.581\n",
      "          - 50trees. average weighted f1-score of 10-cross validation:0.572\n",
      "          - 55trees. average weighted f1-score of 10-cross validation:0.575\n",
      "          - 60trees. average weighted f1-score of 10-cross validation:0.574\n",
      "          - 65trees. average weighted f1-score of 10-cross validation:0.589\n",
      "          - 70trees. average weighted f1-score of 10-cross validation:0.610\n",
      "          - 75trees. average weighted f1-score of 10-cross validation:0.607\n",
      "          - 80trees. average weighted f1-score of 10-cross validation:0.614\n",
      "          - 85trees. average weighted f1-score of 10-cross validation:0.614\n",
      "          - 90trees. average weighted f1-score of 10-cross validation:0.619\n",
      "          - 95trees. average weighted f1-score of 10-cross validation:0.623\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. average weighted f1-score of 10-cross validation:0.541\n",
      "          - hidden layer size[20, 20]. average weighted f1-score of 10-cross validation:0.528\n"
     ]
    }
   ],
   "source": [
    "cv_models(df_2gg,drop_lst,target,k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2cc015",
   "metadata": {},
   "source": [
    "- pca data, random forest 95trees. average weighted f1-score of 10-cross validation:0.623"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d29a5ea2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After undersampling data size is 206 ; Resampled dataset shape Counter({'CN-CN': 103, 'CN-MCI': 103})\n",
      "\n",
      "6 principle components are needed to explain 90% of the data\n",
      "\n",
      "Features sorted by their score for each estimator \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-d00918337de6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m95\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5862\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtitle_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'10-fold crossvalidation of random forest with (95 trees)'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mfeature_importance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtitle_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\GitHub\\Brain_health_challenge_tobereviewed\\notebook\\dash_model_two.py\u001b[0m in \u001b[0;36mfeature_importance\u001b[1;34m(X, y, clf, k, title_label)\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mestimator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'estimator'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m         feature_importances = pd.DataFrame(estimator.feature_importances_,\n\u001b[1;32m--> 275\u001b[1;33m                                            \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m                                             columns=[\"importance_%s\"% (idx+1)])\n\u001b[0;32m    277\u001b[0m         \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_importances\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "res = usampling_scale_data(df_2gg,drop_lst,target)     \n",
    "X = res[2]\n",
    "y = res[3]\n",
    "clf = RandomForestClassifier(n_estimators = 95, random_state = 5862)\n",
    "title_label = '10-fold crossvalidation of random forest with (95 trees)'\n",
    "feature_importance(X,y,clf,k,title_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2af5416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc3c2702",
   "metadata": {},
   "source": [
    "- 'CN-CN': 103, 'CN-MCI': 103, 'MCI-AD': 103, 'MCI-CN': 103, 'MCI-MCI': 103\n",
    "- all not so good. No selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b8ca5209",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After undersampling data size is 515 ; Resampled dataset shape Counter({'CN-CN': 103, 'CN-MCI': 103, 'MCI-AD': 103, 'MCI-CN': 103, 'MCI-MCI': 103})\n",
      "\n",
      "4 principle components are needed to explain 90% of the data\n",
      "\n",
      "Output dataframes sequence: X_train,X_test,X_train_scaled,X_test_scaled,X_train_pca,X_test_pca,y_train,y_test\n",
      "- Using original dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, Training set f1-score:0.345, Test set f1-score: 0.283\n",
      "          - saga_L1, Training set f1-score:0.345, Test set f1-score: 0.283\n",
      "          - newton-cg_L2, Training set f1-score:0.345, Test set f1-score: 0.283\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, Training set f1-score:0.404, Test set f1-score: 0.313\n",
      "          - saga_L1, Training set f1-score:0.345, Test set f1-score: 0.283\n",
      "          - newton-cg_L2, Training set f1-score:0.404, Test set f1-score: 0.313\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, Training set f1-score:0.393, Test set f1-score: 0.368\n",
      "          - saga_L1, Training set f1-score:0.331, Test set f1-score: 0.343\n",
      "          - newton-cg_L2, Training set f1-score:0.393, Test set f1-score: 0.368\n",
      "       - C = 1\n",
      "          - lbfgs_L2, Training set f1-score:0.386, Test set f1-score: 0.401\n",
      "          - saga_L1, Training set f1-score:0.422, Test set f1-score: 0.375\n",
      "          - newton-cg_L2, Training set f1-score:0.386, Test set f1-score: 0.401\n",
      "       - C = 10\n",
      "          - lbfgs_L2, Training set f1-score:0.394, Test set f1-score: 0.364\n",
      "          - saga_L1, Training set f1-score:0.397, Test set f1-score: 0.376\n",
      "          - newton-cg_L2, Training set f1-score:0.394, Test set f1-score: 0.364\n",
      "       - C = 100\n",
      "          - lbfgs_L2, Training set f1-score:0.415, Test set f1-score: 0.342\n",
      "          - saga_L1, Training set f1-score:0.411, Test set f1-score: 0.353\n",
      "          - newton-cg_L2, Training set f1-score:0.415, Test set f1-score: 0.342\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, Training set f1-score:0.433, Test set f1-score: 0.323\n",
      "          - saga_L1, Training set f1-score:0.411, Test set f1-score: 0.342\n",
      "          - newton-cg_L2, Training set f1-score:0.438, Test set f1-score: 0.323\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. f1-score on training data: 0.377 f1-score on test data: 0.303\n",
      "          - tree depth: 2.000. f1-score on training data: 0.428 f1-score on test data: 0.296\n",
      "          - tree depth: 3.000. f1-score on training data: 0.475 f1-score on test data: 0.371\n",
      "          - tree depth: 4.000. f1-score on training data: 0.497 f1-score on test data: 0.336\n",
      "          - tree depth: 5.000. f1-score on training data: 0.553 f1-score on test data: 0.225\n",
      "          - tree depth: 6.000. f1-score on training data: 0.644 f1-score on test data: 0.239\n",
      "          - tree depth: 7.000. f1-score on training data: 0.704 f1-score on test data: 0.211\n",
      "          - tree depth: 8.000. f1-score on training data: 0.766 f1-score on test data: 0.200\n",
      "          - tree depth: 9.000. f1-score on training data: 0.812 f1-score on test data: 0.195\n",
      "          - tree depth: 10.000. f1-score on training data: 0.856 f1-score on test data: 0.216\n",
      "          - tree depth: 11.000. f1-score on training data: 0.896 f1-score on test data: 0.198\n",
      "          - tree depth: 12.000. f1-score on training data: 0.934 f1-score on test data: 0.223\n",
      "          - tree depth: 13.000. f1-score on training data: 0.958 f1-score on test data: 0.227\n",
      "          - tree depth: 14.000. f1-score on training data: 0.976 f1-score on test data: 0.224\n",
      "    - Random forest\n",
      "          - 5trees. f1-score on training data: 0.912 f1-score on test data: 0.299\n",
      "          - 10trees. f1-score on training data: 0.978 f1-score on test data: 0.296\n",
      "          - 15trees. f1-score on training data: 0.993 f1-score on test data: 0.328\n",
      "          - 20trees. f1-score on training data: 1.000 f1-score on test data: 0.319\n",
      "          - 25trees. f1-score on training data: 1.000 f1-score on test data: 0.339\n",
      "          - 30trees. f1-score on training data: 1.000 f1-score on test data: 0.323\n",
      "          - 35trees. f1-score on training data: 1.000 f1-score on test data: 0.346\n",
      "          - 40trees. f1-score on training data: 1.000 f1-score on test data: 0.344\n",
      "          - 45trees. f1-score on training data: 1.000 f1-score on test data: 0.333\n",
      "          - 50trees. f1-score on training data: 1.000 f1-score on test data: 0.346\n",
      "          - 55trees. f1-score on training data: 1.000 f1-score on test data: 0.337\n",
      "          - 60trees. f1-score on training data: 1.000 f1-score on test data: 0.329\n",
      "          - 65trees. f1-score on training data: 1.000 f1-score on test data: 0.328\n",
      "          - 70trees. f1-score on training data: 1.000 f1-score on test data: 0.345\n",
      "          - 75trees. f1-score on training data: 1.000 f1-score on test data: 0.335\n",
      "          - 80trees. f1-score on training data: 1.000 f1-score on test data: 0.325\n",
      "          - 85trees. f1-score on training data: 1.000 f1-score on test data: 0.335\n",
      "          - 90trees. f1-score on training data: 1.000 f1-score on test data: 0.347\n",
      "          - 95trees. f1-score on training data: 1.000 f1-score on test data: 0.348\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. f1-score on training data: 0.743 f1-score on test data: 0.358\n",
      "          - hidden layer size[20, 20]. f1-score on training data: 0.543 f1-score on test data: 0.358\n",
      "          - hidden layer size[100, 100]. f1-score on training data: 0.722 f1-score on test data: 0.284\n",
      "          - hidden layer size[50, 50, 50]. f1-score on training data: 0.649 f1-score on test data: 0.303\n",
      "- Using scaled dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, Training set f1-score:0.402, Test set f1-score: 0.335\n",
      "          - saga_L1, Training set f1-score:0.305, Test set f1-score: 0.439\n",
      "          - newton-cg_L2, Training set f1-score:0.402, Test set f1-score: 0.335\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, Training set f1-score:0.370, Test set f1-score: 0.372\n",
      "          - saga_L1, Training set f1-score:0.345, Test set f1-score: 0.283\n",
      "          - newton-cg_L2, Training set f1-score:0.370, Test set f1-score: 0.372\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, Training set f1-score:0.373, Test set f1-score: 0.395\n",
      "          - saga_L1, Training set f1-score:0.416, Test set f1-score: 0.337\n",
      "          - newton-cg_L2, Training set f1-score:0.373, Test set f1-score: 0.395\n",
      "       - C = 1\n",
      "          - lbfgs_L2, Training set f1-score:0.381, Test set f1-score: 0.335\n",
      "          - saga_L1, Training set f1-score:0.373, Test set f1-score: 0.357\n",
      "          - newton-cg_L2, Training set f1-score:0.381, Test set f1-score: 0.335\n",
      "       - C = 10\n",
      "          - lbfgs_L2, Training set f1-score:0.419, Test set f1-score: 0.346\n",
      "          - saga_L1, Training set f1-score:0.416, Test set f1-score: 0.340\n",
      "          - newton-cg_L2, Training set f1-score:0.419, Test set f1-score: 0.346\n",
      "       - C = 100\n",
      "          - lbfgs_L2, Training set f1-score:0.435, Test set f1-score: 0.323\n",
      "          - saga_L1, Training set f1-score:0.417, Test set f1-score: 0.330\n",
      "          - newton-cg_L2, Training set f1-score:0.432, Test set f1-score: 0.323\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, Training set f1-score:0.437, Test set f1-score: 0.315\n",
      "          - saga_L1, Training set f1-score:0.417, Test set f1-score: 0.330\n",
      "          - newton-cg_L2, Training set f1-score:0.440, Test set f1-score: 0.315\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. f1-score on training data: 0.377 f1-score on test data: 0.303\n",
      "          - tree depth: 2.000. f1-score on training data: 0.428 f1-score on test data: 0.296\n",
      "          - tree depth: 3.000. f1-score on training data: 0.475 f1-score on test data: 0.371\n",
      "          - tree depth: 4.000. f1-score on training data: 0.497 f1-score on test data: 0.336\n",
      "          - tree depth: 5.000. f1-score on training data: 0.553 f1-score on test data: 0.225\n",
      "          - tree depth: 6.000. f1-score on training data: 0.644 f1-score on test data: 0.239\n",
      "          - tree depth: 7.000. f1-score on training data: 0.704 f1-score on test data: 0.211\n",
      "          - tree depth: 8.000. f1-score on training data: 0.766 f1-score on test data: 0.200\n",
      "          - tree depth: 9.000. f1-score on training data: 0.812 f1-score on test data: 0.195\n",
      "          - tree depth: 10.000. f1-score on training data: 0.856 f1-score on test data: 0.216\n",
      "          - tree depth: 11.000. f1-score on training data: 0.896 f1-score on test data: 0.198\n",
      "          - tree depth: 12.000. f1-score on training data: 0.934 f1-score on test data: 0.223\n",
      "          - tree depth: 13.000. f1-score on training data: 0.958 f1-score on test data: 0.227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          - tree depth: 14.000. f1-score on training data: 0.976 f1-score on test data: 0.224\n",
      "    - Random forest\n",
      "          - 5trees. f1-score on training data: 0.912 f1-score on test data: 0.299\n",
      "          - 10trees. f1-score on training data: 0.978 f1-score on test data: 0.296\n",
      "          - 15trees. f1-score on training data: 0.993 f1-score on test data: 0.328\n",
      "          - 20trees. f1-score on training data: 1.000 f1-score on test data: 0.319\n",
      "          - 25trees. f1-score on training data: 1.000 f1-score on test data: 0.339\n",
      "          - 30trees. f1-score on training data: 1.000 f1-score on test data: 0.323\n",
      "          - 35trees. f1-score on training data: 1.000 f1-score on test data: 0.346\n",
      "          - 40trees. f1-score on training data: 1.000 f1-score on test data: 0.344\n",
      "          - 45trees. f1-score on training data: 1.000 f1-score on test data: 0.333\n",
      "          - 50trees. f1-score on training data: 1.000 f1-score on test data: 0.346\n",
      "          - 55trees. f1-score on training data: 1.000 f1-score on test data: 0.337\n",
      "          - 60trees. f1-score on training data: 1.000 f1-score on test data: 0.329\n",
      "          - 65trees. f1-score on training data: 1.000 f1-score on test data: 0.328\n",
      "          - 70trees. f1-score on training data: 1.000 f1-score on test data: 0.345\n",
      "          - 75trees. f1-score on training data: 1.000 f1-score on test data: 0.335\n",
      "          - 80trees. f1-score on training data: 1.000 f1-score on test data: 0.325\n",
      "          - 85trees. f1-score on training data: 1.000 f1-score on test data: 0.335\n",
      "          - 90trees. f1-score on training data: 1.000 f1-score on test data: 0.347\n",
      "          - 95trees. f1-score on training data: 1.000 f1-score on test data: 0.348\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. f1-score on training data: 1.000 f1-score on test data: 0.282\n",
      "          - hidden layer size[20, 20]. f1-score on training data: 1.000 f1-score on test data: 0.283\n",
      "          - hidden layer size[100, 100]. f1-score on training data: 1.000 f1-score on test data: 0.274\n",
      "          - hidden layer size[50, 50, 50]. f1-score on training data: 1.000 f1-score on test data: 0.341\n",
      "- Using 4 pca-components:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, Training set f1-score:0.397, Test set f1-score: 0.340\n",
      "          - saga_L1, Training set f1-score:0.342, Test set f1-score: 0.298\n",
      "          - newton-cg_L2, Training set f1-score:0.397, Test set f1-score: 0.340\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, Training set f1-score:0.380, Test set f1-score: 0.369\n",
      "          - saga_L1, Training set f1-score:0.347, Test set f1-score: 0.421\n",
      "          - newton-cg_L2, Training set f1-score:0.380, Test set f1-score: 0.369\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, Training set f1-score:0.373, Test set f1-score: 0.380\n",
      "          - saga_L1, Training set f1-score:0.363, Test set f1-score: 0.382\n",
      "          - newton-cg_L2, Training set f1-score:0.373, Test set f1-score: 0.380\n",
      "       - C = 1\n",
      "          - lbfgs_L2, Training set f1-score:0.375, Test set f1-score: 0.382\n",
      "          - saga_L1, Training set f1-score:0.378, Test set f1-score: 0.399\n",
      "          - newton-cg_L2, Training set f1-score:0.375, Test set f1-score: 0.382\n",
      "       - C = 10\n",
      "          - lbfgs_L2, Training set f1-score:0.375, Test set f1-score: 0.389\n",
      "          - saga_L1, Training set f1-score:0.375, Test set f1-score: 0.382\n",
      "          - newton-cg_L2, Training set f1-score:0.375, Test set f1-score: 0.389\n",
      "       - C = 100\n",
      "          - lbfgs_L2, Training set f1-score:0.375, Test set f1-score: 0.389\n",
      "          - saga_L1, Training set f1-score:0.375, Test set f1-score: 0.380\n",
      "          - newton-cg_L2, Training set f1-score:0.375, Test set f1-score: 0.389\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, Training set f1-score:0.375, Test set f1-score: 0.389\n",
      "          - saga_L1, Training set f1-score:0.375, Test set f1-score: 0.380\n",
      "          - newton-cg_L2, Training set f1-score:0.375, Test set f1-score: 0.389\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. f1-score on training data: 0.434 f1-score on test data: 0.431\n",
      "          - tree depth: 2.000. f1-score on training data: 0.431 f1-score on test data: 0.408\n",
      "          - tree depth: 3.000. f1-score on training data: 0.422 f1-score on test data: 0.380\n",
      "          - tree depth: 4.000. f1-score on training data: 0.471 f1-score on test data: 0.381\n",
      "          - tree depth: 5.000. f1-score on training data: 0.500 f1-score on test data: 0.366\n",
      "          - tree depth: 6.000. f1-score on training data: 0.529 f1-score on test data: 0.355\n",
      "          - tree depth: 7.000. f1-score on training data: 0.596 f1-score on test data: 0.319\n",
      "          - tree depth: 8.000. f1-score on training data: 0.655 f1-score on test data: 0.355\n",
      "          - tree depth: 9.000. f1-score on training data: 0.716 f1-score on test data: 0.321\n",
      "          - tree depth: 10.000. f1-score on training data: 0.772 f1-score on test data: 0.326\n",
      "          - tree depth: 11.000. f1-score on training data: 0.804 f1-score on test data: 0.323\n",
      "          - tree depth: 12.000. f1-score on training data: 0.842 f1-score on test data: 0.271\n",
      "          - tree depth: 13.000. f1-score on training data: 0.877 f1-score on test data: 0.268\n",
      "          - tree depth: 14.000. f1-score on training data: 0.902 f1-score on test data: 0.257\n",
      "    - Random forest\n",
      "          - 5trees. f1-score on training data: 0.905 f1-score on test data: 0.314\n",
      "          - 10trees. f1-score on training data: 0.978 f1-score on test data: 0.295\n",
      "          - 15trees. f1-score on training data: 0.995 f1-score on test data: 0.306\n",
      "          - 20trees. f1-score on training data: 1.000 f1-score on test data: 0.325\n",
      "          - 25trees. f1-score on training data: 1.000 f1-score on test data: 0.327\n",
      "          - 30trees. f1-score on training data: 1.000 f1-score on test data: 0.313\n",
      "          - 35trees. f1-score on training data: 1.000 f1-score on test data: 0.301\n",
      "          - 40trees. f1-score on training data: 1.000 f1-score on test data: 0.293\n",
      "          - 45trees. f1-score on training data: 1.000 f1-score on test data: 0.304\n",
      "          - 50trees. f1-score on training data: 1.000 f1-score on test data: 0.303\n",
      "          - 55trees. f1-score on training data: 1.000 f1-score on test data: 0.305\n",
      "          - 60trees. f1-score on training data: 1.000 f1-score on test data: 0.334\n",
      "          - 65trees. f1-score on training data: 1.000 f1-score on test data: 0.334\n",
      "          - 70trees. f1-score on training data: 1.000 f1-score on test data: 0.334\n",
      "          - 75trees. f1-score on training data: 1.000 f1-score on test data: 0.334\n",
      "          - 80trees. f1-score on training data: 1.000 f1-score on test data: 0.328\n",
      "          - 85trees. f1-score on training data: 1.000 f1-score on test data: 0.333\n",
      "          - 90trees. f1-score on training data: 1.000 f1-score on test data: 0.334\n",
      "          - 95trees. f1-score on training data: 1.000 f1-score on test data: 0.321\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. f1-score on training data: 1.000 f1-score on test data: 0.343\n",
      "          - hidden layer size[20, 20]. f1-score on training data: 0.932 f1-score on test data: 0.277\n",
      "          - hidden layer size[100, 100]. f1-score on training data: 1.000 f1-score on test data: 0.307\n",
      "          - hidden layer size[50, 50, 50]. f1-score on training data: 1.000 f1-score on test data: 0.197\n"
     ]
    }
   ],
   "source": [
    "models(df_5g,drop_lst,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8b16e627",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After undersampling data size is 515 ; Resampled dataset shape Counter({'CN-CN': 103, 'CN-MCI': 103, 'MCI-AD': 103, 'MCI-CN': 103, 'MCI-MCI': 103})\n",
      "\n",
      "4 principle components are needed to explain 90% of the data\n",
      "\n",
      "- Using original dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.218\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.067\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.218\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.250\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.063\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.250\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.270\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.153\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.270\n",
      "       - C = 1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.294\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.298\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.293\n",
      "       - C = 10\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.329\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.347\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.329\n",
      "       - C = 100\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.343\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.346\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.342\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.342\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.347\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.346\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. average weighted f1-score of 10-cross validation:0.151\n",
      "          - tree depth: 2.000. average weighted f1-score of 10-cross validation:0.229\n",
      "          - tree depth: 3.000. average weighted f1-score of 10-cross validation:0.302\n",
      "          - tree depth: 4.000. average weighted f1-score of 10-cross validation:0.289\n",
      "          - tree depth: 5.000. average weighted f1-score of 10-cross validation:0.284\n",
      "          - tree depth: 6.000. average weighted f1-score of 10-cross validation:0.293\n",
      "          - tree depth: 7.000. average weighted f1-score of 10-cross validation:0.307\n",
      "          - tree depth: 8.000. average weighted f1-score of 10-cross validation:0.312\n",
      "          - tree depth: 9.000. average weighted f1-score of 10-cross validation:0.327\n",
      "          - tree depth: 10.000. average weighted f1-score of 10-cross validation:0.297\n",
      "          - tree depth: 11.000. average weighted f1-score of 10-cross validation:0.307\n",
      "          - tree depth: 12.000. average weighted f1-score of 10-cross validation:0.312\n",
      "          - tree depth: 13.000. average weighted f1-score of 10-cross validation:0.300\n",
      "          - tree depth: 14.000. average weighted f1-score of 10-cross validation:0.306\n",
      "    - Random forest\n",
      "          - 5trees. average weighted f1-score of 10-cross validation:0.326\n",
      "          - 10trees. average weighted f1-score of 10-cross validation:0.357\n",
      "          - 15trees. average weighted f1-score of 10-cross validation:0.351\n",
      "          - 20trees. average weighted f1-score of 10-cross validation:0.350\n",
      "          - 25trees. average weighted f1-score of 10-cross validation:0.346\n",
      "          - 30trees. average weighted f1-score of 10-cross validation:0.345\n",
      "          - 35trees. average weighted f1-score of 10-cross validation:0.343\n",
      "          - 40trees. average weighted f1-score of 10-cross validation:0.355\n",
      "          - 45trees. average weighted f1-score of 10-cross validation:0.342\n",
      "          - 50trees. average weighted f1-score of 10-cross validation:0.350\n",
      "          - 55trees. average weighted f1-score of 10-cross validation:0.352\n",
      "          - 60trees. average weighted f1-score of 10-cross validation:0.364\n",
      "          - 65trees. average weighted f1-score of 10-cross validation:0.350\n",
      "          - 70trees. average weighted f1-score of 10-cross validation:0.354\n",
      "          - 75trees. average weighted f1-score of 10-cross validation:0.353\n",
      "          - 80trees. average weighted f1-score of 10-cross validation:0.355\n",
      "          - 85trees. average weighted f1-score of 10-cross validation:0.356\n",
      "          - 90trees. average weighted f1-score of 10-cross validation:0.350\n",
      "          - 95trees. average weighted f1-score of 10-cross validation:0.351\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. average weighted f1-score of 10-cross validation:0.333\n",
      "          - hidden layer size[20, 20]. average weighted f1-score of 10-cross validation:0.346\n",
      "- Using scaled dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.266\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.067\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.266\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.295\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.064\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.295\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.300\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.282\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.300\n",
      "       - C = 1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.319\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.324\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.319\n",
      "       - C = 10\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.335\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.344\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.335\n",
      "       - C = 100\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.346\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.341\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.346\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.341\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.341\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.341\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. average weighted f1-score of 10-cross validation:0.151\n",
      "          - tree depth: 2.000. average weighted f1-score of 10-cross validation:0.229\n",
      "          - tree depth: 3.000. average weighted f1-score of 10-cross validation:0.302\n",
      "          - tree depth: 4.000. average weighted f1-score of 10-cross validation:0.289\n",
      "          - tree depth: 5.000. average weighted f1-score of 10-cross validation:0.284\n",
      "          - tree depth: 6.000. average weighted f1-score of 10-cross validation:0.293\n",
      "          - tree depth: 7.000. average weighted f1-score of 10-cross validation:0.307\n",
      "          - tree depth: 8.000. average weighted f1-score of 10-cross validation:0.312\n",
      "          - tree depth: 9.000. average weighted f1-score of 10-cross validation:0.327\n",
      "          - tree depth: 10.000. average weighted f1-score of 10-cross validation:0.297\n",
      "          - tree depth: 11.000. average weighted f1-score of 10-cross validation:0.307\n",
      "          - tree depth: 12.000. average weighted f1-score of 10-cross validation:0.312\n",
      "          - tree depth: 13.000. average weighted f1-score of 10-cross validation:0.300\n",
      "          - tree depth: 14.000. average weighted f1-score of 10-cross validation:0.306\n",
      "    - Random forest\n",
      "          - 5trees. average weighted f1-score of 10-cross validation:0.329\n",
      "          - 10trees. average weighted f1-score of 10-cross validation:0.359\n",
      "          - 15trees. average weighted f1-score of 10-cross validation:0.350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          - 20trees. average weighted f1-score of 10-cross validation:0.351\n",
      "          - 25trees. average weighted f1-score of 10-cross validation:0.346\n",
      "          - 30trees. average weighted f1-score of 10-cross validation:0.347\n",
      "          - 35trees. average weighted f1-score of 10-cross validation:0.342\n",
      "          - 40trees. average weighted f1-score of 10-cross validation:0.357\n",
      "          - 45trees. average weighted f1-score of 10-cross validation:0.345\n",
      "          - 50trees. average weighted f1-score of 10-cross validation:0.350\n",
      "          - 55trees. average weighted f1-score of 10-cross validation:0.349\n",
      "          - 60trees. average weighted f1-score of 10-cross validation:0.359\n",
      "          - 65trees. average weighted f1-score of 10-cross validation:0.349\n",
      "          - 70trees. average weighted f1-score of 10-cross validation:0.351\n",
      "          - 75trees. average weighted f1-score of 10-cross validation:0.360\n",
      "          - 80trees. average weighted f1-score of 10-cross validation:0.354\n",
      "          - 85trees. average weighted f1-score of 10-cross validation:0.354\n",
      "          - 90trees. average weighted f1-score of 10-cross validation:0.353\n",
      "          - 95trees. average weighted f1-score of 10-cross validation:0.349\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. average weighted f1-score of 10-cross validation:0.348\n",
      "          - hidden layer size[20, 20]. average weighted f1-score of 10-cross validation:0.318\n",
      "- Using 4 pca-components:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.258\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.067\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.258\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.304\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.170\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.308\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.309\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.306\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.309\n",
      "       - C = 1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.307\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.306\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.307\n",
      "       - C = 10\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.303\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.301\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.303\n",
      "       - C = 100\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.303\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.303\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.303\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.303\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.303\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.303\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. average weighted f1-score of 10-cross validation:0.196\n",
      "          - tree depth: 2.000. average weighted f1-score of 10-cross validation:0.242\n",
      "          - tree depth: 3.000. average weighted f1-score of 10-cross validation:0.259\n",
      "          - tree depth: 4.000. average weighted f1-score of 10-cross validation:0.290\n",
      "          - tree depth: 5.000. average weighted f1-score of 10-cross validation:0.297\n",
      "          - tree depth: 6.000. average weighted f1-score of 10-cross validation:0.314\n",
      "          - tree depth: 7.000. average weighted f1-score of 10-cross validation:0.299\n",
      "          - tree depth: 8.000. average weighted f1-score of 10-cross validation:0.307\n",
      "          - tree depth: 9.000. average weighted f1-score of 10-cross validation:0.303\n",
      "          - tree depth: 10.000. average weighted f1-score of 10-cross validation:0.304\n",
      "          - tree depth: 11.000. average weighted f1-score of 10-cross validation:0.306\n",
      "          - tree depth: 12.000. average weighted f1-score of 10-cross validation:0.297\n",
      "          - tree depth: 13.000. average weighted f1-score of 10-cross validation:0.299\n",
      "          - tree depth: 14.000. average weighted f1-score of 10-cross validation:0.315\n",
      "    - Random forest\n",
      "          - 5trees. average weighted f1-score of 10-cross validation:0.293\n",
      "          - 10trees. average weighted f1-score of 10-cross validation:0.310\n",
      "          - 15trees. average weighted f1-score of 10-cross validation:0.332\n",
      "          - 20trees. average weighted f1-score of 10-cross validation:0.315\n",
      "          - 25trees. average weighted f1-score of 10-cross validation:0.333\n",
      "          - 30trees. average weighted f1-score of 10-cross validation:0.313\n",
      "          - 35trees. average weighted f1-score of 10-cross validation:0.317\n",
      "          - 40trees. average weighted f1-score of 10-cross validation:0.314\n",
      "          - 45trees. average weighted f1-score of 10-cross validation:0.323\n",
      "          - 50trees. average weighted f1-score of 10-cross validation:0.324\n",
      "          - 55trees. average weighted f1-score of 10-cross validation:0.330\n",
      "          - 60trees. average weighted f1-score of 10-cross validation:0.322\n",
      "          - 65trees. average weighted f1-score of 10-cross validation:0.327\n",
      "          - 70trees. average weighted f1-score of 10-cross validation:0.329\n",
      "          - 75trees. average weighted f1-score of 10-cross validation:0.323\n",
      "          - 80trees. average weighted f1-score of 10-cross validation:0.319\n",
      "          - 85trees. average weighted f1-score of 10-cross validation:0.318\n",
      "          - 90trees. average weighted f1-score of 10-cross validation:0.325\n",
      "          - 95trees. average weighted f1-score of 10-cross validation:0.323\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. average weighted f1-score of 10-cross validation:0.335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weipi\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:559: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          - hidden layer size[20, 20]. average weighted f1-score of 10-cross validation:0.329\n"
     ]
    }
   ],
   "source": [
    "cv_models(df_5g,drop_lst,target,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af37cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532f8461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "464d6d89",
   "metadata": {},
   "source": [
    "- 'AD-AD': 103, 'CN-CN': 103, 'CN-MCI': 103, 'MCI-AD': 103, 'MCI-CN': 103, 'MCI-MCI': 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0c397f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After undersampling data size is 618 ; Resampled dataset shape Counter({'AD-AD': 103, 'CN-CN': 103, 'CN-MCI': 103, 'MCI-AD': 103, 'MCI-CN': 103, 'MCI-MCI': 103})\n",
      "\n",
      "6 principle components are needed to explain 90% of the data\n",
      "\n",
      "Output dataframes sequence: X_train,X_test,X_train_scaled,X_test_scaled,X_train_pca,X_test_pca,y_train,y_test\n",
      "- Using original dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, Training set f1-score:0.302, Test set f1-score: 0.216\n",
      "          - saga_L1, Training set f1-score:0.297, Test set f1-score: 0.241\n",
      "          - newton-cg_L2, Training set f1-score:0.302, Test set f1-score: 0.216\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, Training set f1-score:0.292, Test set f1-score: 0.229\n",
      "          - saga_L1, Training set f1-score:0.302, Test set f1-score: 0.216\n",
      "          - newton-cg_L2, Training set f1-score:0.292, Test set f1-score: 0.229\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, Training set f1-score:0.338, Test set f1-score: 0.320\n",
      "          - saga_L1, Training set f1-score:0.302, Test set f1-score: 0.216\n",
      "          - newton-cg_L2, Training set f1-score:0.338, Test set f1-score: 0.320\n",
      "       - C = 1\n",
      "          - lbfgs_L2, Training set f1-score:0.366, Test set f1-score: 0.314\n",
      "          - saga_L1, Training set f1-score:0.338, Test set f1-score: 0.346\n",
      "          - newton-cg_L2, Training set f1-score:0.368, Test set f1-score: 0.314\n",
      "       - C = 10\n",
      "          - lbfgs_L2, Training set f1-score:0.372, Test set f1-score: 0.322\n",
      "          - saga_L1, Training set f1-score:0.391, Test set f1-score: 0.333\n",
      "          - newton-cg_L2, Training set f1-score:0.372, Test set f1-score: 0.322\n",
      "       - C = 100\n",
      "          - lbfgs_L2, Training set f1-score:0.385, Test set f1-score: 0.328\n",
      "          - saga_L1, Training set f1-score:0.396, Test set f1-score: 0.330\n",
      "          - newton-cg_L2, Training set f1-score:0.385, Test set f1-score: 0.328\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, Training set f1-score:0.390, Test set f1-score: 0.328\n",
      "          - saga_L1, Training set f1-score:0.396, Test set f1-score: 0.329\n",
      "          - newton-cg_L2, Training set f1-score:0.390, Test set f1-score: 0.328\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. f1-score on training data: 0.368 f1-score on test data: 0.303\n",
      "          - tree depth: 2.000. f1-score on training data: 0.399 f1-score on test data: 0.386\n",
      "          - tree depth: 3.000. f1-score on training data: 0.405 f1-score on test data: 0.367\n",
      "          - tree depth: 4.000. f1-score on training data: 0.425 f1-score on test data: 0.383\n",
      "          - tree depth: 5.000. f1-score on training data: 0.496 f1-score on test data: 0.415\n",
      "          - tree depth: 6.000. f1-score on training data: 0.556 f1-score on test data: 0.398\n",
      "          - tree depth: 7.000. f1-score on training data: 0.626 f1-score on test data: 0.338\n",
      "          - tree depth: 8.000. f1-score on training data: 0.716 f1-score on test data: 0.324\n",
      "          - tree depth: 9.000. f1-score on training data: 0.756 f1-score on test data: 0.301\n",
      "          - tree depth: 10.000. f1-score on training data: 0.838 f1-score on test data: 0.331\n",
      "          - tree depth: 11.000. f1-score on training data: 0.890 f1-score on test data: 0.387\n",
      "          - tree depth: 12.000. f1-score on training data: 0.943 f1-score on test data: 0.337\n",
      "          - tree depth: 13.000. f1-score on training data: 0.982 f1-score on test data: 0.330\n",
      "          - tree depth: 14.000. f1-score on training data: 0.998 f1-score on test data: 0.339\n",
      "    - Random forest\n",
      "          - 5trees. f1-score on training data: 0.931 f1-score on test data: 0.411\n",
      "          - 10trees. f1-score on training data: 0.980 f1-score on test data: 0.422\n",
      "          - 15trees. f1-score on training data: 0.996 f1-score on test data: 0.406\n",
      "          - 20trees. f1-score on training data: 0.998 f1-score on test data: 0.416\n",
      "          - 25trees. f1-score on training data: 0.998 f1-score on test data: 0.439\n",
      "          - 30trees. f1-score on training data: 0.998 f1-score on test data: 0.416\n",
      "          - 35trees. f1-score on training data: 0.998 f1-score on test data: 0.417\n",
      "          - 40trees. f1-score on training data: 1.000 f1-score on test data: 0.445\n",
      "          - 45trees. f1-score on training data: 1.000 f1-score on test data: 0.443\n",
      "          - 50trees. f1-score on training data: 1.000 f1-score on test data: 0.442\n",
      "          - 55trees. f1-score on training data: 1.000 f1-score on test data: 0.445\n",
      "          - 60trees. f1-score on training data: 1.000 f1-score on test data: 0.443\n",
      "          - 65trees. f1-score on training data: 1.000 f1-score on test data: 0.418\n",
      "          - 70trees. f1-score on training data: 1.000 f1-score on test data: 0.421\n",
      "          - 75trees. f1-score on training data: 1.000 f1-score on test data: 0.412\n",
      "          - 80trees. f1-score on training data: 1.000 f1-score on test data: 0.414\n",
      "          - 85trees. f1-score on training data: 1.000 f1-score on test data: 0.422\n",
      "          - 90trees. f1-score on training data: 1.000 f1-score on test data: 0.415\n",
      "          - 95trees. f1-score on training data: 1.000 f1-score on test data: 0.430\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. f1-score on training data: 0.707 f1-score on test data: 0.288\n",
      "          - hidden layer size[20, 20]. f1-score on training data: 0.639 f1-score on test data: 0.359\n",
      "          - hidden layer size[100, 100]. f1-score on training data: 0.897 f1-score on test data: 0.359\n",
      "          - hidden layer size[50, 50, 50]. f1-score on training data: 0.974 f1-score on test data: 0.253\n",
      "- Using scaled dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, Training set f1-score:0.355, Test set f1-score: 0.310\n",
      "          - saga_L1, Training set f1-score:0.297, Test set f1-score: 0.241\n",
      "          - newton-cg_L2, Training set f1-score:0.355, Test set f1-score: 0.310\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, Training set f1-score:0.361, Test set f1-score: 0.286\n",
      "          - saga_L1, Training set f1-score:0.302, Test set f1-score: 0.216\n",
      "          - newton-cg_L2, Training set f1-score:0.361, Test set f1-score: 0.286\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, Training set f1-score:0.372, Test set f1-score: 0.308\n",
      "          - saga_L1, Training set f1-score:0.362, Test set f1-score: 0.280\n",
      "          - newton-cg_L2, Training set f1-score:0.372, Test set f1-score: 0.308\n",
      "       - C = 1\n",
      "          - lbfgs_L2, Training set f1-score:0.376, Test set f1-score: 0.347\n",
      "          - saga_L1, Training set f1-score:0.378, Test set f1-score: 0.340\n",
      "          - newton-cg_L2, Training set f1-score:0.376, Test set f1-score: 0.347\n",
      "       - C = 10\n",
      "          - lbfgs_L2, Training set f1-score:0.385, Test set f1-score: 0.327\n",
      "          - saga_L1, Training set f1-score:0.387, Test set f1-score: 0.328\n",
      "          - newton-cg_L2, Training set f1-score:0.385, Test set f1-score: 0.327\n",
      "       - C = 100\n",
      "          - lbfgs_L2, Training set f1-score:0.385, Test set f1-score: 0.327\n",
      "          - saga_L1, Training set f1-score:0.385, Test set f1-score: 0.327\n",
      "          - newton-cg_L2, Training set f1-score:0.385, Test set f1-score: 0.327\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, Training set f1-score:0.385, Test set f1-score: 0.327\n",
      "          - saga_L1, Training set f1-score:0.385, Test set f1-score: 0.327\n",
      "          - newton-cg_L2, Training set f1-score:0.385, Test set f1-score: 0.327\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. f1-score on training data: 0.368 f1-score on test data: 0.303\n",
      "          - tree depth: 2.000. f1-score on training data: 0.399 f1-score on test data: 0.386\n",
      "          - tree depth: 3.000. f1-score on training data: 0.405 f1-score on test data: 0.367\n",
      "          - tree depth: 4.000. f1-score on training data: 0.425 f1-score on test data: 0.383\n",
      "          - tree depth: 5.000. f1-score on training data: 0.496 f1-score on test data: 0.415\n",
      "          - tree depth: 6.000. f1-score on training data: 0.556 f1-score on test data: 0.398\n",
      "          - tree depth: 7.000. f1-score on training data: 0.626 f1-score on test data: 0.338\n",
      "          - tree depth: 8.000. f1-score on training data: 0.716 f1-score on test data: 0.324\n",
      "          - tree depth: 9.000. f1-score on training data: 0.756 f1-score on test data: 0.301\n",
      "          - tree depth: 10.000. f1-score on training data: 0.838 f1-score on test data: 0.331\n",
      "          - tree depth: 11.000. f1-score on training data: 0.890 f1-score on test data: 0.387\n",
      "          - tree depth: 12.000. f1-score on training data: 0.943 f1-score on test data: 0.337\n",
      "          - tree depth: 13.000. f1-score on training data: 0.982 f1-score on test data: 0.330\n",
      "          - tree depth: 14.000. f1-score on training data: 0.998 f1-score on test data: 0.339\n",
      "    - Random forest\n",
      "          - 5trees. f1-score on training data: 0.931 f1-score on test data: 0.411\n",
      "          - 10trees. f1-score on training data: 0.980 f1-score on test data: 0.422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          - 15trees. f1-score on training data: 0.996 f1-score on test data: 0.406\n",
      "          - 20trees. f1-score on training data: 0.998 f1-score on test data: 0.416\n",
      "          - 25trees. f1-score on training data: 0.998 f1-score on test data: 0.439\n",
      "          - 30trees. f1-score on training data: 0.998 f1-score on test data: 0.416\n",
      "          - 35trees. f1-score on training data: 0.998 f1-score on test data: 0.417\n",
      "          - 40trees. f1-score on training data: 1.000 f1-score on test data: 0.445\n",
      "          - 45trees. f1-score on training data: 1.000 f1-score on test data: 0.443\n",
      "          - 50trees. f1-score on training data: 1.000 f1-score on test data: 0.442\n",
      "          - 55trees. f1-score on training data: 1.000 f1-score on test data: 0.445\n",
      "          - 60trees. f1-score on training data: 1.000 f1-score on test data: 0.443\n",
      "          - 65trees. f1-score on training data: 1.000 f1-score on test data: 0.418\n",
      "          - 70trees. f1-score on training data: 1.000 f1-score on test data: 0.421\n",
      "          - 75trees. f1-score on training data: 1.000 f1-score on test data: 0.412\n",
      "          - 80trees. f1-score on training data: 1.000 f1-score on test data: 0.414\n",
      "          - 85trees. f1-score on training data: 1.000 f1-score on test data: 0.422\n",
      "          - 90trees. f1-score on training data: 1.000 f1-score on test data: 0.415\n",
      "          - 95trees. f1-score on training data: 1.000 f1-score on test data: 0.430\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. f1-score on training data: 1.000 f1-score on test data: 0.247\n",
      "          - hidden layer size[20, 20]. f1-score on training data: 1.000 f1-score on test data: 0.251\n",
      "          - hidden layer size[100, 100]. f1-score on training data: 1.000 f1-score on test data: 0.376\n",
      "          - hidden layer size[50, 50, 50]. f1-score on training data: 1.000 f1-score on test data: 0.280\n",
      "- Using 6 pca-components:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, Training set f1-score:0.354, Test set f1-score: 0.300\n",
      "          - saga_L1, Training set f1-score:0.282, Test set f1-score: 0.301\n",
      "          - newton-cg_L2, Training set f1-score:0.354, Test set f1-score: 0.300\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, Training set f1-score:0.364, Test set f1-score: 0.297\n",
      "          - saga_L1, Training set f1-score:0.322, Test set f1-score: 0.267\n",
      "          - newton-cg_L2, Training set f1-score:0.364, Test set f1-score: 0.297\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, Training set f1-score:0.355, Test set f1-score: 0.281\n",
      "          - saga_L1, Training set f1-score:0.345, Test set f1-score: 0.309\n",
      "          - newton-cg_L2, Training set f1-score:0.355, Test set f1-score: 0.281\n",
      "       - C = 1\n",
      "          - lbfgs_L2, Training set f1-score:0.365, Test set f1-score: 0.287\n",
      "          - saga_L1, Training set f1-score:0.363, Test set f1-score: 0.259\n",
      "          - newton-cg_L2, Training set f1-score:0.365, Test set f1-score: 0.287\n",
      "       - C = 10\n",
      "          - lbfgs_L2, Training set f1-score:0.365, Test set f1-score: 0.287\n",
      "          - saga_L1, Training set f1-score:0.368, Test set f1-score: 0.287\n",
      "          - newton-cg_L2, Training set f1-score:0.365, Test set f1-score: 0.287\n",
      "       - C = 100\n",
      "          - lbfgs_L2, Training set f1-score:0.365, Test set f1-score: 0.288\n",
      "          - saga_L1, Training set f1-score:0.365, Test set f1-score: 0.288\n",
      "          - newton-cg_L2, Training set f1-score:0.365, Test set f1-score: 0.288\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, Training set f1-score:0.365, Test set f1-score: 0.288\n",
      "          - saga_L1, Training set f1-score:0.365, Test set f1-score: 0.288\n",
      "          - newton-cg_L2, Training set f1-score:0.365, Test set f1-score: 0.288\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. f1-score on training data: 0.381 f1-score on test data: 0.334\n",
      "          - tree depth: 2.000. f1-score on training data: 0.407 f1-score on test data: 0.296\n",
      "          - tree depth: 3.000. f1-score on training data: 0.423 f1-score on test data: 0.297\n",
      "          - tree depth: 4.000. f1-score on training data: 0.440 f1-score on test data: 0.249\n",
      "          - tree depth: 5.000. f1-score on training data: 0.487 f1-score on test data: 0.336\n",
      "          - tree depth: 6.000. f1-score on training data: 0.565 f1-score on test data: 0.291\n",
      "          - tree depth: 7.000. f1-score on training data: 0.636 f1-score on test data: 0.288\n",
      "          - tree depth: 8.000. f1-score on training data: 0.730 f1-score on test data: 0.290\n",
      "          - tree depth: 9.000. f1-score on training data: 0.815 f1-score on test data: 0.298\n",
      "          - tree depth: 10.000. f1-score on training data: 0.858 f1-score on test data: 0.291\n",
      "          - tree depth: 11.000. f1-score on training data: 0.916 f1-score on test data: 0.300\n",
      "          - tree depth: 12.000. f1-score on training data: 0.953 f1-score on test data: 0.280\n",
      "          - tree depth: 13.000. f1-score on training data: 0.978 f1-score on test data: 0.297\n",
      "          - tree depth: 14.000. f1-score on training data: 0.988 f1-score on test data: 0.268\n",
      "    - Random forest\n",
      "          - 5trees. f1-score on training data: 0.927 f1-score on test data: 0.333\n",
      "          - 10trees. f1-score on training data: 0.978 f1-score on test data: 0.342\n",
      "          - 15trees. f1-score on training data: 0.998 f1-score on test data: 0.253\n",
      "          - 20trees. f1-score on training data: 0.998 f1-score on test data: 0.297\n",
      "          - 25trees. f1-score on training data: 1.000 f1-score on test data: 0.307\n",
      "          - 30trees. f1-score on training data: 1.000 f1-score on test data: 0.332\n",
      "          - 35trees. f1-score on training data: 1.000 f1-score on test data: 0.307\n",
      "          - 40trees. f1-score on training data: 1.000 f1-score on test data: 0.309\n",
      "          - 45trees. f1-score on training data: 1.000 f1-score on test data: 0.306\n",
      "          - 50trees. f1-score on training data: 1.000 f1-score on test data: 0.325\n",
      "          - 55trees. f1-score on training data: 1.000 f1-score on test data: 0.335\n",
      "          - 60trees. f1-score on training data: 1.000 f1-score on test data: 0.318\n",
      "          - 65trees. f1-score on training data: 1.000 f1-score on test data: 0.309\n",
      "          - 70trees. f1-score on training data: 1.000 f1-score on test data: 0.310\n",
      "          - 75trees. f1-score on training data: 1.000 f1-score on test data: 0.309\n",
      "          - 80trees. f1-score on training data: 1.000 f1-score on test data: 0.317\n",
      "          - 85trees. f1-score on training data: 1.000 f1-score on test data: 0.301\n",
      "          - 90trees. f1-score on training data: 1.000 f1-score on test data: 0.284\n",
      "          - 95trees. f1-score on training data: 1.000 f1-score on test data: 0.318\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. f1-score on training data: 1.000 f1-score on test data: 0.267\n",
      "          - hidden layer size[20, 20]. f1-score on training data: 1.000 f1-score on test data: 0.308\n",
      "          - hidden layer size[100, 100]. f1-score on training data: 1.000 f1-score on test data: 0.280\n",
      "          - hidden layer size[50, 50, 50]. f1-score on training data: 1.000 f1-score on test data: 0.256\n"
     ]
    }
   ],
   "source": [
    "models(df_6g,drop_lst,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aa378901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After undersampling data size is 618 ; Resampled dataset shape Counter({'AD-AD': 103, 'CN-CN': 103, 'CN-MCI': 103, 'MCI-AD': 103, 'MCI-CN': 103, 'MCI-MCI': 103})\n",
      "\n",
      "6 principle components are needed to explain 90% of the data\n",
      "\n",
      "- Using original dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.191\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.047\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.191\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.221\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.047\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.221\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.236\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.106\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.236\n",
      "       - C = 1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.280\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.274\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.280\n",
      "       - C = 10\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.312\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.316\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.310\n",
      "       - C = 100\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.318\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.317\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.318\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.311\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.317\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.312\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. average weighted f1-score of 10-cross validation:0.138\n",
      "          - tree depth: 2.000. average weighted f1-score of 10-cross validation:0.265\n",
      "          - tree depth: 3.000. average weighted f1-score of 10-cross validation:0.317\n",
      "          - tree depth: 4.000. average weighted f1-score of 10-cross validation:0.320\n",
      "          - tree depth: 5.000. average weighted f1-score of 10-cross validation:0.291\n",
      "          - tree depth: 6.000. average weighted f1-score of 10-cross validation:0.294\n",
      "          - tree depth: 7.000. average weighted f1-score of 10-cross validation:0.284\n",
      "          - tree depth: 8.000. average weighted f1-score of 10-cross validation:0.289\n",
      "          - tree depth: 9.000. average weighted f1-score of 10-cross validation:0.304\n",
      "          - tree depth: 10.000. average weighted f1-score of 10-cross validation:0.295\n",
      "          - tree depth: 11.000. average weighted f1-score of 10-cross validation:0.295\n",
      "          - tree depth: 12.000. average weighted f1-score of 10-cross validation:0.296\n",
      "          - tree depth: 13.000. average weighted f1-score of 10-cross validation:0.296\n",
      "          - tree depth: 14.000. average weighted f1-score of 10-cross validation:0.298\n",
      "    - Random forest\n",
      "          - 5trees. average weighted f1-score of 10-cross validation:0.297\n",
      "          - 10trees. average weighted f1-score of 10-cross validation:0.329\n",
      "          - 15trees. average weighted f1-score of 10-cross validation:0.313\n",
      "          - 20trees. average weighted f1-score of 10-cross validation:0.336\n",
      "          - 25trees. average weighted f1-score of 10-cross validation:0.337\n",
      "          - 30trees. average weighted f1-score of 10-cross validation:0.367\n",
      "          - 35trees. average weighted f1-score of 10-cross validation:0.342\n",
      "          - 40trees. average weighted f1-score of 10-cross validation:0.361\n",
      "          - 45trees. average weighted f1-score of 10-cross validation:0.355\n",
      "          - 50trees. average weighted f1-score of 10-cross validation:0.351\n",
      "          - 55trees. average weighted f1-score of 10-cross validation:0.341\n",
      "          - 60trees. average weighted f1-score of 10-cross validation:0.357\n",
      "          - 65trees. average weighted f1-score of 10-cross validation:0.355\n",
      "          - 70trees. average weighted f1-score of 10-cross validation:0.356\n",
      "          - 75trees. average weighted f1-score of 10-cross validation:0.353\n",
      "          - 80trees. average weighted f1-score of 10-cross validation:0.347\n",
      "          - 85trees. average weighted f1-score of 10-cross validation:0.355\n",
      "          - 90trees. average weighted f1-score of 10-cross validation:0.357\n",
      "          - 95trees. average weighted f1-score of 10-cross validation:0.361\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. average weighted f1-score of 10-cross validation:0.298\n",
      "          - hidden layer size[20, 20]. average weighted f1-score of 10-cross validation:0.336\n",
      "- Using scaled dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.228\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.047\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.228\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.275\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.046\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.275\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.304\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.255\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.304\n",
      "       - C = 1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.303\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.308\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.303\n",
      "       - C = 10\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.306\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.308\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.306\n",
      "       - C = 100\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.306\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.306\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.306\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.306\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.306\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.306\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. average weighted f1-score of 10-cross validation:0.138\n",
      "          - tree depth: 2.000. average weighted f1-score of 10-cross validation:0.265\n",
      "          - tree depth: 3.000. average weighted f1-score of 10-cross validation:0.317\n",
      "          - tree depth: 4.000. average weighted f1-score of 10-cross validation:0.320\n",
      "          - tree depth: 5.000. average weighted f1-score of 10-cross validation:0.291\n",
      "          - tree depth: 6.000. average weighted f1-score of 10-cross validation:0.294\n",
      "          - tree depth: 7.000. average weighted f1-score of 10-cross validation:0.284\n",
      "          - tree depth: 8.000. average weighted f1-score of 10-cross validation:0.289\n",
      "          - tree depth: 9.000. average weighted f1-score of 10-cross validation:0.304\n",
      "          - tree depth: 10.000. average weighted f1-score of 10-cross validation:0.295\n",
      "          - tree depth: 11.000. average weighted f1-score of 10-cross validation:0.295\n",
      "          - tree depth: 12.000. average weighted f1-score of 10-cross validation:0.296\n",
      "          - tree depth: 13.000. average weighted f1-score of 10-cross validation:0.296\n",
      "          - tree depth: 14.000. average weighted f1-score of 10-cross validation:0.298\n",
      "    - Random forest\n",
      "          - 5trees. average weighted f1-score of 10-cross validation:0.297\n",
      "          - 10trees. average weighted f1-score of 10-cross validation:0.332\n",
      "          - 15trees. average weighted f1-score of 10-cross validation:0.314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          - 20trees. average weighted f1-score of 10-cross validation:0.335\n",
      "          - 25trees. average weighted f1-score of 10-cross validation:0.336\n",
      "          - 30trees. average weighted f1-score of 10-cross validation:0.361\n",
      "          - 35trees. average weighted f1-score of 10-cross validation:0.337\n",
      "          - 40trees. average weighted f1-score of 10-cross validation:0.358\n",
      "          - 45trees. average weighted f1-score of 10-cross validation:0.352\n",
      "          - 50trees. average weighted f1-score of 10-cross validation:0.351\n",
      "          - 55trees. average weighted f1-score of 10-cross validation:0.345\n",
      "          - 60trees. average weighted f1-score of 10-cross validation:0.354\n",
      "          - 65trees. average weighted f1-score of 10-cross validation:0.355\n",
      "          - 70trees. average weighted f1-score of 10-cross validation:0.360\n",
      "          - 75trees. average weighted f1-score of 10-cross validation:0.359\n",
      "          - 80trees. average weighted f1-score of 10-cross validation:0.347\n",
      "          - 85trees. average weighted f1-score of 10-cross validation:0.361\n",
      "          - 90trees. average weighted f1-score of 10-cross validation:0.356\n",
      "          - 95trees. average weighted f1-score of 10-cross validation:0.360\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. average weighted f1-score of 10-cross validation:0.279\n",
      "          - hidden layer size[20, 20]. average weighted f1-score of 10-cross validation:0.285\n",
      "- Using 6 pca-components:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.220\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.049\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.220\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.263\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.123\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.263\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.296\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.262\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.296\n",
      "       - C = 1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.301\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.304\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.301\n",
      "       - C = 10\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.306\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.307\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.306\n",
      "       - C = 100\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.306\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.309\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.306\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.306\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.306\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.306\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. average weighted f1-score of 10-cross validation:0.139\n",
      "          - tree depth: 2.000. average weighted f1-score of 10-cross validation:0.197\n",
      "          - tree depth: 3.000. average weighted f1-score of 10-cross validation:0.279\n",
      "          - tree depth: 4.000. average weighted f1-score of 10-cross validation:0.264\n",
      "          - tree depth: 5.000. average weighted f1-score of 10-cross validation:0.285\n",
      "          - tree depth: 6.000. average weighted f1-score of 10-cross validation:0.281\n",
      "          - tree depth: 7.000. average weighted f1-score of 10-cross validation:0.292\n",
      "          - tree depth: 8.000. average weighted f1-score of 10-cross validation:0.283\n",
      "          - tree depth: 9.000. average weighted f1-score of 10-cross validation:0.295\n",
      "          - tree depth: 10.000. average weighted f1-score of 10-cross validation:0.293\n",
      "          - tree depth: 11.000. average weighted f1-score of 10-cross validation:0.290\n",
      "          - tree depth: 12.000. average weighted f1-score of 10-cross validation:0.292\n",
      "          - tree depth: 13.000. average weighted f1-score of 10-cross validation:0.276\n",
      "          - tree depth: 14.000. average weighted f1-score of 10-cross validation:0.286\n",
      "    - Random forest\n",
      "          - 5trees. average weighted f1-score of 10-cross validation:0.297\n",
      "          - 10trees. average weighted f1-score of 10-cross validation:0.302\n",
      "          - 15trees. average weighted f1-score of 10-cross validation:0.316\n",
      "          - 20trees. average weighted f1-score of 10-cross validation:0.316\n",
      "          - 25trees. average weighted f1-score of 10-cross validation:0.315\n",
      "          - 30trees. average weighted f1-score of 10-cross validation:0.334\n",
      "          - 35trees. average weighted f1-score of 10-cross validation:0.346\n",
      "          - 40trees. average weighted f1-score of 10-cross validation:0.350\n",
      "          - 45trees. average weighted f1-score of 10-cross validation:0.350\n",
      "          - 50trees. average weighted f1-score of 10-cross validation:0.342\n",
      "          - 55trees. average weighted f1-score of 10-cross validation:0.341\n",
      "          - 60trees. average weighted f1-score of 10-cross validation:0.339\n",
      "          - 65trees. average weighted f1-score of 10-cross validation:0.343\n",
      "          - 70trees. average weighted f1-score of 10-cross validation:0.339\n",
      "          - 75trees. average weighted f1-score of 10-cross validation:0.337\n",
      "          - 80trees. average weighted f1-score of 10-cross validation:0.335\n",
      "          - 85trees. average weighted f1-score of 10-cross validation:0.344\n",
      "          - 90trees. average weighted f1-score of 10-cross validation:0.342\n",
      "          - 95trees. average weighted f1-score of 10-cross validation:0.341\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. average weighted f1-score of 10-cross validation:0.294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weipi\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:559: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          - hidden layer size[20, 20]. average weighted f1-score of 10-cross validation:0.255\n"
     ]
    }
   ],
   "source": [
    "cv_models(df_6g,drop_lst,target,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0f0d0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4c8fb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64b05ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# feature importance check\n",
    "def feature_importance(X,y,clf,k,title_label):\n",
    "    '''\n",
    "    check the feature importance of the selected classification (decisiontree or random forest) model.\n",
    "    X: input data\n",
    "    y: output data\n",
    "    clf: classification model, e.g.clf = RandomForestClassifier(n_estimators = 90, random_state = 5862) \n",
    "    Return\n",
    "    ------\n",
    "    dataframe of raw importance info\n",
    "    boxplot of importance\n",
    "    '''\n",
    "    output = cross_validate(clf, X, y, cv=k, scoring = 'f1_weighted', return_estimator =True)\n",
    "    d = {}  # dictionary to collect all importance dataframes \n",
    "    print(\"Features sorted by their score for each estimator \")\n",
    "    for idx,estimator in enumerate(output['estimator']):   \n",
    "        feature_importances = pd.DataFrame(estimator.feature_importances_,\n",
    "                                           index = X.columns,\n",
    "                                            columns=[\"importance_%s\"% (idx+1)])\n",
    "        d[idx] = feature_importances  \n",
    "    df = d[0]  # dataframe to concat all dataframes in d\n",
    "    for i in range(1,len(d)):\n",
    "        df = pd.concat([df,d[i]],axis=1)\n",
    "    df['avg_importance'] = df.mean(axis=1)\n",
    "    df = df.sort_values(by = ['avg_importance'], ascending = [False])\n",
    "    # insert avg_importance column as first column\n",
    "    df.insert(0, 'avg_importance', df.pop('avg_importance'))\n",
    "    # preparation for plotting\n",
    "    dff = df.T.reset_index().iloc[1:,1:] \n",
    "    # plot feature importance\n",
    "    bp = dff.boxplot(rot=30,figsize=(12,6),fontsize=12)\n",
    "    bp.set_ylabel('Feature Importance',fontsize=12)\n",
    "    bp.set_title('Feature importance of %s'%(title_label),fontsize=18)\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
