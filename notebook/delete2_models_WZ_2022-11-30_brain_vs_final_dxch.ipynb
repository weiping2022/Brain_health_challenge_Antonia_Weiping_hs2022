{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20f5d23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.tree import export_text\n",
    "import mglearn\n",
    "from dashboard_one import *\n",
    "from dash_model_two import *\n",
    "from feature_selection import *\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b74b94",
   "metadata": {},
   "source": [
    "### brain_volume_ratio_to_baseline_____VS_____final diagnosischanges \n",
    "\n",
    "\n",
    "#### sleep_brain_finaldxch.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fef6c499",
   "metadata": {},
   "outputs": [],
   "source": [
    "com_col = ['Phase', 'RID', 'VISCODE','PTID','RID_Phase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "769bd041",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RID</th>\n",
       "      <th>Phase</th>\n",
       "      <th>VISCODE</th>\n",
       "      <th>PTID</th>\n",
       "      <th>RID_Phase</th>\n",
       "      <th>NPIK1</th>\n",
       "      <th>NPIK2</th>\n",
       "      <th>NPIK3</th>\n",
       "      <th>NPIK4</th>\n",
       "      <th>NPIK5</th>\n",
       "      <th>...</th>\n",
       "      <th>ratio_PTAU_bl</th>\n",
       "      <th>Ventricles_reduction_per_year</th>\n",
       "      <th>Hippocampus_reduction_per_year</th>\n",
       "      <th>wholebrain_reduction_per_year</th>\n",
       "      <th>Entorhinal_reduction_per_year</th>\n",
       "      <th>Fusiform_reduction_per_year</th>\n",
       "      <th>ICV_reduction_per_year</th>\n",
       "      <th>ABETA_reduction_per_year</th>\n",
       "      <th>TAU_reduction_per_year</th>\n",
       "      <th>PTAU_reduction_per_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>011_S_0002</td>\n",
       "      <td>2_ADNI1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>011_S_0002</td>\n",
       "      <td>2_ADNI1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>011_S_0002</td>\n",
       "      <td>2_ADNI1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>011_S_0002</td>\n",
       "      <td>2_ADNI1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>011_S_0002</td>\n",
       "      <td>2_ADNI1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5408</th>\n",
       "      <td>6948</td>\n",
       "      <td>ADNI3</td>\n",
       "      <td>m12</td>\n",
       "      <td>035_S_6948</td>\n",
       "      <td>6948_ADNI3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5409</th>\n",
       "      <td>6950</td>\n",
       "      <td>ADNI3</td>\n",
       "      <td>m12</td>\n",
       "      <td>035_S_6950</td>\n",
       "      <td>6950_ADNI3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5410</th>\n",
       "      <td>6952</td>\n",
       "      <td>ADNI3</td>\n",
       "      <td>m12</td>\n",
       "      <td>073_S_6952</td>\n",
       "      <td>6952_ADNI3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5411</th>\n",
       "      <td>6987</td>\n",
       "      <td>ADNI3</td>\n",
       "      <td>m12</td>\n",
       "      <td>021_S_6987</td>\n",
       "      <td>6987_ADNI3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5412</th>\n",
       "      <td>6996</td>\n",
       "      <td>ADNI3</td>\n",
       "      <td>m12</td>\n",
       "      <td>003_S_6996</td>\n",
       "      <td>6996_ADNI3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5413 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       RID  Phase VISCODE        PTID   RID_Phase  NPIK1  NPIK2  NPIK3  NPIK4  \\\n",
       "0        2  ADNI1     NaN  011_S_0002     2_ADNI1    NaN    NaN    NaN    NaN   \n",
       "1        2  ADNI1     NaN  011_S_0002     2_ADNI1    NaN    NaN    NaN    NaN   \n",
       "2        2  ADNI1     NaN  011_S_0002     2_ADNI1    NaN    NaN    NaN    NaN   \n",
       "3        2  ADNI1     NaN  011_S_0002     2_ADNI1    NaN    NaN    NaN    NaN   \n",
       "4        2  ADNI1     NaN  011_S_0002     2_ADNI1    NaN    NaN    NaN    NaN   \n",
       "...    ...    ...     ...         ...         ...    ...    ...    ...    ...   \n",
       "5408  6948  ADNI3     m12  035_S_6948  6948_ADNI3    NaN    NaN    NaN    NaN   \n",
       "5409  6950  ADNI3     m12  035_S_6950  6950_ADNI3    NaN    NaN    NaN    NaN   \n",
       "5410  6952  ADNI3     m12  073_S_6952  6952_ADNI3    NaN    NaN    NaN    NaN   \n",
       "5411  6987  ADNI3     m12  021_S_6987  6987_ADNI3    NaN    NaN    NaN    NaN   \n",
       "5412  6996  ADNI3     m12  003_S_6996  6996_ADNI3    NaN    NaN    NaN    NaN   \n",
       "\n",
       "      NPIK5  ...  ratio_PTAU_bl  Ventricles_reduction_per_year  \\\n",
       "0       NaN  ...            NaN                            NaN   \n",
       "1       NaN  ...            NaN                            NaN   \n",
       "2       NaN  ...            NaN                            NaN   \n",
       "3       NaN  ...            NaN                            NaN   \n",
       "4       NaN  ...            NaN                            NaN   \n",
       "...     ...  ...            ...                            ...   \n",
       "5408    NaN  ...            NaN                            NaN   \n",
       "5409    NaN  ...            NaN                            NaN   \n",
       "5410    NaN  ...            NaN                            NaN   \n",
       "5411    NaN  ...            NaN                            NaN   \n",
       "5412    NaN  ...            NaN                            NaN   \n",
       "\n",
       "      Hippocampus_reduction_per_year  wholebrain_reduction_per_year  \\\n",
       "0                                NaN                            NaN   \n",
       "1                                NaN                            NaN   \n",
       "2                                NaN                            NaN   \n",
       "3                                NaN                            NaN   \n",
       "4                                NaN                            NaN   \n",
       "...                              ...                            ...   \n",
       "5408                             NaN                            NaN   \n",
       "5409                             NaN                            NaN   \n",
       "5410                             NaN                            NaN   \n",
       "5411                             NaN                            NaN   \n",
       "5412                             NaN                            NaN   \n",
       "\n",
       "      Entorhinal_reduction_per_year  Fusiform_reduction_per_year  \\\n",
       "0                               NaN                          NaN   \n",
       "1                               NaN                          NaN   \n",
       "2                               NaN                          NaN   \n",
       "3                               NaN                          NaN   \n",
       "4                               NaN                          NaN   \n",
       "...                             ...                          ...   \n",
       "5408                            NaN                          NaN   \n",
       "5409                            NaN                          NaN   \n",
       "5410                            NaN                          NaN   \n",
       "5411                            NaN                          NaN   \n",
       "5412                            NaN                          NaN   \n",
       "\n",
       "      ICV_reduction_per_year  ABETA_reduction_per_year  \\\n",
       "0                        NaN                       NaN   \n",
       "1                        NaN                       NaN   \n",
       "2                        NaN                       NaN   \n",
       "3                        NaN                       NaN   \n",
       "4                        NaN                       NaN   \n",
       "...                      ...                       ...   \n",
       "5408                     NaN                       NaN   \n",
       "5409                     NaN                       NaN   \n",
       "5410                     NaN                       NaN   \n",
       "5411                     NaN                       NaN   \n",
       "5412                     NaN                       NaN   \n",
       "\n",
       "      TAU_reduction_per_year PTAU_reduction_per_year  \n",
       "0                        NaN                     NaN  \n",
       "1                        NaN                     NaN  \n",
       "2                        NaN                     NaN  \n",
       "3                        NaN                     NaN  \n",
       "4                        NaN                     NaN  \n",
       "...                      ...                     ...  \n",
       "5408                     NaN                     NaN  \n",
       "5409                     NaN                     NaN  \n",
       "5410                     NaN                     NaN  \n",
       "5411                     NaN                     NaN  \n",
       "5412                     NaN                     NaN  \n",
       "\n",
       "[5413 rows x 39 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sleep_brain_finaldxch = pd.read_csv('sleep_brain_finaldxch.csv').iloc[:,1:].drop(['NPIKSEV'],axis=1)\n",
    "sleep_brain_finaldxch = sleep_brain_finaldxch[sleep_brain_finaldxch['final_dxch'].notna()].reset_index().drop(['index'],axis=1)   # keep the rows where DXCHANGE is not nan\n",
    "sleep_brain_finaldxch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1b7f3e",
   "metadata": {},
   "source": [
    "### sleep______VS______final_dxch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3461f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RID', 'Phase', 'VISCODE', 'PTID', 'RID_Phase', 'NPIK1', 'NPIK2',\n",
       "       'NPIK3', 'NPIK4', 'NPIK5', 'NPIK6', 'NPIK7', 'NPIK8', 'NPIK9A',\n",
       "       'NPIK9B', 'NPIK9C', 'NPIKTOT', 'insomnia', 'OSA', 'final_dxch',\n",
       "       'DXCHANGE', 'ratio_Ventricles_bl', 'ratio_Hippocampus_bl',\n",
       "       'ratio_WholeBrain_bl', 'ratio_Entorhinal_bl', 'ratio_Fusiform_bl',\n",
       "       'ratio_ICV_bl', 'ratio_ABETA_bl', 'ratio_TAU_bl', 'ratio_PTAU_bl',\n",
       "       'Ventricles_reduction_per_year', 'Hippocampus_reduction_per_year',\n",
       "       'wholebrain_reduction_per_year', 'Entorhinal_reduction_per_year',\n",
       "       'Fusiform_reduction_per_year', 'ICV_reduction_per_year',\n",
       "       'ABETA_reduction_per_year', 'TAU_reduction_per_year',\n",
       "       'PTAU_reduction_per_year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sleep_brain_finaldxch.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9b829bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phase</th>\n",
       "      <th>RID</th>\n",
       "      <th>VISCODE</th>\n",
       "      <th>PTID</th>\n",
       "      <th>RID_Phase</th>\n",
       "      <th>final_dxch</th>\n",
       "      <th>ratio_Ventricles_bl</th>\n",
       "      <th>ratio_Hippocampus_bl</th>\n",
       "      <th>ratio_WholeBrain_bl</th>\n",
       "      <th>ratio_Entorhinal_bl</th>\n",
       "      <th>ratio_Fusiform_bl</th>\n",
       "      <th>ratio_ICV_bl</th>\n",
       "      <th>Ventricles_reduction_per_year</th>\n",
       "      <th>Hippocampus_reduction_per_year</th>\n",
       "      <th>wholebrain_reduction_per_year</th>\n",
       "      <th>Entorhinal_reduction_per_year</th>\n",
       "      <th>Fusiform_reduction_per_year</th>\n",
       "      <th>ICV_reduction_per_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADNI1</td>\n",
       "      <td>15</td>\n",
       "      <td>m12</td>\n",
       "      <td>100_S_0015</td>\n",
       "      <td>15_ADNI1</td>\n",
       "      <td>CN-MCI</td>\n",
       "      <td>1.014961</td>\n",
       "      <td>1.063577</td>\n",
       "      <td>1.054649</td>\n",
       "      <td>0.916415</td>\n",
       "      <td>0.989634</td>\n",
       "      <td>1.030040</td>\n",
       "      <td>-0.015169</td>\n",
       "      <td>-0.064460</td>\n",
       "      <td>-0.055408</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.010510</td>\n",
       "      <td>-0.030457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADNI1</td>\n",
       "      <td>15</td>\n",
       "      <td>m36</td>\n",
       "      <td>100_S_0015</td>\n",
       "      <td>15_ADNI1</td>\n",
       "      <td>CN-MCI</td>\n",
       "      <td>1.007660</td>\n",
       "      <td>1.064023</td>\n",
       "      <td>1.037378</td>\n",
       "      <td>0.837938</td>\n",
       "      <td>1.058249</td>\n",
       "      <td>1.049400</td>\n",
       "      <td>-0.002528</td>\n",
       "      <td>-0.021129</td>\n",
       "      <td>-0.012335</td>\n",
       "      <td>0.053483</td>\n",
       "      <td>-0.019223</td>\n",
       "      <td>-0.016303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADNI1</td>\n",
       "      <td>22</td>\n",
       "      <td>m06</td>\n",
       "      <td>011_S_0022</td>\n",
       "      <td>22_ADNI1</td>\n",
       "      <td>CN-MCI</td>\n",
       "      <td>0.983373</td>\n",
       "      <td>1.011856</td>\n",
       "      <td>1.002765</td>\n",
       "      <td>0.918967</td>\n",
       "      <td>1.025827</td>\n",
       "      <td>0.992959</td>\n",
       "      <td>0.033162</td>\n",
       "      <td>-0.023648</td>\n",
       "      <td>-0.005515</td>\n",
       "      <td>0.161622</td>\n",
       "      <td>-0.051513</td>\n",
       "      <td>0.014044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADNI1</td>\n",
       "      <td>22</td>\n",
       "      <td>m12</td>\n",
       "      <td>011_S_0022</td>\n",
       "      <td>22_ADNI1</td>\n",
       "      <td>CN-MCI</td>\n",
       "      <td>1.000857</td>\n",
       "      <td>1.013261</td>\n",
       "      <td>0.997160</td>\n",
       "      <td>0.945500</td>\n",
       "      <td>0.995530</td>\n",
       "      <td>0.994859</td>\n",
       "      <td>-0.000857</td>\n",
       "      <td>-0.013261</td>\n",
       "      <td>0.002840</td>\n",
       "      <td>0.054500</td>\n",
       "      <td>0.004470</td>\n",
       "      <td>0.005141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADNI1</td>\n",
       "      <td>35</td>\n",
       "      <td>m06</td>\n",
       "      <td>100_S_0035</td>\n",
       "      <td>35_ADNI1</td>\n",
       "      <td>CN-MCI</td>\n",
       "      <td>1.036237</td>\n",
       "      <td>0.996185</td>\n",
       "      <td>0.992306</td>\n",
       "      <td>1.015318</td>\n",
       "      <td>1.045095</td>\n",
       "      <td>1.004973</td>\n",
       "      <td>-0.046409</td>\n",
       "      <td>0.004886</td>\n",
       "      <td>0.009854</td>\n",
       "      <td>-0.019618</td>\n",
       "      <td>-0.057753</td>\n",
       "      <td>-0.006369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>6744</td>\n",
       "      <td>m12</td>\n",
       "      <td>305_S_6744</td>\n",
       "      <td>6744_ADNI3</td>\n",
       "      <td>MCI-MCI</td>\n",
       "      <td>1.354956</td>\n",
       "      <td>0.933579</td>\n",
       "      <td>0.990424</td>\n",
       "      <td>1.016333</td>\n",
       "      <td>0.964412</td>\n",
       "      <td>1.004924</td>\n",
       "      <td>-0.361897</td>\n",
       "      <td>0.067720</td>\n",
       "      <td>0.009764</td>\n",
       "      <td>-0.016652</td>\n",
       "      <td>0.036284</td>\n",
       "      <td>-0.005020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>6788</td>\n",
       "      <td>m12</td>\n",
       "      <td>027_S_6788</td>\n",
       "      <td>6788_ADNI3</td>\n",
       "      <td>MCI-AD</td>\n",
       "      <td>1.049859</td>\n",
       "      <td>0.989317</td>\n",
       "      <td>0.992980</td>\n",
       "      <td>1.005187</td>\n",
       "      <td>0.947848</td>\n",
       "      <td>1.003776</td>\n",
       "      <td>-0.041645</td>\n",
       "      <td>0.008923</td>\n",
       "      <td>0.005863</td>\n",
       "      <td>-0.004332</td>\n",
       "      <td>0.043559</td>\n",
       "      <td>-0.003154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>6810</td>\n",
       "      <td>m12</td>\n",
       "      <td>305_S_6810</td>\n",
       "      <td>6810_ADNI3</td>\n",
       "      <td>AD-MCI</td>\n",
       "      <td>1.063515</td>\n",
       "      <td>0.951763</td>\n",
       "      <td>0.986113</td>\n",
       "      <td>0.834359</td>\n",
       "      <td>1.012821</td>\n",
       "      <td>1.006231</td>\n",
       "      <td>-0.101236</td>\n",
       "      <td>0.076885</td>\n",
       "      <td>0.022134</td>\n",
       "      <td>0.264012</td>\n",
       "      <td>-0.020436</td>\n",
       "      <td>-0.009931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>6852</td>\n",
       "      <td>m12</td>\n",
       "      <td>129_S_6852</td>\n",
       "      <td>6852_ADNI3</td>\n",
       "      <td>MCI-AD</td>\n",
       "      <td>1.089601</td>\n",
       "      <td>1.026073</td>\n",
       "      <td>0.968551</td>\n",
       "      <td>1.002634</td>\n",
       "      <td>0.950346</td>\n",
       "      <td>0.990819</td>\n",
       "      <td>-0.055337</td>\n",
       "      <td>-0.016103</td>\n",
       "      <td>0.019423</td>\n",
       "      <td>-0.001627</td>\n",
       "      <td>0.030666</td>\n",
       "      <td>0.005670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>6877</td>\n",
       "      <td>m12</td>\n",
       "      <td>305_S_6877</td>\n",
       "      <td>6877_ADNI3</td>\n",
       "      <td>MCI-MCI</td>\n",
       "      <td>1.005673</td>\n",
       "      <td>0.971493</td>\n",
       "      <td>0.999353</td>\n",
       "      <td>1.215293</td>\n",
       "      <td>1.000469</td>\n",
       "      <td>1.005690</td>\n",
       "      <td>-0.005673</td>\n",
       "      <td>0.028507</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>-0.215293</td>\n",
       "      <td>-0.000469</td>\n",
       "      <td>-0.005690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1300 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Phase   RID VISCODE        PTID   RID_Phase final_dxch  \\\n",
       "0     ADNI1    15     m12  100_S_0015    15_ADNI1     CN-MCI   \n",
       "1     ADNI1    15     m36  100_S_0015    15_ADNI1     CN-MCI   \n",
       "2     ADNI1    22     m06  011_S_0022    22_ADNI1     CN-MCI   \n",
       "3     ADNI1    22     m12  011_S_0022    22_ADNI1     CN-MCI   \n",
       "4     ADNI1    35     m06  100_S_0035    35_ADNI1     CN-MCI   \n",
       "...     ...   ...     ...         ...         ...        ...   \n",
       "1295  ADNI3  6744     m12  305_S_6744  6744_ADNI3    MCI-MCI   \n",
       "1296  ADNI3  6788     m12  027_S_6788  6788_ADNI3     MCI-AD   \n",
       "1297  ADNI3  6810     m12  305_S_6810  6810_ADNI3     AD-MCI   \n",
       "1298  ADNI3  6852     m12  129_S_6852  6852_ADNI3     MCI-AD   \n",
       "1299  ADNI3  6877     m12  305_S_6877  6877_ADNI3    MCI-MCI   \n",
       "\n",
       "      ratio_Ventricles_bl  ratio_Hippocampus_bl  ratio_WholeBrain_bl  \\\n",
       "0                1.014961              1.063577             1.054649   \n",
       "1                1.007660              1.064023             1.037378   \n",
       "2                0.983373              1.011856             1.002765   \n",
       "3                1.000857              1.013261             0.997160   \n",
       "4                1.036237              0.996185             0.992306   \n",
       "...                   ...                   ...                  ...   \n",
       "1295             1.354956              0.933579             0.990424   \n",
       "1296             1.049859              0.989317             0.992980   \n",
       "1297             1.063515              0.951763             0.986113   \n",
       "1298             1.089601              1.026073             0.968551   \n",
       "1299             1.005673              0.971493             0.999353   \n",
       "\n",
       "      ratio_Entorhinal_bl  ratio_Fusiform_bl  ratio_ICV_bl  \\\n",
       "0                0.916415           0.989634      1.030040   \n",
       "1                0.837938           1.058249      1.049400   \n",
       "2                0.918967           1.025827      0.992959   \n",
       "3                0.945500           0.995530      0.994859   \n",
       "4                1.015318           1.045095      1.004973   \n",
       "...                   ...                ...           ...   \n",
       "1295             1.016333           0.964412      1.004924   \n",
       "1296             1.005187           0.947848      1.003776   \n",
       "1297             0.834359           1.012821      1.006231   \n",
       "1298             1.002634           0.950346      0.990819   \n",
       "1299             1.215293           1.000469      1.005690   \n",
       "\n",
       "      Ventricles_reduction_per_year  Hippocampus_reduction_per_year  \\\n",
       "0                         -0.015169                       -0.064460   \n",
       "1                         -0.002528                       -0.021129   \n",
       "2                          0.033162                       -0.023648   \n",
       "3                         -0.000857                       -0.013261   \n",
       "4                         -0.046409                        0.004886   \n",
       "...                             ...                             ...   \n",
       "1295                      -0.361897                        0.067720   \n",
       "1296                      -0.041645                        0.008923   \n",
       "1297                      -0.101236                        0.076885   \n",
       "1298                      -0.055337                       -0.016103   \n",
       "1299                      -0.005673                        0.028507   \n",
       "\n",
       "      wholebrain_reduction_per_year  Entorhinal_reduction_per_year  \\\n",
       "0                         -0.055408                       0.084746   \n",
       "1                         -0.012335                       0.053483   \n",
       "2                         -0.005515                       0.161622   \n",
       "3                          0.002840                       0.054500   \n",
       "4                          0.009854                      -0.019618   \n",
       "...                             ...                            ...   \n",
       "1295                       0.009764                      -0.016652   \n",
       "1296                       0.005863                      -0.004332   \n",
       "1297                       0.022134                       0.264012   \n",
       "1298                       0.019423                      -0.001627   \n",
       "1299                       0.000647                      -0.215293   \n",
       "\n",
       "      Fusiform_reduction_per_year  ICV_reduction_per_year  \n",
       "0                        0.010510               -0.030457  \n",
       "1                       -0.019223               -0.016303  \n",
       "2                       -0.051513                0.014044  \n",
       "3                        0.004470                0.005141  \n",
       "4                       -0.057753               -0.006369  \n",
       "...                           ...                     ...  \n",
       "1295                     0.036284               -0.005020  \n",
       "1296                     0.043559               -0.003154  \n",
       "1297                    -0.020436               -0.009931  \n",
       "1298                     0.030666                0.005670  \n",
       "1299                    -0.000469               -0.005690  \n",
       "\n",
       "[1300 rows x 18 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_lst = [ 'final_dxch', 'ratio_Ventricles_bl', 'ratio_Hippocampus_bl',\n",
    "       'ratio_WholeBrain_bl', 'ratio_Entorhinal_bl', 'ratio_Fusiform_bl',\n",
    "       'ratio_ICV_bl','Ventricles_reduction_per_year', 'Hippocampus_reduction_per_year',\n",
    "       'wholebrain_reduction_per_year', 'Entorhinal_reduction_per_year',\n",
    "       'Fusiform_reduction_per_year', 'ICV_reduction_per_year']\n",
    "sleep_finaldxch = sleep_brain_finaldxch[com_col + col_lst].set_index(com_col).dropna(how='any',axis=0).reset_index()\n",
    "sleep_finaldxch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c75224ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Phase                             0\n",
       "RID                               0\n",
       "VISCODE                           0\n",
       "PTID                              0\n",
       "RID_Phase                         0\n",
       "final_dxch                        0\n",
       "ratio_Ventricles_bl               0\n",
       "ratio_Hippocampus_bl              0\n",
       "ratio_WholeBrain_bl               0\n",
       "ratio_Entorhinal_bl               0\n",
       "ratio_Fusiform_bl                 0\n",
       "ratio_ICV_bl                      0\n",
       "Ventricles_reduction_per_year     0\n",
       "Hippocampus_reduction_per_year    0\n",
       "wholebrain_reduction_per_year     0\n",
       "Entorhinal_reduction_per_year     0\n",
       "Fusiform_reduction_per_year       0\n",
       "ICV_reduction_per_year            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(sleep_finaldxch.isna())   # check nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af84a781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phase</th>\n",
       "      <th>RID</th>\n",
       "      <th>VISCODE</th>\n",
       "      <th>PTID</th>\n",
       "      <th>RID_Phase</th>\n",
       "      <th>ratio_Ventricles_bl</th>\n",
       "      <th>ratio_Hippocampus_bl</th>\n",
       "      <th>ratio_WholeBrain_bl</th>\n",
       "      <th>ratio_Entorhinal_bl</th>\n",
       "      <th>ratio_Fusiform_bl</th>\n",
       "      <th>ratio_ICV_bl</th>\n",
       "      <th>Ventricles_reduction_per_year</th>\n",
       "      <th>Hippocampus_reduction_per_year</th>\n",
       "      <th>wholebrain_reduction_per_year</th>\n",
       "      <th>Entorhinal_reduction_per_year</th>\n",
       "      <th>Fusiform_reduction_per_year</th>\n",
       "      <th>ICV_reduction_per_year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>final_dxch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AD-AD</th>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AD-MCI</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CN-AD</th>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CN-CN</th>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CN-MCI</th>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCI-AD</th>\n",
       "      <td>506</td>\n",
       "      <td>506</td>\n",
       "      <td>506</td>\n",
       "      <td>506</td>\n",
       "      <td>506</td>\n",
       "      <td>506</td>\n",
       "      <td>506</td>\n",
       "      <td>506</td>\n",
       "      <td>506</td>\n",
       "      <td>506</td>\n",
       "      <td>506</td>\n",
       "      <td>506</td>\n",
       "      <td>506</td>\n",
       "      <td>506</td>\n",
       "      <td>506</td>\n",
       "      <td>506</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCI-CN</th>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCI-MCI</th>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Phase  RID  VISCODE  PTID  RID_Phase  ratio_Ventricles_bl  \\\n",
       "final_dxch                                                              \n",
       "AD-AD         184  184      184   184        184                  184   \n",
       "AD-MCI          1    1        1     1          1                    1   \n",
       "CN-AD          80   80       80    80         80                   80   \n",
       "CN-CN          90   90       90    90         90                   90   \n",
       "CN-MCI        172  172      172   172        172                  172   \n",
       "MCI-AD        506  506      506   506        506                  506   \n",
       "MCI-CN        112  112      112   112        112                  112   \n",
       "MCI-MCI       155  155      155   155        155                  155   \n",
       "\n",
       "            ratio_Hippocampus_bl  ratio_WholeBrain_bl  ratio_Entorhinal_bl  \\\n",
       "final_dxch                                                                   \n",
       "AD-AD                        184                  184                  184   \n",
       "AD-MCI                         1                    1                    1   \n",
       "CN-AD                         80                   80                   80   \n",
       "CN-CN                         90                   90                   90   \n",
       "CN-MCI                       172                  172                  172   \n",
       "MCI-AD                       506                  506                  506   \n",
       "MCI-CN                       112                  112                  112   \n",
       "MCI-MCI                      155                  155                  155   \n",
       "\n",
       "            ratio_Fusiform_bl  ratio_ICV_bl  Ventricles_reduction_per_year  \\\n",
       "final_dxch                                                                   \n",
       "AD-AD                     184           184                            184   \n",
       "AD-MCI                      1             1                              1   \n",
       "CN-AD                      80            80                             80   \n",
       "CN-CN                      90            90                             90   \n",
       "CN-MCI                    172           172                            172   \n",
       "MCI-AD                    506           506                            506   \n",
       "MCI-CN                    112           112                            112   \n",
       "MCI-MCI                   155           155                            155   \n",
       "\n",
       "            Hippocampus_reduction_per_year  wholebrain_reduction_per_year  \\\n",
       "final_dxch                                                                  \n",
       "AD-AD                                  184                            184   \n",
       "AD-MCI                                   1                              1   \n",
       "CN-AD                                   80                             80   \n",
       "CN-CN                                   90                             90   \n",
       "CN-MCI                                 172                            172   \n",
       "MCI-AD                                 506                            506   \n",
       "MCI-CN                                 112                            112   \n",
       "MCI-MCI                                155                            155   \n",
       "\n",
       "            Entorhinal_reduction_per_year  Fusiform_reduction_per_year  \\\n",
       "final_dxch                                                               \n",
       "AD-AD                                 184                          184   \n",
       "AD-MCI                                  1                            1   \n",
       "CN-AD                                  80                           80   \n",
       "CN-CN                                  90                           90   \n",
       "CN-MCI                                172                          172   \n",
       "MCI-AD                                506                          506   \n",
       "MCI-CN                                112                          112   \n",
       "MCI-MCI                               155                          155   \n",
       "\n",
       "            ICV_reduction_per_year  \n",
       "final_dxch                          \n",
       "AD-AD                          184  \n",
       "AD-MCI                           1  \n",
       "CN-AD                           80  \n",
       "CN-CN                           90  \n",
       "CN-MCI                         172  \n",
       "MCI-AD                         506  \n",
       "MCI-CN                         112  \n",
       "MCI-MCI                        155  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sleep_finaldxch.groupby('final_dxch').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae317f9",
   "metadata": {},
   "source": [
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b631153b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97, 20)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sleep_dxch_2g = sleep_finaldxch.loc[sleep_finaldxch['final_dxch'].isin(['MCI-AD','AD-AD'])].reset_index().drop(['index'],axis=1)\n",
    "sleep_dxch_2g.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9522d6ff",
   "metadata": {},
   "source": [
    "- drop DXCHANGE labels 'AD-MCI','CN-AD','CN-CN' then undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39783bf",
   "metadata": {},
   "source": [
    "### oversampling and undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdd62ca",
   "metadata": {},
   "source": [
    "- functions\n",
    "    - models(df,drop_lst,target) : under sampling, split, scale, pca, models\n",
    "    - cv_models(df,drop_lst,target,k): under sampling, NOT SPLIT, scale, pca, models with cross-validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c356c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_lst = ['Phase', 'RID', 'VISCODE', 'PTID','RID_Phase','final_dxch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "780482ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After undersampling data size is 88 ; Resampled dataset shape Counter({'AD-AD': 44, 'MCI-AD': 44})\n",
      "\n",
      "9 principle components are needed to explain 90% of the data\n",
      "\n",
      "Output dataframes sequence: X_train,X_test,X_train_scaled,X_test_scaled,X_train_pca,X_test_pca,y_train,y_test\n",
      "- Using original dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, Training set f1-score:0.704, Test set f1-score: 0.500\n",
      "          - saga_L1, Training set f1-score:0.704, Test set f1-score: 0.500\n",
      "          - newton-cg_L2, Training set f1-score:0.704, Test set f1-score: 0.500\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, Training set f1-score:0.682, Test set f1-score: 0.441\n",
      "          - saga_L1, Training set f1-score:0.704, Test set f1-score: 0.500\n",
      "          - newton-cg_L2, Training set f1-score:0.682, Test set f1-score: 0.441\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, Training set f1-score:0.624, Test set f1-score: 0.511\n",
      "          - saga_L1, Training set f1-score:0.704, Test set f1-score: 0.500\n",
      "          - newton-cg_L2, Training set f1-score:0.624, Test set f1-score: 0.511\n",
      "       - C = 1\n",
      "          - lbfgs_L2, Training set f1-score:0.685, Test set f1-score: 0.492\n",
      "          - saga_L1, Training set f1-score:0.658, Test set f1-score: 0.544\n",
      "          - newton-cg_L2, Training set f1-score:0.685, Test set f1-score: 0.492\n",
      "       - C = 10\n",
      "          - lbfgs_L2, Training set f1-score:0.662, Test set f1-score: 0.544\n",
      "          - saga_L1, Training set f1-score:0.662, Test set f1-score: 0.544\n",
      "          - newton-cg_L2, Training set f1-score:0.662, Test set f1-score: 0.544\n",
      "       - C = 100\n",
      "          - lbfgs_L2, Training set f1-score:0.678, Test set f1-score: 0.544\n",
      "          - saga_L1, Training set f1-score:0.665, Test set f1-score: 0.544\n",
      "          - newton-cg_L2, Training set f1-score:0.678, Test set f1-score: 0.544\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, Training set f1-score:0.662, Test set f1-score: 0.544\n",
      "          - saga_L1, Training set f1-score:0.665, Test set f1-score: 0.544\n",
      "          - newton-cg_L2, Training set f1-score:0.662, Test set f1-score: 0.544\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. f1-score on training data: 0.700 f1-score on test data: 0.501\n",
      "          - tree depth: 2.000. f1-score on training data: 0.606 f1-score on test data: 0.379\n",
      "          - tree depth: 3.000. f1-score on training data: 0.704 f1-score on test data: 0.420\n",
      "          - tree depth: 4.000. f1-score on training data: 0.717 f1-score on test data: 0.492\n",
      "          - tree depth: 5.000. f1-score on training data: 0.829 f1-score on test data: 0.544\n",
      "          - tree depth: 6.000. f1-score on training data: 0.872 f1-score on test data: 0.444\n",
      "          - tree depth: 7.000. f1-score on training data: 0.943 f1-score on test data: 0.544\n",
      "          - tree depth: 8.000. f1-score on training data: 0.957 f1-score on test data: 0.492\n",
      "          - tree depth: 9.000. f1-score on training data: 0.986 f1-score on test data: 0.431\n",
      "          - tree depth: 10.000. f1-score on training data: 0.986 f1-score on test data: 0.431\n",
      "          - tree depth: 11.000. f1-score on training data: 0.986 f1-score on test data: 0.431\n",
      "          - tree depth: 12.000. f1-score on training data: 0.986 f1-score on test data: 0.431\n",
      "          - tree depth: 13.000. f1-score on training data: 0.986 f1-score on test data: 0.431\n",
      "          - tree depth: 14.000. f1-score on training data: 0.986 f1-score on test data: 0.431\n",
      "    - Random forest\n",
      "          - 5trees. f1-score on training data: 0.957 f1-score on test data: 0.267\n",
      "          - 10trees. f1-score on training data: 0.986 f1-score on test data: 0.257\n",
      "          - 15trees. f1-score on training data: 0.971 f1-score on test data: 0.257\n",
      "          - 20trees. f1-score on training data: 0.986 f1-score on test data: 0.430\n",
      "          - 25trees. f1-score on training data: 0.986 f1-score on test data: 0.430\n",
      "          - 30trees. f1-score on training data: 0.986 f1-score on test data: 0.371\n",
      "          - 35trees. f1-score on training data: 0.986 f1-score on test data: 0.371\n",
      "          - 40trees. f1-score on training data: 0.986 f1-score on test data: 0.371\n",
      "          - 45trees. f1-score on training data: 0.986 f1-score on test data: 0.371\n",
      "          - 50trees. f1-score on training data: 0.986 f1-score on test data: 0.430\n",
      "          - 55trees. f1-score on training data: 0.986 f1-score on test data: 0.317\n",
      "          - 60trees. f1-score on training data: 0.986 f1-score on test data: 0.430\n",
      "          - 65trees. f1-score on training data: 0.986 f1-score on test data: 0.371\n",
      "          - 70trees. f1-score on training data: 0.986 f1-score on test data: 0.371\n",
      "          - 75trees. f1-score on training data: 0.986 f1-score on test data: 0.371\n",
      "          - 80trees. f1-score on training data: 0.986 f1-score on test data: 0.371\n",
      "          - 85trees. f1-score on training data: 0.986 f1-score on test data: 0.430\n",
      "          - 90trees. f1-score on training data: 0.986 f1-score on test data: 0.430\n",
      "          - 95trees. f1-score on training data: 0.986 f1-score on test data: 0.430\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. f1-score on training data: 0.986 f1-score on test data: 0.430\n",
      "          - hidden layer size[20, 20]. f1-score on training data: 0.986 f1-score on test data: 0.431\n",
      "          - hidden layer size[100, 100]. f1-score on training data: 0.986 f1-score on test data: 0.431\n",
      "          - hidden layer size[50, 50, 50]. f1-score on training data: 0.986 f1-score on test data: 0.371\n",
      "- Using scaled dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, Training set f1-score:0.704, Test set f1-score: 0.500\n",
      "          - saga_L1, Training set f1-score:0.704, Test set f1-score: 0.500\n",
      "          - newton-cg_L2, Training set f1-score:0.704, Test set f1-score: 0.500\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, Training set f1-score:0.700, Test set f1-score: 0.501\n",
      "          - saga_L1, Training set f1-score:0.704, Test set f1-score: 0.500\n",
      "          - newton-cg_L2, Training set f1-score:0.700, Test set f1-score: 0.501\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, Training set f1-score:0.632, Test set f1-score: 0.511\n",
      "          - saga_L1, Training set f1-score:0.704, Test set f1-score: 0.500\n",
      "          - newton-cg_L2, Training set f1-score:0.632, Test set f1-score: 0.511\n",
      "       - C = 1\n",
      "          - lbfgs_L2, Training set f1-score:0.653, Test set f1-score: 0.605\n",
      "          - saga_L1, Training set f1-score:0.642, Test set f1-score: 0.605\n",
      "          - newton-cg_L2, Training set f1-score:0.653, Test set f1-score: 0.605\n",
      "       - C = 10\n",
      "          - lbfgs_L2, Training set f1-score:0.650, Test set f1-score: 0.544\n",
      "          - saga_L1, Training set f1-score:0.650, Test set f1-score: 0.544\n",
      "          - newton-cg_L2, Training set f1-score:0.650, Test set f1-score: 0.544\n",
      "       - C = 100\n",
      "          - lbfgs_L2, Training set f1-score:0.678, Test set f1-score: 0.544\n",
      "          - saga_L1, Training set f1-score:0.678, Test set f1-score: 0.544\n",
      "          - newton-cg_L2, Training set f1-score:0.678, Test set f1-score: 0.544\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, Training set f1-score:0.662, Test set f1-score: 0.544\n",
      "          - saga_L1, Training set f1-score:0.662, Test set f1-score: 0.544\n",
      "          - newton-cg_L2, Training set f1-score:0.662, Test set f1-score: 0.544\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. f1-score on training data: 0.700 f1-score on test data: 0.501\n",
      "          - tree depth: 2.000. f1-score on training data: 0.606 f1-score on test data: 0.379\n",
      "          - tree depth: 3.000. f1-score on training data: 0.704 f1-score on test data: 0.420\n",
      "          - tree depth: 4.000. f1-score on training data: 0.717 f1-score on test data: 0.492\n",
      "          - tree depth: 5.000. f1-score on training data: 0.829 f1-score on test data: 0.544\n",
      "          - tree depth: 6.000. f1-score on training data: 0.872 f1-score on test data: 0.444\n",
      "          - tree depth: 7.000. f1-score on training data: 0.943 f1-score on test data: 0.544\n",
      "          - tree depth: 8.000. f1-score on training data: 0.957 f1-score on test data: 0.492\n",
      "          - tree depth: 9.000. f1-score on training data: 0.986 f1-score on test data: 0.431\n",
      "          - tree depth: 10.000. f1-score on training data: 0.986 f1-score on test data: 0.431\n",
      "          - tree depth: 11.000. f1-score on training data: 0.986 f1-score on test data: 0.431\n",
      "          - tree depth: 12.000. f1-score on training data: 0.986 f1-score on test data: 0.431\n",
      "          - tree depth: 13.000. f1-score on training data: 0.986 f1-score on test data: 0.431\n",
      "          - tree depth: 14.000. f1-score on training data: 0.986 f1-score on test data: 0.431\n",
      "    - Random forest\n",
      "          - 5trees. f1-score on training data: 0.957 f1-score on test data: 0.267\n",
      "          - 10trees. f1-score on training data: 0.986 f1-score on test data: 0.257\n",
      "          - 15trees. f1-score on training data: 0.971 f1-score on test data: 0.257\n",
      "          - 20trees. f1-score on training data: 0.986 f1-score on test data: 0.430\n",
      "          - 25trees. f1-score on training data: 0.986 f1-score on test data: 0.430\n",
      "          - 30trees. f1-score on training data: 0.986 f1-score on test data: 0.371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          - 35trees. f1-score on training data: 0.986 f1-score on test data: 0.371\n",
      "          - 40trees. f1-score on training data: 0.986 f1-score on test data: 0.371\n",
      "          - 45trees. f1-score on training data: 0.986 f1-score on test data: 0.371\n",
      "          - 50trees. f1-score on training data: 0.986 f1-score on test data: 0.371\n",
      "          - 55trees. f1-score on training data: 0.986 f1-score on test data: 0.317\n",
      "          - 60trees. f1-score on training data: 0.986 f1-score on test data: 0.371\n",
      "          - 65trees. f1-score on training data: 0.986 f1-score on test data: 0.371\n",
      "          - 70trees. f1-score on training data: 0.986 f1-score on test data: 0.371\n",
      "          - 75trees. f1-score on training data: 0.986 f1-score on test data: 0.371\n",
      "          - 80trees. f1-score on training data: 0.986 f1-score on test data: 0.371\n",
      "          - 85trees. f1-score on training data: 0.986 f1-score on test data: 0.371\n",
      "          - 90trees. f1-score on training data: 0.986 f1-score on test data: 0.371\n",
      "          - 95trees. f1-score on training data: 0.986 f1-score on test data: 0.371\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. f1-score on training data: 0.986 f1-score on test data: 0.333\n",
      "          - hidden layer size[20, 20]. f1-score on training data: 0.986 f1-score on test data: 0.430\n",
      "          - hidden layer size[100, 100]. f1-score on training data: 0.986 f1-score on test data: 0.379\n",
      "          - hidden layer size[50, 50, 50]. f1-score on training data: 0.986 f1-score on test data: 0.431\n",
      "- Using 9 pca-components:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, Training set f1-score:0.704, Test set f1-score: 0.500\n",
      "          - saga_L1, Training set f1-score:0.627, Test set f1-score: 0.800\n",
      "          - newton-cg_L2, Training set f1-score:0.704, Test set f1-score: 0.500\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, Training set f1-score:0.700, Test set f1-score: 0.501\n",
      "          - saga_L1, Training set f1-score:0.704, Test set f1-score: 0.500\n",
      "          - newton-cg_L2, Training set f1-score:0.700, Test set f1-score: 0.501\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, Training set f1-score:0.649, Test set f1-score: 0.556\n",
      "          - saga_L1, Training set f1-score:0.704, Test set f1-score: 0.500\n",
      "          - newton-cg_L2, Training set f1-score:0.649, Test set f1-score: 0.556\n",
      "       - C = 1\n",
      "          - lbfgs_L2, Training set f1-score:0.652, Test set f1-score: 0.605\n",
      "          - saga_L1, Training set f1-score:0.662, Test set f1-score: 0.556\n",
      "          - newton-cg_L2, Training set f1-score:0.652, Test set f1-score: 0.605\n",
      "       - C = 10\n",
      "          - lbfgs_L2, Training set f1-score:0.662, Test set f1-score: 0.605\n",
      "          - saga_L1, Training set f1-score:0.662, Test set f1-score: 0.605\n",
      "          - newton-cg_L2, Training set f1-score:0.662, Test set f1-score: 0.605\n",
      "       - C = 100\n",
      "          - lbfgs_L2, Training set f1-score:0.646, Test set f1-score: 0.605\n",
      "          - saga_L1, Training set f1-score:0.662, Test set f1-score: 0.605\n",
      "          - newton-cg_L2, Training set f1-score:0.646, Test set f1-score: 0.605\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, Training set f1-score:0.646, Test set f1-score: 0.605\n",
      "          - saga_L1, Training set f1-score:0.646, Test set f1-score: 0.605\n",
      "          - newton-cg_L2, Training set f1-score:0.646, Test set f1-score: 0.605\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. f1-score on training data: 0.671 f1-score on test data: 0.430\n",
      "          - tree depth: 2.000. f1-score on training data: 0.753 f1-score on test data: 0.492\n",
      "          - tree depth: 3.000. f1-score on training data: 0.800 f1-score on test data: 0.621\n",
      "          - tree depth: 4.000. f1-score on training data: 0.902 f1-score on test data: 0.621\n",
      "          - tree depth: 5.000. f1-score on training data: 0.943 f1-score on test data: 0.556\n",
      "          - tree depth: 6.000. f1-score on training data: 0.943 f1-score on test data: 0.556\n",
      "          - tree depth: 7.000. f1-score on training data: 0.972 f1-score on test data: 0.583\n",
      "          - tree depth: 8.000. f1-score on training data: 0.986 f1-score on test data: 0.513\n",
      "          - tree depth: 9.000. f1-score on training data: 0.986 f1-score on test data: 0.513\n",
      "          - tree depth: 10.000. f1-score on training data: 0.986 f1-score on test data: 0.621\n",
      "          - tree depth: 11.000. f1-score on training data: 0.986 f1-score on test data: 0.621\n",
      "          - tree depth: 12.000. f1-score on training data: 0.986 f1-score on test data: 0.621\n",
      "          - tree depth: 13.000. f1-score on training data: 0.986 f1-score on test data: 0.621\n",
      "          - tree depth: 14.000. f1-score on training data: 0.986 f1-score on test data: 0.621\n",
      "    - Random forest\n",
      "          - 5trees. f1-score on training data: 0.943 f1-score on test data: 0.492\n",
      "          - 10trees. f1-score on training data: 0.957 f1-score on test data: 0.583\n",
      "          - 15trees. f1-score on training data: 0.971 f1-score on test data: 0.556\n",
      "          - 20trees. f1-score on training data: 0.986 f1-score on test data: 0.556\n",
      "          - 25trees. f1-score on training data: 0.986 f1-score on test data: 0.513\n",
      "          - 30trees. f1-score on training data: 0.986 f1-score on test data: 0.513\n",
      "          - 35trees. f1-score on training data: 0.986 f1-score on test data: 0.513\n",
      "          - 40trees. f1-score on training data: 0.986 f1-score on test data: 0.513\n",
      "          - 45trees. f1-score on training data: 0.986 f1-score on test data: 0.430\n",
      "          - 50trees. f1-score on training data: 0.986 f1-score on test data: 0.492\n",
      "          - 55trees. f1-score on training data: 0.986 f1-score on test data: 0.492\n",
      "          - 60trees. f1-score on training data: 0.986 f1-score on test data: 0.544\n",
      "          - 65trees. f1-score on training data: 0.986 f1-score on test data: 0.492\n",
      "          - 70trees. f1-score on training data: 0.986 f1-score on test data: 0.492\n",
      "          - 75trees. f1-score on training data: 0.986 f1-score on test data: 0.492\n",
      "          - 80trees. f1-score on training data: 0.986 f1-score on test data: 0.492\n",
      "          - 85trees. f1-score on training data: 0.986 f1-score on test data: 0.492\n",
      "          - 90trees. f1-score on training data: 0.986 f1-score on test data: 0.430\n",
      "          - 95trees. f1-score on training data: 0.986 f1-score on test data: 0.430\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. f1-score on training data: 0.986 f1-score on test data: 0.444\n",
      "          - hidden layer size[20, 20]. f1-score on training data: 0.986 f1-score on test data: 0.371\n",
      "          - hidden layer size[100, 100]. f1-score on training data: 0.986 f1-score on test data: 0.333\n",
      "          - hidden layer size[50, 50, 50]. f1-score on training data: 0.986 f1-score on test data: 0.492\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "models(sleep_dxch_2g,drop_lst,'final_dxch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "8b90c02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After undersampling data size is 154 ; Resampled dataset shape Counter({'MCI-AD': 77, 'MCI-MCI': 77})\n",
      "\n",
      "10 principle components are needed to explain 90% of the data\n",
      "\n",
      "- Using original dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.490\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.326\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.490\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.534\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.326\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.534\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.591\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.483\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.591\n",
      "       - C = 1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.560\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.539\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.560\n",
      "       - C = 10\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.566\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.566\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.566\n",
      "       - C = 100\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.559\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.559\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.559\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.559\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.559\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.559\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. average weighted f1-score of 10-cross validation:0.519\n",
      "          - tree depth: 2.000. average weighted f1-score of 10-cross validation:0.553\n",
      "          - tree depth: 3.000. average weighted f1-score of 10-cross validation:0.581\n",
      "          - tree depth: 4.000. average weighted f1-score of 10-cross validation:0.565\n",
      "          - tree depth: 5.000. average weighted f1-score of 10-cross validation:0.491\n",
      "          - tree depth: 6.000. average weighted f1-score of 10-cross validation:0.493\n",
      "          - tree depth: 7.000. average weighted f1-score of 10-cross validation:0.473\n",
      "          - tree depth: 8.000. average weighted f1-score of 10-cross validation:0.466\n",
      "          - tree depth: 9.000. average weighted f1-score of 10-cross validation:0.494\n",
      "          - tree depth: 10.000. average weighted f1-score of 10-cross validation:0.423\n",
      "          - tree depth: 11.000. average weighted f1-score of 10-cross validation:0.463\n",
      "          - tree depth: 12.000. average weighted f1-score of 10-cross validation:0.443\n",
      "          - tree depth: 13.000. average weighted f1-score of 10-cross validation:0.443\n",
      "          - tree depth: 14.000. average weighted f1-score of 10-cross validation:0.451\n",
      "    - Random forest\n",
      "          - 5trees. average weighted f1-score of 10-cross validation:0.522\n",
      "          - 10trees. average weighted f1-score of 10-cross validation:0.501\n",
      "          - 15trees. average weighted f1-score of 10-cross validation:0.506\n",
      "          - 20trees. average weighted f1-score of 10-cross validation:0.514\n",
      "          - 25trees. average weighted f1-score of 10-cross validation:0.528\n",
      "          - 30trees. average weighted f1-score of 10-cross validation:0.529\n",
      "          - 35trees. average weighted f1-score of 10-cross validation:0.534\n",
      "          - 40trees. average weighted f1-score of 10-cross validation:0.523\n",
      "          - 45trees. average weighted f1-score of 10-cross validation:0.536\n",
      "          - 50trees. average weighted f1-score of 10-cross validation:0.527\n",
      "          - 55trees. average weighted f1-score of 10-cross validation:0.532\n",
      "          - 60trees. average weighted f1-score of 10-cross validation:0.520\n",
      "          - 65trees. average weighted f1-score of 10-cross validation:0.519\n",
      "          - 70trees. average weighted f1-score of 10-cross validation:0.520\n",
      "          - 75trees. average weighted f1-score of 10-cross validation:0.507\n",
      "          - 80trees. average weighted f1-score of 10-cross validation:0.514\n",
      "          - 85trees. average weighted f1-score of 10-cross validation:0.514\n",
      "          - 90trees. average weighted f1-score of 10-cross validation:0.514\n",
      "          - 95trees. average weighted f1-score of 10-cross validation:0.519\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. average weighted f1-score of 10-cross validation:0.472\n",
      "          - hidden layer size[20, 20]. average weighted f1-score of 10-cross validation:0.463\n",
      "          - hidden layer size[100, 100]. average weighted f1-score of 10-cross validation:0.518\n",
      "          - hidden layer size[50, 50, 50]. average weighted f1-score of 10-cross validation:0.454\n",
      "- Using scaled dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.509\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.334\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.509\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.532\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.326\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.532\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.563\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.500\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.563\n",
      "       - C = 1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.572\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.565\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.572\n",
      "       - C = 10\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.559\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.566\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.559\n",
      "       - C = 100\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.559\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.559\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.559\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.559\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.559\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.559\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. average weighted f1-score of 10-cross validation:0.519\n",
      "          - tree depth: 2.000. average weighted f1-score of 10-cross validation:0.553\n",
      "          - tree depth: 3.000. average weighted f1-score of 10-cross validation:0.581\n",
      "          - tree depth: 4.000. average weighted f1-score of 10-cross validation:0.565\n",
      "          - tree depth: 5.000. average weighted f1-score of 10-cross validation:0.491\n",
      "          - tree depth: 6.000. average weighted f1-score of 10-cross validation:0.493\n",
      "          - tree depth: 7.000. average weighted f1-score of 10-cross validation:0.473\n",
      "          - tree depth: 8.000. average weighted f1-score of 10-cross validation:0.466\n",
      "          - tree depth: 9.000. average weighted f1-score of 10-cross validation:0.494\n",
      "          - tree depth: 10.000. average weighted f1-score of 10-cross validation:0.423\n",
      "          - tree depth: 11.000. average weighted f1-score of 10-cross validation:0.463\n",
      "          - tree depth: 12.000. average weighted f1-score of 10-cross validation:0.443\n",
      "          - tree depth: 13.000. average weighted f1-score of 10-cross validation:0.443\n",
      "          - tree depth: 14.000. average weighted f1-score of 10-cross validation:0.451\n",
      "    - Random forest\n",
      "          - 5trees. average weighted f1-score of 10-cross validation:0.522\n",
      "          - 10trees. average weighted f1-score of 10-cross validation:0.499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          - 15trees. average weighted f1-score of 10-cross validation:0.499\n",
      "          - 20trees. average weighted f1-score of 10-cross validation:0.508\n",
      "          - 25trees. average weighted f1-score of 10-cross validation:0.514\n",
      "          - 30trees. average weighted f1-score of 10-cross validation:0.523\n",
      "          - 35trees. average weighted f1-score of 10-cross validation:0.515\n",
      "          - 40trees. average weighted f1-score of 10-cross validation:0.510\n",
      "          - 45trees. average weighted f1-score of 10-cross validation:0.523\n",
      "          - 50trees. average weighted f1-score of 10-cross validation:0.508\n",
      "          - 55trees. average weighted f1-score of 10-cross validation:0.514\n",
      "          - 60trees. average weighted f1-score of 10-cross validation:0.514\n",
      "          - 65trees. average weighted f1-score of 10-cross validation:0.507\n",
      "          - 70trees. average weighted f1-score of 10-cross validation:0.514\n",
      "          - 75trees. average weighted f1-score of 10-cross validation:0.507\n",
      "          - 80trees. average weighted f1-score of 10-cross validation:0.508\n",
      "          - 85trees. average weighted f1-score of 10-cross validation:0.508\n",
      "          - 90trees. average weighted f1-score of 10-cross validation:0.508\n",
      "          - 95trees. average weighted f1-score of 10-cross validation:0.508\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. average weighted f1-score of 10-cross validation:0.509\n",
      "          - hidden layer size[20, 20]. average weighted f1-score of 10-cross validation:0.487\n",
      "          - hidden layer size[100, 100]. average weighted f1-score of 10-cross validation:0.491\n",
      "          - hidden layer size[50, 50, 50]. average weighted f1-score of 10-cross validation:0.458\n",
      "- Using 10 pca-components:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.550\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.326\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.550\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.544\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.341\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.544\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.531\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.522\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.531\n",
      "       - C = 1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.532\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.539\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.532\n",
      "       - C = 10\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.539\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.539\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.539\n",
      "       - C = 100\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.539\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.539\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.539\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.539\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.539\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.539\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. average weighted f1-score of 10-cross validation:0.499\n",
      "          - tree depth: 2.000. average weighted f1-score of 10-cross validation:0.426\n",
      "          - tree depth: 3.000. average weighted f1-score of 10-cross validation:0.519\n",
      "          - tree depth: 4.000. average weighted f1-score of 10-cross validation:0.454\n",
      "          - tree depth: 5.000. average weighted f1-score of 10-cross validation:0.496\n",
      "          - tree depth: 6.000. average weighted f1-score of 10-cross validation:0.462\n",
      "          - tree depth: 7.000. average weighted f1-score of 10-cross validation:0.495\n",
      "          - tree depth: 8.000. average weighted f1-score of 10-cross validation:0.505\n",
      "          - tree depth: 9.000. average weighted f1-score of 10-cross validation:0.513\n",
      "          - tree depth: 10.000. average weighted f1-score of 10-cross validation:0.504\n",
      "          - tree depth: 11.000. average weighted f1-score of 10-cross validation:0.478\n",
      "          - tree depth: 12.000. average weighted f1-score of 10-cross validation:0.486\n",
      "          - tree depth: 13.000. average weighted f1-score of 10-cross validation:0.486\n",
      "          - tree depth: 14.000. average weighted f1-score of 10-cross validation:0.480\n",
      "    - Random forest\n",
      "          - 5trees. average weighted f1-score of 10-cross validation:0.523\n",
      "          - 10trees. average weighted f1-score of 10-cross validation:0.559\n",
      "          - 15trees. average weighted f1-score of 10-cross validation:0.592\n",
      "          - 20trees. average weighted f1-score of 10-cross validation:0.622\n",
      "          - 25trees. average weighted f1-score of 10-cross validation:0.600\n",
      "          - 30trees. average weighted f1-score of 10-cross validation:0.598\n",
      "          - 35trees. average weighted f1-score of 10-cross validation:0.595\n",
      "          - 40trees. average weighted f1-score of 10-cross validation:0.594\n",
      "          - 45trees. average weighted f1-score of 10-cross validation:0.576\n",
      "          - 50trees. average weighted f1-score of 10-cross validation:0.562\n",
      "          - 55trees. average weighted f1-score of 10-cross validation:0.552\n",
      "          - 60trees. average weighted f1-score of 10-cross validation:0.552\n",
      "          - 65trees. average weighted f1-score of 10-cross validation:0.545\n",
      "          - 70trees. average weighted f1-score of 10-cross validation:0.563\n",
      "          - 75trees. average weighted f1-score of 10-cross validation:0.550\n",
      "          - 80trees. average weighted f1-score of 10-cross validation:0.561\n",
      "          - 85trees. average weighted f1-score of 10-cross validation:0.576\n",
      "          - 90trees. average weighted f1-score of 10-cross validation:0.576\n",
      "          - 95trees. average weighted f1-score of 10-cross validation:0.584\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. average weighted f1-score of 10-cross validation:0.553\n",
      "          - hidden layer size[20, 20]. average weighted f1-score of 10-cross validation:0.506\n",
      "          - hidden layer size[100, 100]. average weighted f1-score of 10-cross validation:0.532\n",
      "          - hidden layer size[50, 50, 50]. average weighted f1-score of 10-cross validation:0.540\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv_models(sleep_dxch_2g,drop_lst,'DXCHANGE',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "80eed256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After undersampling data size is 123 ; Resampled dataset shape Counter({'MCI-AD': 41, 'MCI-CN': 41, 'MCI-MCI': 41})\n",
      "\n",
      "9 principle components are needed to explain 90% of the data\n",
      "\n",
      "Output dataframes sequence: X_train,X_test,X_train_scaled,X_test_scaled,X_train_pca,X_test_pca,y_train,y_test\n",
      "- Using original dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, Training set f1-score:0.621, Test set f1-score: 0.447\n",
      "          - saga_L1, Training set f1-score:0.504, Test set f1-score: 0.485\n",
      "          - newton-cg_L2, Training set f1-score:0.621, Test set f1-score: 0.447\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, Training set f1-score:0.588, Test set f1-score: 0.396\n",
      "          - saga_L1, Training set f1-score:0.504, Test set f1-score: 0.485\n",
      "          - newton-cg_L2, Training set f1-score:0.588, Test set f1-score: 0.396\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, Training set f1-score:0.595, Test set f1-score: 0.440\n",
      "          - saga_L1, Training set f1-score:0.534, Test set f1-score: 0.482\n",
      "          - newton-cg_L2, Training set f1-score:0.595, Test set f1-score: 0.440\n",
      "       - C = 1\n",
      "          - lbfgs_L2, Training set f1-score:0.629, Test set f1-score: 0.457\n",
      "          - saga_L1, Training set f1-score:0.610, Test set f1-score: 0.458\n",
      "          - newton-cg_L2, Training set f1-score:0.629, Test set f1-score: 0.457\n",
      "       - C = 10\n",
      "          - lbfgs_L2, Training set f1-score:0.629, Test set f1-score: 0.416\n",
      "          - saga_L1, Training set f1-score:0.629, Test set f1-score: 0.416\n",
      "          - newton-cg_L2, Training set f1-score:0.629, Test set f1-score: 0.416\n",
      "       - C = 100\n",
      "          - lbfgs_L2, Training set f1-score:0.618, Test set f1-score: 0.413\n",
      "          - saga_L1, Training set f1-score:0.627, Test set f1-score: 0.416\n",
      "          - newton-cg_L2, Training set f1-score:0.618, Test set f1-score: 0.413\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, Training set f1-score:0.618, Test set f1-score: 0.413\n",
      "          - saga_L1, Training set f1-score:0.627, Test set f1-score: 0.413\n",
      "          - newton-cg_L2, Training set f1-score:0.618, Test set f1-score: 0.413\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. f1-score on training data: 0.646 f1-score on test data: 0.440\n",
      "          - tree depth: 2.000. f1-score on training data: 0.625 f1-score on test data: 0.440\n",
      "          - tree depth: 3.000. f1-score on training data: 0.633 f1-score on test data: 0.369\n",
      "          - tree depth: 4.000. f1-score on training data: 0.700 f1-score on test data: 0.465\n",
      "          - tree depth: 5.000. f1-score on training data: 0.790 f1-score on test data: 0.359\n",
      "          - tree depth: 6.000. f1-score on training data: 0.837 f1-score on test data: 0.328\n",
      "          - tree depth: 7.000. f1-score on training data: 0.877 f1-score on test data: 0.367\n",
      "          - tree depth: 8.000. f1-score on training data: 0.917 f1-score on test data: 0.319\n",
      "          - tree depth: 9.000. f1-score on training data: 0.917 f1-score on test data: 0.272\n",
      "          - tree depth: 10.000. f1-score on training data: 0.938 f1-score on test data: 0.320\n",
      "          - tree depth: 11.000. f1-score on training data: 0.938 f1-score on test data: 0.280\n",
      "          - tree depth: 12.000. f1-score on training data: 0.938 f1-score on test data: 0.275\n",
      "          - tree depth: 13.000. f1-score on training data: 0.939 f1-score on test data: 0.327\n",
      "          - tree depth: 14.000. f1-score on training data: 0.939 f1-score on test data: 0.321\n",
      "    - Random forest\n",
      "          - 5trees. f1-score on training data: 0.898 f1-score on test data: 0.220\n",
      "          - 10trees. f1-score on training data: 0.938 f1-score on test data: 0.301\n",
      "          - 15trees. f1-score on training data: 0.928 f1-score on test data: 0.337\n",
      "          - 20trees. f1-score on training data: 0.938 f1-score on test data: 0.374\n",
      "          - 25trees. f1-score on training data: 0.938 f1-score on test data: 0.339\n",
      "          - 30trees. f1-score on training data: 0.938 f1-score on test data: 0.366\n",
      "          - 35trees. f1-score on training data: 0.938 f1-score on test data: 0.337\n",
      "          - 40trees. f1-score on training data: 0.938 f1-score on test data: 0.367\n",
      "          - 45trees. f1-score on training data: 0.938 f1-score on test data: 0.367\n",
      "          - 50trees. f1-score on training data: 0.938 f1-score on test data: 0.372\n",
      "          - 55trees. f1-score on training data: 0.938 f1-score on test data: 0.335\n",
      "          - 60trees. f1-score on training data: 0.938 f1-score on test data: 0.335\n",
      "          - 65trees. f1-score on training data: 0.938 f1-score on test data: 0.372\n",
      "          - 70trees. f1-score on training data: 0.938 f1-score on test data: 0.372\n",
      "          - 75trees. f1-score on training data: 0.938 f1-score on test data: 0.372\n",
      "          - 80trees. f1-score on training data: 0.938 f1-score on test data: 0.344\n",
      "          - 85trees. f1-score on training data: 0.938 f1-score on test data: 0.344\n",
      "          - 90trees. f1-score on training data: 0.938 f1-score on test data: 0.345\n",
      "          - 95trees. f1-score on training data: 0.938 f1-score on test data: 0.344\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. f1-score on training data: 0.939 f1-score on test data: 0.396\n",
      "          - hidden layer size[20, 20]. f1-score on training data: 0.939 f1-score on test data: 0.288\n",
      "          - hidden layer size[100, 100]. f1-score on training data: 0.938 f1-score on test data: 0.412\n",
      "          - hidden layer size[50, 50, 50]. f1-score on training data: 0.939 f1-score on test data: 0.440\n",
      "- Using scaled dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, Training set f1-score:0.620, Test set f1-score: 0.588\n",
      "          - saga_L1, Training set f1-score:0.504, Test set f1-score: 0.485\n",
      "          - newton-cg_L2, Training set f1-score:0.620, Test set f1-score: 0.588\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, Training set f1-score:0.593, Test set f1-score: 0.529\n",
      "          - saga_L1, Training set f1-score:0.504, Test set f1-score: 0.485\n",
      "          - newton-cg_L2, Training set f1-score:0.593, Test set f1-score: 0.529\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, Training set f1-score:0.657, Test set f1-score: 0.434\n",
      "          - saga_L1, Training set f1-score:0.601, Test set f1-score: 0.448\n",
      "          - newton-cg_L2, Training set f1-score:0.657, Test set f1-score: 0.434\n",
      "       - C = 1\n",
      "          - lbfgs_L2, Training set f1-score:0.637, Test set f1-score: 0.457\n",
      "          - saga_L1, Training set f1-score:0.635, Test set f1-score: 0.457\n",
      "          - newton-cg_L2, Training set f1-score:0.637, Test set f1-score: 0.457\n",
      "       - C = 10\n",
      "          - lbfgs_L2, Training set f1-score:0.629, Test set f1-score: 0.416\n",
      "          - saga_L1, Training set f1-score:0.627, Test set f1-score: 0.416\n",
      "          - newton-cg_L2, Training set f1-score:0.629, Test set f1-score: 0.416\n",
      "       - C = 100\n",
      "          - lbfgs_L2, Training set f1-score:0.618, Test set f1-score: 0.413\n",
      "          - saga_L1, Training set f1-score:0.618, Test set f1-score: 0.413\n",
      "          - newton-cg_L2, Training set f1-score:0.618, Test set f1-score: 0.413\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, Training set f1-score:0.618, Test set f1-score: 0.413\n",
      "          - saga_L1, Training set f1-score:0.618, Test set f1-score: 0.413\n",
      "          - newton-cg_L2, Training set f1-score:0.618, Test set f1-score: 0.413\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. f1-score on training data: 0.646 f1-score on test data: 0.440\n",
      "          - tree depth: 2.000. f1-score on training data: 0.625 f1-score on test data: 0.440\n",
      "          - tree depth: 3.000. f1-score on training data: 0.633 f1-score on test data: 0.369\n",
      "          - tree depth: 4.000. f1-score on training data: 0.700 f1-score on test data: 0.465\n",
      "          - tree depth: 5.000. f1-score on training data: 0.790 f1-score on test data: 0.359\n",
      "          - tree depth: 6.000. f1-score on training data: 0.837 f1-score on test data: 0.328\n",
      "          - tree depth: 7.000. f1-score on training data: 0.877 f1-score on test data: 0.367\n",
      "          - tree depth: 8.000. f1-score on training data: 0.917 f1-score on test data: 0.319\n",
      "          - tree depth: 9.000. f1-score on training data: 0.917 f1-score on test data: 0.272\n",
      "          - tree depth: 10.000. f1-score on training data: 0.938 f1-score on test data: 0.320\n",
      "          - tree depth: 11.000. f1-score on training data: 0.938 f1-score on test data: 0.280\n",
      "          - tree depth: 12.000. f1-score on training data: 0.938 f1-score on test data: 0.275\n",
      "          - tree depth: 13.000. f1-score on training data: 0.939 f1-score on test data: 0.327\n",
      "          - tree depth: 14.000. f1-score on training data: 0.939 f1-score on test data: 0.321\n",
      "    - Random forest\n",
      "          - 5trees. f1-score on training data: 0.898 f1-score on test data: 0.272\n",
      "          - 10trees. f1-score on training data: 0.938 f1-score on test data: 0.301\n",
      "          - 15trees. f1-score on training data: 0.928 f1-score on test data: 0.337\n",
      "          - 20trees. f1-score on training data: 0.938 f1-score on test data: 0.374\n",
      "          - 25trees. f1-score on training data: 0.938 f1-score on test data: 0.339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          - 30trees. f1-score on training data: 0.938 f1-score on test data: 0.366\n",
      "          - 35trees. f1-score on training data: 0.938 f1-score on test data: 0.337\n",
      "          - 40trees. f1-score on training data: 0.938 f1-score on test data: 0.367\n",
      "          - 45trees. f1-score on training data: 0.938 f1-score on test data: 0.367\n",
      "          - 50trees. f1-score on training data: 0.938 f1-score on test data: 0.372\n",
      "          - 55trees. f1-score on training data: 0.938 f1-score on test data: 0.335\n",
      "          - 60trees. f1-score on training data: 0.938 f1-score on test data: 0.335\n",
      "          - 65trees. f1-score on training data: 0.938 f1-score on test data: 0.372\n",
      "          - 70trees. f1-score on training data: 0.938 f1-score on test data: 0.372\n",
      "          - 75trees. f1-score on training data: 0.938 f1-score on test data: 0.372\n",
      "          - 80trees. f1-score on training data: 0.938 f1-score on test data: 0.344\n",
      "          - 85trees. f1-score on training data: 0.938 f1-score on test data: 0.344\n",
      "          - 90trees. f1-score on training data: 0.938 f1-score on test data: 0.345\n",
      "          - 95trees. f1-score on training data: 0.938 f1-score on test data: 0.344\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. f1-score on training data: 0.938 f1-score on test data: 0.405\n",
      "          - hidden layer size[20, 20]. f1-score on training data: 0.938 f1-score on test data: 0.399\n",
      "          - hidden layer size[100, 100]. f1-score on training data: 0.938 f1-score on test data: 0.306\n",
      "          - hidden layer size[50, 50, 50]. f1-score on training data: 0.940 f1-score on test data: 0.348\n",
      "- Using 9 pca-components:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, Training set f1-score:0.618, Test set f1-score: 0.537\n",
      "          - saga_L1, Training set f1-score:0.504, Test set f1-score: 0.485\n",
      "          - newton-cg_L2, Training set f1-score:0.618, Test set f1-score: 0.537\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, Training set f1-score:0.600, Test set f1-score: 0.482\n",
      "          - saga_L1, Training set f1-score:0.504, Test set f1-score: 0.485\n",
      "          - newton-cg_L2, Training set f1-score:0.600, Test set f1-score: 0.482\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, Training set f1-score:0.628, Test set f1-score: 0.389\n",
      "          - saga_L1, Training set f1-score:0.590, Test set f1-score: 0.487\n",
      "          - newton-cg_L2, Training set f1-score:0.628, Test set f1-score: 0.389\n",
      "       - C = 1\n",
      "          - lbfgs_L2, Training set f1-score:0.636, Test set f1-score: 0.389\n",
      "          - saga_L1, Training set f1-score:0.628, Test set f1-score: 0.438\n",
      "          - newton-cg_L2, Training set f1-score:0.636, Test set f1-score: 0.389\n",
      "       - C = 10\n",
      "          - lbfgs_L2, Training set f1-score:0.636, Test set f1-score: 0.389\n",
      "          - saga_L1, Training set f1-score:0.636, Test set f1-score: 0.389\n",
      "          - newton-cg_L2, Training set f1-score:0.636, Test set f1-score: 0.389\n",
      "       - C = 100\n",
      "          - lbfgs_L2, Training set f1-score:0.636, Test set f1-score: 0.389\n",
      "          - saga_L1, Training set f1-score:0.636, Test set f1-score: 0.389\n",
      "          - newton-cg_L2, Training set f1-score:0.636, Test set f1-score: 0.389\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, Training set f1-score:0.636, Test set f1-score: 0.389\n",
      "          - saga_L1, Training set f1-score:0.636, Test set f1-score: 0.389\n",
      "          - newton-cg_L2, Training set f1-score:0.636, Test set f1-score: 0.389\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. f1-score on training data: 0.634 f1-score on test data: 0.489\n",
      "          - tree depth: 2.000. f1-score on training data: 0.625 f1-score on test data: 0.358\n",
      "          - tree depth: 3.000. f1-score on training data: 0.706 f1-score on test data: 0.416\n",
      "          - tree depth: 4.000. f1-score on training data: 0.781 f1-score on test data: 0.335\n",
      "          - tree depth: 5.000. f1-score on training data: 0.818 f1-score on test data: 0.282\n",
      "          - tree depth: 6.000. f1-score on training data: 0.867 f1-score on test data: 0.331\n",
      "          - tree depth: 7.000. f1-score on training data: 0.919 f1-score on test data: 0.320\n",
      "          - tree depth: 8.000. f1-score on training data: 0.939 f1-score on test data: 0.316\n",
      "          - tree depth: 9.000. f1-score on training data: 0.939 f1-score on test data: 0.325\n",
      "          - tree depth: 10.000. f1-score on training data: 0.939 f1-score on test data: 0.325\n",
      "          - tree depth: 11.000. f1-score on training data: 0.939 f1-score on test data: 0.316\n",
      "          - tree depth: 12.000. f1-score on training data: 0.939 f1-score on test data: 0.356\n",
      "          - tree depth: 13.000. f1-score on training data: 0.939 f1-score on test data: 0.356\n",
      "          - tree depth: 14.000. f1-score on training data: 0.939 f1-score on test data: 0.356\n",
      "    - Random forest\n",
      "          - 5trees. f1-score on training data: 0.908 f1-score on test data: 0.468\n",
      "          - 10trees. f1-score on training data: 0.939 f1-score on test data: 0.408\n",
      "          - 15trees. f1-score on training data: 0.939 f1-score on test data: 0.422\n",
      "          - 20trees. f1-score on training data: 0.938 f1-score on test data: 0.459\n",
      "          - 25trees. f1-score on training data: 0.939 f1-score on test data: 0.317\n",
      "          - 30trees. f1-score on training data: 0.939 f1-score on test data: 0.317\n",
      "          - 35trees. f1-score on training data: 0.939 f1-score on test data: 0.317\n",
      "          - 40trees. f1-score on training data: 0.938 f1-score on test data: 0.360\n",
      "          - 45trees. f1-score on training data: 0.938 f1-score on test data: 0.360\n",
      "          - 50trees. f1-score on training data: 0.939 f1-score on test data: 0.360\n",
      "          - 55trees. f1-score on training data: 0.938 f1-score on test data: 0.360\n",
      "          - 60trees. f1-score on training data: 0.938 f1-score on test data: 0.360\n",
      "          - 65trees. f1-score on training data: 0.938 f1-score on test data: 0.360\n",
      "          - 70trees. f1-score on training data: 0.938 f1-score on test data: 0.360\n",
      "          - 75trees. f1-score on training data: 0.938 f1-score on test data: 0.360\n",
      "          - 80trees. f1-score on training data: 0.938 f1-score on test data: 0.360\n",
      "          - 85trees. f1-score on training data: 0.938 f1-score on test data: 0.360\n",
      "          - 90trees. f1-score on training data: 0.938 f1-score on test data: 0.360\n",
      "          - 95trees. f1-score on training data: 0.938 f1-score on test data: 0.360\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. f1-score on training data: 0.938 f1-score on test data: 0.337\n",
      "          - hidden layer size[20, 20]. f1-score on training data: 0.938 f1-score on test data: 0.318\n",
      "          - hidden layer size[100, 100]. f1-score on training data: 0.938 f1-score on test data: 0.244\n",
      "          - hidden layer size[50, 50, 50]. f1-score on training data: 0.938 f1-score on test data: 0.260\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "models(sleep_dxch_3g,drop_lst,'DXCHANGE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5c4fa8",
   "metadata": {},
   "source": [
    "normal data: random forest: 85trees. f1-score on training data: 0.969 f1-score on test data: 0.780\n",
    "normal data: random forest: 85trees. f1-score on training data: 0.969 f1-score on test data: 0.780\n",
    "\n",
    "pca:decision tree: tree depth: 6.000. f1-score on training data: 0.891 f1-score on test data: 0.810"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "0071686b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After undersampling data size is 123 ; Resampled dataset shape Counter({'MCI-AD': 41, 'MCI-CN': 41, 'MCI-MCI': 41})\n",
      "\n",
      "9 principle components are needed to explain 90% of the data\n",
      "\n",
      "- Using original dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.433\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.160\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.433\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.476\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.167\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.476\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.440\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.419\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.440\n",
      "       - C = 1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.456\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.465\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.456\n",
      "       - C = 10\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.443\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.441\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.443\n",
      "       - C = 100\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.431\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.442\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.431\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.421\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.431\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.421\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. average weighted f1-score of 10-cross validation:0.398\n",
      "          - tree depth: 2.000. average weighted f1-score of 10-cross validation:0.421\n",
      "          - tree depth: 3.000. average weighted f1-score of 10-cross validation:0.386\n",
      "          - tree depth: 4.000. average weighted f1-score of 10-cross validation:0.391\n",
      "          - tree depth: 5.000. average weighted f1-score of 10-cross validation:0.349\n",
      "          - tree depth: 6.000. average weighted f1-score of 10-cross validation:0.332\n",
      "          - tree depth: 7.000. average weighted f1-score of 10-cross validation:0.347\n",
      "          - tree depth: 8.000. average weighted f1-score of 10-cross validation:0.361\n",
      "          - tree depth: 9.000. average weighted f1-score of 10-cross validation:0.359\n",
      "          - tree depth: 10.000. average weighted f1-score of 10-cross validation:0.400\n",
      "          - tree depth: 11.000. average weighted f1-score of 10-cross validation:0.355\n",
      "          - tree depth: 12.000. average weighted f1-score of 10-cross validation:0.365\n",
      "          - tree depth: 13.000. average weighted f1-score of 10-cross validation:0.355\n",
      "          - tree depth: 14.000. average weighted f1-score of 10-cross validation:0.338\n",
      "    - Random forest\n",
      "          - 5trees. average weighted f1-score of 10-cross validation:0.387\n",
      "          - 10trees. average weighted f1-score of 10-cross validation:0.369\n",
      "          - 15trees. average weighted f1-score of 10-cross validation:0.439\n",
      "          - 20trees. average weighted f1-score of 10-cross validation:0.407\n",
      "          - 25trees. average weighted f1-score of 10-cross validation:0.381\n",
      "          - 30trees. average weighted f1-score of 10-cross validation:0.365\n",
      "          - 35trees. average weighted f1-score of 10-cross validation:0.350\n",
      "          - 40trees. average weighted f1-score of 10-cross validation:0.342\n",
      "          - 45trees. average weighted f1-score of 10-cross validation:0.351\n",
      "          - 50trees. average weighted f1-score of 10-cross validation:0.360\n",
      "          - 55trees. average weighted f1-score of 10-cross validation:0.369\n",
      "          - 60trees. average weighted f1-score of 10-cross validation:0.368\n",
      "          - 65trees. average weighted f1-score of 10-cross validation:0.388\n",
      "          - 70trees. average weighted f1-score of 10-cross validation:0.388\n",
      "          - 75trees. average weighted f1-score of 10-cross validation:0.370\n",
      "          - 80trees. average weighted f1-score of 10-cross validation:0.370\n",
      "          - 85trees. average weighted f1-score of 10-cross validation:0.370\n",
      "          - 90trees. average weighted f1-score of 10-cross validation:0.370\n",
      "          - 95trees. average weighted f1-score of 10-cross validation:0.361\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. average weighted f1-score of 10-cross validation:0.346\n",
      "          - hidden layer size[20, 20]. average weighted f1-score of 10-cross validation:0.348\n",
      "          - hidden layer size[100, 100]. average weighted f1-score of 10-cross validation:0.366\n",
      "          - hidden layer size[50, 50, 50]. average weighted f1-score of 10-cross validation:0.328\n",
      "- Using scaled dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.406\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.174\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.406\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.428\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.167\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.428\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.430\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.452\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.430\n",
      "       - C = 1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.463\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.450\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.463\n",
      "       - C = 10\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weipi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\weipi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.440\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.442\n",
      "       - C = 100\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weipi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\weipi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\weipi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\weipi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\weipi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.431\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.431\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weipi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\weipi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\weipi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\weipi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\weipi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.432\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.421\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. average weighted f1-score of 10-cross validation:0.398\n",
      "          - tree depth: 2.000. average weighted f1-score of 10-cross validation:0.421\n",
      "          - tree depth: 3.000. average weighted f1-score of 10-cross validation:0.386\n",
      "          - tree depth: 4.000. average weighted f1-score of 10-cross validation:0.391\n",
      "          - tree depth: 5.000. average weighted f1-score of 10-cross validation:0.349\n",
      "          - tree depth: 6.000. average weighted f1-score of 10-cross validation:0.332\n",
      "          - tree depth: 7.000. average weighted f1-score of 10-cross validation:0.347\n",
      "          - tree depth: 8.000. average weighted f1-score of 10-cross validation:0.361\n",
      "          - tree depth: 9.000. average weighted f1-score of 10-cross validation:0.359\n",
      "          - tree depth: 10.000. average weighted f1-score of 10-cross validation:0.400\n",
      "          - tree depth: 11.000. average weighted f1-score of 10-cross validation:0.355\n",
      "          - tree depth: 12.000. average weighted f1-score of 10-cross validation:0.365\n",
      "          - tree depth: 13.000. average weighted f1-score of 10-cross validation:0.355\n",
      "          - tree depth: 14.000. average weighted f1-score of 10-cross validation:0.338\n",
      "    - Random forest\n",
      "          - 5trees. average weighted f1-score of 10-cross validation:0.389\n",
      "          - 10trees. average weighted f1-score of 10-cross validation:0.369\n",
      "          - 15trees. average weighted f1-score of 10-cross validation:0.439\n",
      "          - 20trees. average weighted f1-score of 10-cross validation:0.407\n",
      "          - 25trees. average weighted f1-score of 10-cross validation:0.368\n",
      "          - 30trees. average weighted f1-score of 10-cross validation:0.355\n",
      "          - 35trees. average weighted f1-score of 10-cross validation:0.345\n",
      "          - 40trees. average weighted f1-score of 10-cross validation:0.331\n",
      "          - 45trees. average weighted f1-score of 10-cross validation:0.340\n",
      "          - 50trees. average weighted f1-score of 10-cross validation:0.349\n",
      "          - 55trees. average weighted f1-score of 10-cross validation:0.358\n",
      "          - 60trees. average weighted f1-score of 10-cross validation:0.357\n",
      "          - 65trees. average weighted f1-score of 10-cross validation:0.369\n",
      "          - 70trees. average weighted f1-score of 10-cross validation:0.369\n",
      "          - 75trees. average weighted f1-score of 10-cross validation:0.358\n",
      "          - 80trees. average weighted f1-score of 10-cross validation:0.358\n",
      "          - 85trees. average weighted f1-score of 10-cross validation:0.359\n",
      "          - 90trees. average weighted f1-score of 10-cross validation:0.359\n",
      "          - 95trees. average weighted f1-score of 10-cross validation:0.350\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. average weighted f1-score of 10-cross validation:0.283\n",
      "          - hidden layer size[20, 20]. average weighted f1-score of 10-cross validation:0.360\n",
      "          - hidden layer size[100, 100]. average weighted f1-score of 10-cross validation:0.342\n",
      "          - hidden layer size[50, 50, 50]. average weighted f1-score of 10-cross validation:0.316\n",
      "- Using 9 pca-components:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.432\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.167\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.432\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.438\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.174\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.438\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.435\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.462\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.435\n",
      "       - C = 1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.439\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.463\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.439\n",
      "       - C = 10\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.437\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.445\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.437\n",
      "       - C = 100\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weipi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\weipi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\weipi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\weipi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.437\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.437\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weipi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\weipi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\weipi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\weipi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\weipi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\weipi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.444\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.437\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. average weighted f1-score of 10-cross validation:0.345\n",
      "          - tree depth: 2.000. average weighted f1-score of 10-cross validation:0.415\n",
      "          - tree depth: 3.000. average weighted f1-score of 10-cross validation:0.388\n",
      "          - tree depth: 4.000. average weighted f1-score of 10-cross validation:0.375\n",
      "          - tree depth: 5.000. average weighted f1-score of 10-cross validation:0.290\n",
      "          - tree depth: 6.000. average weighted f1-score of 10-cross validation:0.348\n",
      "          - tree depth: 7.000. average weighted f1-score of 10-cross validation:0.348\n",
      "          - tree depth: 8.000. average weighted f1-score of 10-cross validation:0.342\n",
      "          - tree depth: 9.000. average weighted f1-score of 10-cross validation:0.317\n",
      "          - tree depth: 10.000. average weighted f1-score of 10-cross validation:0.320\n",
      "          - tree depth: 11.000. average weighted f1-score of 10-cross validation:0.310\n",
      "          - tree depth: 12.000. average weighted f1-score of 10-cross validation:0.324\n",
      "          - tree depth: 13.000. average weighted f1-score of 10-cross validation:0.332\n",
      "          - tree depth: 14.000. average weighted f1-score of 10-cross validation:0.332\n",
      "    - Random forest\n",
      "          - 5trees. average weighted f1-score of 10-cross validation:0.361\n",
      "          - 10trees. average weighted f1-score of 10-cross validation:0.393\n",
      "          - 15trees. average weighted f1-score of 10-cross validation:0.408\n",
      "          - 20trees. average weighted f1-score of 10-cross validation:0.452\n",
      "          - 25trees. average weighted f1-score of 10-cross validation:0.443\n",
      "          - 30trees. average weighted f1-score of 10-cross validation:0.417\n",
      "          - 35trees. average weighted f1-score of 10-cross validation:0.390\n",
      "          - 40trees. average weighted f1-score of 10-cross validation:0.393\n",
      "          - 45trees. average weighted f1-score of 10-cross validation:0.415\n",
      "          - 50trees. average weighted f1-score of 10-cross validation:0.418\n",
      "          - 55trees. average weighted f1-score of 10-cross validation:0.400\n",
      "          - 60trees. average weighted f1-score of 10-cross validation:0.400\n",
      "          - 65trees. average weighted f1-score of 10-cross validation:0.383\n",
      "          - 70trees. average weighted f1-score of 10-cross validation:0.380\n",
      "          - 75trees. average weighted f1-score of 10-cross validation:0.410\n",
      "          - 80trees. average weighted f1-score of 10-cross validation:0.410\n",
      "          - 85trees. average weighted f1-score of 10-cross validation:0.406\n",
      "          - 90trees. average weighted f1-score of 10-cross validation:0.393\n",
      "          - 95trees. average weighted f1-score of 10-cross validation:0.405\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. average weighted f1-score of 10-cross validation:0.340\n",
      "          - hidden layer size[20, 20]. average weighted f1-score of 10-cross validation:0.363\n",
      "          - hidden layer size[100, 100]. average weighted f1-score of 10-cross validation:0.357\n",
      "          - hidden layer size[50, 50, 50]. average weighted f1-score of 10-cross validation:0.338\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv_models(sleep_dxch_3g,drop_lst,'DXCHANGE',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "a1f8203f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After undersampling data size is 190 ; Resampled dataset shape Counter({'AD-AD': 38, 'CN-MCI': 38, 'MCI-AD': 38, 'MCI-CN': 38, 'MCI-MCI': 38})\n",
      "\n",
      "10 principle components are needed to explain 90% of the data\n",
      "\n",
      "Output dataframes sequence: X_train,X_test,X_train_scaled,X_test_scaled,X_train_pca,X_test_pca,y_train,y_test\n",
      "- Using original dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, Training set f1-score:0.442, Test set f1-score: 0.242\n",
      "          - saga_L1, Training set f1-score:0.357, Test set f1-score: 0.233\n",
      "          - newton-cg_L2, Training set f1-score:0.442, Test set f1-score: 0.242\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, Training set f1-score:0.441, Test set f1-score: 0.249\n",
      "          - saga_L1, Training set f1-score:0.357, Test set f1-score: 0.233\n",
      "          - newton-cg_L2, Training set f1-score:0.441, Test set f1-score: 0.249\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, Training set f1-score:0.429, Test set f1-score: 0.230\n",
      "          - saga_L1, Training set f1-score:0.380, Test set f1-score: 0.248\n",
      "          - newton-cg_L2, Training set f1-score:0.429, Test set f1-score: 0.230\n",
      "       - C = 1\n",
      "          - lbfgs_L2, Training set f1-score:0.413, Test set f1-score: 0.255\n",
      "          - saga_L1, Training set f1-score:0.414, Test set f1-score: 0.267\n",
      "          - newton-cg_L2, Training set f1-score:0.413, Test set f1-score: 0.255\n",
      "       - C = 10\n",
      "          - lbfgs_L2, Training set f1-score:0.427, Test set f1-score: 0.268\n",
      "          - saga_L1, Training set f1-score:0.425, Test set f1-score: 0.274\n",
      "          - newton-cg_L2, Training set f1-score:0.427, Test set f1-score: 0.268\n",
      "       - C = 100\n",
      "          - lbfgs_L2, Training set f1-score:0.427, Test set f1-score: 0.268\n",
      "          - saga_L1, Training set f1-score:0.426, Test set f1-score: 0.268\n",
      "          - newton-cg_L2, Training set f1-score:0.427, Test set f1-score: 0.268\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, Training set f1-score:0.427, Test set f1-score: 0.268\n",
      "          - saga_L1, Training set f1-score:0.427, Test set f1-score: 0.268\n",
      "          - newton-cg_L2, Training set f1-score:0.427, Test set f1-score: 0.268\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. f1-score on training data: 0.442 f1-score on test data: 0.242\n",
      "          - tree depth: 2.000. f1-score on training data: 0.417 f1-score on test data: 0.216\n",
      "          - tree depth: 3.000. f1-score on training data: 0.415 f1-score on test data: 0.258\n",
      "          - tree depth: 4.000. f1-score on training data: 0.460 f1-score on test data: 0.314\n",
      "          - tree depth: 5.000. f1-score on training data: 0.550 f1-score on test data: 0.235\n",
      "          - tree depth: 6.000. f1-score on training data: 0.576 f1-score on test data: 0.223\n",
      "          - tree depth: 7.000. f1-score on training data: 0.644 f1-score on test data: 0.223\n",
      "          - tree depth: 8.000. f1-score on training data: 0.686 f1-score on test data: 0.268\n",
      "          - tree depth: 9.000. f1-score on training data: 0.747 f1-score on test data: 0.273\n",
      "          - tree depth: 10.000. f1-score on training data: 0.783 f1-score on test data: 0.269\n",
      "          - tree depth: 11.000. f1-score on training data: 0.811 f1-score on test data: 0.274\n",
      "          - tree depth: 12.000. f1-score on training data: 0.861 f1-score on test data: 0.253\n",
      "          - tree depth: 13.000. f1-score on training data: 0.883 f1-score on test data: 0.259\n",
      "          - tree depth: 14.000. f1-score on training data: 0.902 f1-score on test data: 0.221\n",
      "    - Random forest\n",
      "          - 5trees. f1-score on training data: 0.855 f1-score on test data: 0.272\n",
      "          - 10trees. f1-score on training data: 0.894 f1-score on test data: 0.299\n",
      "          - 15trees. f1-score on training data: 0.902 f1-score on test data: 0.266\n",
      "          - 20trees. f1-score on training data: 0.914 f1-score on test data: 0.244\n",
      "          - 25trees. f1-score on training data: 0.914 f1-score on test data: 0.303\n",
      "          - 30trees. f1-score on training data: 0.914 f1-score on test data: 0.293\n",
      "          - 35trees. f1-score on training data: 0.914 f1-score on test data: 0.243\n",
      "          - 40trees. f1-score on training data: 0.914 f1-score on test data: 0.243\n",
      "          - 45trees. f1-score on training data: 0.914 f1-score on test data: 0.238\n",
      "          - 50trees. f1-score on training data: 0.914 f1-score on test data: 0.238\n",
      "          - 55trees. f1-score on training data: 0.914 f1-score on test data: 0.262\n",
      "          - 60trees. f1-score on training data: 0.914 f1-score on test data: 0.265\n",
      "          - 65trees. f1-score on training data: 0.914 f1-score on test data: 0.269\n",
      "          - 70trees. f1-score on training data: 0.914 f1-score on test data: 0.294\n",
      "          - 75trees. f1-score on training data: 0.914 f1-score on test data: 0.275\n",
      "          - 80trees. f1-score on training data: 0.915 f1-score on test data: 0.273\n",
      "          - 85trees. f1-score on training data: 0.914 f1-score on test data: 0.269\n",
      "          - 90trees. f1-score on training data: 0.914 f1-score on test data: 0.273\n",
      "          - 95trees. f1-score on training data: 0.914 f1-score on test data: 0.269\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. f1-score on training data: 0.915 f1-score on test data: 0.165\n",
      "          - hidden layer size[20, 20]. f1-score on training data: 0.914 f1-score on test data: 0.374\n",
      "          - hidden layer size[100, 100]. f1-score on training data: 0.915 f1-score on test data: 0.250\n",
      "          - hidden layer size[50, 50, 50]. f1-score on training data: 0.915 f1-score on test data: 0.241\n",
      "- Using scaled dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, Training set f1-score:0.436, Test set f1-score: 0.282\n",
      "          - saga_L1, Training set f1-score:0.357, Test set f1-score: 0.233\n",
      "          - newton-cg_L2, Training set f1-score:0.436, Test set f1-score: 0.282\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, Training set f1-score:0.430, Test set f1-score: 0.216\n",
      "          - saga_L1, Training set f1-score:0.357, Test set f1-score: 0.233\n",
      "          - newton-cg_L2, Training set f1-score:0.430, Test set f1-score: 0.216\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, Training set f1-score:0.430, Test set f1-score: 0.251\n",
      "          - saga_L1, Training set f1-score:0.456, Test set f1-score: 0.316\n",
      "          - newton-cg_L2, Training set f1-score:0.430, Test set f1-score: 0.251\n",
      "       - C = 1\n",
      "          - lbfgs_L2, Training set f1-score:0.440, Test set f1-score: 0.268\n",
      "          - saga_L1, Training set f1-score:0.439, Test set f1-score: 0.272\n",
      "          - newton-cg_L2, Training set f1-score:0.440, Test set f1-score: 0.268\n",
      "       - C = 10\n",
      "          - lbfgs_L2, Training set f1-score:0.426, Test set f1-score: 0.268\n",
      "          - saga_L1, Training set f1-score:0.432, Test set f1-score: 0.274\n",
      "          - newton-cg_L2, Training set f1-score:0.426, Test set f1-score: 0.268\n",
      "       - C = 100\n",
      "          - lbfgs_L2, Training set f1-score:0.427, Test set f1-score: 0.268\n",
      "          - saga_L1, Training set f1-score:0.426, Test set f1-score: 0.268\n",
      "          - newton-cg_L2, Training set f1-score:0.427, Test set f1-score: 0.268\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, Training set f1-score:0.427, Test set f1-score: 0.268\n",
      "          - saga_L1, Training set f1-score:0.427, Test set f1-score: 0.268\n",
      "          - newton-cg_L2, Training set f1-score:0.427, Test set f1-score: 0.268\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. f1-score on training data: 0.442 f1-score on test data: 0.242\n",
      "          - tree depth: 2.000. f1-score on training data: 0.417 f1-score on test data: 0.216\n",
      "          - tree depth: 3.000. f1-score on training data: 0.415 f1-score on test data: 0.258\n",
      "          - tree depth: 4.000. f1-score on training data: 0.460 f1-score on test data: 0.314\n",
      "          - tree depth: 5.000. f1-score on training data: 0.550 f1-score on test data: 0.235\n",
      "          - tree depth: 6.000. f1-score on training data: 0.576 f1-score on test data: 0.223\n",
      "          - tree depth: 7.000. f1-score on training data: 0.644 f1-score on test data: 0.223\n",
      "          - tree depth: 8.000. f1-score on training data: 0.686 f1-score on test data: 0.268\n",
      "          - tree depth: 9.000. f1-score on training data: 0.747 f1-score on test data: 0.273\n",
      "          - tree depth: 10.000. f1-score on training data: 0.783 f1-score on test data: 0.269\n",
      "          - tree depth: 11.000. f1-score on training data: 0.811 f1-score on test data: 0.274\n",
      "          - tree depth: 12.000. f1-score on training data: 0.861 f1-score on test data: 0.253\n",
      "          - tree depth: 13.000. f1-score on training data: 0.883 f1-score on test data: 0.259\n",
      "          - tree depth: 14.000. f1-score on training data: 0.902 f1-score on test data: 0.221\n",
      "    - Random forest\n",
      "          - 5trees. f1-score on training data: 0.855 f1-score on test data: 0.251\n",
      "          - 10trees. f1-score on training data: 0.894 f1-score on test data: 0.270\n",
      "          - 15trees. f1-score on training data: 0.902 f1-score on test data: 0.294\n",
      "          - 20trees. f1-score on training data: 0.914 f1-score on test data: 0.244\n",
      "          - 25trees. f1-score on training data: 0.914 f1-score on test data: 0.332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          - 30trees. f1-score on training data: 0.914 f1-score on test data: 0.294\n",
      "          - 35trees. f1-score on training data: 0.914 f1-score on test data: 0.239\n",
      "          - 40trees. f1-score on training data: 0.914 f1-score on test data: 0.271\n",
      "          - 45trees. f1-score on training data: 0.914 f1-score on test data: 0.237\n",
      "          - 50trees. f1-score on training data: 0.914 f1-score on test data: 0.237\n",
      "          - 55trees. f1-score on training data: 0.914 f1-score on test data: 0.271\n",
      "          - 60trees. f1-score on training data: 0.914 f1-score on test data: 0.265\n",
      "          - 65trees. f1-score on training data: 0.914 f1-score on test data: 0.270\n",
      "          - 70trees. f1-score on training data: 0.914 f1-score on test data: 0.271\n",
      "          - 75trees. f1-score on training data: 0.914 f1-score on test data: 0.271\n",
      "          - 80trees. f1-score on training data: 0.915 f1-score on test data: 0.270\n",
      "          - 85trees. f1-score on training data: 0.914 f1-score on test data: 0.270\n",
      "          - 90trees. f1-score on training data: 0.914 f1-score on test data: 0.270\n",
      "          - 95trees. f1-score on training data: 0.914 f1-score on test data: 0.266\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. f1-score on training data: 0.914 f1-score on test data: 0.223\n",
      "          - hidden layer size[20, 20]. f1-score on training data: 0.915 f1-score on test data: 0.382\n",
      "          - hidden layer size[100, 100]. f1-score on training data: 0.915 f1-score on test data: 0.371\n",
      "          - hidden layer size[50, 50, 50]. f1-score on training data: 0.914 f1-score on test data: 0.225\n",
      "- Using 10 pca-components:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, Training set f1-score:0.446, Test set f1-score: 0.282\n",
      "          - saga_L1, Training set f1-score:0.330, Test set f1-score: 0.348\n",
      "          - newton-cg_L2, Training set f1-score:0.446, Test set f1-score: 0.282\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, Training set f1-score:0.434, Test set f1-score: 0.225\n",
      "          - saga_L1, Training set f1-score:0.357, Test set f1-score: 0.233\n",
      "          - newton-cg_L2, Training set f1-score:0.434, Test set f1-score: 0.225\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, Training set f1-score:0.400, Test set f1-score: 0.255\n",
      "          - saga_L1, Training set f1-score:0.426, Test set f1-score: 0.215\n",
      "          - newton-cg_L2, Training set f1-score:0.400, Test set f1-score: 0.255\n",
      "       - C = 1\n",
      "          - lbfgs_L2, Training set f1-score:0.402, Test set f1-score: 0.283\n",
      "          - saga_L1, Training set f1-score:0.419, Test set f1-score: 0.255\n",
      "          - newton-cg_L2, Training set f1-score:0.402, Test set f1-score: 0.283\n",
      "       - C = 10\n",
      "          - lbfgs_L2, Training set f1-score:0.409, Test set f1-score: 0.283\n",
      "          - saga_L1, Training set f1-score:0.409, Test set f1-score: 0.283\n",
      "          - newton-cg_L2, Training set f1-score:0.409, Test set f1-score: 0.283\n",
      "       - C = 100\n",
      "          - lbfgs_L2, Training set f1-score:0.409, Test set f1-score: 0.283\n",
      "          - saga_L1, Training set f1-score:0.409, Test set f1-score: 0.283\n",
      "          - newton-cg_L2, Training set f1-score:0.409, Test set f1-score: 0.283\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, Training set f1-score:0.409, Test set f1-score: 0.283\n",
      "          - saga_L1, Training set f1-score:0.409, Test set f1-score: 0.283\n",
      "          - newton-cg_L2, Training set f1-score:0.409, Test set f1-score: 0.283\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. f1-score on training data: 0.451 f1-score on test data: 0.242\n",
      "          - tree depth: 2.000. f1-score on training data: 0.468 f1-score on test data: 0.187\n",
      "          - tree depth: 3.000. f1-score on training data: 0.437 f1-score on test data: 0.160\n",
      "          - tree depth: 4.000. f1-score on training data: 0.507 f1-score on test data: 0.238\n",
      "          - tree depth: 5.000. f1-score on training data: 0.610 f1-score on test data: 0.291\n",
      "          - tree depth: 6.000. f1-score on training data: 0.649 f1-score on test data: 0.255\n",
      "          - tree depth: 7.000. f1-score on training data: 0.711 f1-score on test data: 0.302\n",
      "          - tree depth: 8.000. f1-score on training data: 0.785 f1-score on test data: 0.261\n",
      "          - tree depth: 9.000. f1-score on training data: 0.818 f1-score on test data: 0.333\n",
      "          - tree depth: 10.000. f1-score on training data: 0.839 f1-score on test data: 0.242\n",
      "          - tree depth: 11.000. f1-score on training data: 0.881 f1-score on test data: 0.227\n",
      "          - tree depth: 12.000. f1-score on training data: 0.901 f1-score on test data: 0.243\n",
      "          - tree depth: 13.000. f1-score on training data: 0.915 f1-score on test data: 0.350\n",
      "          - tree depth: 14.000. f1-score on training data: 0.915 f1-score on test data: 0.332\n",
      "    - Random forest\n",
      "          - 5trees. f1-score on training data: 0.848 f1-score on test data: 0.322\n",
      "          - 10trees. f1-score on training data: 0.908 f1-score on test data: 0.236\n",
      "          - 15trees. f1-score on training data: 0.915 f1-score on test data: 0.248\n",
      "          - 20trees. f1-score on training data: 0.914 f1-score on test data: 0.240\n",
      "          - 25trees. f1-score on training data: 0.914 f1-score on test data: 0.233\n",
      "          - 30trees. f1-score on training data: 0.915 f1-score on test data: 0.252\n",
      "          - 35trees. f1-score on training data: 0.915 f1-score on test data: 0.240\n",
      "          - 40trees. f1-score on training data: 0.914 f1-score on test data: 0.240\n",
      "          - 45trees. f1-score on training data: 0.914 f1-score on test data: 0.240\n",
      "          - 50trees. f1-score on training data: 0.914 f1-score on test data: 0.270\n",
      "          - 55trees. f1-score on training data: 0.914 f1-score on test data: 0.270\n",
      "          - 60trees. f1-score on training data: 0.914 f1-score on test data: 0.266\n",
      "          - 65trees. f1-score on training data: 0.915 f1-score on test data: 0.266\n",
      "          - 70trees. f1-score on training data: 0.915 f1-score on test data: 0.266\n",
      "          - 75trees. f1-score on training data: 0.915 f1-score on test data: 0.266\n",
      "          - 80trees. f1-score on training data: 0.915 f1-score on test data: 0.289\n",
      "          - 85trees. f1-score on training data: 0.915 f1-score on test data: 0.287\n",
      "          - 90trees. f1-score on training data: 0.914 f1-score on test data: 0.287\n",
      "          - 95trees. f1-score on training data: 0.914 f1-score on test data: 0.287\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. f1-score on training data: 0.915 f1-score on test data: 0.304\n",
      "          - hidden layer size[20, 20]. f1-score on training data: 0.914 f1-score on test data: 0.285\n",
      "          - hidden layer size[100, 100]. f1-score on training data: 0.914 f1-score on test data: 0.318\n",
      "          - hidden layer size[50, 50, 50]. f1-score on training data: 0.914 f1-score on test data: 0.233\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "models(sleep_dxch_6g,drop_lst,'DXCHANGE')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
