{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20f5d23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.tree import export_text\n",
    "import mglearn\n",
    "from dashboard_one import *\n",
    "from dash_model_two import *\n",
    "from feature_selection import *\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b74b94",
   "metadata": {},
   "source": [
    "### sleep_____VS_____final diagnosischanges of each patient in each phase\n",
    "\n",
    "\n",
    "#### sleep_brain_finaldxch.csv\n",
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fef6c499",
   "metadata": {},
   "outputs": [],
   "source": [
    "com_col = ['Phase', 'RID', 'VISCODE','PTID','RID_Phase']\n",
    "target = 'final_dxch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "769bd041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RID</th>\n",
       "      <th>Phase</th>\n",
       "      <th>VISCODE</th>\n",
       "      <th>PTID</th>\n",
       "      <th>RID_Phase</th>\n",
       "      <th>NPIK1</th>\n",
       "      <th>NPIK2</th>\n",
       "      <th>NPIK3</th>\n",
       "      <th>NPIK4</th>\n",
       "      <th>NPIK5</th>\n",
       "      <th>...</th>\n",
       "      <th>ratio_PTAU_bl</th>\n",
       "      <th>Ventricles_reduction_per_year</th>\n",
       "      <th>Hippocampus_reduction_per_year</th>\n",
       "      <th>wholebrain_reduction_per_year</th>\n",
       "      <th>Entorhinal_reduction_per_year</th>\n",
       "      <th>Fusiform_reduction_per_year</th>\n",
       "      <th>ICV_reduction_per_year</th>\n",
       "      <th>ABETA_reduction_per_year</th>\n",
       "      <th>TAU_reduction_per_year</th>\n",
       "      <th>PTAU_reduction_per_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>ADNI2</td>\n",
       "      <td>v06</td>\n",
       "      <td>011_S_0002</td>\n",
       "      <td>2_ADNI2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ADNI2</td>\n",
       "      <td>v21</td>\n",
       "      <td>011_S_0002</td>\n",
       "      <td>2_ADNI2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ADNI2</td>\n",
       "      <td>v31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2_ADNI2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>ADNI2</td>\n",
       "      <td>v41</td>\n",
       "      <td>011_S_0002</td>\n",
       "      <td>2_ADNI2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>ADNI2</td>\n",
       "      <td>v06</td>\n",
       "      <td>011_S_0008</td>\n",
       "      <td>8_ADNI2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18438</th>\n",
       "      <td>6996</td>\n",
       "      <td>ADNI3</td>\n",
       "      <td>m12</td>\n",
       "      <td>003_S_6996</td>\n",
       "      <td>6996_ADNI3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18439</th>\n",
       "      <td>6999</td>\n",
       "      <td>ADNI3</td>\n",
       "      <td>m12</td>\n",
       "      <td>035_S_6999</td>\n",
       "      <td>6999_ADNI3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18440</th>\n",
       "      <td>6999</td>\n",
       "      <td>ADNI3</td>\n",
       "      <td>y1</td>\n",
       "      <td>035_S_6999</td>\n",
       "      <td>6999_ADNI3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18441</th>\n",
       "      <td>7000</td>\n",
       "      <td>ADNI3</td>\n",
       "      <td>m12</td>\n",
       "      <td>035_S_7000</td>\n",
       "      <td>7000_ADNI3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18442</th>\n",
       "      <td>7000</td>\n",
       "      <td>ADNI3</td>\n",
       "      <td>y1</td>\n",
       "      <td>035_S_7000</td>\n",
       "      <td>7000_ADNI3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18443 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RID  Phase VISCODE        PTID   RID_Phase  NPIK1  NPIK2  NPIK3  \\\n",
       "0         2  ADNI2     v06  011_S_0002     2_ADNI2    NaN    NaN    NaN   \n",
       "1         2  ADNI2     v21  011_S_0002     2_ADNI2    NaN    NaN    NaN   \n",
       "2         2  ADNI2     v31         NaN     2_ADNI2    NaN    NaN    NaN   \n",
       "3         2  ADNI2     v41  011_S_0002     2_ADNI2    NaN    NaN    NaN   \n",
       "4         8  ADNI2     v06  011_S_0008     8_ADNI2    1.0    0.0    0.0   \n",
       "...     ...    ...     ...         ...         ...    ...    ...    ...   \n",
       "18438  6996  ADNI3     m12  003_S_6996  6996_ADNI3    NaN    NaN    NaN   \n",
       "18439  6999  ADNI3     m12  035_S_6999  6999_ADNI3    NaN    NaN    NaN   \n",
       "18440  6999  ADNI3      y1  035_S_6999  6999_ADNI3    NaN    NaN    NaN   \n",
       "18441  7000  ADNI3     m12  035_S_7000  7000_ADNI3    NaN    NaN    NaN   \n",
       "18442  7000  ADNI3      y1  035_S_7000  7000_ADNI3    NaN    NaN    NaN   \n",
       "\n",
       "       NPIK4  NPIK5  ...  ratio_PTAU_bl  Ventricles_reduction_per_year  \\\n",
       "0        NaN    NaN  ...            NaN                            NaN   \n",
       "1        NaN    NaN  ...            NaN                            NaN   \n",
       "2        NaN    NaN  ...            NaN                            NaN   \n",
       "3        NaN    NaN  ...            NaN                            NaN   \n",
       "4        0.0    0.0  ...            NaN                            NaN   \n",
       "...      ...    ...  ...            ...                            ...   \n",
       "18438    NaN    NaN  ...            NaN                            NaN   \n",
       "18439    NaN    NaN  ...            NaN                            NaN   \n",
       "18440    NaN    NaN  ...            NaN                            NaN   \n",
       "18441    NaN    NaN  ...            NaN                            NaN   \n",
       "18442    NaN    NaN  ...            NaN                            NaN   \n",
       "\n",
       "       Hippocampus_reduction_per_year  wholebrain_reduction_per_year  \\\n",
       "0                                 NaN                            NaN   \n",
       "1                                 NaN                            NaN   \n",
       "2                                 NaN                            NaN   \n",
       "3                                 NaN                            NaN   \n",
       "4                                 NaN                            NaN   \n",
       "...                               ...                            ...   \n",
       "18438                             NaN                            NaN   \n",
       "18439                             NaN                            NaN   \n",
       "18440                             NaN                            NaN   \n",
       "18441                             NaN                            NaN   \n",
       "18442                             NaN                            NaN   \n",
       "\n",
       "       Entorhinal_reduction_per_year  Fusiform_reduction_per_year  \\\n",
       "0                                NaN                          NaN   \n",
       "1                                NaN                          NaN   \n",
       "2                                NaN                          NaN   \n",
       "3                                NaN                          NaN   \n",
       "4                                NaN                          NaN   \n",
       "...                              ...                          ...   \n",
       "18438                            NaN                          NaN   \n",
       "18439                            NaN                          NaN   \n",
       "18440                            NaN                          NaN   \n",
       "18441                            NaN                          NaN   \n",
       "18442                            NaN                          NaN   \n",
       "\n",
       "       ICV_reduction_per_year  ABETA_reduction_per_year  \\\n",
       "0                         NaN                       NaN   \n",
       "1                         NaN                       NaN   \n",
       "2                         NaN                       NaN   \n",
       "3                         NaN                       NaN   \n",
       "4                         NaN                       NaN   \n",
       "...                       ...                       ...   \n",
       "18438                     NaN                       NaN   \n",
       "18439                     NaN                       NaN   \n",
       "18440                     NaN                       NaN   \n",
       "18441                     NaN                       NaN   \n",
       "18442                     NaN                       NaN   \n",
       "\n",
       "       TAU_reduction_per_year PTAU_reduction_per_year  \n",
       "0                         NaN                     NaN  \n",
       "1                         NaN                     NaN  \n",
       "2                         NaN                     NaN  \n",
       "3                         NaN                     NaN  \n",
       "4                         NaN                     NaN  \n",
       "...                       ...                     ...  \n",
       "18438                     NaN                     NaN  \n",
       "18439                     NaN                     NaN  \n",
       "18440                     NaN                     NaN  \n",
       "18441                     NaN                     NaN  \n",
       "18442                     NaN                     NaN  \n",
       "\n",
       "[18443 rows x 39 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sleep_brain_finaldxch = pd.read_csv('sleep_brain_finaldxch.csv').iloc[:,1:].drop(['NPIKSEV'],axis=1)\n",
    "sleep_brain_finaldxch = sleep_brain_finaldxch[sleep_brain_finaldxch['final_dxch'].notna()].reset_index().drop(['index'],axis=1)   # keep the rows where DXCHANGE is not nan\n",
    "sleep_brain_finaldxch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51ce40a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18443 entries, 0 to 18442\n",
      "Data columns (total 39 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   RID                             18443 non-null  int64  \n",
      " 1   Phase                           18443 non-null  object \n",
      " 2   VISCODE                         17197 non-null  object \n",
      " 3   PTID                            17781 non-null  object \n",
      " 4   RID_Phase                       18443 non-null  object \n",
      " 5   NPIK1                           848 non-null    float64\n",
      " 6   NPIK2                           847 non-null    float64\n",
      " 7   NPIK3                           846 non-null    float64\n",
      " 8   NPIK4                           846 non-null    float64\n",
      " 9   NPIK5                           846 non-null    float64\n",
      " 10  NPIK6                           847 non-null    float64\n",
      " 11  NPIK7                           847 non-null    float64\n",
      " 12  NPIK8                           844 non-null    float64\n",
      " 13  NPIK9A                          849 non-null    float64\n",
      " 14  NPIK9B                          848 non-null    float64\n",
      " 15  NPIK9C                          849 non-null    float64\n",
      " 16  NPIKTOT                         848 non-null    float64\n",
      " 17  insomnia                        9899 non-null   float64\n",
      " 18  OSA                             18441 non-null  float64\n",
      " 19  final_dxch                      18443 non-null  object \n",
      " 20  DXCHANGE                        16275 non-null  object \n",
      " 21  ratio_Ventricles_bl             5588 non-null   float64\n",
      " 22  ratio_Hippocampus_bl            4957 non-null   float64\n",
      " 23  ratio_WholeBrain_bl             5847 non-null   float64\n",
      " 24  ratio_Entorhinal_bl             4673 non-null   float64\n",
      " 25  ratio_Fusiform_bl               4673 non-null   float64\n",
      " 26  ratio_ICV_bl                    6158 non-null   float64\n",
      " 27  ratio_ABETA_bl                  696 non-null    float64\n",
      " 28  ratio_TAU_bl                    868 non-null    float64\n",
      " 29  ratio_PTAU_bl                   600 non-null    float64\n",
      " 30  Ventricles_reduction_per_year   5588 non-null   float64\n",
      " 31  Hippocampus_reduction_per_year  4957 non-null   float64\n",
      " 32  wholebrain_reduction_per_year   5847 non-null   float64\n",
      " 33  Entorhinal_reduction_per_year   4673 non-null   float64\n",
      " 34  Fusiform_reduction_per_year     4673 non-null   float64\n",
      " 35  ICV_reduction_per_year          6158 non-null   float64\n",
      " 36  ABETA_reduction_per_year        696 non-null    float64\n",
      " 37  TAU_reduction_per_year          868 non-null    float64\n",
      " 38  PTAU_reduction_per_year         600 non-null    float64\n",
      "dtypes: float64(32), int64(1), object(6)\n",
      "memory usage: 5.5+ MB\n"
     ]
    }
   ],
   "source": [
    "sleep_brain_finaldxch.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81696451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RID', 'Phase', 'VISCODE', 'PTID', 'RID_Phase', 'NPIK1', 'NPIK2',\n",
       "       'NPIK3', 'NPIK4', 'NPIK5', 'NPIK6', 'NPIK7', 'NPIK8', 'NPIK9A',\n",
       "       'NPIK9B', 'NPIK9C', 'NPIKTOT', 'insomnia', 'OSA', 'final_dxch',\n",
       "       'DXCHANGE', 'ratio_Ventricles_bl', 'ratio_Hippocampus_bl',\n",
       "       'ratio_WholeBrain_bl', 'ratio_Entorhinal_bl', 'ratio_Fusiform_bl',\n",
       "       'ratio_ICV_bl', 'ratio_ABETA_bl', 'ratio_TAU_bl', 'ratio_PTAU_bl',\n",
       "       'Ventricles_reduction_per_year', 'Hippocampus_reduction_per_year',\n",
       "       'wholebrain_reduction_per_year', 'Entorhinal_reduction_per_year',\n",
       "       'Fusiform_reduction_per_year', 'ICV_reduction_per_year',\n",
       "       'ABETA_reduction_per_year', 'TAU_reduction_per_year',\n",
       "       'PTAU_reduction_per_year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sleep_brain_finaldxch.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1b7f3e",
   "metadata": {},
   "source": [
    "### brain_biomarker______VS______final_dxch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9b829bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "col_lst = [ 'final_dxch','NPIK1', 'NPIK2',\n",
    "       'NPIK3', 'NPIK4', 'NPIK5', 'NPIK6', 'NPIK7', 'NPIK8', 'NPIK9A',\n",
    "       'NPIK9B', 'NPIK9C', 'NPIKTOT', 'insomnia', 'OSA']\n",
    "bio_lst = [ 'final_dxch','ratio_ABETA_bl', 'ratio_TAU_bl','ratio_PTAU_bl']\n",
    "sleep_dxch = sleep_brain_finaldxch[com_col + col_lst].set_index(com_col).dropna(how='any',axis=0).reset_index()\n",
    "#biomarkers to dxch\n",
    "bio_dxch = sleep_brain_finaldxch[com_col + bio_lst].set_index(com_col).dropna(how='any',axis=0).reset_index()\n",
    "df = sleep_dxch.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c75224ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Phase         0\n",
       "RID           0\n",
       "VISCODE       0\n",
       "PTID          3\n",
       "RID_Phase     0\n",
       "final_dxch    0\n",
       "NPIK1         0\n",
       "NPIK2         0\n",
       "NPIK3         0\n",
       "NPIK4         0\n",
       "NPIK5         0\n",
       "NPIK6         0\n",
       "NPIK7         0\n",
       "NPIK8         0\n",
       "NPIK9A        0\n",
       "NPIK9B        0\n",
       "NPIK9C        0\n",
       "NPIKTOT       0\n",
       "insomnia      0\n",
       "OSA           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df.isna())   # check nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af84a781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phase</th>\n",
       "      <th>RID</th>\n",
       "      <th>VISCODE</th>\n",
       "      <th>PTID</th>\n",
       "      <th>RID_Phase</th>\n",
       "      <th>NPIK1</th>\n",
       "      <th>NPIK2</th>\n",
       "      <th>NPIK3</th>\n",
       "      <th>NPIK4</th>\n",
       "      <th>NPIK5</th>\n",
       "      <th>NPIK6</th>\n",
       "      <th>NPIK7</th>\n",
       "      <th>NPIK8</th>\n",
       "      <th>NPIK9A</th>\n",
       "      <th>NPIK9B</th>\n",
       "      <th>NPIK9C</th>\n",
       "      <th>NPIKTOT</th>\n",
       "      <th>insomnia</th>\n",
       "      <th>OSA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>final_dxch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AD-AD</th>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AD-MCI</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CN-AD</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CN-CN</th>\n",
       "      <td>186</td>\n",
       "      <td>186</td>\n",
       "      <td>186</td>\n",
       "      <td>185</td>\n",
       "      <td>186</td>\n",
       "      <td>186</td>\n",
       "      <td>186</td>\n",
       "      <td>186</td>\n",
       "      <td>186</td>\n",
       "      <td>186</td>\n",
       "      <td>186</td>\n",
       "      <td>186</td>\n",
       "      <td>186</td>\n",
       "      <td>186</td>\n",
       "      <td>186</td>\n",
       "      <td>186</td>\n",
       "      <td>186</td>\n",
       "      <td>186</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CN-MCI</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCI-AD</th>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCI-CN</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCI-MCI</th>\n",
       "      <td>351</td>\n",
       "      <td>351</td>\n",
       "      <td>351</td>\n",
       "      <td>349</td>\n",
       "      <td>351</td>\n",
       "      <td>351</td>\n",
       "      <td>351</td>\n",
       "      <td>351</td>\n",
       "      <td>351</td>\n",
       "      <td>351</td>\n",
       "      <td>351</td>\n",
       "      <td>351</td>\n",
       "      <td>351</td>\n",
       "      <td>351</td>\n",
       "      <td>351</td>\n",
       "      <td>351</td>\n",
       "      <td>351</td>\n",
       "      <td>351</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Phase  RID  VISCODE  PTID  RID_Phase  NPIK1  NPIK2  NPIK3  NPIK4  \\\n",
       "final_dxch                                                                     \n",
       "AD-AD         199  199      199   199        199    199    199    199    199   \n",
       "AD-MCI          4    4        4     4          4      4      4      4      4   \n",
       "CN-AD           1    1        1     1          1      1      1      1      1   \n",
       "CN-CN         186  186      186   185        186    186    186    186    186   \n",
       "CN-MCI         14   14       14    14         14     14     14     14     14   \n",
       "MCI-AD         44   44       44    44         44     44     44     44     44   \n",
       "MCI-CN          4    4        4     4          4      4      4      4      4   \n",
       "MCI-MCI       351  351      351   349        351    351    351    351    351   \n",
       "\n",
       "            NPIK5  NPIK6  NPIK7  NPIK8  NPIK9A  NPIK9B  NPIK9C  NPIKTOT  \\\n",
       "final_dxch                                                                \n",
       "AD-AD         199    199    199    199     199     199     199      199   \n",
       "AD-MCI          4      4      4      4       4       4       4        4   \n",
       "CN-AD           1      1      1      1       1       1       1        1   \n",
       "CN-CN         186    186    186    186     186     186     186      186   \n",
       "CN-MCI         14     14     14     14      14      14      14       14   \n",
       "MCI-AD         44     44     44     44      44      44      44       44   \n",
       "MCI-CN          4      4      4      4       4       4       4        4   \n",
       "MCI-MCI       351    351    351    351     351     351     351      351   \n",
       "\n",
       "            insomnia  OSA  \n",
       "final_dxch                 \n",
       "AD-AD            199  199  \n",
       "AD-MCI             4    4  \n",
       "CN-AD              1    1  \n",
       "CN-CN            186  186  \n",
       "CN-MCI            14   14  \n",
       "MCI-AD            44   44  \n",
       "MCI-CN             4    4  \n",
       "MCI-MCI          351  351  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(target).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae317f9",
   "metadata": {},
   "source": [
    "- unselect the labels with too little data: AD-MCI, CN-AD, CN-MCI, MCI-CN\n",
    "- the possible groups: ['CN-CN','MCI-AD', 'MCI-MCI','AD-AD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9a4caaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(395, 20)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2g = df.loc[df[target].isin(['MCI-AD', 'MCI-MCI'])].reset_index().drop(['index'],axis=1)\n",
    "df_2g.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4cf4b57d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(780, 20)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to distinguish MCI to AD or stay in MCI or get back to CN\n",
    "df_4g = df.loc[df[target].isin(['CN-CN','MCI-AD', 'MCI-MCI','AD-AD'])].reset_index().drop(['index'],axis=1)\n",
    "df_4g.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39783bf",
   "metadata": {},
   "source": [
    "### undersampling and modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdd62ca",
   "metadata": {},
   "source": [
    "- functions\n",
    "    - models(df,drop_lst,target) : under sampling, split, scale, pca, models\n",
    "    - cv_models(df,drop_lst,target,k): under sampling, NOT SPLIT, scale, pca, models with cross-validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c356c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_lst = ['Phase', 'RID', 'VISCODE', 'PTID','RID_Phase',target]\n",
    "k=10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916eb3f2",
   "metadata": {},
   "source": [
    "# - 'MCI-AD': 44, 'MCI-MCI': 44"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5895d717",
   "metadata": {},
   "source": [
    "-  'MCI-AD': 44, 'MCI-MCI': 44\n",
    "- #original dataset: random forest 30 trees. average weighted f1-score of 10-cross validation:0.715"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fcc70e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After undersampling data size is 88 ; Resampled dataset shape Counter({'MCI-AD': 44, 'MCI-MCI': 44})\n",
      "\n",
      "9 principle components are needed to explain 90% of the data\n",
      "\n",
      "Output dataframes sequence: X_train,X_test,X_train_scaled,X_test_scaled,X_train_pca,X_test_pca,y_train,y_test\n",
      "- Using original dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, Training set f1-score:0.679, Test set f1-score: 0.615\n",
      "          - saga_L1, Training set f1-score:0.679, Test set f1-score: 0.615\n",
      "          - newton-cg_L2, Training set f1-score:0.679, Test set f1-score: 0.615\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, Training set f1-score:0.609, Test set f1-score: 0.657\n",
      "          - saga_L1, Training set f1-score:0.654, Test set f1-score: 0.714\n",
      "          - newton-cg_L2, Training set f1-score:0.609, Test set f1-score: 0.657\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, Training set f1-score:0.622, Test set f1-score: 0.735\n",
      "          - saga_L1, Training set f1-score:0.679, Test set f1-score: 0.615\n",
      "          - newton-cg_L2, Training set f1-score:0.622, Test set f1-score: 0.735\n",
      "       - C = 1\n",
      "          - lbfgs_L2, Training set f1-score:0.659, Test set f1-score: 0.725\n",
      "          - saga_L1, Training set f1-score:0.645, Test set f1-score: 0.675\n",
      "          - newton-cg_L2, Training set f1-score:0.659, Test set f1-score: 0.725\n",
      "       - C = 10\n",
      "          - lbfgs_L2, Training set f1-score:0.658, Test set f1-score: 0.590\n",
      "          - saga_L1, Training set f1-score:0.672, Test set f1-score: 0.590\n",
      "          - newton-cg_L2, Training set f1-score:0.658, Test set f1-score: 0.590\n",
      "       - C = 100\n",
      "          - lbfgs_L2, Training set f1-score:0.658, Test set f1-score: 0.559\n",
      "          - saga_L1, Training set f1-score:0.658, Test set f1-score: 0.559\n",
      "          - newton-cg_L2, Training set f1-score:0.658, Test set f1-score: 0.559\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, Training set f1-score:0.658, Test set f1-score: 0.559\n",
      "          - saga_L1, Training set f1-score:0.658, Test set f1-score: 0.559\n",
      "          - newton-cg_L2, Training set f1-score:0.658, Test set f1-score: 0.559\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. f1-score on training data: 0.627 f1-score on test data: 0.631\n",
      "          - tree depth: 2.000. f1-score on training data: 0.662 f1-score on test data: 0.721\n",
      "          - tree depth: 3.000. f1-score on training data: 0.668 f1-score on test data: 0.721\n",
      "          - tree depth: 4.000. f1-score on training data: 0.734 f1-score on test data: 0.498\n",
      "          - tree depth: 5.000. f1-score on training data: 0.787 f1-score on test data: 0.488\n",
      "          - tree depth: 6.000. f1-score on training data: 0.829 f1-score on test data: 0.667\n",
      "          - tree depth: 7.000. f1-score on training data: 0.860 f1-score on test data: 0.615\n",
      "          - tree depth: 8.000. f1-score on training data: 0.914 f1-score on test data: 0.615\n",
      "          - tree depth: 9.000. f1-score on training data: 0.943 f1-score on test data: 0.505\n",
      "          - tree depth: 10.000. f1-score on training data: 0.957 f1-score on test data: 0.556\n",
      "          - tree depth: 11.000. f1-score on training data: 0.957 f1-score on test data: 0.556\n",
      "          - tree depth: 12.000. f1-score on training data: 0.971 f1-score on test data: 0.556\n",
      "          - tree depth: 13.000. f1-score on training data: 0.971 f1-score on test data: 0.615\n",
      "          - tree depth: 14.000. f1-score on training data: 0.986 f1-score on test data: 0.556\n",
      "    - Random forest\n",
      "          - 5trees. f1-score on training data: 0.929 f1-score on test data: 0.667\n",
      "          - 10trees. f1-score on training data: 0.957 f1-score on test data: 0.556\n",
      "          - 15trees. f1-score on training data: 0.986 f1-score on test data: 0.505\n",
      "          - 20trees. f1-score on training data: 0.986 f1-score on test data: 0.556\n",
      "          - 25trees. f1-score on training data: 0.986 f1-score on test data: 0.505\n",
      "          - 30trees. f1-score on training data: 0.986 f1-score on test data: 0.505\n",
      "          - 35trees. f1-score on training data: 0.986 f1-score on test data: 0.505\n",
      "          - 40trees. f1-score on training data: 0.986 f1-score on test data: 0.556\n",
      "          - 45trees. f1-score on training data: 0.986 f1-score on test data: 0.505\n",
      "          - 50trees. f1-score on training data: 0.986 f1-score on test data: 0.505\n",
      "          - 55trees. f1-score on training data: 0.986 f1-score on test data: 0.505\n",
      "          - 60trees. f1-score on training data: 0.986 f1-score on test data: 0.458\n",
      "          - 65trees. f1-score on training data: 0.986 f1-score on test data: 0.505\n",
      "          - 70trees. f1-score on training data: 0.986 f1-score on test data: 0.458\n",
      "          - 75trees. f1-score on training data: 0.986 f1-score on test data: 0.505\n",
      "          - 80trees. f1-score on training data: 0.986 f1-score on test data: 0.505\n",
      "          - 85trees. f1-score on training data: 0.986 f1-score on test data: 0.556\n",
      "          - 90trees. f1-score on training data: 0.986 f1-score on test data: 0.556\n",
      "          - 95trees. f1-score on training data: 0.986 f1-score on test data: 0.556\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. f1-score on training data: 0.986 f1-score on test data: 0.505\n",
      "          - hidden layer size[20, 20]. f1-score on training data: 0.986 f1-score on test data: 0.505\n",
      "- Using scaled dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, Training set f1-score:0.679, Test set f1-score: 0.615\n",
      "          - saga_L1, Training set f1-score:0.679, Test set f1-score: 0.615\n",
      "          - newton-cg_L2, Training set f1-score:0.679, Test set f1-score: 0.615\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, Training set f1-score:0.654, Test set f1-score: 0.675\n",
      "          - saga_L1, Training set f1-score:0.679, Test set f1-score: 0.615\n",
      "          - newton-cg_L2, Training set f1-score:0.654, Test set f1-score: 0.675\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, Training set f1-score:0.716, Test set f1-score: 0.667\n",
      "          - saga_L1, Training set f1-score:0.679, Test set f1-score: 0.615\n",
      "          - newton-cg_L2, Training set f1-score:0.716, Test set f1-score: 0.667\n",
      "       - C = 1\n",
      "          - lbfgs_L2, Training set f1-score:0.658, Test set f1-score: 0.567\n",
      "          - saga_L1, Training set f1-score:0.658, Test set f1-score: 0.667\n",
      "          - newton-cg_L2, Training set f1-score:0.658, Test set f1-score: 0.567\n",
      "       - C = 10\n",
      "          - lbfgs_L2, Training set f1-score:0.658, Test set f1-score: 0.590\n",
      "          - saga_L1, Training set f1-score:0.672, Test set f1-score: 0.590\n",
      "          - newton-cg_L2, Training set f1-score:0.658, Test set f1-score: 0.590\n",
      "       - C = 100\n",
      "          - lbfgs_L2, Training set f1-score:0.658, Test set f1-score: 0.559\n",
      "          - saga_L1, Training set f1-score:0.658, Test set f1-score: 0.559\n",
      "          - newton-cg_L2, Training set f1-score:0.658, Test set f1-score: 0.559\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, Training set f1-score:0.658, Test set f1-score: 0.559\n",
      "          - saga_L1, Training set f1-score:0.658, Test set f1-score: 0.559\n",
      "          - newton-cg_L2, Training set f1-score:0.658, Test set f1-score: 0.559\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. f1-score on training data: 0.627 f1-score on test data: 0.631\n",
      "          - tree depth: 2.000. f1-score on training data: 0.662 f1-score on test data: 0.721\n",
      "          - tree depth: 3.000. f1-score on training data: 0.668 f1-score on test data: 0.721\n",
      "          - tree depth: 4.000. f1-score on training data: 0.734 f1-score on test data: 0.498\n",
      "          - tree depth: 5.000. f1-score on training data: 0.787 f1-score on test data: 0.488\n",
      "          - tree depth: 6.000. f1-score on training data: 0.829 f1-score on test data: 0.667\n",
      "          - tree depth: 7.000. f1-score on training data: 0.860 f1-score on test data: 0.615\n",
      "          - tree depth: 8.000. f1-score on training data: 0.914 f1-score on test data: 0.615\n",
      "          - tree depth: 9.000. f1-score on training data: 0.943 f1-score on test data: 0.505\n",
      "          - tree depth: 10.000. f1-score on training data: 0.957 f1-score on test data: 0.556\n",
      "          - tree depth: 11.000. f1-score on training data: 0.957 f1-score on test data: 0.556\n",
      "          - tree depth: 12.000. f1-score on training data: 0.971 f1-score on test data: 0.556\n",
      "          - tree depth: 13.000. f1-score on training data: 0.971 f1-score on test data: 0.615\n",
      "          - tree depth: 14.000. f1-score on training data: 0.986 f1-score on test data: 0.556\n",
      "    - Random forest\n",
      "          - 5trees. f1-score on training data: 0.929 f1-score on test data: 0.721\n",
      "          - 10trees. f1-score on training data: 0.957 f1-score on test data: 0.556\n",
      "          - 15trees. f1-score on training data: 0.986 f1-score on test data: 0.505\n",
      "          - 20trees. f1-score on training data: 0.986 f1-score on test data: 0.556\n",
      "          - 25trees. f1-score on training data: 0.986 f1-score on test data: 0.505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          - 30trees. f1-score on training data: 0.986 f1-score on test data: 0.505\n",
      "          - 35trees. f1-score on training data: 0.986 f1-score on test data: 0.505\n",
      "          - 40trees. f1-score on training data: 0.986 f1-score on test data: 0.556\n",
      "          - 45trees. f1-score on training data: 0.986 f1-score on test data: 0.505\n",
      "          - 50trees. f1-score on training data: 0.986 f1-score on test data: 0.505\n",
      "          - 55trees. f1-score on training data: 0.986 f1-score on test data: 0.505\n",
      "          - 60trees. f1-score on training data: 0.986 f1-score on test data: 0.505\n",
      "          - 65trees. f1-score on training data: 0.986 f1-score on test data: 0.505\n",
      "          - 70trees. f1-score on training data: 0.986 f1-score on test data: 0.505\n",
      "          - 75trees. f1-score on training data: 0.986 f1-score on test data: 0.505\n",
      "          - 80trees. f1-score on training data: 0.986 f1-score on test data: 0.505\n",
      "          - 85trees. f1-score on training data: 0.986 f1-score on test data: 0.556\n",
      "          - 90trees. f1-score on training data: 0.986 f1-score on test data: 0.556\n",
      "          - 95trees. f1-score on training data: 0.986 f1-score on test data: 0.556\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. f1-score on training data: 0.986 f1-score on test data: 0.590\n",
      "          - hidden layer size[20, 20]. f1-score on training data: 0.986 f1-score on test data: 0.667\n",
      "- Using 9 pca-components:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, Training set f1-score:0.679, Test set f1-score: 0.615\n",
      "          - saga_L1, Training set f1-score:0.654, Test set f1-score: 0.714\n",
      "          - newton-cg_L2, Training set f1-score:0.679, Test set f1-score: 0.615\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, Training set f1-score:0.614, Test set f1-score: 0.721\n",
      "          - saga_L1, Training set f1-score:0.679, Test set f1-score: 0.615\n",
      "          - newton-cg_L2, Training set f1-score:0.614, Test set f1-score: 0.721\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, Training set f1-score:0.661, Test set f1-score: 0.778\n",
      "          - saga_L1, Training set f1-score:0.679, Test set f1-score: 0.615\n",
      "          - newton-cg_L2, Training set f1-score:0.661, Test set f1-score: 0.778\n",
      "       - C = 1\n",
      "          - lbfgs_L2, Training set f1-score:0.645, Test set f1-score: 0.725\n",
      "          - saga_L1, Training set f1-score:0.645, Test set f1-score: 0.778\n",
      "          - newton-cg_L2, Training set f1-score:0.645, Test set f1-score: 0.725\n",
      "       - C = 10\n",
      "          - lbfgs_L2, Training set f1-score:0.645, Test set f1-score: 0.725\n",
      "          - saga_L1, Training set f1-score:0.645, Test set f1-score: 0.725\n",
      "          - newton-cg_L2, Training set f1-score:0.645, Test set f1-score: 0.725\n",
      "       - C = 100\n",
      "          - lbfgs_L2, Training set f1-score:0.645, Test set f1-score: 0.725\n",
      "          - saga_L1, Training set f1-score:0.645, Test set f1-score: 0.725\n",
      "          - newton-cg_L2, Training set f1-score:0.645, Test set f1-score: 0.725\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, Training set f1-score:0.645, Test set f1-score: 0.725\n",
      "          - saga_L1, Training set f1-score:0.645, Test set f1-score: 0.725\n",
      "          - newton-cg_L2, Training set f1-score:0.645, Test set f1-score: 0.725\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. f1-score on training data: 0.658 f1-score on test data: 0.778\n",
      "          - tree depth: 2.000. f1-score on training data: 0.694 f1-score on test data: 0.675\n",
      "          - tree depth: 3.000. f1-score on training data: 0.787 f1-score on test data: 0.615\n",
      "          - tree depth: 4.000. f1-score on training data: 0.887 f1-score on test data: 0.833\n",
      "          - tree depth: 5.000. f1-score on training data: 0.900 f1-score on test data: 0.778\n",
      "          - tree depth: 6.000. f1-score on training data: 0.971 f1-score on test data: 0.778\n",
      "          - tree depth: 7.000. f1-score on training data: 0.986 f1-score on test data: 0.833\n",
      "          - tree depth: 8.000. f1-score on training data: 0.986 f1-score on test data: 0.833\n",
      "          - tree depth: 9.000. f1-score on training data: 0.986 f1-score on test data: 0.833\n",
      "          - tree depth: 10.000. f1-score on training data: 0.986 f1-score on test data: 0.833\n",
      "          - tree depth: 11.000. f1-score on training data: 0.986 f1-score on test data: 0.833\n",
      "          - tree depth: 12.000. f1-score on training data: 0.986 f1-score on test data: 0.833\n",
      "          - tree depth: 13.000. f1-score on training data: 0.986 f1-score on test data: 0.833\n",
      "          - tree depth: 14.000. f1-score on training data: 0.986 f1-score on test data: 0.833\n",
      "    - Random forest\n",
      "          - 5trees. f1-score on training data: 0.929 f1-score on test data: 0.735\n",
      "          - 10trees. f1-score on training data: 0.957 f1-score on test data: 0.783\n",
      "          - 15trees. f1-score on training data: 0.986 f1-score on test data: 0.783\n",
      "          - 20trees. f1-score on training data: 0.986 f1-score on test data: 0.783\n",
      "          - 25trees. f1-score on training data: 0.986 f1-score on test data: 0.835\n",
      "          - 30trees. f1-score on training data: 0.986 f1-score on test data: 0.835\n",
      "          - 35trees. f1-score on training data: 0.986 f1-score on test data: 0.835\n",
      "          - 40trees. f1-score on training data: 0.986 f1-score on test data: 0.835\n",
      "          - 45trees. f1-score on training data: 0.986 f1-score on test data: 0.835\n",
      "          - 50trees. f1-score on training data: 0.986 f1-score on test data: 0.835\n",
      "          - 55trees. f1-score on training data: 0.986 f1-score on test data: 0.835\n",
      "          - 60trees. f1-score on training data: 0.986 f1-score on test data: 0.835\n",
      "          - 65trees. f1-score on training data: 0.986 f1-score on test data: 0.778\n",
      "          - 70trees. f1-score on training data: 0.986 f1-score on test data: 0.778\n",
      "          - 75trees. f1-score on training data: 0.986 f1-score on test data: 0.835\n",
      "          - 80trees. f1-score on training data: 0.986 f1-score on test data: 0.778\n",
      "          - 85trees. f1-score on training data: 0.986 f1-score on test data: 0.778\n",
      "          - 90trees. f1-score on training data: 0.986 f1-score on test data: 0.778\n",
      "          - 95trees. f1-score on training data: 0.986 f1-score on test data: 0.778\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. f1-score on training data: 0.986 f1-score on test data: 0.505\n",
      "          - hidden layer size[20, 20]. f1-score on training data: 0.986 f1-score on test data: 0.567\n"
     ]
    }
   ],
   "source": [
    "models(df_2g,drop_lst,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43e5725c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After undersampling data size is 88 ; Resampled dataset shape Counter({'MCI-AD': 44, 'MCI-MCI': 44})\n",
      "\n",
      "9 principle components are needed to explain 90% of the data\n",
      "\n",
      "- Using original dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.406\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.322\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.406\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.510\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.335\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.510\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.519\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.359\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.519\n",
      "       - C = 1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.481\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.526\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.481\n",
      "       - C = 10\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.480\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.480\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.480\n",
      "       - C = 100\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.480\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.480\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.480\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.469\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.480\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.469\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. average weighted f1-score of 10-cross validation:0.359\n",
      "          - tree depth: 2.000. average weighted f1-score of 10-cross validation:0.461\n",
      "          - tree depth: 3.000. average weighted f1-score of 10-cross validation:0.399\n",
      "          - tree depth: 4.000. average weighted f1-score of 10-cross validation:0.412\n",
      "          - tree depth: 5.000. average weighted f1-score of 10-cross validation:0.443\n",
      "          - tree depth: 6.000. average weighted f1-score of 10-cross validation:0.443\n",
      "          - tree depth: 7.000. average weighted f1-score of 10-cross validation:0.440\n",
      "          - tree depth: 8.000. average weighted f1-score of 10-cross validation:0.462\n",
      "          - tree depth: 9.000. average weighted f1-score of 10-cross validation:0.480\n",
      "          - tree depth: 10.000. average weighted f1-score of 10-cross validation:0.445\n",
      "          - tree depth: 11.000. average weighted f1-score of 10-cross validation:0.419\n",
      "          - tree depth: 12.000. average weighted f1-score of 10-cross validation:0.439\n",
      "          - tree depth: 13.000. average weighted f1-score of 10-cross validation:0.409\n",
      "          - tree depth: 14.000. average weighted f1-score of 10-cross validation:0.441\n",
      "    - Random forest\n",
      "          - 5trees. average weighted f1-score of 10-cross validation:0.527\n",
      "          - 10trees. average weighted f1-score of 10-cross validation:0.580\n",
      "          - 15trees. average weighted f1-score of 10-cross validation:0.508\n",
      "          - 20trees. average weighted f1-score of 10-cross validation:0.489\n",
      "          - 25trees. average weighted f1-score of 10-cross validation:0.456\n",
      "          - 30trees. average weighted f1-score of 10-cross validation:0.459\n",
      "          - 35trees. average weighted f1-score of 10-cross validation:0.460\n",
      "          - 40trees. average weighted f1-score of 10-cross validation:0.451\n",
      "          - 45trees. average weighted f1-score of 10-cross validation:0.472\n",
      "          - 50trees. average weighted f1-score of 10-cross validation:0.472\n",
      "          - 55trees. average weighted f1-score of 10-cross validation:0.429\n",
      "          - 60trees. average weighted f1-score of 10-cross validation:0.469\n",
      "          - 65trees. average weighted f1-score of 10-cross validation:0.444\n",
      "          - 70trees. average weighted f1-score of 10-cross validation:0.436\n",
      "          - 75trees. average weighted f1-score of 10-cross validation:0.411\n",
      "          - 80trees. average weighted f1-score of 10-cross validation:0.450\n",
      "          - 85trees. average weighted f1-score of 10-cross validation:0.432\n",
      "          - 90trees. average weighted f1-score of 10-cross validation:0.446\n",
      "          - 95trees. average weighted f1-score of 10-cross validation:0.423\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. average weighted f1-score of 10-cross validation:0.512\n",
      "          - hidden layer size[20, 20]. average weighted f1-score of 10-cross validation:0.451\n",
      "- Using scaled dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.360\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.322\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.360\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.526\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.298\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.526\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.516\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.263\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.516\n",
      "       - C = 1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.504\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.469\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.504\n",
      "       - C = 10\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.480\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.480\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.480\n",
      "       - C = 100\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.469\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.469\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.469\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.479\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.479\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.479\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. average weighted f1-score of 10-cross validation:0.359\n",
      "          - tree depth: 2.000. average weighted f1-score of 10-cross validation:0.461\n",
      "          - tree depth: 3.000. average weighted f1-score of 10-cross validation:0.399\n",
      "          - tree depth: 4.000. average weighted f1-score of 10-cross validation:0.412\n",
      "          - tree depth: 5.000. average weighted f1-score of 10-cross validation:0.443\n",
      "          - tree depth: 6.000. average weighted f1-score of 10-cross validation:0.443\n",
      "          - tree depth: 7.000. average weighted f1-score of 10-cross validation:0.440\n",
      "          - tree depth: 8.000. average weighted f1-score of 10-cross validation:0.462\n",
      "          - tree depth: 9.000. average weighted f1-score of 10-cross validation:0.480\n",
      "          - tree depth: 10.000. average weighted f1-score of 10-cross validation:0.445\n",
      "          - tree depth: 11.000. average weighted f1-score of 10-cross validation:0.419\n",
      "          - tree depth: 12.000. average weighted f1-score of 10-cross validation:0.439\n",
      "          - tree depth: 13.000. average weighted f1-score of 10-cross validation:0.409\n",
      "          - tree depth: 14.000. average weighted f1-score of 10-cross validation:0.441\n",
      "    - Random forest\n",
      "          - 5trees. average weighted f1-score of 10-cross validation:0.533\n",
      "          - 10trees. average weighted f1-score of 10-cross validation:0.577\n",
      "          - 15trees. average weighted f1-score of 10-cross validation:0.534\n",
      "          - 20trees. average weighted f1-score of 10-cross validation:0.502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          - 25trees. average weighted f1-score of 10-cross validation:0.469\n",
      "          - 30trees. average weighted f1-score of 10-cross validation:0.472\n",
      "          - 35trees. average weighted f1-score of 10-cross validation:0.496\n",
      "          - 40trees. average weighted f1-score of 10-cross validation:0.490\n",
      "          - 45trees. average weighted f1-score of 10-cross validation:0.489\n",
      "          - 50trees. average weighted f1-score of 10-cross validation:0.499\n",
      "          - 55trees. average weighted f1-score of 10-cross validation:0.449\n",
      "          - 60trees. average weighted f1-score of 10-cross validation:0.486\n",
      "          - 65trees. average weighted f1-score of 10-cross validation:0.471\n",
      "          - 70trees. average weighted f1-score of 10-cross validation:0.463\n",
      "          - 75trees. average weighted f1-score of 10-cross validation:0.438\n",
      "          - 80trees. average weighted f1-score of 10-cross validation:0.463\n",
      "          - 85trees. average weighted f1-score of 10-cross validation:0.448\n",
      "          - 90trees. average weighted f1-score of 10-cross validation:0.463\n",
      "          - 95trees. average weighted f1-score of 10-cross validation:0.464\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. average weighted f1-score of 10-cross validation:0.421\n",
      "          - hidden layer size[20, 20]. average weighted f1-score of 10-cross validation:0.467\n",
      "- Using 9 pca-components:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.358\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.310\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.358\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.559\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.335\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.559\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.539\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.270\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.539\n",
      "       - C = 1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.529\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.529\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.529\n",
      "       - C = 10\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.529\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.529\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.529\n",
      "       - C = 100\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.529\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.529\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.529\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.529\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.529\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.529\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. average weighted f1-score of 10-cross validation:0.407\n",
      "          - tree depth: 2.000. average weighted f1-score of 10-cross validation:0.409\n",
      "          - tree depth: 3.000. average weighted f1-score of 10-cross validation:0.393\n",
      "          - tree depth: 4.000. average weighted f1-score of 10-cross validation:0.503\n",
      "          - tree depth: 5.000. average weighted f1-score of 10-cross validation:0.471\n",
      "          - tree depth: 6.000. average weighted f1-score of 10-cross validation:0.449\n",
      "          - tree depth: 7.000. average weighted f1-score of 10-cross validation:0.462\n",
      "          - tree depth: 8.000. average weighted f1-score of 10-cross validation:0.465\n",
      "          - tree depth: 9.000. average weighted f1-score of 10-cross validation:0.468\n",
      "          - tree depth: 10.000. average weighted f1-score of 10-cross validation:0.438\n",
      "          - tree depth: 11.000. average weighted f1-score of 10-cross validation:0.438\n",
      "          - tree depth: 12.000. average weighted f1-score of 10-cross validation:0.452\n",
      "          - tree depth: 13.000. average weighted f1-score of 10-cross validation:0.452\n",
      "          - tree depth: 14.000. average weighted f1-score of 10-cross validation:0.452\n",
      "    - Random forest\n",
      "          - 5trees. average weighted f1-score of 10-cross validation:0.459\n",
      "          - 10trees. average weighted f1-score of 10-cross validation:0.517\n",
      "          - 15trees. average weighted f1-score of 10-cross validation:0.574\n",
      "          - 20trees. average weighted f1-score of 10-cross validation:0.508\n",
      "          - 25trees. average weighted f1-score of 10-cross validation:0.497\n",
      "          - 30trees. average weighted f1-score of 10-cross validation:0.520\n",
      "          - 35trees. average weighted f1-score of 10-cross validation:0.503\n",
      "          - 40trees. average weighted f1-score of 10-cross validation:0.518\n",
      "          - 45trees. average weighted f1-score of 10-cross validation:0.513\n",
      "          - 50trees. average weighted f1-score of 10-cross validation:0.534\n",
      "          - 55trees. average weighted f1-score of 10-cross validation:0.501\n",
      "          - 60trees. average weighted f1-score of 10-cross validation:0.511\n",
      "          - 65trees. average weighted f1-score of 10-cross validation:0.490\n",
      "          - 70trees. average weighted f1-score of 10-cross validation:0.501\n",
      "          - 75trees. average weighted f1-score of 10-cross validation:0.479\n",
      "          - 80trees. average weighted f1-score of 10-cross validation:0.479\n",
      "          - 85trees. average weighted f1-score of 10-cross validation:0.466\n",
      "          - 90trees. average weighted f1-score of 10-cross validation:0.466\n",
      "          - 95trees. average weighted f1-score of 10-cross validation:0.466\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. average weighted f1-score of 10-cross validation:0.490\n",
      "          - hidden layer size[20, 20]. average weighted f1-score of 10-cross validation:0.479\n"
     ]
    }
   ],
   "source": [
    "cv_models(df_2g,drop_lst,target,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e0322c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-89580f477b76>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#res = usampling_scale_data(df_2g,drop_lst,target)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5862\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtitle_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'10-fold crossvalidation of random forest with (30 trees)'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'res' is not defined"
     ]
    }
   ],
   "source": [
    "res = usampling_scale_data(df_2g,drop_lst,target)     \n",
    "X = res[0]\n",
    "y = res[3]\n",
    "#clf = RandomForestClassifier(n_estimators =30, random_state = 5862)\n",
    "title_label = '10-fold crossvalidation of random forest with (30 trees)'\n",
    "feature_importance(X,y,clf,10,title_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d37f91",
   "metadata": {},
   "source": [
    "## - 'AD-AD': 44, 'CN-CN': 44, 'MCI-AD': 44, 'MCI-MCI': 44\n",
    "\n",
    "-not good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03f26e77",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After undersampling data size is 176 ; Resampled dataset shape Counter({'AD-AD': 44, 'CN-CN': 44, 'MCI-AD': 44, 'MCI-MCI': 44})\n",
      "\n",
      "9 principle components are needed to explain 90% of the data\n",
      "\n",
      "Output dataframes sequence: X_train,X_test,X_train_scaled,X_test_scaled,X_train_pca,X_test_pca,y_train,y_test\n",
      "- Using original dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, Training set f1-score:0.445, Test set f1-score: 0.406\n",
      "          - saga_L1, Training set f1-score:0.409, Test set f1-score: 0.364\n",
      "          - newton-cg_L2, Training set f1-score:0.445, Test set f1-score: 0.406\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, Training set f1-score:0.465, Test set f1-score: 0.417\n",
      "          - saga_L1, Training set f1-score:0.418, Test set f1-score: 0.326\n",
      "          - newton-cg_L2, Training set f1-score:0.465, Test set f1-score: 0.417\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, Training set f1-score:0.499, Test set f1-score: 0.455\n",
      "          - saga_L1, Training set f1-score:0.434, Test set f1-score: 0.419\n",
      "          - newton-cg_L2, Training set f1-score:0.499, Test set f1-score: 0.455\n",
      "       - C = 1\n",
      "          - lbfgs_L2, Training set f1-score:0.475, Test set f1-score: 0.570\n",
      "          - saga_L1, Training set f1-score:0.473, Test set f1-score: 0.484\n",
      "          - newton-cg_L2, Training set f1-score:0.475, Test set f1-score: 0.570\n",
      "       - C = 10\n",
      "          - lbfgs_L2, Training set f1-score:0.475, Test set f1-score: 0.531\n",
      "          - saga_L1, Training set f1-score:0.475, Test set f1-score: 0.531\n",
      "          - newton-cg_L2, Training set f1-score:0.475, Test set f1-score: 0.531\n",
      "       - C = 100\n",
      "          - lbfgs_L2, Training set f1-score:0.469, Test set f1-score: 0.553\n",
      "          - saga_L1, Training set f1-score:0.469, Test set f1-score: 0.531\n",
      "          - newton-cg_L2, Training set f1-score:0.469, Test set f1-score: 0.553\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, Training set f1-score:0.469, Test set f1-score: 0.553\n",
      "          - saga_L1, Training set f1-score:0.469, Test set f1-score: 0.531\n",
      "          - newton-cg_L2, Training set f1-score:0.469, Test set f1-score: 0.553\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. f1-score on training data: 0.503 f1-score on test data: 0.406\n",
      "          - tree depth: 2.000. f1-score on training data: 0.509 f1-score on test data: 0.434\n",
      "          - tree depth: 3.000. f1-score on training data: 0.499 f1-score on test data: 0.377\n",
      "          - tree depth: 4.000. f1-score on training data: 0.574 f1-score on test data: 0.339\n",
      "          - tree depth: 5.000. f1-score on training data: 0.607 f1-score on test data: 0.304\n",
      "          - tree depth: 6.000. f1-score on training data: 0.666 f1-score on test data: 0.326\n",
      "          - tree depth: 7.000. f1-score on training data: 0.719 f1-score on test data: 0.292\n",
      "          - tree depth: 8.000. f1-score on training data: 0.791 f1-score on test data: 0.325\n",
      "          - tree depth: 9.000. f1-score on training data: 0.835 f1-score on test data: 0.362\n",
      "          - tree depth: 10.000. f1-score on training data: 0.865 f1-score on test data: 0.315\n",
      "          - tree depth: 11.000. f1-score on training data: 0.873 f1-score on test data: 0.295\n",
      "          - tree depth: 12.000. f1-score on training data: 0.888 f1-score on test data: 0.322\n",
      "          - tree depth: 13.000. f1-score on training data: 0.900 f1-score on test data: 0.381\n",
      "          - tree depth: 14.000. f1-score on training data: 0.908 f1-score on test data: 0.351\n",
      "    - Random forest\n",
      "          - 5trees. f1-score on training data: 0.864 f1-score on test data: 0.393\n",
      "          - 10trees. f1-score on training data: 0.900 f1-score on test data: 0.389\n",
      "          - 15trees. f1-score on training data: 0.892 f1-score on test data: 0.380\n",
      "          - 20trees. f1-score on training data: 0.906 f1-score on test data: 0.385\n",
      "          - 25trees. f1-score on training data: 0.907 f1-score on test data: 0.369\n",
      "          - 30trees. f1-score on training data: 0.907 f1-score on test data: 0.385\n",
      "          - 35trees. f1-score on training data: 0.906 f1-score on test data: 0.415\n",
      "          - 40trees. f1-score on training data: 0.907 f1-score on test data: 0.385\n",
      "          - 45trees. f1-score on training data: 0.906 f1-score on test data: 0.418\n",
      "          - 50trees. f1-score on training data: 0.907 f1-score on test data: 0.387\n",
      "          - 55trees. f1-score on training data: 0.907 f1-score on test data: 0.387\n",
      "          - 60trees. f1-score on training data: 0.907 f1-score on test data: 0.418\n",
      "          - 65trees. f1-score on training data: 0.907 f1-score on test data: 0.418\n",
      "          - 70trees. f1-score on training data: 0.906 f1-score on test data: 0.414\n",
      "          - 75trees. f1-score on training data: 0.907 f1-score on test data: 0.413\n",
      "          - 80trees. f1-score on training data: 0.906 f1-score on test data: 0.384\n",
      "          - 85trees. f1-score on training data: 0.906 f1-score on test data: 0.384\n",
      "          - 90trees. f1-score on training data: 0.906 f1-score on test data: 0.414\n",
      "          - 95trees. f1-score on training data: 0.906 f1-score on test data: 0.414\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. f1-score on training data: 0.907 f1-score on test data: 0.401\n",
      "          - hidden layer size[20, 20]. f1-score on training data: 0.907 f1-score on test data: 0.474\n",
      "- Using scaled dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, Training set f1-score:0.487, Test set f1-score: 0.424\n",
      "          - saga_L1, Training set f1-score:0.418, Test set f1-score: 0.326\n",
      "          - newton-cg_L2, Training set f1-score:0.487, Test set f1-score: 0.424\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, Training set f1-score:0.485, Test set f1-score: 0.472\n",
      "          - saga_L1, Training set f1-score:0.409, Test set f1-score: 0.364\n",
      "          - newton-cg_L2, Training set f1-score:0.485, Test set f1-score: 0.472\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, Training set f1-score:0.487, Test set f1-score: 0.507\n",
      "          - saga_L1, Training set f1-score:0.451, Test set f1-score: 0.583\n",
      "          - newton-cg_L2, Training set f1-score:0.487, Test set f1-score: 0.507\n",
      "       - C = 1\n",
      "          - lbfgs_L2, Training set f1-score:0.475, Test set f1-score: 0.571\n",
      "          - saga_L1, Training set f1-score:0.499, Test set f1-score: 0.507\n",
      "          - newton-cg_L2, Training set f1-score:0.475, Test set f1-score: 0.571\n",
      "       - C = 10\n",
      "          - lbfgs_L2, Training set f1-score:0.475, Test set f1-score: 0.531\n",
      "          - saga_L1, Training set f1-score:0.475, Test set f1-score: 0.531\n",
      "          - newton-cg_L2, Training set f1-score:0.475, Test set f1-score: 0.531\n",
      "       - C = 100\n",
      "          - lbfgs_L2, Training set f1-score:0.469, Test set f1-score: 0.553\n",
      "          - saga_L1, Training set f1-score:0.469, Test set f1-score: 0.553\n",
      "          - newton-cg_L2, Training set f1-score:0.469, Test set f1-score: 0.553\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, Training set f1-score:0.469, Test set f1-score: 0.553\n",
      "          - saga_L1, Training set f1-score:0.469, Test set f1-score: 0.553\n",
      "          - newton-cg_L2, Training set f1-score:0.469, Test set f1-score: 0.553\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. f1-score on training data: 0.503 f1-score on test data: 0.406\n",
      "          - tree depth: 2.000. f1-score on training data: 0.509 f1-score on test data: 0.434\n",
      "          - tree depth: 3.000. f1-score on training data: 0.499 f1-score on test data: 0.377\n",
      "          - tree depth: 4.000. f1-score on training data: 0.574 f1-score on test data: 0.339\n",
      "          - tree depth: 5.000. f1-score on training data: 0.607 f1-score on test data: 0.304\n",
      "          - tree depth: 6.000. f1-score on training data: 0.666 f1-score on test data: 0.326\n",
      "          - tree depth: 7.000. f1-score on training data: 0.719 f1-score on test data: 0.291\n",
      "          - tree depth: 8.000. f1-score on training data: 0.791 f1-score on test data: 0.348\n",
      "          - tree depth: 9.000. f1-score on training data: 0.835 f1-score on test data: 0.349\n",
      "          - tree depth: 10.000. f1-score on training data: 0.865 f1-score on test data: 0.301\n",
      "          - tree depth: 11.000. f1-score on training data: 0.873 f1-score on test data: 0.281\n",
      "          - tree depth: 12.000. f1-score on training data: 0.888 f1-score on test data: 0.309\n",
      "          - tree depth: 13.000. f1-score on training data: 0.900 f1-score on test data: 0.376\n",
      "          - tree depth: 14.000. f1-score on training data: 0.908 f1-score on test data: 0.344\n",
      "    - Random forest\n",
      "          - 5trees. f1-score on training data: 0.864 f1-score on test data: 0.371\n",
      "          - 10trees. f1-score on training data: 0.900 f1-score on test data: 0.389\n",
      "          - 15trees. f1-score on training data: 0.892 f1-score on test data: 0.354\n",
      "          - 20trees. f1-score on training data: 0.906 f1-score on test data: 0.354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          - 25trees. f1-score on training data: 0.907 f1-score on test data: 0.335\n",
      "          - 30trees. f1-score on training data: 0.907 f1-score on test data: 0.326\n",
      "          - 35trees. f1-score on training data: 0.906 f1-score on test data: 0.385\n",
      "          - 40trees. f1-score on training data: 0.907 f1-score on test data: 0.385\n",
      "          - 45trees. f1-score on training data: 0.906 f1-score on test data: 0.385\n",
      "          - 50trees. f1-score on training data: 0.907 f1-score on test data: 0.357\n",
      "          - 55trees. f1-score on training data: 0.907 f1-score on test data: 0.355\n",
      "          - 60trees. f1-score on training data: 0.907 f1-score on test data: 0.389\n",
      "          - 65trees. f1-score on training data: 0.906 f1-score on test data: 0.388\n",
      "          - 70trees. f1-score on training data: 0.906 f1-score on test data: 0.386\n",
      "          - 75trees. f1-score on training data: 0.906 f1-score on test data: 0.384\n",
      "          - 80trees. f1-score on training data: 0.906 f1-score on test data: 0.384\n",
      "          - 85trees. f1-score on training data: 0.906 f1-score on test data: 0.384\n",
      "          - 90trees. f1-score on training data: 0.906 f1-score on test data: 0.414\n",
      "          - 95trees. f1-score on training data: 0.906 f1-score on test data: 0.414\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. f1-score on training data: 0.907 f1-score on test data: 0.520\n",
      "          - hidden layer size[20, 20]. f1-score on training data: 0.907 f1-score on test data: 0.439\n",
      "- Using 9 pca-components:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, Training set f1-score:0.479, Test set f1-score: 0.424\n",
      "          - saga_L1, Training set f1-score:0.382, Test set f1-score: 0.468\n",
      "          - newton-cg_L2, Training set f1-score:0.479, Test set f1-score: 0.424\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, Training set f1-score:0.473, Test set f1-score: 0.433\n",
      "          - saga_L1, Training set f1-score:0.418, Test set f1-score: 0.326\n",
      "          - newton-cg_L2, Training set f1-score:0.473, Test set f1-score: 0.433\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, Training set f1-score:0.480, Test set f1-score: 0.485\n",
      "          - saga_L1, Training set f1-score:0.489, Test set f1-score: 0.462\n",
      "          - newton-cg_L2, Training set f1-score:0.480, Test set f1-score: 0.485\n",
      "       - C = 1\n",
      "          - lbfgs_L2, Training set f1-score:0.473, Test set f1-score: 0.421\n",
      "          - saga_L1, Training set f1-score:0.479, Test set f1-score: 0.392\n",
      "          - newton-cg_L2, Training set f1-score:0.473, Test set f1-score: 0.421\n",
      "       - C = 10\n",
      "          - lbfgs_L2, Training set f1-score:0.481, Test set f1-score: 0.420\n",
      "          - saga_L1, Training set f1-score:0.475, Test set f1-score: 0.420\n",
      "          - newton-cg_L2, Training set f1-score:0.481, Test set f1-score: 0.420\n",
      "       - C = 100\n",
      "          - lbfgs_L2, Training set f1-score:0.481, Test set f1-score: 0.420\n",
      "          - saga_L1, Training set f1-score:0.481, Test set f1-score: 0.420\n",
      "          - newton-cg_L2, Training set f1-score:0.481, Test set f1-score: 0.420\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, Training set f1-score:0.481, Test set f1-score: 0.420\n",
      "          - saga_L1, Training set f1-score:0.481, Test set f1-score: 0.420\n",
      "          - newton-cg_L2, Training set f1-score:0.481, Test set f1-score: 0.420\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. f1-score on training data: 0.484 f1-score on test data: 0.373\n",
      "          - tree depth: 2.000. f1-score on training data: 0.502 f1-score on test data: 0.471\n",
      "          - tree depth: 3.000. f1-score on training data: 0.547 f1-score on test data: 0.455\n",
      "          - tree depth: 4.000. f1-score on training data: 0.609 f1-score on test data: 0.478\n",
      "          - tree depth: 5.000. f1-score on training data: 0.666 f1-score on test data: 0.317\n",
      "          - tree depth: 6.000. f1-score on training data: 0.735 f1-score on test data: 0.428\n",
      "          - tree depth: 7.000. f1-score on training data: 0.787 f1-score on test data: 0.386\n",
      "          - tree depth: 8.000. f1-score on training data: 0.837 f1-score on test data: 0.452\n",
      "          - tree depth: 9.000. f1-score on training data: 0.867 f1-score on test data: 0.382\n",
      "          - tree depth: 10.000. f1-score on training data: 0.880 f1-score on test data: 0.469\n",
      "          - tree depth: 11.000. f1-score on training data: 0.894 f1-score on test data: 0.467\n",
      "          - tree depth: 12.000. f1-score on training data: 0.901 f1-score on test data: 0.497\n",
      "          - tree depth: 13.000. f1-score on training data: 0.908 f1-score on test data: 0.467\n",
      "          - tree depth: 14.000. f1-score on training data: 0.908 f1-score on test data: 0.467\n",
      "    - Random forest\n",
      "          - 5trees. f1-score on training data: 0.857 f1-score on test data: 0.364\n",
      "          - 10trees. f1-score on training data: 0.886 f1-score on test data: 0.389\n",
      "          - 15trees. f1-score on training data: 0.900 f1-score on test data: 0.363\n",
      "          - 20trees. f1-score on training data: 0.906 f1-score on test data: 0.298\n",
      "          - 25trees. f1-score on training data: 0.907 f1-score on test data: 0.386\n",
      "          - 30trees. f1-score on training data: 0.907 f1-score on test data: 0.402\n",
      "          - 35trees. f1-score on training data: 0.906 f1-score on test data: 0.441\n",
      "          - 40trees. f1-score on training data: 0.906 f1-score on test data: 0.441\n",
      "          - 45trees. f1-score on training data: 0.906 f1-score on test data: 0.468\n",
      "          - 50trees. f1-score on training data: 0.907 f1-score on test data: 0.384\n",
      "          - 55trees. f1-score on training data: 0.906 f1-score on test data: 0.438\n",
      "          - 60trees. f1-score on training data: 0.906 f1-score on test data: 0.437\n",
      "          - 65trees. f1-score on training data: 0.906 f1-score on test data: 0.414\n",
      "          - 70trees. f1-score on training data: 0.906 f1-score on test data: 0.358\n",
      "          - 75trees. f1-score on training data: 0.906 f1-score on test data: 0.362\n",
      "          - 80trees. f1-score on training data: 0.906 f1-score on test data: 0.362\n",
      "          - 85trees. f1-score on training data: 0.906 f1-score on test data: 0.385\n",
      "          - 90trees. f1-score on training data: 0.906 f1-score on test data: 0.385\n",
      "          - 95trees. f1-score on training data: 0.906 f1-score on test data: 0.385\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. f1-score on training data: 0.907 f1-score on test data: 0.423\n",
      "          - hidden layer size[20, 20]. f1-score on training data: 0.907 f1-score on test data: 0.359\n"
     ]
    }
   ],
   "source": [
    "models(df_4g,drop_lst,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2de15359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After undersampling data size is 176 ; Resampled dataset shape Counter({'AD-AD': 44, 'CN-CN': 44, 'MCI-AD': 44, 'MCI-MCI': 44})\n",
      "\n",
      "9 principle components are needed to explain 90% of the data\n",
      "\n",
      "- Using original dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.262\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.105\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.262\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.340\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.097\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.340\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.388\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.238\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.388\n",
      "       - C = 1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.352\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.361\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.352\n",
      "       - C = 10\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.321\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.321\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.321\n",
      "       - C = 100\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.321\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.321\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.321\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.328\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.321\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.328\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. average weighted f1-score of 10-cross validation:0.217\n",
      "          - tree depth: 2.000. average weighted f1-score of 10-cross validation:0.237\n",
      "          - tree depth: 3.000. average weighted f1-score of 10-cross validation:0.337\n",
      "          - tree depth: 4.000. average weighted f1-score of 10-cross validation:0.365\n",
      "          - tree depth: 5.000. average weighted f1-score of 10-cross validation:0.376\n",
      "          - tree depth: 6.000. average weighted f1-score of 10-cross validation:0.384\n",
      "          - tree depth: 7.000. average weighted f1-score of 10-cross validation:0.368\n",
      "          - tree depth: 8.000. average weighted f1-score of 10-cross validation:0.345\n",
      "          - tree depth: 9.000. average weighted f1-score of 10-cross validation:0.306\n",
      "          - tree depth: 10.000. average weighted f1-score of 10-cross validation:0.312\n",
      "          - tree depth: 11.000. average weighted f1-score of 10-cross validation:0.293\n",
      "          - tree depth: 12.000. average weighted f1-score of 10-cross validation:0.323\n",
      "          - tree depth: 13.000. average weighted f1-score of 10-cross validation:0.313\n",
      "          - tree depth: 14.000. average weighted f1-score of 10-cross validation:0.330\n",
      "    - Random forest\n",
      "          - 5trees. average weighted f1-score of 10-cross validation:0.264\n",
      "          - 10trees. average weighted f1-score of 10-cross validation:0.302\n",
      "          - 15trees. average weighted f1-score of 10-cross validation:0.314\n",
      "          - 20trees. average weighted f1-score of 10-cross validation:0.313\n",
      "          - 25trees. average weighted f1-score of 10-cross validation:0.326\n",
      "          - 30trees. average weighted f1-score of 10-cross validation:0.318\n",
      "          - 35trees. average weighted f1-score of 10-cross validation:0.298\n",
      "          - 40trees. average weighted f1-score of 10-cross validation:0.298\n",
      "          - 45trees. average weighted f1-score of 10-cross validation:0.303\n",
      "          - 50trees. average weighted f1-score of 10-cross validation:0.288\n",
      "          - 55trees. average weighted f1-score of 10-cross validation:0.299\n",
      "          - 60trees. average weighted f1-score of 10-cross validation:0.304\n",
      "          - 65trees. average weighted f1-score of 10-cross validation:0.309\n",
      "          - 70trees. average weighted f1-score of 10-cross validation:0.302\n",
      "          - 75trees. average weighted f1-score of 10-cross validation:0.297\n",
      "          - 80trees. average weighted f1-score of 10-cross validation:0.293\n",
      "          - 85trees. average weighted f1-score of 10-cross validation:0.287\n",
      "          - 90trees. average weighted f1-score of 10-cross validation:0.290\n",
      "          - 95trees. average weighted f1-score of 10-cross validation:0.288\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. average weighted f1-score of 10-cross validation:0.265\n",
      "          - hidden layer size[20, 20]. average weighted f1-score of 10-cross validation:0.308\n",
      "- Using scaled dataset:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.353\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.096\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.353\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.317\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.092\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.317\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.337\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.332\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.337\n",
      "       - C = 1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.336\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.353\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.336\n",
      "       - C = 10\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.311\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.317\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.311\n",
      "       - C = 100\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.322\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.322\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.322\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.328\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.328\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.328\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. average weighted f1-score of 10-cross validation:0.217\n",
      "          - tree depth: 2.000. average weighted f1-score of 10-cross validation:0.237\n",
      "          - tree depth: 3.000. average weighted f1-score of 10-cross validation:0.337\n",
      "          - tree depth: 4.000. average weighted f1-score of 10-cross validation:0.365\n",
      "          - tree depth: 5.000. average weighted f1-score of 10-cross validation:0.376\n",
      "          - tree depth: 6.000. average weighted f1-score of 10-cross validation:0.378\n",
      "          - tree depth: 7.000. average weighted f1-score of 10-cross validation:0.368\n",
      "          - tree depth: 8.000. average weighted f1-score of 10-cross validation:0.345\n",
      "          - tree depth: 9.000. average weighted f1-score of 10-cross validation:0.306\n",
      "          - tree depth: 10.000. average weighted f1-score of 10-cross validation:0.312\n",
      "          - tree depth: 11.000. average weighted f1-score of 10-cross validation:0.285\n",
      "          - tree depth: 12.000. average weighted f1-score of 10-cross validation:0.323\n",
      "          - tree depth: 13.000. average weighted f1-score of 10-cross validation:0.313\n",
      "          - tree depth: 14.000. average weighted f1-score of 10-cross validation:0.335\n",
      "    - Random forest\n",
      "          - 5trees. average weighted f1-score of 10-cross validation:0.267\n",
      "          - 10trees. average weighted f1-score of 10-cross validation:0.302\n",
      "          - 15trees. average weighted f1-score of 10-cross validation:0.314\n",
      "          - 20trees. average weighted f1-score of 10-cross validation:0.322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          - 25trees. average weighted f1-score of 10-cross validation:0.321\n",
      "          - 30trees. average weighted f1-score of 10-cross validation:0.313\n",
      "          - 35trees. average weighted f1-score of 10-cross validation:0.308\n",
      "          - 40trees. average weighted f1-score of 10-cross validation:0.293\n",
      "          - 45trees. average weighted f1-score of 10-cross validation:0.293\n",
      "          - 50trees. average weighted f1-score of 10-cross validation:0.288\n",
      "          - 55trees. average weighted f1-score of 10-cross validation:0.299\n",
      "          - 60trees. average weighted f1-score of 10-cross validation:0.304\n",
      "          - 65trees. average weighted f1-score of 10-cross validation:0.309\n",
      "          - 70trees. average weighted f1-score of 10-cross validation:0.302\n",
      "          - 75trees. average weighted f1-score of 10-cross validation:0.297\n",
      "          - 80trees. average weighted f1-score of 10-cross validation:0.293\n",
      "          - 85trees. average weighted f1-score of 10-cross validation:0.279\n",
      "          - 90trees. average weighted f1-score of 10-cross validation:0.276\n",
      "          - 95trees. average weighted f1-score of 10-cross validation:0.291\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. average weighted f1-score of 10-cross validation:0.366\n",
      "          - hidden layer size[20, 20]. average weighted f1-score of 10-cross validation:0.287\n",
      "- Using 9 pca-components:\n",
      "    - Logistic regression\n",
      "       - C = 0.001\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.336\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.096\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.336\n",
      "       - C = 0.01\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.329\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.096\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.329\n",
      "       - C = 0.1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.312\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.346\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.312\n",
      "       - C = 1\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.335\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.329\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.335\n",
      "       - C = 10\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.333\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.335\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.333\n",
      "       - C = 100\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.338\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.338\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.338\n",
      "       - C = 1000\n",
      "          - lbfgs_L2, average weighted f1-score of 10-cross validation:0.338\n",
      "          - saga_L1, average weighted f1-score of 10-cross validation:0.338\n",
      "          - newton-cg_L2, average weighted f1-score of 10-cross validation:0.338\n",
      "    - Decision tree\n",
      "          - tree depth: 1.000. average weighted f1-score of 10-cross validation:0.182\n",
      "          - tree depth: 2.000. average weighted f1-score of 10-cross validation:0.184\n",
      "          - tree depth: 3.000. average weighted f1-score of 10-cross validation:0.299\n",
      "          - tree depth: 4.000. average weighted f1-score of 10-cross validation:0.292\n",
      "          - tree depth: 5.000. average weighted f1-score of 10-cross validation:0.273\n",
      "          - tree depth: 6.000. average weighted f1-score of 10-cross validation:0.302\n",
      "          - tree depth: 7.000. average weighted f1-score of 10-cross validation:0.297\n",
      "          - tree depth: 8.000. average weighted f1-score of 10-cross validation:0.279\n",
      "          - tree depth: 9.000. average weighted f1-score of 10-cross validation:0.321\n",
      "          - tree depth: 10.000. average weighted f1-score of 10-cross validation:0.318\n",
      "          - tree depth: 11.000. average weighted f1-score of 10-cross validation:0.316\n",
      "          - tree depth: 12.000. average weighted f1-score of 10-cross validation:0.319\n",
      "          - tree depth: 13.000. average weighted f1-score of 10-cross validation:0.309\n",
      "          - tree depth: 14.000. average weighted f1-score of 10-cross validation:0.317\n",
      "    - Random forest\n",
      "          - 5trees. average weighted f1-score of 10-cross validation:0.294\n",
      "          - 10trees. average weighted f1-score of 10-cross validation:0.299\n",
      "          - 15trees. average weighted f1-score of 10-cross validation:0.343\n",
      "          - 20trees. average weighted f1-score of 10-cross validation:0.352\n",
      "          - 25trees. average weighted f1-score of 10-cross validation:0.354\n",
      "          - 30trees. average weighted f1-score of 10-cross validation:0.320\n",
      "          - 35trees. average weighted f1-score of 10-cross validation:0.319\n",
      "          - 40trees. average weighted f1-score of 10-cross validation:0.313\n",
      "          - 45trees. average weighted f1-score of 10-cross validation:0.317\n",
      "          - 50trees. average weighted f1-score of 10-cross validation:0.330\n",
      "          - 55trees. average weighted f1-score of 10-cross validation:0.329\n",
      "          - 60trees. average weighted f1-score of 10-cross validation:0.333\n",
      "          - 65trees. average weighted f1-score of 10-cross validation:0.321\n",
      "          - 70trees. average weighted f1-score of 10-cross validation:0.331\n",
      "          - 75trees. average weighted f1-score of 10-cross validation:0.334\n",
      "          - 80trees. average weighted f1-score of 10-cross validation:0.328\n",
      "          - 85trees. average weighted f1-score of 10-cross validation:0.330\n",
      "          - 90trees. average weighted f1-score of 10-cross validation:0.345\n",
      "          - 95trees. average weighted f1-score of 10-cross validation:0.329\n",
      "    - MLP\n",
      "          - hidden layer size[50, 50]. average weighted f1-score of 10-cross validation:0.341\n",
      "          - hidden layer size[20, 20]. average weighted f1-score of 10-cross validation:0.323\n"
     ]
    }
   ],
   "source": [
    "cv_models(df_4g,drop_lst,target,k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
